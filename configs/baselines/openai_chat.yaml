hydra:
  job:
    name: ${backbone.name}_${backbone.model_name}
  run:
    dir: /home/tigina/bug-localization/output/${hydra:job.name}
  job_logging:
    root:
      handlers: [console, file]
backbone:
  _target_: src.baselines.backbones.chat.openai_chat_backbone.OpenAIChatBackbone
  name: openai_chat
  model_name: gpt-3.5-turbo-1106
  api_key: null
  parameters:
    seed: 76097149
    temperature: 0
  prompt:
    _target_: src.baselines.backbones.chat.prompts.chat_file_list_prompt.FileListPrompt
data_source:
  _target_: src.baselines.data_sources.hf_data_source.HFDataSource
  repos_dir:  /mnt/data/shared-data/lca/repos_updated
  cache_dir: null
  hub_name: tiginamaria/bug-localization
  configs:
    - py
    - java
    - kt
  split: test

