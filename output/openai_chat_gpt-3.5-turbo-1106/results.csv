id,text_id,repo_owner,repo_name,issue_url,pull_url,comment_url,links_count,link_keyword,issue_title,issue_body,base_sha,head_sha,diff_url,diff,changed_files,changed_files_exts,changed_files_count,java_changed_files_count,kt_changed_files_count,py_changed_files_count,code_changed_files_count,repo_symbols_count,repo_tokens_count,repo_lines_count,repo_files_without_tests_count,changed_symbols_count,changed_tokens_count,changed_lines_count,changed_files_without_tests_count,issue_symbols_count,issue_words_count,issue_tokens_count,issue_lines_count,issue_links_count,issue_code_blocks_count,pull_create_at,stars,language,languages,license,all_generated_files,final_files,raw_completions,batches_count,time_ms
8543,thealgorithms/python/295/289,thealgorithms,python,https://github.com/TheAlgorithms/Python/issues/289,https://github.com/TheAlgorithms/Python/pull/295,https://github.com/TheAlgorithms/Python/pull/295,1,fixes,ProjectEuler -- Problem 1 -- solv2.py -- Error,"For the Input ```1000``` I get ```233366.4```. The correct answer should be ```233168``` 
See [file](https://github.com/TheAlgorithms/Python/blob/master/Project%20Euler/Problem%2001/sol2.py)",dbfc220264e514cbc94320b6e4769acfaea85fad,356218254263f45536bd1b053f8cb9e30450087a,https://github.com/thealgorithms/python/compare/dbfc220264e514cbc94320b6e4769acfaea85fad...356218254263f45536bd1b053f8cb9e30450087a,"diff --git a/Project Euler/Problem 01/sol2.py b/Project Euler/Problem 01/sol2.py
index d330387e..2b7760e0 100644
--- a/Project Euler/Problem 01/sol2.py	
+++ b/Project Euler/Problem 01/sol2.py	
@@ -11,10 +11,10 @@ except NameError:
     raw_input = input  # Python 3
 n = int(raw_input().strip())
 sum = 0
-terms = (n-1)/3
-sum+= ((terms)*(6+(terms-1)*3))/2 #sum of an A.P.
-terms = (n-1)/5
-sum+= ((terms)*(10+(terms-1)*5))/2
-terms = (n-1)/15
-sum-= ((terms)*(30+(terms-1)*15))/2
+terms = (n-1)//3
+sum+= ((terms)*(6+(terms-1)*3))//2 #sum of an A.P.
+terms = (n-1)//5
+sum+= ((terms)*(10+(terms-1)*5))//2
+terms = (n-1)//15
+sum-= ((terms)*(30+(terms-1)*15))//2
 print(sum)",['Project Euler/Problem 01/sol2.py'],{'.py': 1},1,0,0,1,1,341307,91783,12235,195,357,159,12,1,191,15,57,2,1,3,2018-04-16 13:59:32,162825,Python,"{'Python': 2826228, 'Dockerfile': 406}",MIT License,['Project Euler/Problem 01/sol2.py'],['Project Euler/Problem 01/sol2.py'],"['```json\n{\n  ""files"": [\n    ""Project Euler/Problem 01/sol2.py""\n  ]\n}\n```']",1,1321.5458393096924
6859,keras-team/keras/15943/15942,keras-team,keras,https://github.com/keras-team/keras/issues/15942,https://github.com/keras-team/keras/pull/15943,https://github.com/keras-team/keras/pull/15943,1,closes,tf.keras.layers.Conv2D seems to accept 0 as the value of filters by mistake.,"**System information**.
- Have I written custom code (as opposed to using a stock example script provided in Keras): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): 2.7.0
- Python version: 3.8

Please refer to tensorflow/python/keras/layers/convolutional.py, lines 139-141:
```python
 if filters is not None and filters < 0:
      raise ValueError(f'Received a negative value for `filters`.'
                       f'Was expecting a positive value, got {filters}.')
```
The error message says that the filters expects a positive value. It seems that the validation code  should be ""filters <= 0"".",36d5e2fb3f30805b848b81273a02a60b5bbcffeb,ea7bfbd2c0e33ddf96b5b2d2d7723dc1e40b1b51,https://github.com/keras-team/keras/compare/36d5e2fb3f30805b848b81273a02a60b5bbcffeb...ea7bfbd2c0e33ddf96b5b2d2d7723dc1e40b1b51,"diff --git a/keras/layers/convolutional/base_conv.py b/keras/layers/convolutional/base_conv.py
index bcab3847d2..1782306415 100644
--- a/keras/layers/convolutional/base_conv.py
+++ b/keras/layers/convolutional/base_conv.py
@@ -118,9 +118,10 @@ class Conv(Layer):
 
     if isinstance(filters, float):
       filters = int(filters)
-    if filters is not None and filters < 0:
-      raise ValueError(f'Received a negative value for `filters`.'
-                       f'Was expecting a positive value. Received {filters}.')
+    if filters is not None and filters <= 0:
+      raise ValueError('Invalid value for argument `filters`. '
+                       'Expected a strictly positive value. '
+                       f'Received filters={filters}.')
     self.filters = filters
     self.groups = groups or 1
     self.kernel_size = conv_utils.normalize_tuple(",['keras/layers/convolutional/base_conv.py'],{'.py': 1},1,0,0,1,1,8976850,2163592,235173,553,422,82,7,1,681,96,166,13,0,1,2022-01-24 05:17:20,58976,Python,"{'Python': 11774453, 'Starlark': 290645, 'Shell': 12478, 'Dockerfile': 297}",Apache License 2.0,"['keras/layers/convolutional/conv2d_transpose.py', 'keras/layers/convolutional/conv_test.py', 'keras/layers/convolutional/conv2d.py']","['keras/layers/convolutional/conv2d_transpose.py', 'keras/layers/convolutional/conv_test.py', 'keras/layers/convolutional/conv2d.py']","['```json\n{\n  ""files"": [\n    ""keras/layers/convolutional/conv2d.py"",\n    ""keras/layers/convolutional/conv2d_transpose.py"",\n    ""keras/layers/convolutional/conv_test.py""\n  ]\n}\n```']",1,1309.1537952423096
8732,serverless/serverless/5500/5499,serverless,serverless,https://github.com/serverless/serverless/issues/5499,https://github.com/serverless/serverless/pull/5500,https://github.com/serverless/serverless/pull/5500,1,fixes,After upgrade to 1.33.1 Getting error on local invoke,"Upgraded to 1.33.1. 

When I issue this command: `serverless invoke local -f Function_Name -p event.json`

Getting this error:

```
starting...

Traceback (most recent call last):
  File ""/usr/local/lib/node_modules/serverless/lib/plugins/aws/invokeLocal/invoke.py"", line 77, in <module>

    tty = subprocess.run('tty', stdout=subprocess.PIPE, stderr=subprocess.PIPE)
AttributeError: 'module' object has no attribute 'run'
```

Using python 2.7",4bcd16336c4188bfc30b88b3877d7fcbd23253d9,dd43b852bc5c59de806cbf446616221abea320fd,https://github.com/serverless/serverless/compare/4bcd16336c4188bfc30b88b3877d7fcbd23253d9...dd43b852bc5c59de806cbf446616221abea320fd,"diff --git a/lib/plugins/aws/invokeLocal/invoke.py b/lib/plugins/aws/invokeLocal/invoke.py
index e0eea5bc0..3884cd05a 100755
--- a/lib/plugins/aws/invokeLocal/invoke.py
+++ b/lib/plugins/aws/invokeLocal/invoke.py
@@ -74,8 +74,11 @@ if __name__ == '__main__':
 
     input = json.load(sys.stdin)
     if sys.platform != 'win32':
-        tty = subprocess.run('tty', stdout=subprocess.PIPE, stderr=subprocess.PIPE)
-        if tty.returncode == 0:
+        try:
+            subprocess.check_call('tty', stdout=subprocess.PIPE, stderr=subprocess.PIPE)
+        except (OSError, subprocess.CalledProcessError):
+            pass
+        else:
             sys.stdin = open('/dev/tty')
 
     context = FakeLambdaContext(**input.get('context', {}))",['lib/plugins/aws/invokeLocal/invoke.py'],{'.py': 1},1,0,0,1,1,4714,1125,194,10,312,61,7,1,461,47,114,17,0,1,2018-11-16 20:39:05,44971,JavaScript,"{'JavaScript': 3650650, 'Java': 42813, 'Shell': 4184, 'Python': 2693, 'Ruby': 1936, 'PowerShell': 455, 'Dockerfile': 354, 'TypeScript': 184}",MIT License,"['lib/plugins/aws/invokeLocal/invoke.py', 'lib/plugins/aws/invokeLocal/fixture/handler.py']","['lib/plugins/aws/invokeLocal/invoke.py', 'lib/plugins/aws/invokeLocal/fixture/handler.py']","['```json\n{\n  ""files"": [\n    ""lib/plugins/aws/invokeLocal/invoke.py"",\n    ""lib/plugins/aws/invokeLocal/fixture/handler.py""\n  ]\n}\n```']",1,735.1126670837402
9266,textualize/rich/2212/2197,textualize,rich,https://github.com/Textualize/rich/issues/2197,https://github.com/Textualize/rich/pull/2212,https://github.com/Textualize/rich/pull/2212,1,fixes,[BUG] Importing rich fails with `FileNotFoundError` if current working directory does not exist,"**Describe the bug**

See https://github.com/pypa/pip/issues/11036#issuecomment-1100913072 for the original report and reproducer.

Broadly, importing rich fails with a `FileNotFoundError` since it tries to lookup cwd unconditionally, but it is possible to cwd to not exist.

```sh
❯ mkdir y
❯ cd y
❯ rm -rf ../y
❯ python -c ""import rich""
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/tmp/rich-cwd-issue/.venv/lib/python3.9/site-packages/rich/__init__.py"", line 16, in <module>
    _IMPORT_CWD = os.path.abspath(os.getcwd())
FileNotFoundError: [Errno 2] No such file or directory
```

**Platform**
<details>
<summary>Click to expand</summary>

What platform (Win/Linux/Mac) are you running on? What terminal software are you using?

This is not relevant, but MacOS and VSCode's integrated terminal. :)

```
❯ python -m rich.diagnose
╭───────────────────────── <class 'rich.console.Console'> ─────────────────────────╮
│ A high level console interface.                                                  │
│                                                                                  │
│ ╭──────────────────────────────────────────────────────────────────────────────╮ │
│ │ <console width=180 ColorSystem.TRUECOLOR>                                    │ │
│ ╰──────────────────────────────────────────────────────────────────────────────╯ │
│                                                                                  │
│     color_system = 'truecolor'                                                   │
│         encoding = 'utf-8'                                                       │
│             file = <_io.TextIOWrapper name='<stdout>' mode='w' encoding='utf-8'> │
│           height = 26                                                            │
│    is_alt_screen = False                                                         │
│ is_dumb_terminal = False                                                         │
│   is_interactive = True                                                          │
│       is_jupyter = False                                                         │
│      is_terminal = True                                                          │
│   legacy_windows = False                                                         │
│         no_color = False                                                         │
│          options = ConsoleOptions(                                               │
│                        size=ConsoleDimensions(width=180, height=26),             │
│                        legacy_windows=False,                                     │
│                        min_width=1,                                              │
│                        max_width=180,                                            │
│                        is_terminal=True,                                         │
│                        encoding='utf-8',                                         │
│                        max_height=26,                                            │
│                        justify=None,                                             │
│                        overflow=None,                                            │
│                        no_wrap=False,                                            │
│                        highlight=None,                                           │
│                        markup=None,                                              │
│                        height=None                                               │
│                    )                                                             │
│            quiet = False                                                         │
│           record = False                                                         │
│         safe_box = True                                                          │
│             size = ConsoleDimensions(width=180, height=26)                       │
│        soft_wrap = False                                                         │
│           stderr = False                                                         │
│            style = None                                                          │
│         tab_size = 8                                                             │
│            width = 180                                                           │
╰──────────────────────────────────────────────────────────────────────────────────╯
╭─── <class 'rich._windows.WindowsConsoleFeatures'> ────╮
│ Windows features available.                           │
│                                                       │
│ ╭───────────────────────────────────────────────────╮ │
│ │ WindowsConsoleFeatures(vt=False, truecolor=False) │ │
│ ╰───────────────────────────────────────────────────╯ │
│                                                       │
│ truecolor = False                                     │
│        vt = False                                     │
╰───────────────────────────────────────────────────────╯
╭────── Environment Variables ───────╮
│ {                                  │
│     'TERM': 'xterm-256color',      │
│     'COLORTERM': 'truecolor',      │
│     'CLICOLOR': '1',               │
│     'NO_COLOR': None,              │
│     'TERM_PROGRAM': 'vscode',      │
│     'COLUMNS': None,               │
│     'LINES': None,                 │
│     'JPY_PARENT_PID': None,        │
│     'VSCODE_VERBOSE_LOGGING': None │
│ }                                  │
╰────────────────────────────────────╯
platform=""Darwin""
❯ pip freeze | grep rich       
rich==12.2.0
```

</details>
",0ed9309a0e298ed91b21498caa021a37cac15591,5100a2be526a3ef517cd25676b055bf6c06f12b9,https://github.com/textualize/rich/compare/0ed9309a0e298ed91b21498caa021a37cac15591...5100a2be526a3ef517cd25676b055bf6c06f12b9,"diff --git a/rich/__init__.py b/rich/__init__.py
index 853d792a..07bc1a19 100644
--- a/rich/__init__.py
+++ b/rich/__init__.py
@@ -13,7 +13,11 @@ if TYPE_CHECKING:
 # Global console used by alternative print
 _console: Optional[""Console""] = None
 
-_IMPORT_CWD = os.path.abspath(os.getcwd())
+try:
+    _IMPORT_CWD = os.path.abspath(os.getcwd())
+except FileNotFoundError:
+    # Can happen if the cwd has been deleted
+    _IMPORT_CWD = """"
 
 
 def get_console() -> ""Console"":",['rich/__init__.py'],{'.py': 1},1,0,0,1,1,919269,243351,27637,122,192,45,6,1,5791,387,991,101,1,2,2022-04-22 08:53:12,44169,Python,"{'Python': 1370173, 'Batchfile': 799, 'Makefile': 307}",MIT License,['rich/__init__.py'],['rich/__init__.py'],"['```json\n{\n  ""files"": [\n    ""rich/__init__.py""\n  ]\n}\n```']",1,870.5804347991943
7516,mitmproxy/mitmproxy/4298/3994,mitmproxy,mitmproxy,https://github.com/mitmproxy/mitmproxy/issues/3994,https://github.com/mitmproxy/mitmproxy/pull/4298,https://github.com/mitmproxy/mitmproxy/pull/4298,1,fixes,SSLKEYLOGFILE is not containing TLSv1.3 secrets,"#### When using mitmproxy with the SSLKEYLOGFILE environment variable TLSv1.3 keys are not exported or correctly labeled. 

I want to analyze and decrypt TLSv1.3 traffic of an application with mitmproxy and Wireshark.
I configured a gateway running mitmproxy in transparent mode and inside mitmproxy the traffic gets decrypted but Wireshark can not decrypt the captured data using the keylogfile provided by mitmproxy. 
After some research I found [this presentation](https://lekensteyn.nl/files/wireshark-tls-debugging-sharkfest19us.pdf) regarding the decryption of TLSv1.3 traffic with Wireshark. On Slide 9 there is a keylogfile example for decrypting TLSv1.3. 
In the  keylogfile provided by mitmproxy I can't find any lines starting with CLIENT_HANDSHAKE_TRAFFIC_SECRET, CLIENT_TRAFFIC_SECRET_0 nor EXPORTER_SECRET but only ones starting with CLIENT_RANDOM.


#### Steps to reproduce the behavior:
1. Export the SSLKEYLOGFILE environment variable
2. Setup mitmproxy in transparent monde
3. Open a website using TLSv1.3
4. Check the keylogfile

#### System Information
Mitmproxy: 5.1.1 binary
Python:    3.7.6
OpenSSL:   OpenSSL 1.1.1f  31 Mar 2020
Platform:  Linux-5.5.0-kali2-amd64-x86_64-with-debian-kali-rolling
",b01d574d8b1fceae7cea10484b525301b4ba4a77,98d630b89c309acb5eece345b2b4d1e019a99514,https://github.com/mitmproxy/mitmproxy/compare/b01d574d8b1fceae7cea10484b525301b4ba4a77...98d630b89c309acb5eece345b2b4d1e019a99514,"diff --git a/mitmproxy/net/tls.py b/mitmproxy/net/tls.py
index 8e217ec0c..a5c0cba76 100644
--- a/mitmproxy/net/tls.py
+++ b/mitmproxy/net/tls.py
@@ -79,43 +79,24 @@ def client_arguments_from_options(options: ""mitmproxy.options.Options"") -> dict:
 
 class MasterSecretLogger:
     def __init__(self, filename):
-        self.filename = filename
+        self.filename = os.path.expanduser(filename)
         self.f = None
         self.lock = threading.Lock()
 
     # required for functools.wraps, which pyOpenSSL uses.
     __name__ = ""MasterSecretLogger""
 
-    def __call__(self, connection, where, ret):
-        done_now = (
-            where == SSL.SSL_CB_HANDSHAKE_DONE and ret == 1
-        )
-        # this is a horrendous workaround for https://github.com/mitmproxy/mitmproxy/pull/3692#issuecomment-608454530:
-        # OpenSSL 1.1.1f decided to not make connection.master_key() fail in the SSL_CB_HANDSHAKE_DONE callback.
-        # To support various OpenSSL versions and still log master secrets, we now mark connections where this has
-        # happened and then try again on the next event. This is ugly and shouldn't be done, but eventually we
-        # replace this with context.set_keylog_callback anyways.
-        done_previously_but_not_logged_yet = (
-            hasattr(connection, ""_still_needs_masterkey"")
-        )
-        if done_now or done_previously_but_not_logged_yet:
-            with self.lock:
-                if not self.f:
-                    d = os.path.dirname(self.filename)
-                    if not os.path.isdir(d):
-                        os.makedirs(d)
-                    self.f = open(self.filename, ""ab"")
-                    self.f.write(b""\\r\\n"")
-                try:
-                    client_random = binascii.hexlify(connection.client_random())
-                    masterkey = binascii.hexlify(connection.master_key())
-                except (AssertionError, SSL.Error):  # careful: exception type changes between pyOpenSSL versions
-                    connection._still_needs_masterkey = True
-                else:
-                    self.f.write(b""CLIENT_RANDOM %s %s\\r\\n"" % (client_random, masterkey))
-                    self.f.flush()
-                    if hasattr(connection, ""_still_needs_masterkey""):
-                        delattr(connection, ""_still_needs_masterkey"")
+    def __call__(self, connection, keymaterial):
+        with self.lock:
+            if not self.f:
+                d = os.path.dirname(self.filename)
+                if not os.path.isdir(d):
+                    os.makedirs(d)
+                self.f = open(self.filename, ""ab"")
+                self.f.write(b""\\n"")
+            self.f.write(keymaterial)
+            self.f.write(b""\\n"")
+            self.f.flush()
 
     def close(self):
         with self.lock:
@@ -203,7 +184,7 @@ def _create_ssl_context(
 
     # SSLKEYLOGFILE
     if log_master_secret:
-        context.set_info_callback(log_master_secret)
+        context.set_keylog_callback(log_master_secret)
 
     if alpn_protos is not None:
         # advertise application layer protocols
diff --git a/setup.py b/setup.py
index e02bd4b8c..ff009188a 100644
--- a/setup.py
+++ b/setup.py
@@ -83,7 +83,7 @@ setup(
         ""passlib>=1.6.5, <1.8"",
         ""protobuf>=3.6.0, <3.14"",
         ""pyasn1>=0.3.1,<0.5"",
-        ""pyOpenSSL>=19.1.0,<19.2"",
+        ""pyOpenSSL>=20.0,<20.1"",
         ""pyparsing>=2.4.2,<2.5"",
         ""pyperclip>=1.6.0,<1.9"",
         ""ruamel.yaml>=0.16,<0.17"",
diff --git a/test/mitmproxy/net/test_tls.py b/test/mitmproxy/net/test_tls.py
index e78564c7b..951573fe0 100644
--- a/test/mitmproxy/net/test_tls.py
+++ b/test/mitmproxy/net/test_tls.py
@@ -43,7 +43,7 @@ class TestMasterSecretLogger(tservers.ServerTestBase):
 
             tls.log_master_secret.close()
             with open(logfile, ""rb"") as f:
-                assert f.read().count(b""CLIENT_RANDOM"") >= 2
+                assert f.read().count(b""SERVER_HANDSHAKE_TRAFFIC_SECRET"") >= 2
 
         tls.log_master_secret = _logfun
 ","['mitmproxy/net/tls.py', 'test/mitmproxy/net/test_tls.py', 'setup.py']",{'.py': 3},3,0,0,3,3,1427639,327760,43155,307,2487,512,47,2,1239,155,329,20,1,0,2020-11-19 13:41:39,31896,Python,"{'Python': 2586018, 'TypeScript': 304537, 'JavaScript': 134951, 'Less': 21454, 'HTML': 11057, 'Kaitai Struct': 3685, 'CSS': 3618, 'Shell': 3018, 'Dockerfile': 623, 'PowerShell': 258}",MIT License,"['mitmproxy/io/protobuf.py', 'mitmproxy/io/compat.py', 'mitmproxy/net/tls.py', 'mitmproxy/net/http/http1/read.py', 'mitmproxy/net/http/http1/assemble.py']","['mitmproxy/io/protobuf.py', 'mitmproxy/io/compat.py', 'mitmproxy/net/tls.py', 'mitmproxy/net/http/http1/read.py', 'mitmproxy/net/http/http1/assemble.py']","['```json\n{\n  ""files"": [\n    ""mitmproxy/net/tls.py"",\n    ""mitmproxy/net/http/http1/assemble.py"",\n    ""mitmproxy/net/http/http1/read.py"",\n    ""mitmproxy/io/compat.py"",\n    ""mitmproxy/io/protobuf.py""\n  ]\n}\n```']",1,1484.3494892120361
9005,hpcaitech/colossalai/3621/3620,hpcaitech,colossalai,https://github.com/hpcaitech/ColossalAI/issues/3620,https://github.com/hpcaitech/ColossalAI/pull/3621,https://github.com/hpcaitech/ColossalAI/pull/3621,1,fixed,[BUG]: [chat] Unable to run train_prompts.sh by single card,"### 🐛 Describe the bug

Missing definition for prompt_sampler and pretrain_sampler in `examples/train_prompts.py` when dist.get_world_size() == 1.

### Environment

_No response_",d7bf284706ef256c38d3aad53142b07cfc0fc10e,739cfe33600a72e364a1c017b82302f78d9b5091,https://github.com/hpcaitech/colossalai/compare/d7bf284706ef256c38d3aad53142b07cfc0fc10e...739cfe33600a72e364a1c017b82302f78d9b5091,"diff --git a/applications/Chat/examples/train_prompts.py b/applications/Chat/examples/train_prompts.py
index 5ded6d84..2086ff00 100644
--- a/applications/Chat/examples/train_prompts.py
+++ b/applications/Chat/examples/train_prompts.py
@@ -8,7 +8,7 @@ from coati.models.bloom import BLOOMRM, BLOOMActor, BLOOMCritic
 from coati.models.gpt import GPTRM, GPTActor, GPTCritic
 from coati.models.llama import LlamaActor, LlamaCritic, LlamaRM
 from coati.models.opt import OPTRM, OPTActor, OPTCritic
-from coati.models.roberta import RoBERTaRM, RoBERTaActor, RoBERTaCritic
+from coati.models.roberta import RoBERTaActor, RoBERTaCritic, RoBERTaRM
 from coati.trainer import PPOTrainer
 from coati.trainer.strategies import ColossalAIStrategy, DDPStrategy, NaiveStrategy
 from coati.utils import prepare_llama_tokenizer_and_embedding
@@ -143,6 +143,8 @@ def main(args):
     prompt_dataset = PromptDataset(tokenizer=tokenizer, data_path=args.prompt_path, max_datasets_size=16384)
     if dist.is_initialized() and dist.get_world_size() > 1:
         prompt_sampler = DistributedSampler(prompt_dataset, shuffle=True, seed=42, drop_last=True)
+    else:
+        prompt_sampler = None
     prompt_dataloader = DataLoader(prompt_dataset,
                                    shuffle=(prompt_sampler is None),
                                    sampler=prompt_sampler,
@@ -151,6 +153,8 @@ def main(args):
     pretrain_dataset = SupervisedDataset(tokenizer=tokenizer, data_path=args.pretrain_dataset, max_datasets_size=16384)
     if dist.is_initialized() and dist.get_world_size() > 1:
         pretrain_sampler = DistributedSampler(pretrain_dataset, shuffle=True, seed=42, drop_last=True)
+    else:
+        pretrain_sampler = None
     pretrain_dataloader = DataLoader(pretrain_dataset,
                                      shuffle=(pretrain_sampler is None),
                                      sampler=pretrain_sampler,",['applications/Chat/examples/train_prompts.py'],{'.py': 1},1,0,0,1,1,5194531,1142792,130076,880,231,67,6,1,178,21,41,7,0,0,2023-04-22 06:26:00,31510,Python,"{'Python': 5399888, 'Cuda': 241198, 'C++': 151307, 'Shell': 13438, 'C': 9105, 'Dockerfile': 1812}",Apache License 2.0,"['examples/tutorial/sequence_parallel/data/datasets/bert_dataset.py', 'applications/Chat/examples/train_prompts.py']","['examples/tutorial/sequence_parallel/data/datasets/bert_dataset.py', 'applications/Chat/examples/train_prompts.py']","['```json\n{\n  ""files"": [\n    ""examples/tutorial/sequence_parallel/data/datasets/bert_dataset.py"",\n    ""applications/Chat/examples/train_prompts.py""\n  ]\n}\n```']",1,1262.5200748443604
4701,docker/compose/8158/8136,docker,compose,https://github.com/docker/compose/issues/8136,https://github.com/docker/compose/pull/8158,https://github.com/docker/compose/pull/8158,1,resolves,"""docker-compose logs"" should not fail if not specifying directly the service with non-readable logging driver","<!--
Welcome to the docker-compose issue tracker! Before creating an issue, please heed the following:

1. This tracker should only be used to report bugs and request features / enhancements to docker-compose
    - For questions and general support, use https://forums.docker.com
    - For documentation issues, use https://github.com/docker/docker.github.io
    - For issues with the `docker stack` commands and the version 3 of the Compose file, use
      https://github.com/docker/cli
2. Use the search function before creating a new issue. Duplicates will be closed and directed to
   the original discussion.
3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue

This is an usability issue. After https://github.com/docker/compose/pull/8082, running `docker-compose logs` will quit with `ERROR: configured logging driver does not support reading`, if any of the services has `logging.driver: none`. I would expect:

+  `docker-compose logs` (without service name) to automatically ignore those containers (like `docker-compose up`), possibly showing a warning instead of error.
+ `docker-compose logs service-name` will fail if the service has `logging.driver: none`

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.28.3, build 14736152
```

**Output of `docker version`**
```
Docker version 20.10.3, build 48d30b5
```

**Output of `docker-compose config`**
```
services:
  nginx:
    image: openresty/openresty:alpine
    logging:
        driver: 'none'
  echo:
    image: node:alpine
    command: [npx, http-echo-server]
```


## Steps to reproduce the issue

1. Run `docker-compose up -d`
2. Run `docker-compose logs -f`
3.

### Observed result

```
Attaching to test-project_nginx_1, test-project_echo_1
ERROR: configured logging driver does not support reading
```

### Expected result

docker-compose can attach to logs of `echo` service, ignoring `nginx` service.
",fc744a0cc9394ddb2a56b37c79f4cf7d33881222,6ca2aed7ec106302ba8452d2f9ac923a9f5935dc,https://github.com/docker/compose/compare/fc744a0cc9394ddb2a56b37c79f4cf7d33881222...6ca2aed7ec106302ba8452d2f9ac923a9f5935dc,"diff --git a/compose/cli/main.py b/compose/cli/main.py
index 53c9c42b..494e8562 100644
--- a/compose/cli/main.py
+++ b/compose/cli/main.py
@@ -1482,7 +1482,7 @@ def log_printer_from_project(
         keep_prefix=True,
 ):
     return LogPrinter(
-        containers,
+        [c for c in containers if c.log_driver not in (None, 'none')],
         build_log_presenters(project.service_names, monochrome, keep_prefix),
         event_stream or project.events(),
         cascade_stop=cascade_stop,",['compose/cli/main.py'],{'.py': 1},1,0,0,1,1,387649,80917,11567,44,92,22,2,1,2134,276,498,63,4,4,2021-02-25 16:17:20,30143,Go,"{'Go': 829928, 'Dockerfile': 21438, 'Makefile': 5555, 'Gherkin': 5265, 'HCL': 3084, 'HTML': 656, 'Shell': 654}",Apache License 2.0,"['compose/service.py', 'compose/config/config.py', 'compose/cli/main.py', 'compose/config/types.py', 'compose/cli/docker_client.py']","['compose/service.py', 'compose/config/config.py', 'compose/cli/main.py', 'compose/config/types.py', 'compose/cli/docker_client.py']","['```json\n{\n  ""files"": [\n    ""compose/service.py"",\n    ""compose/cli/main.py"",\n    ""compose/cli/docker_client.py"",\n    ""compose/config/config.py"",\n    ""compose/config/types.py""\n  ]\n}\n```']",1,1052.7384281158447
8749,ccxt/ccxt/18301/18192,ccxt,ccxt,https://github.com/ccxt/ccxt/issues/18192,https://github.com/ccxt/ccxt/pull/18301,https://github.com/ccxt/ccxt/pull/18301,1,fixes,Python: importing ccxt.pro maps synchronous calls instead of asynchronous?,"### ؜

Hi there,
 I have just realized, as I wasn't running tests on this part of the code recently, that by importing ccxt.pro some of the Exchange methods, such as:
 - load_markets()
 - fetch_status()
 - fetch_orders()
 - fetch_balance()
 - cancel_order()
 are actually synchronous instead of asynchronous... the things which put me off completely is that the watch_ methods also appear to be synchronous, am I missing something? I am sure the past versions of the ccxt.pro where extending the ccxt.async_support not the ccxt synchronous version.

My libraries:
poetry show ccxt
 name         : ccxt                                                                                                         
 version      : 3.1.34                                                                                                       
 description  : A JavaScript / TypeScript / Python / C# / PHP cryptocurrency trading library with support for 130+ exchanges 

dependencies
 - aiodns >=1.1.1
 - aiohttp >=3.8
 - certifi >=2018.1.18
 - cryptography >=2.6.1
 - requests >=2.18.4
 - setuptools >=60.9.0
 - yarl >=1.7.2

Let me add a current example with watch_trades():

```
import ccxt.async_support as ccxt
params: Dict[str, Any] = dict(
    apiKey=api_key,
    secret=secret,
    enableRateLimit=True,
    newUpdates=True,
)
self.__conn: ccxt.Exchange = getattr(ccxt, exchange_name)(params)
ccxt_trades: List[Dict] = await self.__conn.watch_trades(market.symbol)
```

If I am importing from `ccxt.async_support` I am getting the error with Binance as `exchange_name` that: ""binance watchTrades() is not supported yet"" while I understood that with the merging of the ccxt pro version into the ccxt library, the watch_* methods should have been moved into the async_support module. And I am pretty sure it was running like that till a while ago, because I have trading logs of that version, with successful trade watching :-)

What is more strange to me now is that if I change the `import ccxt.async_support as ccxt` into `import ccxt.pro as ccxt` I am having the watch_* back and they actually work, which means I do not get the error that they aren't supported, but when inspecting those methods they seem to point me back to the synchronous version of the ccxt library and not to the ccxt.async_support which is where they are supposed to point (or at least it was like that a while ago). This is where it is pointing:

```
def watch_trades(self, symbol: str, since: Optional[int] = None, limit: Optional[int] = None, params={}):
    raise NotSupported(self.id + ' watchTrades() is not supported yet')
```
which is in `base.exchange.py::Exchange` instead of being in `async_support.base.exchange.py::Exchange` and being declared as an `async` method.

This is the issue that when running mypy on the code, I get a lot of warning that all of the watch_* method shouldn't be awaited because they are synchronous... which is wired and didn't happen before.

HTH, let me know if you need more information.",801fc5551b3aef1fa98e4d69f7dd5e82e26194a4,4b6df72c036d2667a7793240a91da3d9253420e1,https://github.com/ccxt/ccxt/compare/801fc5551b3aef1fa98e4d69f7dd5e82e26194a4...4b6df72c036d2667a7793240a91da3d9253420e1,"diff --git a/python/ccxt/pro/__init__.py b/python/ccxt/pro/__init__.py
index dcfbd0a41d..1a55e6770b 100644
--- a/python/ccxt/pro/__init__.py
+++ b/python/ccxt/pro/__init__.py
@@ -8,7 +8,7 @@ __version__ = '3.1.47'
 
 # ----------------------------------------------------------------------------
 
-from ccxt.base.exchange import Exchange  # noqa: F401
+from ccxt.async_support.base.exchange import Exchange  # noqa: F401
 
 # CCXT Pro exchanges (now this is mainly used for importing exchanges in WS tests)
 ",['python/ccxt/pro/__init__.py'],{'.py': 1},1,0,0,1,1,22028410,5119974,477192,686,123,30,2,1,3054,427,692,53,0,2,2023-06-21 15:25:13,28809,Python,"{'Python': 21299176, 'TypeScript': 13185654, 'JavaScript': 12892092, 'PHP': 10648253, 'Shell': 16965, 'HTML': 2452, 'Dockerfile': 1840, 'Handlebars': 1695}",MIT License,"['python/ccxt/pro/__init__.py', 'python/ccxt/pro/binance.py', 'python/ccxt/pro/alpaca.py', 'python/ccxt/pro/ascendex.py', 'python/ccxt/pro/bequant.py']","['python/ccxt/pro/__init__.py', 'python/ccxt/pro/binance.py', 'python/ccxt/pro/alpaca.py', 'python/ccxt/pro/ascendex.py', 'python/ccxt/pro/bequant.py']","['```json\n{\n  ""files"": [\n    ""python/ccxt/pro/__init__.py"",\n    ""python/ccxt/pro/alpaca.py"",\n    ""python/ccxt/pro/ascendex.py"",\n    ""python/ccxt/pro/bequant.py"",\n    ""python/ccxt/pro/binance.py""\n  ]\n}\n```']",1,1384.9561214447021
7093,microsoft/deepspeed/4084/4083,microsoft,deepspeed,https://github.com/microsoft/DeepSpeed/issues/4083,https://github.com/microsoft/DeepSpeed/pull/4084,https://github.com/microsoft/DeepSpeed/pull/4084,2,fix,[BUG] BF16 training with FP32 gradient accumulation - Zero Stage 1 CPU - DeepSpeedCPUAdam,"I am trying to train a model with bf16,  fp32 gradient accumulation and zero stage 1. Using DeepSpeedCPUAdam as optimizer. 


**Config**
```json
{
    ""steps_per_print"":10000,
    ""wall_clock_breakdown"":true,
    ""train_batch_size"": 1024,
    ""gradient_accumulation_steps"": 16,
    ""train_micro_batch_size_per_gpu"": 2,
    ""fp32_allreduce"": true,
    ""data_types"": {
        ""grad_accum_dtype"":""fp32""
    },
    ""bf16"": {
        ""enabled"": true
    },
    ""optimizer"": {
        ""type"": ""DeepSpeedCPUAdam"",
        ""params"": {
            ""lr"": 0.001
        }
    },
    ""gradient_clipping"": 1.0,
    ""scheduler"": {
        ""type"": ""WarmupLR"",
        ""params"": {
            ""warmup_min_lr"": 0,
            ""warmup_max_lr"": 0.001,
            ""warmup_num_steps"": 1000
        }
    },

    ""zero_optimization"": {
        ""stage"": 1,
        ""offload_optimizer"": {
            ""device"": ""cpu"",
            ""pin_memory"": true
          },
      ""allgather_partitions"": true,
      ""reduce_bucket_size"": 5e8,
      ""allgather_bucket_size"": 5e8,
      ""reduce_scatter"": true,
      ""overlap_comm"": true,
      ""round_robin_gradients"":true,
      ""contiguous_gradients"": true,
      ""sub_group_size"": 1e9
    },
  }
```


**ds_report output**
```[2023-08-03 03:07:32,395] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
--------------------------------------------------
DeepSpeed C++/CUDA extension op report
--------------------------------------------------
NOTE: Ops not installed will be just-in-time (JIT) compiled at
      runtime if needed. Op compatibility means that your system
      meet the required dependencies to JIT install the op.
--------------------------------------------------
JIT compiled ops requires ninja
ninja .................. [OKAY]
--------------------------------------------------
op name ................ installed .. compatible
--------------------------------------------------
 [WARNING]  async_io requires the dev libaio .so object and headers but these were not found.
 [WARNING]  async_io: please install the libaio-dev package with apt
 [WARNING]  If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.
async_io ............... [NO] ....... [NO]
cpu_adagrad ............ [YES] ...... [OKAY]
cpu_adam ............... [YES] ...... [OKAY]
fused_adam ............. [YES] ...... [OKAY]
fused_lamb ............. [YES] ...... [OKAY]
quantizer .............. [YES] ...... [OKAY]
random_ltd ............. [YES] ...... [OKAY]
 [WARNING]  sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.1
 [WARNING]  using untested triton version (2.1.0+9e3e10c5ed), only 1.0.0 is known to be compatible
sparse_attn ............ [NO] ....... [NO]
spatial_inference ...... [YES] ...... [OKAY]
transformer ............ [YES] ...... [OKAY]
stochastic_transformer . [YES] ...... [OKAY]
transformer_inference .. [YES] ...... [OKAY]
--------------------------------------------------
DeepSpeed general environment info:
torch install path ............... ['/work2/conda/envs/env/lib/python3.11/site-packages/torch']
torch version .................... 2.1.0.dev20230725+cu121
deepspeed install path ........... ['/work2/conda/envs/env/lib/python3.11/site-packages/deepspeed']
deepspeed info ................... 0.10.0+unknown, unknown, unknown
torch cuda version ............... 12.1
torch hip version ................ None
nvcc version ..................... 12.0
deepspeed wheel compiled w. ...... torch 2.1, cuda 12.1
```

**Error message**
CPUAdam param is on cuda:7 and must be 'cpu', make sure you enabled 'offload_optimizer': 'cpu' in your ZeRO config.

But offload_optimizer is already set in our config. 
Same config works if I change the grad_accum_dtype to ""bf16"" with zero code changes.

```Traceback (most recent call last):
    self._configure_optimizer(optimizer, model_parameters)
           ^^^^^^^^^^^^^^^^^^
  File ""/work2/dragoon_deepspeed/deepspeed_trainer.py"", line 320, in <module>
  File ""/work2/conda/envs/env/lib/python3.11/site-packages/deepspeed/runtime/engine.py"", line 1220, in _configure_optimizer
AssertionError: CPUAdam param is on cuda:5 and must be 'cpu', make sure you enabled 'offload_optimizer': 'cpu' in your ZeRO config.```


Can someone help by letting me know how to solve this? 
",975bcbc0bdec3df7830f95f54906d904aa8add78,42c5381d1a16c6bdf0fbc56175c2a9f23f6f0b78,https://github.com/microsoft/deepspeed/compare/975bcbc0bdec3df7830f95f54906d904aa8add78...42c5381d1a16c6bdf0fbc56175c2a9f23f6f0b78,"diff --git a/deepspeed/runtime/engine.py b/deepspeed/runtime/engine.py
index cc25ce69..5e5f9728 100644
--- a/deepspeed/runtime/engine.py
+++ b/deepspeed/runtime/engine.py
@@ -1137,9 +1137,8 @@ class DeepSpeedEngine(Module):
 
                 if self.global_rank == 0:
                     logger.warning(""**** You are using ZeRO with an untested optimizer, proceed with caution *****"")
-
             if model_dtype == torch.bfloat16 and grad_accum_dtype == torch.float32 and self.zero_optimization_stage(
-            ) == 1:
+            ) == 1 and not self.zero_cpu_offload():
                 return BFLOAT16
             return ZERO_OPTIMIZATION
         elif amp_enabled:
diff --git a/deepspeed/runtime/zero/stage_1_and_2.py b/deepspeed/runtime/zero/stage_1_and_2.py
index bb578218..e9e8fc16 100755
--- a/deepspeed/runtime/zero/stage_1_and_2.py
+++ b/deepspeed/runtime/zero/stage_1_and_2.py
@@ -836,7 +836,10 @@ class DeepSpeedZeroOptimizer(ZeROOptimizer):
                 param.grad_accum = param.grad
 
     def get_gradient_for_reduction(self, param):
-        return param.grad_accum.to(self.dtype) if self.use_grad_accum_for_reduction else param.grad
+        if self.use_grad_accum_for_reduction:
+            return param.grad_accum.to(self.dtype) if param.grad_accum is not None else None
+        else:
+            return param.grad
 
     # Clear the tensor the reduction gradient attribute is pointing to
     def clear_grad_reduc_pointer(self, param):
@@ -902,7 +905,7 @@ class DeepSpeedZeroOptimizer(ZeROOptimizer):
             else:
                 # keeping the gradients contiguous to prevent memory fragmentation, and avoid flattening
                 new_grad_tensor = self.ipg_buffer[self.ipg_index].narrow(0, self.elements_in_ipg_bucket, param.numel())
-                new_grad_tensor.copy_(param.grad.view(-1))
+                new_grad_tensor.copy_(grad_reduc.view(-1))
                 grad_reduc.data = new_grad_tensor.data.view_as(grad_reduc)
 
         self.elements_in_ipg_bucket += param.numel()
@@ -1262,7 +1265,8 @@ class DeepSpeedZeroOptimizer(ZeROOptimizer):
                 _, _, param_id = self.params_in_ipg_bucket[0]
                 assert self.get_param_id(self.extra_large_param_to_reduce
                                          ) == param_id, ""param in ipg bucket does not match extra-large param""
-                self.average_tensor(self.extra_large_param_to_reduce.grad.view(-1))
+                extra_large_grad_reduc = self.get_gradient_for_reduction(self.extra_large_param_to_reduce)
+                self.average_tensor(extra_large_grad_reduc.view(-1))
                 self.extra_large_param_to_reduce = None
             else:
                 self.average_tensor(self.ipg_buffer[self.ipg_index])
@@ -1520,7 +1524,6 @@ class DeepSpeedZeroOptimizer(ZeROOptimizer):
                 if set_to_none:
                     p.grad = None  # epilogue and in step
                     p.grad_accum = None
-                    p.grad_reduc = None
                 else:
                     if p.grad is not None:
                         p.grad.detach_()
@@ -1629,7 +1632,6 @@ class DeepSpeedZeroOptimizer(ZeROOptimizer):
     def free_grad_in_param_list(self, param_list):
         for p in param_list:
             p.grad = None  # in step
-            p.grad_reduc = None
             p.grad_accum = None
 
     def reset_cpu_buffers(self):
@@ -1941,7 +1943,7 @@ class DeepSpeedZeroOptimizer(ZeROOptimizer):
             self.loss_scaler.backward(loss.float(), retain_graph=retain_graph)
 
         # Only for Stage 1, Mode 2
-        if self.use_separate_grad_accum and not self.partition_gradients:
+        if self.use_grad_accum_for_reduction:
             self.update_separate_grad_accum()
         else:
             self.set_grad_accum_pointer()","['deepspeed/runtime/engine.py', 'deepspeed/runtime/zero/stage_1_and_2.py']",{'.py': 2},2,0,0,2,2,2650112,571850,63569,317,941,187,17,2,4487,438,1121,112,0,3,2023-08-03 19:02:42,27477,Python,"{'Python': 3564056, 'C++': 484557, 'Cuda': 456462, 'Shell': 24697, 'Dockerfile': 8284, 'C': 6826, 'Batchfile': 337}",Apache License 2.0,"['deepspeed/runtime/zero/contiguous_memory_allocator.py', 'deepspeed/runtime/zero/linear.py', 'deepspeed/runtime/zero/config.py', 'deepspeed/runtime/zero/mics.py', 'deepspeed/runtime/zero/mics_utils.py']","['deepspeed/runtime/zero/contiguous_memory_allocator.py', 'deepspeed/runtime/zero/linear.py', 'deepspeed/runtime/zero/config.py', 'deepspeed/runtime/zero/mics.py', 'deepspeed/runtime/zero/mics_utils.py']","['```json\n{\n  ""files"": [\n    ""deepspeed/runtime/zero/config.py"",\n    ""deepspeed/runtime/zero/contiguous_memory_allocator.py"",\n    ""deepspeed/runtime/zero/linear.py"",\n    ""deepspeed/runtime/zero/mics.py"",\n    ""deepspeed/runtime/zero/mics_utils.py""\n  ]\n}\n```']",1,1249.4516372680664
7523,streamlit/streamlit/6459/6440,streamlit,streamlit,https://github.com/streamlit/streamlit/issues/6440,https://github.com/streamlit/streamlit/pull/6459,https://github.com/streamlit/streamlit/pull/6459,1,fix,`@st.cache_data` cannot handle UUID objects (but `@st.cache` can),"### Checklist

- [X] I have searched the [existing issues](https://github.com/streamlit/streamlit/issues) for similar issues.
- [X] I added a very descriptive title to this issue.
- [X] I have provided sufficient information below to help reproduce this issue.

### Summary

It looks like the ""new"" `@st.cache_data` decorator chokes on `uuid.UUID` objects, while the deprecated `@st.cache` seems to handle them just fine; see minimal example.


### Reproducible Code Example

```Python
import streamlit as st
import uuid


@st.cache
def works(some_id: uuid.UUID) -> None:
    print(""Works"")


@st.cache_data
def doesnt_work(some_id: uuid.UUID) -> None:
    print(""Nope"")


some_id = uuid.uuid4()

works(some_id)
doesnt_work(some_id)
```


### Steps To Reproduce

_No response_

### Expected Behavior

_No response_

### Current Behavior

The minimal example above produces the following output:

```
2023-04-06 10:46:30.563 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager
2023-04-06 10:46:30.678 
  Warning: to view this Streamlit app on a browser, run it with the following
  command:

    streamlit run /Users/timothy/Library/Application Support/JetBrains/PyCharmCE2023.1/scratches/scratch_7.py [ARGUMENTS]
2023-04-06 10:46:30.680 `st.cache` is deprecated. Please use one of Streamlit's new caching commands,
`st.cache_data` or `st.cache_resource`.

More information [in our docs](https://docs.streamlit.io/library/advanced-features/caching).
2023-04-06 10:46:30.681 No runtime found, using MemoryCacheStorageManager
Traceback (most recent call last):
  File ""/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py"", line 383, in _to_bytes
    reduce_data = obj.__reduce__()
  File ""/usr/local/anaconda3/envs/demo-project/lib/python3.10/copyreg.py"", line 76, in _reduce_ex
    raise TypeError(f""cannot pickle {cls.__name__!r} object"")
TypeError: cannot pickle 'function' object

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py"", line 375, in _make_value_key
    update_hash(
  File ""/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py"", line 56, in update_hash
    ch.update(hasher, val)
  File ""/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py"", line 209, in update
    b = self.to_bytes(obj)
  File ""/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py"", line 191, in to_bytes
    b = b""%s:%s"" % (tname, self._to_bytes(obj))
  File ""/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py"", line 239, in _to_bytes
    self.update(h, item)
  File ""/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py"", line 209, in update
    b = self.to_bytes(obj)
  File ""/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py"", line 191, in to_bytes
    b = b""%s:%s"" % (tname, self._to_bytes(obj))
  File ""/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py"", line 388, in _to_bytes
    self.update(h, item)
  File ""/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py"", line 209, in update
    b = self.to_bytes(obj)
  File ""/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py"", line 191, in to_bytes
    b = b""%s:%s"" % (tname, self._to_bytes(obj))
  File ""/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py"", line 385, in _to_bytes
    raise UnhashableTypeError() from ex
streamlit.runtime.caching.cache_errors.UnhashableTypeError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/Users/timothy/Library/Application Support/JetBrains/PyCharmCE2023.1/scratches/scratch_7.py"", line 20, in <module>
    doesnt_work(some_id)
  File ""/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py"", line 194, in wrapper
    return cached_func(*args, **kwargs)
  File ""/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py"", line 223, in __call__
    return self._get_or_create_cached_value(args, kwargs)
  File ""/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py"", line 237, in _get_or_create_cached_value
    value_key = _make_value_key(
  File ""/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py"", line 381, in _make_value_key
    raise UnhashableParamError(cache_type, func, arg_name, arg_value, exc)
  File ""/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/cache_utils.py"", line 375, in _make_value_key
    update_hash(
  File ""/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py"", line 56, in update_hash
    ch.update(hasher, val)
  File ""/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py"", line 209, in update
    b = self.to_bytes(obj)
  File ""/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py"", line 191, in to_bytes
    b = b""%s:%s"" % (tname, self._to_bytes(obj))
  File ""/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py"", line 239, in _to_bytes
    self.update(h, item)
  File ""/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py"", line 209, in update
    b = self.to_bytes(obj)
  File ""/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py"", line 191, in to_bytes
    b = b""%s:%s"" % (tname, self._to_bytes(obj))
  File ""/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py"", line 388, in _to_bytes
    self.update(h, item)
  File ""/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py"", line 209, in update
    b = self.to_bytes(obj)
  File ""/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py"", line 191, in to_bytes
    b = b""%s:%s"" % (tname, self._to_bytes(obj))
  File ""/usr/local/anaconda3/envs/demo-project/lib/python3.10/site-packages/streamlit/runtime/caching/hashing.py"", line 385, in _to_bytes
    raise UnhashableTypeError() from ex
streamlit.runtime.caching.cache_errors.UnhashableParamError: Cannot hash argument 'some_id' (of type `uuid.UUID`) in 'doesnt_work'.

To address this, you can tell Streamlit not to hash this argument by adding a
leading underscore to the argument's name in the function signature:

\\```
@st.cache_data
def doesnt_work(_some_id, ...):
    ...
\\```
            
Works
```

### Is this a regression?

- [ ] Yes, this used to work in a previous version.

### Debug info

- Streamlit version: 1.20.0
- Python version: 3.10.10
- Operating System: macOS 13.2.1 (22D68)
- Browser: —
- Virtual environment: conda


### Additional Information

The root of the problems seems to be this:
```
Cannot hash argument 'some_id' (of type `uuid.UUID`) in 'doesnt_work'.
```
Which is a little strange because pickling and hashing `UUID` objects does not seem to be a problem in general:
```python
>>> import pickle
>>> import uuid
>>> pickle.dumps(uuid.uuid4())
b'\\x80\\x04\\x950\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x04uuid\\x94\\x8c\\x04UUID\\x94\\x93\\x94)\\x81\\x94}\\x94\\x8c\\x03int\\x94\\x8a\\x10\\xa8\\x0eL\\x84\\x14\\xd9\\xcf\\x8d\\xae@M\\x9e\\x11\\xb0\\x9cvsb.'
>>> hash(uuid.uuid4())
1532964488252874118
```

A simple workaround for now is to cast `UUID` objects to strings (which are cacheable also with `@st.cache_data`), but of course it would be nicer if that were not necessary :)

### Are you willing to submit a PR?

- [ ] Yes, I am willing to submit a PR!",76bba47f71eeeca22c52d4e599387bb416da15ca,2f23288ed80b3c7d3ca75fa0097505d341fb2816,https://github.com/streamlit/streamlit/compare/76bba47f71eeeca22c52d4e599387bb416da15ca...2f23288ed80b3c7d3ca75fa0097505d341fb2816,"diff --git a/lib/streamlit/runtime/caching/hashing.py b/lib/streamlit/runtime/caching/hashing.py
index 8d53db8a9..8c995675a 100644
--- a/lib/streamlit/runtime/caching/hashing.py
+++ b/lib/streamlit/runtime/caching/hashing.py
@@ -25,6 +25,7 @@ import sys
 import tempfile
 import threading
 import unittest.mock
+import uuid
 import weakref
 from enum import Enum
 from typing import Any, Dict, List, Optional, Pattern
@@ -130,6 +131,7 @@ def _key(obj: Optional[Any]) -> Any:
             or isinstance(obj, float)
             or isinstance(obj, int)
             or isinstance(obj, bool)
+            or isinstance(obj, uuid.UUID)
             or obj is None
         )
 
@@ -233,6 +235,9 @@ class _CacheFuncHasher:
         elif isinstance(obj, int):
             return _int_to_bytes(obj)
 
+        elif isinstance(obj, uuid.UUID):
+            return obj.bytes
+
         elif isinstance(obj, (list, tuple)):
             h = hashlib.new(""md5"")
             for item in obj:
diff --git a/lib/tests/streamlit/runtime/caching/hashing_test.py b/lib/tests/streamlit/runtime/caching/hashing_test.py
index dcdd09a7c..2e067fa68 100644
--- a/lib/tests/streamlit/runtime/caching/hashing_test.py
+++ b/lib/tests/streamlit/runtime/caching/hashing_test.py
@@ -21,6 +21,7 @@ import re
 import tempfile
 import types
 import unittest
+import uuid
 from dataclasses import dataclass
 from enum import Enum, auto
 from io import BytesIO, StringIO
@@ -74,6 +75,26 @@ class HashTest(unittest.TestCase):
         self.assertNotEqual(get_hash(2**7), get_hash(2**7 - 1))
         self.assertNotEqual(get_hash(2**7), get_hash(2**7 + 1))
 
+    def test_uuid(self):
+        uuid1 = uuid.uuid4()
+        uuid1_copy = uuid.UUID(uuid1.hex)
+        uuid2 = uuid.uuid4()
+
+        # Our hashing functionality should work with UUIDs
+        # regardless of UUID factory function.
+
+        uuid3 = uuid.uuid5(uuid.NAMESPACE_DNS, ""streamlit.io"")
+        uuid3_copy = uuid.UUID(uuid3.hex)
+        uuid4 = uuid.uuid5(uuid.NAMESPACE_DNS, ""snowflake.com"")
+
+        self.assertEqual(get_hash(uuid1), get_hash(uuid1_copy))
+        self.assertNotEqual(id(uuid1), id(uuid1_copy))
+        self.assertNotEqual(get_hash(uuid1), get_hash(uuid2))
+
+        self.assertEqual(get_hash(uuid3), get_hash(uuid3_copy))
+        self.assertNotEqual(id(uuid3), id(uuid3_copy))
+        self.assertNotEqual(get_hash(uuid3), get_hash(uuid4))
+
     def test_mocks_do_not_result_in_infinite_recursion(self):
         try:
             get_hash(Mock())","['lib/tests/streamlit/runtime/caching/hashing_test.py', 'lib/streamlit/runtime/caching/hashing.py']",{'.py': 2},2,0,0,2,2,1812859,447868,52736,362,129,24,5,1,8543,684,2321,176,2,5,2023-04-08 17:43:28,26373,Python,"{'Python': 3540730, 'TypeScript': 2881864, 'JavaScript': 375436, 'CSS': 20638, 'Makefile': 14719, 'SCSS': 9777, 'HTML': 8099, 'Shell': 7107, 'Dockerfile': 4230, 'Batchfile': 671}",Apache License 2.0,"['lib/streamlit/runtime/caching/storage/cache_storage_protocol.py', 'lib/streamlit/runtime/caching/hashing.py', 'lib/streamlit/runtime/caching/cache_utils.py', 'lib/streamlit/runtime/caching/storage/in_memory_cache_storage_wrapper.py', 'lib/streamlit/runtime/caching/cache_data_api.py']","['lib/streamlit/runtime/caching/storage/cache_storage_protocol.py', 'lib/streamlit/runtime/caching/hashing.py', 'lib/streamlit/runtime/caching/cache_utils.py', 'lib/streamlit/runtime/caching/storage/in_memory_cache_storage_wrapper.py', 'lib/streamlit/runtime/caching/cache_data_api.py']","['```json\n{\n  ""files"": [\n    ""lib/streamlit/runtime/caching/cache_data_api.py"",\n    ""lib/streamlit/runtime/caching/cache_utils.py"",\n    ""lib/streamlit/runtime/caching/hashing.py"",\n    ""lib/streamlit/runtime/caching/storage/cache_storage_protocol.py"",\n    ""lib/streamlit/runtime/caching/storage/in_memory_cache_storage_wrapper.py""\n  ]\n}\n```']",1,1618.8757419586182
9961,huggingface/pytorch-image-models/1351/1348,huggingface,pytorch-image-models,https://github.com/huggingface/pytorch-image-models/issues/1348,https://github.com/huggingface/pytorch-image-models/pull/1351,https://github.com/huggingface/pytorch-image-models/pull/1351,1,resolves,[BUG] Update Hugging Face integration to use hf_hub_download,"**Describe the bug**

`cached_download` is being deprecated. 

```
/usr/local/lib/python3.7/dist-packages/huggingface_hub/file_download.py:563: FutureWarning: `cached_download` is the legacy way to download files from the HF hub, please consider upgrading to `hf_hub_download`
```

**To Reproduce**
Steps to reproduce the behavior:

Authenticate w/ huggingface with `huggingface-cli login` or `huggingface_hub.notebook_login` if you're in a notebook.

then run

```python
import timm

# Build a model 🔧
model = timm.create_model('resnet18', pretrained=True, num_classes=4)

# Push it to the 🤗 hub
timm.models.hub.push_to_hf_hub(
    model,
    'resnet18-random-classifier',
    model_config={'labels': ['a', 'b', 'c', 'd']}
)
```

**Expected behavior**
There should be no warning

**Screenshots**
N/A

**Desktop (please complete the following information):**
 - Colab, `timm` latest PyPi release.

**Additional context**

I should be able to issue this fix if you want @rwightman 
",324a4e58b6b0365d16dcf8f93739be8f74cd7d37,51cca82aa123ddda3c88ce1503d4c0049c3f3c1d,https://github.com/huggingface/pytorch-image-models/compare/324a4e58b6b0365d16dcf8f93739be8f74cd7d37...51cca82aa123ddda3c88ce1503d4c0049c3f3c1d,"diff --git a/timm/models/hub.py b/timm/models/hub.py
index dd7870c..c3d3d15 100644
--- a/timm/models/hub.py
+++ b/timm/models/hub.py
@@ -14,11 +14,11 @@ except ImportError:
 
 from timm import __version__
 try:
-    from huggingface_hub import HfApi, HfFolder, Repository, cached_download, hf_hub_url
-    cached_download = partial(cached_download, library_name=""timm"", library_version=__version__)
+    from huggingface_hub import HfApi, HfFolder, Repository, hf_hub_download, hf_hub_url
+    hf_hub_download = partial(hf_hub_download, library_name=""timm"", library_version=__version__)
     _has_hf_hub = True
 except ImportError:
-    cached_download = None
+    hf_hub_download = None
     _has_hf_hub = False
 
 _logger = logging.getLogger(__name__)
@@ -78,8 +78,7 @@ def load_cfg_from_json(json_file: Union[str, os.PathLike]):
 
 def _download_from_hf(model_id: str, filename: str):
     hf_model_id, hf_revision = hf_split(model_id)
-    url = hf_hub_url(hf_model_id, filename, revision=hf_revision)
-    return cached_download(url, cache_dir=get_cache_dir('hf'))
+    return hf_hub_download(hf_model_id, filename, revision=hf_revision, cache_dir=get_cache_dir('hf'))
 
 
 def load_model_config_from_hf(model_id: str):",['timm/models/hub.py'],{'.py': 1},1,0,0,1,1,2079992,560863,51926,200,666,161,9,1,1022,115,260,42,0,2,2022-07-14 20:43:24,26267,Python,"{'Python': 2840785, 'MDX': 568078, 'Shell': 81}",Apache License 2.0,"['timm/models/factory.py', 'timm/models/hub.py', 'timm/models/registry.py', 'timm/__init__.py', 'timm/models/helpers.py']","['timm/models/factory.py', 'timm/models/hub.py', 'timm/models/registry.py', 'timm/__init__.py', 'timm/models/helpers.py']","['```json\n{\n  ""files"": [\n    ""timm/models/hub.py"",\n    ""timm/models/registry.py"",\n    ""timm/models/factory.py"",\n    ""timm/models/helpers.py"",\n    ""timm/__init__.py""\n  ]\n}\n```']",1,1088.8476371765137
8997,dokku/dokku/2452/2445,dokku,dokku,https://github.com/dokku/dokku/issues/2445,https://github.com/dokku/dokku/pull/2452,https://github.com/dokku/dokku/pull/2452,1,resolves,Web SSH Key not added when key is already attached to server,"As both the debian package and the web ui use the `admin` user, the web ui will fail to add the ssh key, resulting in some users not having access to dokku push.

We should instead use `admin-web` as the admin user from the web ui if we detect that there is an existing `admin` user.

[Here](https://github.com/dokku/dokku/blob/master/contrib/dokku-installer.py#L103) is the line of code that executes this. What I'd do is list users, check if `admin` is in the list, and if so, change the username there from `admin` to `admin-web`.
",95dc3ca20e8c76cc54b738fe73c2649c045735c2,10bb4900c031cfbece8f9f71ce7e8307a0874a68,https://github.com/dokku/dokku/compare/95dc3ca20e8c76cc54b738fe73c2649c045735c2...10bb4900c031cfbece8f9f71ce7e8307a0874a68,"diff --git a/contrib/dokku-installer.py b/contrib/dokku-installer.py
index b57cf3b63..9c897fc70 100755
--- a/contrib/dokku-installer.py
+++ b/contrib/dokku-installer.py
@@ -3,6 +3,7 @@
 import cgi
 import json
 import os
+import re
 import SimpleHTTPServer
 import SocketServer
 import subprocess
@@ -100,8 +101,20 @@ class GetHandler(SimpleHTTPServer.SimpleHTTPRequestHandler):
         with open('{0}/HOSTNAME'.format(dokku_root), 'w') as f:
             f.write(params['hostname'].value)
 
-        command = ['sshcommand', 'acl-add', 'dokku', 'admin']
-        for key in params['keys'].value.split(""\\n""):
+        for (index, key) in enumerate(params['keys'].value.splitlines(), 1):
+            user = 'admin'
+            if self.admin_user_exists() is not None:
+                user = 'web-admin'
+                if self.web_admin_user_exists() is not None:
+                    index = int(self.web_admin_user_exists()) + 1
+                elif self.web_admin_user_exists() is None:
+                    index = 1
+            elif self.admin_user_exists() is None:
+                pass
+            else:
+                index = int(self.admin_user_exists()) + 1
+            user = user + str(index)
+            command = ['sshcommand', 'acl-add', 'dokku', user]
             proc = subprocess.Popen(command, stdin=subprocess.PIPE)
             proc.stdin.write(key)
             proc.stdin.close()
@@ -119,6 +132,29 @@ class GetHandler(SimpleHTTPServer.SimpleHTTPRequestHandler):
         self.end_headers()
         self.wfile.write(json.dumps({'status': 'ok'}))
 
+    def web_admin_user_exists(self):
+        return self.user_exists('web-admin(\\d+)')
+
+    def admin_user_exists(self):
+        return self.user_exists('admin(\\d+)')
+
+    def user_exists(self, name):
+        command = 'dokku ssh-keys:list'
+        pattern = re.compile(r'NAME=""' + name + '""')
+        proc = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE)
+        max_num = 0
+        exists = False
+        for line in proc.stdout:
+            m = pattern.search(line)
+            if m:
+                # User of the form `user` or `user#` exists
+                exists = True
+                max_num = max(max_num, m.group(1))
+        if exists:
+            return max_num
+        else:
+            return None
+
 
 def set_debconf_selection(debconf_type, key, value):
     found = False",['contrib/dokku-installer.py'],{'.py': 1},1,0,0,1,1,8645,2166,249,1,1548,343,40,1,534,89,139,6,1,0,2016-10-08 09:32:08,24826,Shell,"{'Shell': 884070, 'Go': 374605, 'Makefile': 35967, 'Python': 31840, 'HTML': 14752, 'Dockerfile': 9189, 'Procfile': 8608, 'JavaScript': 6686, 'Scala': 2235, 'HCL': 1585, 'Java': 853, 'Clojure': 666, 'Ruby': 221, 'SCSS': 197, 'Handlebars': 171, 'PHP': 43}",MIT License,['contrib/dokku-installer.py'],['contrib/dokku-installer.py'],"['```json\n{\n  ""files"": [\n    ""contrib/dokku-installer.py""\n  ]\n}\n```']",1,804.4772148132324
7564,google/jax/15796/15782,google,jax,https://github.com/google/jax/issues/15782,https://github.com/google/jax/pull/15796,https://github.com/google/jax/pull/15796,1,fixes,Computation with distributed arrays results in unexpected PartitionSpec,"### Description

Computation with distributed arrays seems to normalize `PartitionSpec` in at least three ways:

- Leading axes of length 1 are replaced by `None`.
- Trailing axes of length 1 are removed.
- Strings are replaced by tuples of strings.

I found this behavior rather unexpected, because this normalization is applied and validated somewhat inconsistently:
1. `PartitionSpec` objects don't get normalized when put into a `NamedSharding`.
1. Partition specs on arrays created with `device_put` also are not get normalized.
2. Differently normalized `NamedSharding` objects sometimes (but not always) compare equal.
3. Differently normalized `PartitionSpec` objects never compare equal.

Example code:
```python
import chex
import jax
import jax.numpy as jnp
import numpy as np

chex.set_n_cpu_devices(8)
P = jax.sharding.PartitionSpec

mesh = jax.sharding.Mesh(jax.devices(), axis_names=['x'])
spec = P('x')
sharding = jax.sharding.NamedSharding(mesh, spec)

x = jax.device_put(jnp.arange(32), sharding)
y = x + 1

print('example one:')
print(f'{x.sharding=}')
print(f'{y.sharding=}')
print(x.sharding == y.sharding)
print(x.sharding.spec == y.sharding.spec)

devices = np.reshape(jax.devices(), (1, 8, 1))
mesh = jax.sharding.Mesh(devices, axis_names=['x', 'y', 'z'])
spec = P('x', 'y', 'z')
sharding = jax.sharding.NamedSharding(mesh, spec)

x = jax.device_put(jnp.arange(32).reshape(1, -1, 1), sharding)
y = x + 1

print()
print('example two:')
print(f'{x.sharding=}')
print(f'{y.sharding=}')
print(x.sharding == y.sharding)
print(x.sharding.spec == y.sharding.spec)
```
Prints:
```
example one:
x.sharding=NamedSharding(mesh={'x': 8}, spec=PartitionSpec('x',))
y.sharding=NamedSharding(mesh={'x': 8}, spec=PartitionSpec(('x',),))
True
False

example two:
x.sharding=NamedSharding(mesh={'x': 1, 'y': 8, 'z': 1}, spec=PartitionSpec('x', 'y', 'z'))
y.sharding=NamedSharding(mesh={'x': 1, 'y': 8, 'z': 1}, spec=PartitionSpec(None, ('y',)))
False
False
```

### What jax/jaxlib version are you using?

_No response_

### Which accelerator(s) are you using?

_No response_

### Additional system info

_No response_

### NVIDIA GPU info

_No response_",3386e77cfa6855dd0cafbab5084be01d633d4690,4a3fb238f6c5b5c8757c152d6fef90a1bdd6e623,https://github.com/google/jax/compare/3386e77cfa6855dd0cafbab5084be01d633d4690...4a3fb238f6c5b5c8757c152d6fef90a1bdd6e623,"diff --git a/jax/_src/interpreters/pxla.py b/jax/_src/interpreters/pxla.py
index 2d8cd11fc..4de5f7446 100644
--- a/jax/_src/interpreters/pxla.py
+++ b/jax/_src/interpreters/pxla.py
@@ -2435,13 +2435,18 @@ orig_out_sharding_handlers[sharding_impls.PositionalSharding] = _gspmd_to_positi
 
 
 def _get_out_sharding_from_orig_sharding(
-    out_shardings, orig_s, are_out_sharding_from_xla):
+    out_shardings, orig_s, orig_aval, are_out_sharding_from_xla):
   out = []
   orig_handler = orig_out_sharding_handlers[type(orig_s)]
   for o, from_xla in safe_zip(out_shardings, are_out_sharding_from_xla):
     if isinstance(o, sharding_impls.GSPMDSharding):
       try:
-        out.append((orig_handler(o._op_sharding, orig_s), False))
+        if (orig_aval is not None and
+            sharding_impls.are_op_shardings_equal(
+                o._op_sharding, orig_s._to_xla_op_sharding(orig_aval.ndim))):
+          out.append((orig_s, False))
+        else:
+          out.append((orig_handler(o._op_sharding, orig_s), False))
       except:
         out.append((o, from_xla))
     else:
@@ -2449,20 +2454,22 @@ def _get_out_sharding_from_orig_sharding(
   return out
 
 def maybe_get_orig_out_sharding(
-    in_shardings, out_shardings, are_out_shardings_from_xla):
+    in_shardings, out_shardings, are_out_shardings_from_xla, in_avals):
   if all(hasattr(o, '_original_sharding') for o in out_shardings):
     return ([o._original_sharding for o in out_shardings],
             (False,) * len(out_shardings))
 
   orig_s = None
-  for i in in_shardings:
+  orig_aval = None
+  for i, aval in safe_zip(in_shardings, in_avals):
     oi = getattr(i, '_original_sharding', None)
     if type(oi) in orig_out_sharding_handlers:
       orig_s = oi
+      orig_aval = aval
       break
   if orig_s is not None:
     return zip(*_get_out_sharding_from_orig_sharding(
-        out_shardings, orig_s, are_out_shardings_from_xla))
+        out_shardings, orig_s, orig_aval, are_out_shardings_from_xla))
 
   return out_shardings, are_out_shardings_from_xla
 
@@ -2675,7 +2682,8 @@ class UnloadedMeshExecutable:
           xla_executable.local_devices(), len(in_shardings), len(out_shardings))
 
     out_shardings, are_out_shardings_from_xla = maybe_get_orig_out_sharding(
-        in_shardings, out_shardings, are_out_shardings_from_xla)
+        in_shardings, out_shardings, are_out_shardings_from_xla,
+        global_in_avals)
 
     return UnloadedMeshExecutable(
         xla_executable=xla_executable,
diff --git a/jax/_src/pjit.py b/jax/_src/pjit.py
index ba281861c..ea23e2e4d 100644
--- a/jax/_src/pjit.py
+++ b/jax/_src/pjit.py
@@ -1374,7 +1374,7 @@ def _pjit_batcher_for_sharding(
     new_gs = GSPMDSharding(s._device_assignment, new_op)  # type: ignore
     if hasattr(s, '_original_sharding'):
       vmapped_s, _ = pxla._get_out_sharding_from_orig_sharding(
-          [new_gs], s._original_sharding, [False])[0]  # type: ignore
+          [new_gs], s._original_sharding, None, [False])[0]  # type: ignore
       new_gs = to_gspmd_sharding(vmapped_s, ndim)
     return new_gs
   else:
diff --git a/jax/_src/sharding_impls.py b/jax/_src/sharding_impls.py
index 003daf56e..46386b6a8 100644
--- a/jax/_src/sharding_impls.py
+++ b/jax/_src/sharding_impls.py
@@ -1167,6 +1167,7 @@ def parse_flatten_op_sharding(op_sharding: xc.OpSharding,
         raise NotImplementedError(""Unhandled OpSharding type. Please open a bug report!"")
     if replicate_on_last_tile_dim:
       partitions = partitions[:-1]
-    return [ParsedPartitionSpec('<internally generated spec>', partitions)]
+    return [CanonicalizedParsedPartitionSpec(
+        ParsedPartitionSpec('<internally generated spec>', partitions))]
   else:
     raise AssertionError(""Unhandled OpSharding type. Please open a bug report!"")
diff --git a/tests/pjit_test.py b/tests/pjit_test.py
index da455227b..9016610fc 100644
--- a/tests/pjit_test.py
+++ b/tests/pjit_test.py
@@ -3311,6 +3311,13 @@ class ArrayPjitTest(jtu.JaxTestCase):
     # and 2 in _array_shard_arg.
     self.assertEqual(cache_info2.misses, cache_info1.misses + 4)
 
+  def test_same_named_sharding_pspec_on_eager_ops(self):
+    mesh = jtu.create_global_mesh((1, 8, 1), ('x', 'y', 'z'))
+    sharding = jax.sharding.NamedSharding(mesh, P('x', 'y', 'z'))
+    x = jax.device_put(jnp.arange(32).reshape(1, -1, 1), sharding)
+    y = x + 1
+    self.assertEqual(x.sharding, y.sharding)
+
 
 class TempSharding(Sharding):
 
@@ -3660,6 +3667,8 @@ class UtilTest(jtu.JaxTestCase):
       spec = [()] * dims
       for axis in rng.permutation(mesh_axes)[:rng.randint(low=1, high=len(mesh_axes) + 1)]:
         spec[rng.choice(dims)] += (axis,)
+      while spec and spec[-1] == ():
+        spec.pop()
       roundtrip(P(*spec))
 
   @parameterized.named_parameters(","['tests/pjit_test.py', 'jax/_src/sharding_impls.py', 'jax/_src/interpreters/pxla.py', 'jax/_src/pjit.py']",{'.py': 4},4,0,0,4,4,4890791,1295680,125058,361,1375,381,25,3,2223,255,620,82,0,2,2023-04-30 00:08:43,24081,Python,"{'Python': 9536039, 'C++': 383667, 'Starlark': 129993, 'Jupyter Notebook': 91501, 'C': 28407, 'Shell': 14183, 'MAXScript': 4037, 'Dockerfile': 1514}",Apache License 2.0,"['jax/sharding.py', 'jax/_src/lax/control_flow/loops.py', 'jax/_src/lax/lax.py', 'jax/_src/lax/control_flow/conditionals.py']","['jax/sharding.py', 'jax/_src/lax/control_flow/loops.py', 'jax/_src/lax/lax.py', 'jax/_src/lax/control_flow/conditionals.py']","['```json\n{\n  ""files"": [\n    ""jax/sharding.py"",\n    ""jax/_src/lax/control_flow/loops.py"",\n    ""jax/_src/lax/control_flow/conditionals.py"",\n    ""jax/_src/lax/lax.py""\n  ]\n}\n```']",1,1302.6995658874512
7536,google/jax/1039/1033,google,jax,https://github.com/google/jax/issues/1033,https://github.com/google/jax/pull/1039,https://github.com/google/jax/pull/1039#issuecomment-513342622,2,fixes,"jax.random.fold_in function is using static_argnum=(1,)","Currently, the implementation of `jax.random.fold_in` function treats second argument `data` as static:
https://github.com/google/jax/blob/4c34541c00c02fa750b63a6ea9149909e6c4078f/jax/random.py#L193
Is that the intended behavior? 
If I understand correctly, it means, for instance, that innocent-looking loops of sort:
```python
base_key = jax.random.PRNGKey(0)
for i in range(N): 
   do_something_random(jax.random.fold_in(base_key, i))
```
cause fold_in to recompile at every iteration of the loop and take a lot of time. 
On the other hand, if we jit-compile `fold_in` function, things seem to work correctly and fast; like in this gist (thanks @christopherhesse): 
https://gist.github.com/christopherhesse/f493e516b7786533d76c3ef689cb6a45
Should that be the default behavior? ",e71680212fac51bf5c2d13847d9967cb4d0feffa,8985d684a1b6dee1ec6e0a7a29683a3e0f9d979d,https://github.com/google/jax/compare/e71680212fac51bf5c2d13847d9967cb4d0feffa...8985d684a1b6dee1ec6e0a7a29683a3e0f9d979d,"diff --git a/jax/random.py b/jax/random.py
index 551cd8b3d..3203cd949 100644
--- a/jax/random.py
+++ b/jax/random.py
@@ -190,7 +190,7 @@ def fold_in(key, data):
   """"""
   return _fold_in(key, data)
 
-@partial(jit, static_argnums=(1,))
+@jit
 def _fold_in(key, data):
   key2 = lax.tie_in(key, PRNGKey(data))
   return threefry_2x32(key, key2)",['jax/random.py'],{'.py': 1},1,0,0,1,1,888447,239574,24660,78,41,15,2,1,792,87,220,13,2,1,2019-07-19 19:05:59,24081,Python,"{'Python': 9536039, 'C++': 383667, 'Starlark': 129993, 'Jupyter Notebook': 91501, 'C': 28407, 'Shell': 14183, 'MAXScript': 4037, 'Dockerfile': 1514}",Apache License 2.0,['jax/random.py'],['jax/random.py'],"['```json\n{\n  ""files"": [\n    ""jax/random.py""\n  ]\n}\n```']",1,615.9429550170898
4064,pypa/pipenv/1767/1750,pypa,pipenv,https://github.com/pypa/pipenv/issues/1750,https://github.com/pypa/pipenv/pull/1767,https://github.com/pypa/pipenv/pull/1767,1,fixes,Pipenv clean fails if venv doesn't exist,"

<details><summary>$ python -m pipenv.help output</summary>
Pipenv version: `'11.7.1'`

Pipenv location: `'/usr/local/Cellar/pipenv/11.7.1/libexec/lib/python3.6/site-packages/pipenv'`

Python location: `'/usr/local/Cellar/pipenv/11.7.1/libexec/bin/python'`

Other Python installations in `PATH`:

  - `2.7`: `/usr/bin/python2.7`
  - `2.7`: `/usr/bin/python2.7`
  - `3.6`: `/usr/local/bin/python3.6m`
  - `3.6`: `/usr/local/Cellar/pipenv/11.7.1/libexec/bin/python3.6`
  - `3.6`: `/usr/local/bin/python3.6`
  - `3.6`: `/usr/local/bin/python3.6`

  - `3.6.4`: `/usr/local/Cellar/pipenv/11.7.1/libexec/bin/python`
  - `2.7.10`: `/usr/bin/python`
  - `3.6.4`: `/usr/local/Cellar/pipenv/11.7.1/libexec/bin/python3`
  - `3.6.4`: `/usr/local/bin/python3`
  - `3.6.4`: `/usr/local/bin/python3`

PEP 508 Information:

```
{'implementation_name': 'cpython',
 'implementation_version': '3.6.4',
 'os_name': 'posix',
 'platform_machine': 'x86_64',
 'platform_python_implementation': 'CPython',
 'platform_release': '17.4.0',
 'platform_system': 'Darwin',
 'platform_version': 'Darwin Kernel Version 17.4.0: Sun Dec 17 09:19:54 PST '
                     '2017; root:xnu-4570.41.2~1/RELEASE_X86_64',
 'python_full_version': '3.6.4',
 'python_version': '3.6',
 'sys_platform': 'darwin'}
```

System environment variables:

  - `LDFLAGS`
  - `VIRTUALENVWRAPPER_SCRIPT`
  - `VIRTUALENVWRAPPER_PROJECT_FILENAME`
  - `TERM_PROGRAM`
  - `NVM_CD_FLAGS`
  - `TERM`
  - `SHELL`
  - `HISTSIZE`
  - `CPPFLAGS`
  - `TMPDIR`
  - `Apple_PubSub_Socket_Render`
  - `TERM_PROGRAM_VERSION`
  - `OLDPWD`
  - `TERM_SESSION_ID`
  - `LC_ALL`
  - `NVM_DIR`
  - `USER`
  - `CROSS_ACCOUNT_STACK_AWS_PROFILE_NAME_BBM_MASTER`
  - `COMMAND_MODE`
  - `SSH_AUTH_SOCK`
  - `__CF_USER_TEXT_ENCODING`
  - `FAB_COMPLETION_CACHE_TASKS`
  - `VIRTUAL_ENV`
  - `WORKON_HOME`
  - `PROJECT_HOME`
  - `VIRTUALENVWRAPPER_PYTHON`
  - `NPM_TOKEN`
  - `PATH`
  - `WERKZEUG_DEBUG_PIN`
  - `VIRTUALENVWRAPPER_HOOK_DIR`
  - `PWD`
  - `LANG`
  - `ITERM_PROFILE`
  - `XPC_FLAGS`
  - `PS1`
  - `FAB_COMPLETION_CACHED_TASKS_FILENAME`
  - `PYTEST_ADDOPTS`
  - `HISTCONTROL`
  - `XPC_SERVICE_NAME`
  - `SHLVL`
  - `HOME`
  - `COLORFGBG`
  - `CFLAGS`
  - `ITERM_SESSION_ID`
  - `LOGNAME`
  - `LC_CTYPE`
  - `PKG_CONFIG_PATH`
  - `PROMPT_COMMAND`
  - `VIRTUALENVWRAPPER_WORKON_CD`
  - `EXTRA_CFLAGS`
  - `SECURITYSESSIONID`
  - `EXTRA_LDFLAGS`
  - `COLORTERM`
  - `_`
  - `PIP_PYTHON_PATH`
  - `PYTHONUNBUFFERED`

Pipenv–specific environment variables:


Debug–specific environment variables:

  - `PATH`: `/usr/local/Cellar/pipenv/11.7.1/libexec/bin:/Users/craig/.yarn/bin:/Users/craig/.local/bin:/usr/local/opt/openssl/bin:/usr/local/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin`
  - `SHELL`: `/bin/bash`
  - `LANG`: `en_GB.UTF-8`
  - `PWD`: `/tmp`
  - `VIRTUAL_ENV`: `/usr/local/Cellar/pipenv/11.7.1/libexec`


---------------------------

Contents of `Pipfile` ('/private/tmp/Pipfile'):

```toml
[[source]]

url = ""https://pypi.python.org/simple""
verify_ssl = true
name = ""pypi""


[packages]

requests = ""*""


[dev-packages]



[requires]

python_version = ""3.6""

```


Contents of `Pipfile.lock` ('/private/tmp/Pipfile.lock'):

```json
{
    ""_meta"": {
        ""hash"": {
            ""sha256"": ""33a0ec7c8e3bae6f62dd618f847de92ece20e2bd4efb496927e2524b9c7b8df8""
        },
        ""pipfile-spec"": 6,
        ""requires"": {
            ""python_version"": ""3.6""
        },
        ""sources"": [
            {
                ""name"": ""pypi"",
                ""url"": ""https://pypi.python.org/simple"",
                ""verify_ssl"": true
            }
        ]
    },
    ""default"": {
        ""certifi"": {
            ""hashes"": [
                ""sha256:14131608ad2fd56836d33a71ee60fa1c82bc9d2c8d98b7bdbc631fe1b3cd1296"",
                ""sha256:edbc3f203427eef571f79a7692bb160a2b0f7ccaa31953e99bd17e307cf63f7d""
            ],
            ""version"": ""==2018.1.18""
        },
        ""chardet"": {
            ""hashes"": [
                ""sha256:84ab92ed1c4d4f16916e05906b6b75a6c0fb5db821cc65e70cbd64a3e2a5eaae"",
                ""sha256:fc323ffcaeaed0e0a02bf4d117757b98aed530d9ed4531e3e15460124c106691""
            ],
            ""version"": ""==3.0.4""
        },
        ""idna"": {
            ""hashes"": [
                ""sha256:2c6a5de3089009e3da7c5dde64a141dbc8551d5b7f6cf4ed7c2568d0cc520a8f"",
                ""sha256:8c7309c718f94b3a625cb648ace320157ad16ff131ae0af362c9f21b80ef6ec4""
            ],
            ""version"": ""==2.6""
        },
        ""requests"": {
            ""hashes"": [
                ""sha256:6a1b267aa90cac58ac3a765d067950e7dbbf75b1da07e895d1f594193a40a38b"",
                ""sha256:9c443e7324ba5b85070c4a818ade28bfabedf16ea10206da1132edaa6dda237e""
            ],
            ""index"": ""pypi"",
            ""version"": ""==2.18.4""
        },
        ""urllib3"": {
            ""hashes"": [
                ""sha256:06330f386d6e4b195fbfc736b297f58c5a892e4440e54d294d7004e3a9bbea1b"",
                ""sha256:cc44da8e1145637334317feebd728bd869a35285b93cbb4cca2577da7e62db4f""
            ],
            ""version"": ""==1.22""
        }
    },
    ""develop"": {}
}

```
</details>
------------

##### Expected result

`pipenv clean` exist successfully. Virtualenv is created.

##### Actual result

```
craig@amogato2:/tmp
$ pipenv clean
Creating a virtualenv for this project…
Using /usr/local/bin/python3.6m (3.6.4) to create virtualenv…
⠋Running virtualenv with interpreter /usr/local/bin/python3.6m
Using base prefix '/usr/local/Cellar/python/3.6.4_4/Frameworks/Python.framework/Versions/3.6'
New python executable in /Users/craig/.virtualenvs/tmp-agwWamBd/bin/python3.6
Also creating executable in /Users/craig/.virtualenvs/tmp-agwWamBd/bin/python
Installing setuptools, pip, wheel...done.

Virtualenv location: /Users/craig/.virtualenvs/tmp-agwWamBd
Traceback (most recent call last):
  File ""/usr/local/Cellar/pipenv/11.7.1/libexec/bin/pipenv"", line 11, in <module>
    load_entry_point('pipenv==11.7.1', 'console_scripts', 'pipenv')()
  File ""/usr/local/Cellar/pipenv/11.7.1/libexec/lib/python3.6/site-packages/pipenv/vendor/click/core.py"", line 722, in __call__
    return self.main(*args, **kwargs)
  File ""/usr/local/Cellar/pipenv/11.7.1/libexec/lib/python3.6/site-packages/pipenv/vendor/click/core.py"", line 697, in main
    rv = self.invoke(ctx)
  File ""/usr/local/Cellar/pipenv/11.7.1/libexec/lib/python3.6/site-packages/pipenv/vendor/click/core.py"", line 1066, in invoke
    return _process_result(sub_ctx.command.invoke(sub_ctx))
  File ""/usr/local/Cellar/pipenv/11.7.1/libexec/lib/python3.6/site-packages/pipenv/vendor/click/core.py"", line 895, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File ""/usr/local/Cellar/pipenv/11.7.1/libexec/lib/python3.6/site-packages/pipenv/vendor/click/core.py"", line 535, in invoke
    return callback(*args, **kwargs)
  File ""/usr/local/Cellar/pipenv/11.7.1/libexec/lib/python3.6/site-packages/pipenv/vendor/click/decorators.py"", line 17, in new_func
    return f(get_current_context(), *args, **kwargs)
  File ""/usr/local/Cellar/pipenv/11.7.1/libexec/lib/python3.6/site-packages/pipenv/cli.py"", line 459, in clean
    ctx=ctx, three=three, python=python, dry_run=dry_run, verbose=verbose
  File ""/usr/local/Cellar/pipenv/11.7.1/libexec/lib/python3.6/site-packages/pipenv/core.py"", line 2451, in do_clean
    r = get_requirement(installed)
  File ""/usr/local/Cellar/pipenv/11.7.1/libexec/lib/python3.6/site-packages/pipenv/utils.py"", line 128, in get_requirement
    req = [r for r in requirements.parse(dep)][0]
IndexError: list index out of range
```

##### Steps to replicate

```
$ cd /tmp
$ mkdir clean-bug
$ cd clean-bug
$ pipenv install requests
$ pipenv --rm
$ pipenv clean
```
",fce2214e644e371b4438692f919d036f0fa5fbbb,c7e1abab2421bbe2f35b81b3f26b198e7a40c30b,https://github.com/pypa/pipenv/compare/fce2214e644e371b4438692f919d036f0fa5fbbb...c7e1abab2421bbe2f35b81b3f26b198e7a40c30b,"diff --git a/pipenv/core.py b/pipenv/core.py
index 3e307c40..7b4d2392 100644
--- a/pipenv/core.py
+++ b/pipenv/core.py
@@ -2523,12 +2523,12 @@ def do_clean(
     # Ensure that virtualenv is available.
     ensure_project(three=three, python=python, validate=False)
     ensure_lockfile()
-    installed_packages = delegator.run(
+    installed_packages = filter(None, delegator.run(
         '{0} freeze'.format(which('pip'))
     ).out.strip(
     ).split(
         '\\n'
-    )
+    ))
     installed_package_names = []
     for installed in installed_packages:
         r = get_requirement(installed)
diff --git a/tests/test_pipenv.py b/tests/test_pipenv.py
index 5cb012c1..110bd68e 100644
--- a/tests/test_pipenv.py
+++ b/tests/test_pipenv.py
@@ -1051,3 +1051,9 @@ requests = ""==2.14.0""
             assert target_package in p.pipfile['packages']
             assert p.pipfile['packages'][target_package] == '*'
             assert target_package in p.lockfile['default']
+
+    @pytest.mark.clean
+    def test_clean_on_empty_venv(self, pypi):
+        with PipenvInstance(pypi=pypi) as p:
+            c = p.pipenv('clean')
+            assert c.return_code == 0","['pipenv/core.py', 'tests/test_pipenv.py']",{'.py': 2},2,0,0,2,2,10855118,3994173,251015,811,109,23,4,1,7939,534,2659,258,2,5,2018-03-16 21:00:43,24012,Python,"{'Python': 8914203, 'Makefile': 6931, 'Roff': 2560, 'Shell': 1816, 'HTML': 1343, 'Batchfile': 325, 'Dockerfile': 99}",MIT License,"['pipenv/core.py', 'Pipfile.lock', 'pipenv/utils.py', 'Pipfile']","['pipenv/core.py', 'pipenv/utils.py']","['```json\n{\n  ""files"": [\n    ""pipenv/core.py"",\n    ""pipenv/utils.py"",\n    ""Pipfile"",\n    ""Pipfile.lock""\n  ]\n}\n```']",1,1431.891918182373
4805,stevenblack/hosts/112/107,stevenblack,hosts,https://github.com/StevenBlack/hosts/issues/107,https://github.com/StevenBlack/hosts/pull/112,https://github.com/StevenBlack/hosts/pull/112,1,fixes,"script run with --noupdate should not ask ""Do you want to update all data sources?""","> python updateHostsFile.py -n
> ←[94mDo you want to update all data sources?←[0m [Y/n]

the culprit is

> response = ""yes"" if auto else query_yes_no(""Do you want to update all data sources?"")
>     if response == ""yes"" and update:

query_yes_no should not be asked for update=False set by `update = not args.noUpdate`
",e993e7e82b33f4655d16f15bb3b16699158a61c1,4ce0fbdf3fe0a04764020fad14ecf0572e8ec469,https://github.com/stevenblack/hosts/compare/e993e7e82b33f4655d16f15bb3b16699158a61c1...4ce0fbdf3fe0a04764020fad14ecf0572e8ec469,"diff --git a/updateHostsFile.py b/updateHostsFile.py
index dda1b51d..a8ae555d 100644
--- a/updateHostsFile.py
+++ b/updateHostsFile.py
@@ -146,8 +146,11 @@ def promptForUpdate():
         except:
             printFailure(""ERROR: No 'hosts' file in the folder, try creating one manually"")
 
+    if not update:
+        return
+
     response = ""yes"" if auto else query_yes_no(""Do you want to update all data sources?"")
-    if response == ""yes"" and update:
+    if response == ""yes"":
         updateAllSources()
     else:
         if not auto:",['updateHostsFile.py'],{'.py': 1},1,0,0,1,1,19078,4528,509,1,102,25,5,1,319,52,89,10,0,0,2016-03-18 20:27:28,23591,Python,"{'Python': 135000, 'Batchfile': 2850, 'Shell': 1830, 'Nix': 1703, 'Dockerfile': 207}",MIT License,['updateHostsFile.py'],['updateHostsFile.py'],"['```json\n{\n  ""files"": [""updateHostsFile.py""]\n}\n```']",1,1486.5334033966064
9407,openbb-finance/openbbterminal/410/409,openbb-finance,openbbterminal,https://github.com/OpenBB-finance/OpenBBTerminal/issues/409,https://github.com/OpenBB-finance/OpenBBTerminal/pull/410,https://github.com/OpenBB-finance/OpenBBTerminal/issues/409#issuecomment-828049737,2,closed,[Bug] Error generating notebook DD,"**Describe the bug**
```
---------------------------------------------------------------------------
Exception encountered at ""In [12]"":
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-12-09e82de1763f> in <module>
----> 1 mw.prepare_df_financials(ticker, ""income"")

~\\Documents\\PY-Projects\\GamestonkTerminal\\gamestonk_terminal\\fundamental_analysis\\market_watch_model.py in prepare_df_financials(ticker, statement, quarter)
     75     s_header_end_trend = (""5-year trend"", ""5- qtr trend"")[quarter]
     76     df_financials = pd.DataFrame(
---> 77         columns=a_financials_header[0 : a_financials_header.index(s_header_end_trend)]
     78     )
     79

ValueError: '5-year trend' is not in list
```

**To Reproduce**
```
mill
dd -t HYLN
```

**Desktop (please complete the following information):**
 - OS: Windows
 - Python version 3.6.8
",ed113cf95819596362e8f5b4e84525867cebf900,11308e653ec46789ca3e2c835ddeb76268ff659d,https://github.com/openbb-finance/openbbterminal/compare/ed113cf95819596362e8f5b4e84525867cebf900...11308e653ec46789ca3e2c835ddeb76268ff659d,"diff --git a/gamestonk_terminal/fundamental_analysis/market_watch_model.py b/gamestonk_terminal/fundamental_analysis/market_watch_model.py
index fc1715949d..0d55d1d761 100644
--- a/gamestonk_terminal/fundamental_analysis/market_watch_model.py
+++ b/gamestonk_terminal/fundamental_analysis/market_watch_model.py
@@ -73,6 +73,10 @@ def prepare_df_financials(
         a_financials_header.append(financials_header.text.strip(""\\n"").split(""\\n"")[0])
 
     s_header_end_trend = (""5-year trend"", ""5- qtr trend"")[quarter]
+
+    if s_header_end_trend not in a_financials_header:
+        return pd.DataFrame()
+
     df_financials = pd.DataFrame(
         columns=a_financials_header[0 : a_financials_header.index(s_header_end_trend)]
     )
diff --git a/gamestonk_terminal/fundamental_analysis/market_watch_view.py b/gamestonk_terminal/fundamental_analysis/market_watch_view.py
index 795f88e7b7..e8e86aa376 100644
--- a/gamestonk_terminal/fundamental_analysis/market_watch_view.py
+++ b/gamestonk_terminal/fundamental_analysis/market_watch_view.py
@@ -73,7 +73,10 @@ def income(other_args: List[str], ticker: str):
             pd.set_option(""display.max_colwidth"", None)
             pd.set_option(""display.max_rows"", None)
 
-        print(df_financials.to_string(index=False))
+        if df_financials.empty:
+            print(""Marketwatch does not yet provide financials for this ticker"")
+        else:
+            print(df_financials.to_string(index=False))
         print("""")
 
     except Exception as e:
@@ -155,7 +158,10 @@ def balance(other_args: List[str], ticker: str):
             pd.set_option(""display.max_colwidth"", None)
             pd.set_option(""display.max_rows"", None)
 
-        print(df_financials.to_string(index=False))
+        if df_financials.empty:
+            print(""Marketwatch does not yet provide financials for this ticker"")
+        else:
+            print(df_financials.to_string(index=False))
         print("""")
 
     except Exception as e:
@@ -233,7 +239,10 @@ def cash(other_args: List[str], ticker: str):
             pd.set_option(""display.max_colwidth"", None)
             pd.set_option(""display.max_rows"", None)
 
-        print(df_financials.to_string(index=False))
+        if df_financials.empty:
+            print(""Marketwatch does not yet provide financials for this ticker"")
+        else:
+            print(df_financials.to_string(index=False))
         print("""")
 
     except Exception as e:","['gamestonk_terminal/fundamental_analysis/market_watch_model.py', 'gamestonk_terminal/fundamental_analysis/market_watch_view.py']",{'.py': 2},2,0,0,2,2,819117,183774,26287,130,808,165,19,2,990,78,233,29,0,2,2021-04-27 22:41:11,23053,Python,{'Python': 7763186},MIT License,['gamestonk_terminal/fundamental_analysis/market_watch_model.py'],['gamestonk_terminal/fundamental_analysis/market_watch_model.py'],"['```json\n{\n  ""files"": [\n    ""gamestonk_terminal/fundamental_analysis/market_watch_model.py""\n  ]\n}\n```']",1,1216.334581375122
9247,textualize/textual/1653/1634,textualize,textual,https://github.com/Textualize/textual/issues/1634,https://github.com/Textualize/textual/pull/1653,https://github.com/Textualize/textual/pull/1653,1,fixes,"Removing a widget from an action, when it initiated the action, causes the app to hang","The following code may be a little convoluted in that it's using `@click` from inside a renderable, this started out as an investigation as to why dependency links in [PISpy](https://github.com/davep/pispy) were hanging the application after upgrading Textual to 0.10.1 -- when I get a moment I'll see if I can reduce it the the smallest recreation possible.

Anyway, given this:

```python
from textual.app        import App, ComposeResult
from textual.containers import Vertical
from textual.widgets    import Header, Footer, Label

class Output( Vertical ):

    async def clear( self ) -> None:
        await self.query( ""*"" ).remove()

    async def populate( self ) -> None:
        await self.clear()
        await self.mount( *[
            Label( f""[@click=app.populate]Repopulate this widget[/] {n}"")
            for n in range( 20 )
        ] )

    async def on_mount( self ) -> None:
        await self.populate()

class AsyncClickApp( App[ None ] ):

    def compose( self ) -> ComposeResult:
        yield Header()
        yield Output()
        yield Footer()

    async def action_populate( self ) -> None:
        await self.query_one( Output ).populate()

if __name__ == ""__main__"":
    AsyncClickApp().run()
```

Clicking on any of the links causes the application to hang with 0.10.1. If I run this with 0.9.1 it works fine, clearing the `Vertical` of its content and repopulating it.",2662e6b2923d0f5aad8abff1281d463036e7d3d0,aba2633f4457992e42160bdbb092706373c8a728,https://github.com/textualize/textual/compare/2662e6b2923d0f5aad8abff1281d463036e7d3d0...aba2633f4457992e42160bdbb092706373c8a728,"diff --git a/src/textual/_context.py b/src/textual/_context.py
index 04b264d33..625152a95 100644
--- a/src/textual/_context.py
+++ b/src/textual/_context.py
@@ -4,6 +4,7 @@ from contextvars import ContextVar
 
 if TYPE_CHECKING:
     from .app import App
+    from .message_pump import MessagePump
 
 
 class NoActiveAppError(RuntimeError):
@@ -11,3 +12,4 @@ class NoActiveAppError(RuntimeError):
 
 
 active_app: ContextVar[""App""] = ContextVar(""active_app"")
+active_message_pump: ContextVar[""MessagePump""] = ContextVar(""active_message_pump"")
diff --git a/src/textual/app.py b/src/textual/app.py
index 068b94e0b..8712353e1 100644
--- a/src/textual/app.py
+++ b/src/textual/app.py
@@ -46,7 +46,7 @@ from ._animator import DEFAULT_EASING, Animatable, Animator, EasingFunction
 from ._ansi_sequences import SYNC_END, SYNC_START
 from ._asyncio import create_task
 from ._callback import invoke
-from ._context import active_app
+from ._context import active_app, active_message_pump
 from ._event_broker import NoHandler, extract_handler_actions
 from ._filter import LineFilter, Monochrome
 from ._path import _make_path_object_relative
@@ -1095,8 +1095,12 @@ class App(Generic[ReturnType], DOMNode):
 
         Args:
             *widgets: The widget(s) to mount.
-            before: Optional location to mount before.
-            after: Optional location to mount after.
+            before: Optional location to mount before. An `int` is the index
+                of the child to mount before, a `str` is a `query_one` query to
+                find the widget to mount before.
+            after: Optional location to mount after. An `int` is the index
+                of the child to mount after, a `str` is a `query_one` query to
+                find the widget to mount after.
 
         Returns:
             An awaitable object that waits for widgets to be mounted.
@@ -1113,6 +1117,7 @@ class App(Generic[ReturnType], DOMNode):
     def mount_all(
         self,
         widgets: Iterable[Widget],
+        *,
         before: int | str | Widget | None = None,
         after: int | str | Widget | None = None,
     ) -> AwaitMount:
@@ -1120,8 +1125,12 @@ class App(Generic[ReturnType], DOMNode):
 
         Args:
             widgets: An iterable of widgets.
-            before: Optional location to mount before.
-            after: Optional location to mount after.
+            before: Optional location to mount before. An `int` is the index
+                of the child to mount before, a `str` is a `query_one` query to
+                find the widget to mount before.
+            after: Optional location to mount after. An `int` is the index
+                of the child to mount after, a `str` is a `query_one` query to
+                find the widget to mount after.
 
         Returns:
             An awaitable object that waits for widgets to be mounted.
@@ -2103,7 +2112,7 @@ class App(Generic[ReturnType], DOMNode):
         """"""Remove nodes from DOM, and return an awaitable that awaits cleanup.
 
         Args:
-            widgets: List of nodes to remvoe.
+            widgets: List of nodes to remove.
 
         Returns:
             Awaitable that returns when the nodes have been fully removed.
@@ -2127,17 +2136,19 @@ class App(Generic[ReturnType], DOMNode):
         removed_widgets = self._detach_from_dom(widgets)
 
         finished_event = asyncio.Event()
-        create_task(
+        remove_task = create_task(
             prune_widgets_task(removed_widgets, finished_event), name=""prune nodes""
         )
 
-        return AwaitRemove(finished_event)
+        await_remove = AwaitRemove(finished_event, remove_task)
+        self.call_next(await_remove)
+        return await_remove
 
     async def _prune_nodes(self, widgets: list[Widget]) -> None:
         """"""Remove nodes and children.
 
         Args:
-            widgets: _description_
+            widgets: Widgets to remove.
         """"""
         async with self._dom_lock:
             for widget in widgets:
diff --git a/src/textual/await_remove.py b/src/textual/await_remove.py
index cd794d8c6..f8d61e3ff 100644
--- a/src/textual/await_remove.py
+++ b/src/textual/await_remove.py
@@ -1,19 +1,24 @@
 """"""Provides the type of an awaitable remove.""""""
 
-from asyncio import Event
+from asyncio import Event, Task
 from typing import Generator
 
 
 class AwaitRemove:
     """"""An awaitable returned by App.remove and DOMQuery.remove.""""""
 
-    def __init__(self, finished_flag: Event) -> None:
+    def __init__(self, finished_flag: Event, task: Task) -> None:
         """"""Initialise the instance of ``AwaitRemove``.
 
         Args:
             finished_flag: The asyncio event to wait on.
+            task: The task which does the remove (required to keep a reference).
         """"""
         self.finished_flag = finished_flag
+        self._task = task
+
+    async def __call__(self) -> None:
+        return await self
 
     def __await__(self) -> Generator[None, None, None]:
         async def await_prune() -> None:
diff --git a/src/textual/message_pump.py b/src/textual/message_pump.py
index 7cbaf2875..c469b381d 100644
--- a/src/textual/message_pump.py
+++ b/src/textual/message_pump.py
@@ -17,7 +17,7 @@ from weakref import WeakSet
 from . import Logger, events, log, messages
 from ._asyncio import create_task
 from ._callback import invoke
-from ._context import NoActiveAppError, active_app
+from ._context import NoActiveAppError, active_app, active_message_pump
 from ._time import time
 from .case import camel_to_snake
 from .errors import DuplicateKeyHandlers
@@ -313,12 +313,18 @@ class MessagePump(metaclass=MessagePumpMeta):
         Reactive._reset_object(self)
         await self._message_queue.put(None)
         if wait and self._task is not None and asyncio.current_task() != self._task:
-            # Ensure everything is closed before returning
-            await self._task
+            try:
+                running_widget = active_message_pump.get()
+            except LookupError:
+                running_widget = None
+
+            if running_widget is None or running_widget is not self:
+                await self._task
 
     def _start_messages(self) -> None:
         """"""Start messages task.""""""
         if self.app._running:
+            active_message_pump.set(self)
             self._task = create_task(
                 self._process_messages(), name=f""message pump {self}""
             )
@@ -357,7 +363,6 @@ class MessagePump(metaclass=MessagePumpMeta):
     async def _process_messages_loop(self) -> None:
         """"""Process messages until the queue is closed.""""""
         _rich_traceback_guard = True
-
         while not self._closed:
             try:
                 message = await self._get_message()
diff --git a/src/textual/widget.py b/src/textual/widget.py
index e6c9c2626..46708f6cd 100644
--- a/src/textual/widget.py
+++ b/src/textual/widget.py
@@ -618,6 +618,37 @@ class Widget(DOMNode):
         self.call_next(await_mount)
         return await_mount
 
+    def mount_all(
+        self,
+        widgets: Iterable[Widget],
+        *,
+        before: int | str | Widget | None = None,
+        after: int | str | Widget | None = None,
+    ) -> AwaitMount:
+        """"""Mount widgets from an iterable.
+
+        Args:
+            widgets: An iterable of widgets.
+            before: Optional location to mount before. An `int` is the index
+                of the child to mount before, a `str` is a `query_one` query to
+                find the widget to mount before.
+            after: Optional location to mount after. An `int` is the index
+                of the child to mount after, a `str` is a `query_one` query to
+                find the widget to mount after.
+
+        Returns:
+            An awaitable object that waits for widgets to be mounted.
+
+        Raises:
+            MountError: If there is a problem with the mount request.
+
+        Note:
+            Only one of ``before`` or ``after`` can be provided. If both are
+            provided a ``MountError`` will be raised.
+        """"""
+        await_mount = self.mount(*widgets, before=before, after=after)
+        return await_mount
+
     def move_child(
         self,
         child: int | Widget,
diff --git a/tests/test_widget.py b/tests/test_widget.py
index e3c0a618c..a06cf7857 100644
--- a/tests/test_widget.py
+++ b/tests/test_widget.py
@@ -1,13 +1,12 @@
 import pytest
-import rich
 
 from textual._node_list import DuplicateIds
 from textual.app import App, ComposeResult
 from textual.css.errors import StyleValueError
 from textual.css.query import NoMatches
-from textual.dom import DOMNode
 from textual.geometry import Size
 from textual.widget import Widget, MountError
+from textual.widgets import Label
 
 
 @pytest.mark.parametrize(
@@ -157,3 +156,28 @@ def test_widget_mount_ids_must_be_unique_mounting_multiple_calls(parent):
     parent.mount(widget1)
     with pytest.raises(DuplicateIds):
         parent.mount(widget2)
+
+
+# Regression test for https://github.com/Textualize/textual/issues/1634
+async def test_remove():
+    class RemoveMeLabel(Label):
+        async def on_mount(self) -> None:
+            await self.action(""app.remove_all"")
+
+    class Container(Widget):
+        async def clear(self) -> None:
+            await self.query(""*"").remove()
+
+    class RemoveApp(App):
+        def compose(self) -> ComposeResult:
+            yield Container(RemoveMeLabel())
+
+        async def action_remove_all(self) -> None:
+            await self.query_one(Container).clear()
+            self.exit(123)
+
+    app = RemoveApp()
+    async with app.run_test() as pilot:
+        await pilot.press(""r"")
+        await pilot.pause()
+    assert app.return_value == 123","['src/textual/app.py', 'tests/test_widget.py', 'src/textual/await_remove.py', 'src/textual/message_pump.py', 'src/textual/_context.py', 'src/textual/widget.py']",{'.py': 6},6,0,0,6,6,1153631,256358,37005,313,3724,782,84,5,1443,191,343,39,1,1,2023-01-24 14:32:40,20292,Python,"{'Python': 2181885, 'Jinja': 11112, 'CSS': 6932, 'TypeScript': 4869, 'Makefile': 2083}",MIT License,"['src/textual/app.py', 'src/textual/widgets/_label.py', 'src/textual/widgets/_button.py']","['src/textual/app.py', 'src/textual/widgets/_label.py', 'src/textual/widgets/_button.py']","['```json\n{\n  ""files"": [\n    ""src/textual/widgets/_label.py"",\n    ""src/textual/widgets/_button.py"",\n    ""src/textual/app.py""\n  ]\n}\n```']",1,914.4761562347412
10048,jerryjliu/llama_index/6630/6629,jerryjliu,llama_index,https://github.com/jerryjliu/llama_index/issues/6629,https://github.com/jerryjliu/llama_index/pull/6630,https://github.com/jerryjliu/llama_index/pull/6630,1,fixes,[Bug]: Explicitly imported SimpleDirectoryReader does not add extra_info to parsed nodes,"### Bug Description

I am deploying an app based on Llamaindex inside of a docker container. I ran into a docker-related issue using the `download_loader()` to create a `SimpleDirectoryReader`:

``` python 
  # Create the GPTVectorStoreIndex
  logger.debug(f""Build index from {tempdir_path}"")
  SimpleDirectoryReader = download_loader(""SimpleDirectoryReader"")
  loader = SimpleDirectoryReader(
      tempdir_path, recursive=True, exclude_hidden=False
  )
  documents = loader.load_data()
  logger.debug(""Loaded..."")
```

The dynamic installation and loading of `SimpleDirectoryReader` worked as expected for the most part in a local container that has the local app directory as a read/write volume. After a query, the source node looks like this:

```
Node: ['__abstractmethods__', '__annotations__', '__class__', '__dataclass_fields__', '__dataclass_params__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__match_args__', '__module__', '__ne__', '__new__', '__post_init__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_generate_doc_hash', 'child_node_ids', 'dataclass_json_config', 'doc_hash', 'doc_id', 'embedding', 'extra_info', 'extra_info_str', 'from_dict', 'from_json', 'get_doc_hash', 'get_doc_id', 'get_embedding', 'get_node_info', 'get_origin_type', 'get_text', 'get_type', 'get_types', 'is_doc_id_none', 'is_text_none', 'next_node_id', 'node_info', 'parent_node_id', 'prev_node_id', 'ref_doc_id', 'relationships', 'schema', 'text', 'to_dict', 'to_json']
Extra info: {'file_name': 'NVCA-2020-Stock-Purchase-Agreement-1-September-1-2020_eVQ4P4y.docx'}
Node info: {'start': 56846, 'end': 60980, '_node_type': '1'}
[NVCA-2020-Stock-Purchase-Agreement-1-September-1-2020.docx](https://github.com/jerryjliu/llama_index/files/11899087/NVCA-2020-Stock-Purchase-Agreement-1-September-1-2020.docx)
```

**In production,** however, my Docker container does not have write access to the python install directory or packages dir,  *but* it appears loading the `SimpleDirectoryReader` using `download_loader` in this way tries to modify packages on the fly (not a huge surprise, but I hadn't considered this ahead of time). I didn't want to have the container modifying my Python packages dynamically for a) security reason and b) this has a performance penalty as the containers will be loaded and stopped repeatedly and so this install process needs to re-occur repeatedly, increasing latency and bandwidth costs. 

I tried to work around this by manually installing `llama-hub` when creating the container and then loading `SimpleDirectoryLoader` explicitly like so:

```python
from llama_index.readers.file.base import SimpleDirectoryReader

# Create the GPTVectorStoreIndex
logger.debug(f""Build index from {tempdir_path}"")
loader = SimpleDirectoryReader(
    tempdir_path, recursive=True, exclude_hidden=False
)
documents = loader.load_data()
logger.debug(""Loaded..."")
```

Now my docker issue is solved, there are no run time modifications of my python directory, **BUT** it appears the instantiated readers are no longer adding the `extra_info` metadata. Here's my logs related to the source nodes:

```
Node: ['__abstractmethods__', '__annotations__', '__class__', '__dataclass_fields__', '__dataclass_params__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__match_args__', '__module__', '__ne__', '__new__', '__post_init__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_generate_doc_hash', 'child_node_ids', 'dataclass_json_config', 'doc_hash', 'doc_id', 'embedding', 'extra_info', 'extra_info_str', 'from_dict', 'from_json', 'get_doc_hash', 'get_doc_id', 'get_embedding', 'get_node_info', 'get_origin_type', 'get_text', 'get_type', 'get_types', 'is_doc_id_none', 'is_text_none', 'next_node_id', 'node_info', 'parent_node_id', 'prev_node_id', 'ref_doc_id', 'relationships', 'schema', 'text', 'to_dict', 'to_json']
Extra info: None
Node info: {'start': 24890, 'end': 29195, '_node_type': '1'}
```

Any idea what's up here?



### Version

0.6.30

### Steps to Reproduce

Instantiate a SimpleDirectoryReader using download_loader() and load attached docx. `Extra_info` will be populated in returned queries' sources. 

Then, instantiate a SimpleDirectoryReader loaded via `from llama_index.readers.file.base import SimpleDirectoryReader`. Create an index with the same docx and run a query. No extra_info is attached to the response nodes. 

[NVCA-2020-Stock-Purchase-Agreement-1-September-1-2020.docx](https://github.com/jerryjliu/llama_index/files/11899174/NVCA-2020-Stock-Purchase-Agreement-1-September-1-2020.docx)


### Relevant Logs/Tracbacks

```shell
See above
```
",65ecd50cc522b9de0658f61823e5e24a4efa6c74,ced4f463d6120e103fa02d70d5a5695b2251706f,https://github.com/jerryjliu/llama_index/compare/65ecd50cc522b9de0658f61823e5e24a4efa6c74...ced4f463d6120e103fa02d70d5a5695b2251706f,"diff --git a/llama_index/readers/file/base.py b/llama_index/readers/file/base.py
index 8a3811c9..92faab7e 100644
--- a/llama_index/readers/file/base.py
+++ b/llama_index/readers/file/base.py
@@ -192,7 +192,7 @@ class SimpleDirectoryReader(BaseReader):
                     reader_cls = DEFAULT_FILE_READER_CLS[file_suffix]
                     self.file_extractor[file_suffix] = reader_cls()
                 reader = self.file_extractor[file_suffix]
-                docs = reader.load_data(input_file, metadata=metadata or {})
+                docs = reader.load_data(input_file, extra_info=metadata)
 
                 # iterate over docs if needed
                 if self.filename_as_id:
diff --git a/llama_index/readers/file/docs_reader.py b/llama_index/readers/file/docs_reader.py
index 40727945..05ab0246 100644
--- a/llama_index/readers/file/docs_reader.py
+++ b/llama_index/readers/file/docs_reader.py
@@ -13,7 +13,9 @@ from llama_index.schema import Document
 class PDFReader(BaseReader):
     """"""PDF parser.""""""
 
-    def load_data(self, file: Path, metadata: Optional[Dict] = None) -> List[Document]:
+    def load_data(
+        self, file: Path, extra_info: Optional[Dict] = None
+    ) -> List[Document]:
         """"""Parse file.""""""
         try:
             import pypdf
@@ -36,8 +38,8 @@ class PDFReader(BaseReader):
                 page_label = pdf.page_labels[page]
 
                 metadata = {""page_label"": page_label, ""file_name"": file.name}
-                if metadata is not None:
-                    metadata.update(metadata)
+                if extra_info is not None:
+                    metadata.update(extra_info)
 
                 docs.append(Document(text=page_text, metadata=metadata))
             return docs
@@ -46,7 +48,9 @@ class PDFReader(BaseReader):
 class DocxReader(BaseReader):
     """"""Docx parser.""""""
 
-    def load_data(self, file: Path, metadata: Optional[Dict] = None) -> List[Document]:
+    def load_data(
+        self, file: Path, extra_info: Optional[Dict] = None
+    ) -> List[Document]:
         """"""Parse file.""""""
         try:
             import docx2txt
@@ -58,7 +62,7 @@ class DocxReader(BaseReader):
 
         text = docx2txt.process(file)
         metadata = {""file_name"": file.name}
-        if metadata is not None:
-            metadata.update(metadata)
+        if extra_info is not None:
+            metadata.update(extra_info)
 
-        return [Document(text=text, metadata=metadata)]
+        return [Document(text=text, metadata=metadata or {})]
diff --git a/llama_index/readers/file/epub_reader.py b/llama_index/readers/file/epub_reader.py
index cb868fd8..b0967167 100644
--- a/llama_index/readers/file/epub_reader.py
+++ b/llama_index/readers/file/epub_reader.py
@@ -13,7 +13,9 @@ from llama_index.schema import Document
 class EpubReader(BaseReader):
     """"""Epub Parser.""""""
 
-    def load_data(self, file: Path, metadata: Optional[Dict] = None) -> List[Document]:
+    def load_data(
+        self, file: Path, extra_info: Optional[Dict] = None
+    ) -> List[Document]:
         """"""Parse file.""""""
         try:
             import ebooklib
@@ -38,4 +40,4 @@ class EpubReader(BaseReader):
                 )
 
         text = ""\\n"".join(text_list)
-        return [Document(text=text, metadata=metadata)]
+        return [Document(text=text, metadata=extra_info or {})]
diff --git a/llama_index/readers/file/image_caption_reader.py b/llama_index/readers/file/image_caption_reader.py
index ecce2f02..17092088 100644
--- a/llama_index/readers/file/image_caption_reader.py
+++ b/llama_index/readers/file/image_caption_reader.py
@@ -54,7 +54,9 @@ class ImageCaptionReader(BaseReader):
         self._keep_image = keep_image
         self._prompt = prompt
 
-    def load_data(self, file: Path, metadata: Optional[Dict] = None) -> List[Document]:
+    def load_data(
+        self, file: Path, extra_info: Optional[Dict] = None
+    ) -> List[Document]:
         """"""Parse file.""""""
         from PIL import Image
 
@@ -89,6 +91,6 @@ class ImageCaptionReader(BaseReader):
             ImageDocument(
                 text=text_str,
                 image=image_str,
-                metadata=metadata,
+                metadata=extra_info or {},
             )
         ]
diff --git a/llama_index/readers/file/image_reader.py b/llama_index/readers/file/image_reader.py
index 4fa0771f..3ef02b33 100644
--- a/llama_index/readers/file/image_reader.py
+++ b/llama_index/readers/file/image_reader.py
@@ -51,7 +51,9 @@ class ImageReader(BaseReader):
         self._keep_image = keep_image
         self._parse_text = parse_text
 
-    def load_data(self, file: Path, metadata: Optional[Dict] = None) -> List[Document]:
+    def load_data(
+        self, file: Path, extra_info: Optional[Dict] = None
+    ) -> List[Document]:
         """"""Parse file.""""""
         from PIL import Image
 
@@ -107,4 +109,6 @@ class ImageReader(BaseReader):
             # remove first task start token
             text_str = re.sub(r""<.*?>"", """", sequence, count=1).strip()
 
-        return [ImageDocument(text=text_str, image=image_str, metadata=metadata)]
+        return [
+            ImageDocument(text=text_str, image=image_str, metadata=extra_info or {})
+        ]
diff --git a/llama_index/readers/file/image_vision_llm_reader.py b/llama_index/readers/file/image_vision_llm_reader.py
index 0a521623..1cbe3957 100644
--- a/llama_index/readers/file/image_vision_llm_reader.py
+++ b/llama_index/readers/file/image_vision_llm_reader.py
@@ -50,7 +50,9 @@ class ImageVisionLLMReader(BaseReader):
         self._keep_image = keep_image
         self._prompt = prompt
 
-    def load_data(self, file: Path, metadata: Optional[Dict] = None) -> List[Document]:
+    def load_data(
+        self, file: Path, extra_info: Optional[Dict] = None
+    ) -> List[Document]:
         """"""Parse file.""""""
         from PIL import Image
 
@@ -85,6 +87,6 @@ class ImageVisionLLMReader(BaseReader):
             ImageDocument(
                 text=text_str,
                 image=image_str,
-                metadata=metadata,
+                metadata=extra_info or {},
             )
         ]
diff --git a/llama_index/readers/file/ipynb_reader.py b/llama_index/readers/file/ipynb_reader.py
index 40302b6f..0e1b145b 100644
--- a/llama_index/readers/file/ipynb_reader.py
+++ b/llama_index/readers/file/ipynb_reader.py
@@ -18,7 +18,9 @@ class IPYNBReader(BaseReader):
         self._parser_config = parser_config
         self._concatenate = concatenate
 
-    def load_data(self, file: Path, metadata: Optional[Dict] = None) -> List[Document]:
+    def load_data(
+        self, file: Path, extra_info: Optional[Dict] = None
+    ) -> List[Document]:
         """"""Parse file.""""""
 
         if file.name.endswith("".ipynb""):
@@ -33,7 +35,7 @@ class IPYNBReader(BaseReader):
         splits.pop(0)
 
         if self._concatenate:
-            docs = [Document(text=""\\n\\n"".join(splits), metadata=metadata)]
+            docs = [Document(text=""\\n\\n"".join(splits), metadata=extra_info or {})]
         else:
-            docs = [Document(text=s, metadata=metadata) for s in splits]
+            docs = [Document(text=s, metadata=extra_info or {}) for s in splits]
         return docs
diff --git a/llama_index/readers/file/markdown_reader.py b/llama_index/readers/file/markdown_reader.py
index 5c600222..5f9402dd 100644
--- a/llama_index/readers/file/markdown_reader.py
+++ b/llama_index/readers/file/markdown_reader.py
@@ -99,16 +99,18 @@ class MarkdownReader(BaseReader):
         markdown_tups = self.markdown_to_tups(content)
         return markdown_tups
 
-    def load_data(self, file: Path, metadata: Optional[Dict] = None) -> List[Document]:
+    def load_data(
+        self, file: Path, extra_info: Optional[Dict] = None
+    ) -> List[Document]:
         """"""Parse file into string.""""""
         tups = self.parse_tups(file)
         results = []
         # TODO: don't include headers right now
         for header, value in tups:
             if header is None:
-                results.append(Document(text=value, metadata=metadata or {}))
+                results.append(Document(text=value, metadata=extra_info or {}))
             else:
                 results.append(
-                    Document(text=f""\\n\\n{header}\\n{value}"", metadata=metadata or {})
+                    Document(text=f""\\n\\n{header}\\n{value}"", metadata=extra_info or {})
                 )
         return results
diff --git a/llama_index/readers/file/mbox_reader.py b/llama_index/readers/file/mbox_reader.py
index a2639517..2219b509 100644
--- a/llama_index/readers/file/mbox_reader.py
+++ b/llama_index/readers/file/mbox_reader.py
@@ -50,7 +50,9 @@ class MboxReader(BaseReader):
         self.max_count = max_count
         self.message_format = message_format
 
-    def load_data(self, file: Path, metadata: Optional[Dict] = None) -> List[Document]:
+    def load_data(
+        self, file: Path, extra_info: Optional[Dict] = None
+    ) -> List[Document]:
         """"""Parse file into string.""""""
         # Import required libraries
         import mailbox
@@ -102,4 +104,4 @@ class MboxReader(BaseReader):
             if self.max_count > 0 and i >= self.max_count:
                 break
 
-        return [Document(text=result, metadata=metadata) for result in results]
+        return [Document(text=result, metadata=extra_info or {}) for result in results]
diff --git a/llama_index/readers/file/slides_reader.py b/llama_index/readers/file/slides_reader.py
index 01b88dbd..ca9d12c3 100644
--- a/llama_index/readers/file/slides_reader.py
+++ b/llama_index/readers/file/slides_reader.py
@@ -86,7 +86,7 @@ class PptxReader(BaseReader):
     def load_data(
         self,
         file: Path,
-        metadata: Optional[Dict] = None,
+        extra_info: Optional[Dict] = None,
     ) -> List[Document]:
         """"""Parse file.""""""
         from pptx import Presentation
@@ -110,4 +110,4 @@ class PptxReader(BaseReader):
                 if hasattr(shape, ""text""):
                     result += f""{shape.text}\\n""
 
-        return [Document(text=result, metadata=metadata)]
+        return [Document(text=result, metadata=extra_info or {})]
diff --git a/llama_index/readers/file/tabular_reader.py b/llama_index/readers/file/tabular_reader.py
index bc7035a0..a9bf4484 100644
--- a/llama_index/readers/file/tabular_reader.py
+++ b/llama_index/readers/file/tabular_reader.py
@@ -27,7 +27,9 @@ class CSVReader(BaseReader):
         super().__init__(*args, **kwargs)
         self._concat_rows = concat_rows
 
-    def load_data(self, file: Path, metadata: Optional[Dict] = None) -> List[Document]:
+    def load_data(
+        self, file: Path, extra_info: Optional[Dict] = None
+    ) -> List[Document]:
         """"""Parse file.
 
         Returns:
@@ -44,9 +46,9 @@ class CSVReader(BaseReader):
             for row in csv_reader:
                 text_list.append("", "".join(row))
         if self._concat_rows:
-            return [Document(text=""\\n"".join(text_list), metadata=metadata)]
+            return [Document(text=""\\n"".join(text_list), metadata=extra_info)]
         else:
-            return [Document(text=text, metadata=metadata) for text in text_list]
+            return [Document(text=text, metadata=extra_info) for text in text_list]
 
 
 class PandasCSVReader(BaseReader):
@@ -91,7 +93,9 @@ class PandasCSVReader(BaseReader):
         self._row_joiner = row_joiner
         self._pandas_config = pandas_config
 
-    def load_data(self, file: Path, metadata: Optional[Dict] = None) -> List[Document]:
+    def load_data(
+        self, file: Path, extra_info: Optional[Dict] = None
+    ) -> List[Document]:
         """"""Parse file.""""""
         df = pd.read_csv(file, **self._pandas_config)
 
@@ -101,7 +105,11 @@ class PandasCSVReader(BaseReader):
 
         if self._concat_rows:
             return [
-                Document(text=(self._row_joiner).join(text_list), metadata=metadata)
+                Document(
+                    text=(self._row_joiner).join(text_list), metadata=extra_info or {}
+                )
             ]
         else:
-            return [Document(text=text, metadata=metadata) for text in text_list]
+            return [
+                Document(text=text, metadata=extra_info or {}) for text in text_list
+            ]
diff --git a/llama_index/readers/file/video_audio_reader.py b/llama_index/readers/file/video_audio_reader.py
index 459c1224..b783992d 100644
--- a/llama_index/readers/file/video_audio_reader.py
+++ b/llama_index/readers/file/video_audio_reader.py
@@ -35,7 +35,9 @@ class VideoAudioReader(BaseReader):
 
         self.parser_config = {""model"": model}
 
-    def load_data(self, file: Path, metadata: Optional[Dict] = None) -> List[Document]:
+    def load_data(
+        self, file: Path, extra_info: Optional[Dict] = None
+    ) -> List[Document]:
         """"""Parse file.""""""
         import whisper
 
@@ -59,4 +61,4 @@ class VideoAudioReader(BaseReader):
 
         transcript = result[""text""]
 
-        return [Document(text=transcript, metadata=metadata)]
+        return [Document(text=transcript, metadata=extra_info or {})]","['llama_index/readers/file/ipynb_reader.py', 'llama_index/readers/file/markdown_reader.py', 'llama_index/readers/file/docs_reader.py', 'llama_index/readers/file/tabular_reader.py', 'llama_index/readers/file/video_audio_reader.py', 'llama_index/readers/file/slides_reader.py', 'llama_index/readers/file/epub_reader.py', 'llama_index/readers/file/mbox_reader.py', 'llama_index/readers/file/base.py', 'llama_index/readers/file/image_vision_llm_reader.py', 'llama_index/readers/file/image_reader.py', 'llama_index/readers/file/image_caption_reader.py']",{'.py': 12},12,0,0,12,12,1400320,299024,41022,386,5339,1230,98,12,5102,493,1293,71,2,5,2023-06-28 19:34:22,19780,Python,"{'Python': 2082853, 'HTML': 730874, 'Jupyter Notebook': 24799, 'Shell': 1470, 'Makefile': 531}",MIT License,"['llama_index/readers/file/base.py', 'llama_index/readers/file/image_vision_llm_reader.py', 'llama_index/readers/file/image_caption_reader.py', 'llama_index/readers/file/image_reader.py', 'llama_index/readers/file/docs_reader.py']","['llama_index/readers/file/base.py', 'llama_index/readers/file/image_vision_llm_reader.py', 'llama_index/readers/file/image_caption_reader.py', 'llama_index/readers/file/image_reader.py', 'llama_index/readers/file/docs_reader.py']","['```json\n{\n  ""files"": [\n    ""llama_index/readers/file/base.py"",\n    ""llama_index/readers/file/docs_reader.py"",\n    ""llama_index/readers/file/image_caption_reader.py"",\n    ""llama_index/readers/file/image_reader.py"",\n    ""llama_index/readers/file/image_vision_llm_reader.py""\n  ]\n}\n```']",1,1418.518304824829
8658,wekan/wekan/3889/3884,wekan,wekan,https://github.com/wekan/wekan/issues/3884,https://github.com/wekan/wekan/pull/3889,https://github.com/wekan/wekan/pull/3889,2,fixes,Building OpenAPI docs is broken in Wekan v3.56,"Hi,
building OpenAPI docs is broken in upcoming Wekan v3.56. Maybe it's related to added tests?
https://github.com/wekan/wekan/blob/master/CHANGELOG.md
```
$ ./releases/rebuild-docs.sh 5.36
Traceback (most recent call last):
  File ""./openapi/generate_openapi.py"", line 1073, in <module>
    main()
  File ""./openapi/generate_openapi.py"", line 1068, in main
    schemas, entry_points = parse_schemas(args.dir)
  File ""./openapi/generate_openapi.py"", line 824, in parse_schemas
    program = context.program
AttributeError: 'NoneType' object has no attribute 'program'
✓ Read source file!
✗ Error during conversion via Widdershin:
Cannot read property 'swagger' of undefined
```

@bentiss can you look at this?",63605ee42e85d2e2e0beb1463cb1c18937724763,ebe39771a64069ff768123d6015ce2f184a8c8ed,https://github.com/wekan/wekan/compare/63605ee42e85d2e2e0beb1463cb1c18937724763...ebe39771a64069ff768123d6015ce2f184a8c8ed,"diff --git a/openapi/generate_openapi.py b/openapi/generate_openapi.py
index 9aed62e4f..4b6aa9a27 100644
--- a/openapi/generate_openapi.py
+++ b/openapi/generate_openapi.py
@@ -821,6 +821,11 @@ def parse_schemas(schemas_dir):
         for filename in files:
             path = os.path.join(root, filename)
             context = parse_file(path)
+
+            if context is None:
+              # the file doesn't contain a schema (see above)
+              continue
+
             program = context.program
 
             current_schema = None",['openapi/generate_openapi.py'],{'.py': 1},1,0,0,1,1,49174,10213,1366,2,123,23,5,1,727,82,195,19,1,1,2021-07-01 08:25:20,18686,JavaScript,"{'JavaScript': 1640920, 'HTML': 878060, 'Pug': 268407, 'CSS': 227502, 'Shell': 183619, 'Stylus': 147123, 'Python': 78609, 'Batchfile': 23763, 'Dockerfile': 18895, 'Perl': 11519, ""Cap'n Proto"": 9397, 'Mustache': 3280}",MIT License,['openapi/generate_openapi.py'],['openapi/generate_openapi.py'],"['```json\n{\n  ""files"": [\n    ""openapi/generate_openapi.py""\n  ]\n}\n```']",1,719.6431159973145
4706,sanic-org/sanic/1327/1323,sanic-org,sanic,https://github.com/sanic-org/sanic/issues/1323,https://github.com/sanic-org/sanic/pull/1327,https://github.com/sanic-org/sanic/pull/1327,1,fixes,Trouble with import conflict in request.py,"```
Traceback (most recent call last):
  File ""/env/lib/python3.6/site-packages/sanic/__main__.py"", line 4, in <module>
    from sanic.log import logger
  File ""/env/lib/python3.6/site-packages/sanic/__init__.py"", line 1, in <module>
    from sanic.app import Sanic
  File ""/env/lib/python3.6/site-packages/sanic/app.py"", line 21, in <module>
    from sanic.server import serve, serve_multiple, HttpProtocol, Signal
  File ""/env/lib/python3.6/site-packages/sanic/server.py"", line 31, in <module>
    from sanic.request import Request
  File ""/env/lib/python3.6/site-packages/sanic/request.py"", line 6, in <module>
    from http.cookies import SimpleCookie
ModuleNotFoundError: No module named 'http.cookies'; 'http' is not a package
```

It seems it tries to use sanic's `http.py` instead of the builtin Python library. The `http.py` itself is used only twice, in the `response.py` & `exceptions.py`.
Am I missing something and/or have something misconfigured? 
",04b8dd989f175935a8b86f791508d533c36f0212,f8a6af1e28c21d47617183b479d4be8adbd710bf,https://github.com/sanic-org/sanic/compare/04b8dd989f175935a8b86f791508d533c36f0212...f8a6af1e28c21d47617183b479d4be8adbd710bf,"diff --git a/sanic/exceptions.py b/sanic/exceptions.py
index 25dbd47d..e90dff7a 100644
--- a/sanic/exceptions.py
+++ b/sanic/exceptions.py
@@ -1,4 +1,4 @@
-from sanic.http import STATUS_CODES
+from sanic.helpers import STATUS_CODES
 
 TRACEBACK_STYLE = '''
     <style>
diff --git a/sanic/http.py b/sanic/helpers.py
similarity index 100%
rename from sanic/http.py
rename to sanic/helpers.py
diff --git a/sanic/response.py b/sanic/response.py
index f169b4f2..ed1df0f4 100644
--- a/sanic/response.py
+++ b/sanic/response.py
@@ -10,7 +10,7 @@ except BaseException:
 from aiofiles import open as open_async
 from multidict import CIMultiDict
 
-from sanic import http
+from sanic.helpers import STATUS_CODES, has_message_body, remove_entity_headers
 from sanic.cookies import CookieJar
 
 
@@ -103,7 +103,7 @@ class StreamingHTTPResponse(BaseHTTPResponse):
         if self.status is 200:
             status = b'OK'
         else:
-            status = http.STATUS_CODES.get(self.status)
+            status = STATUS_CODES.get(self.status)
 
         return (b'HTTP/%b %d %b\\r\\n'
                 b'%b'
@@ -141,7 +141,7 @@ class HTTPResponse(BaseHTTPResponse):
             timeout_header = b'Keep-Alive: %d\\r\\n' % keep_alive_timeout
 
         body = b''
-        if http.has_message_body(self.status):
+        if has_message_body(self.status):
             body = self.body
             self.headers['Content-Length'] = self.headers.get(
                 'Content-Length', len(self.body))
@@ -150,14 +150,14 @@ class HTTPResponse(BaseHTTPResponse):
                                        'Content-Type', self.content_type)
 
         if self.status in (304, 412):
-            self.headers = http.remove_entity_headers(self.headers)
+            self.headers = remove_entity_headers(self.headers)
 
         headers = self._parse_headers()
 
         if self.status is 200:
             status = b'OK'
         else:
-            status = http.STATUS_CODES.get(self.status, b'UNKNOWN RESPONSE')
+            status = STATUS_CODES.get(self.status, b'UNKNOWN RESPONSE')
 
         return (b'HTTP/%b %d %b\\r\\n'
                 b'Connection: %b\\r\\n'","['sanic/response.py', 'sanic/exceptions.py', 'sanic/http.py']",{'.py': 3},3,0,0,3,3,198663,41363,5910,45,664,124,12,3,979,104,258,18,0,1,2018-09-25 17:50:34,17218,Python,"{'Python': 1339120, 'CSS': 5887, 'Makefile': 2356, 'HTML': 1173, 'Go': 482, 'Dockerfile': 159}",MIT License,"['sanic/server.py', 'sanic/request.py', 'sanic/__init__.py', 'sanic/exceptions.py', 'sanic/response.py']","['sanic/server.py', 'sanic/request.py', 'sanic/__init__.py', 'sanic/exceptions.py', 'sanic/response.py']","['```json\n{\n  ""files"": [\n    ""sanic/request.py"",\n    ""sanic/response.py"",\n    ""sanic/exceptions.py"",\n    ""sanic/__init__.py"",\n    ""sanic/server.py""\n  ]\n}\n```']",1,1141.5867805480957
8258,huggingface/datasets/4828/4796,huggingface,datasets,https://github.com/huggingface/datasets/issues/4796,https://github.com/huggingface/datasets/pull/4828,https://github.com/huggingface/datasets/pull/4828,1,fix,ArrowInvalid: Could not convert <PIL.Image.Image image mode=RGB when adding image to Dataset,"## Describe the bug

When adding a Pillow image to an existing Dataset on the hub, `add_item` fails due to the Pillow image not being automatically converted into the Image feature.

## Steps to reproduce the bug
```python
from datasets import load_dataset
from PIL import Image

dataset = load_dataset(""hf-internal-testing/example-documents"")

# load any random Pillow image
image = Image.open(""/content/cord_example.png"").convert(""RGB"")

new_image = {'image': image}
dataset['test'] = dataset['test'].add_item(new_image)
```

## Expected results
The image should be automatically casted to the Image feature when using `add_item`. For now, this can be fixed by using `encode_example`:

```
import datasets

feature = datasets.Image(decode=False)
new_image = {'image': feature.encode_example(image)}
dataset['test'] = dataset['test'].add_item(new_image)
```

## Actual results

```
ArrowInvalid: Could not convert <PIL.Image.Image image mode=RGB size=576x864 at 0x7F7CCC4589D0> with type Image: did not recognize Python value type when inferring an Arrow data type
```
",94b16b674111ca5e1a03ddcb71dc0b53acc2f934,4f95a8905141a09993db7fcdd55f8da99545308a,https://github.com/huggingface/datasets/compare/94b16b674111ca5e1a03ddcb71dc0b53acc2f934...4f95a8905141a09993db7fcdd55f8da99545308a,"diff --git a/src/datasets/arrow_dataset.py b/src/datasets/arrow_dataset.py
index cd299c55f..caf414211 100644
--- a/src/datasets/arrow_dataset.py
+++ b/src/datasets/arrow_dataset.py
@@ -5339,14 +5339,15 @@ class Dataset(DatasetInfoMixin, IndexableMixin, TensorflowDatasetMixin):
         })
         ```
         """"""
-        column_table = InMemoryTable.from_pydict({name: column})
+        ts = OptimizedTypedSequence(column, type=None, col=name)
+        column_table = InMemoryTable.from_pydict({name: ts})
         _check_column_names(self._data.column_names + column_table.column_names)
         dataset = self.flatten_indices() if self._indices is not None else self
         # Concatenate tables horizontally
         table = concat_tables([dataset._data, column_table], axis=1)
         # Update features
         info = dataset.info.copy()
-        info.features.update(Features.from_arrow_schema(column_table.schema))
+        info.features.update(Features({name: ts.get_inferred_type()}))
         table = update_metadata_with_features(table, info.features)
         return Dataset(table, info=info, split=self.split, indices_table=None, fingerprint=new_fingerprint)
 
@@ -5582,9 +5583,12 @@ class Dataset(DatasetInfoMixin, IndexableMixin, TensorflowDatasetMixin):
         {'label': 0, 'text': 'this movie is the absolute worst thing I have ever seen'}
         ```
         """"""
-        item_table = InMemoryTable.from_pydict({k: [v] for k, v in item.items()})
+        item = {k: OptimizedTypedSequence([v], type=None, col=k) for k, v in item.items()}
+        item_table = InMemoryTable.from_pydict(item)
         # We don't call _check_if_features_can_be_aligned here so this cast is ""unsafe""
-        dset_features, item_features = _align_features([self.features, Features.from_arrow_schema(item_table.schema)])
+        dset_features, item_features = _align_features(
+            [self.features, Features({k: v.get_inferred_type() for k, v in item.items()})]
+        )
         # Cast to align the schemas of the tables and concatenate the tables
         table = concat_tables(
             [
diff --git a/tests/test_arrow_dataset.py b/tests/test_arrow_dataset.py
index c13ea46e4..2222c337d 100644
--- a/tests/test_arrow_dataset.py
+++ b/tests/test_arrow_dataset.py
@@ -3214,6 +3214,18 @@ def test_dataset_add_column(column, expected_dtype, in_memory, transform, datase
     assert_arrow_metadata_are_synced_with_dataset_features(dataset)
 
 
+@require_pil
+def test_dataset_add_column_complex_features(image_file):
+    import PIL.Image
+
+    pil_image = PIL.Image.open(image_file)
+    dataset = Dataset.from_dict({""col_1"": [""a"", ""b""]})
+    dataset = dataset.add_column(""col_2"", [pil_image, None])
+    assert dataset.data.shape == (2, 2)
+    assert dataset.features == Features({""col_1"": Value(""string""), ""col_2"": Image()})
+    assert dataset[:] == {""col_1"": [""a"", ""b""], ""col_2"": [pil_image, None]}
+
+
 @pytest.mark.parametrize(
     ""transform"",
     [None, (""shuffle"", (42,), {}), (""with_format"", (""pandas"",), {}), (""class_encode_column"", (""col_2"",), {})],
@@ -3280,6 +3292,18 @@ def test_dataset_add_item_introduce_feature_type():
     assert dataset[:] == {""col_1"": [None, None, None, ""a""]}
 
 
+@require_pil
+def test_dataset_add_item_complex_features(image_file):
+    import PIL.Image
+
+    pil_image = PIL.Image.open(image_file)
+    dataset = Dataset.from_dict({""col_1"": [pil_image, None]})
+    dataset = dataset.add_item({""col_1"": pil_image})
+    assert dataset.data.shape == (3, 1)
+    assert dataset.features == Features({""col_1"": Image()})
+    assert dataset[:] == {""col_1"": [pil_image, None, pil_image]}
+
+
 def test_dataset_filter_batched_indices():
     ds = Dataset.from_dict({""num"": [0, 1, 2, 3]})
     ds = ds.filter(lambda num: num % 2 == 0, input_columns=""num"", batch_size=2)","['src/datasets/arrow_dataset.py', 'tests/test_arrow_dataset.py']",{'.py': 2},2,0,0,2,2,1993511,437090,47175,168,853,201,12,1,1104,135,251,35,0,3,2022-08-11 14:25:45,16876,Python,"{'Python': 3209601, 'Jupyter Notebook': 329182, 'Shell': 9904, 'Makefile': 421}",Apache License 2.0,"['src/datasets/features/image.py', 'src/datasets/utils/py_utils.py']","['src/datasets/features/image.py', 'src/datasets/utils/py_utils.py']","['```json\n{\n  ""files"": [\n    ""src/datasets/features/image.py"",\n    ""src/datasets/utils/py_utils.py""\n  ]\n}\n```']",1,611.1738681793213
7854,rasahq/rasa/4035/4015,rasahq,rasa,https://github.com/RasaHQ/rasa/issues/4015,https://github.com/RasaHQ/rasa/pull/4035,https://github.com/RasaHQ/rasa/pull/4035,1,fixes,Rasa v1.0 missing detailed logs like previous versions,"<!-- THIS INFORMATION IS MANDATORY - YOUR ISSUE WILL BE CLOSED IF IT IS MISSING. If you don't know your Rasa version, use `rasa --version`. 
Please format any code or console output with three ticks ``` above and below.
If you are asking a usage question (e.g. ""How do I do xyz"") please post your question on https://forum.rasa.com instead -->

**Rasa version**: 1.1.3

**Rasa X version** (if used & relevant): N/A

**Python version**: 3.6.6

**Operating system** (windows, osx, ...): Windows 10

**Issue**:
After upgrading to Rasa v1.0.x, logs outputted to `rasa_core.log` are missing any additional output that appears in the shell/server.

**Error (including full traceback)**:
Currently the log only ever displays:
```
2019-07-12 12:00:20,917 [DEBUG]  Available web server routes: 
/webhooks/rest                                     GET                            custom_webhook_RestInput.health
/webhooks/rest/webhook                             POST                           custom_webhook_RestInput.receive
```

When before, they'd look something like this:
```
Rasa process starting
Added 'nlp_spacy' to component cache. Key 'nlp_spacy-en'.
Available web server routes: 
static                                             GET, OPTIONS, HEAD             /static/[filename]
custom_webhook_RestInput.health                    GET, OPTIONS, HEAD             /webhooks/rest/
custom_webhook_RestInput.receive                   OPTIONS, POST                  /webhooks/rest/webhook
Rasa Core server is up and running on http://localhost:5002
Creating a new tracker for id 'test'.
Received user message 'hi' with intent '{'name': 'greet', 'confidence': 0.6400831082282148}' and entities '[]'
Logged UserUtterance - tracker now has 2 events
Current slot values: 
	target: None
	target_found: None
	user: None
Current tracker state [None, {}, {'prev_action_listen': 1.0, 'intent_greet': 1.0}]
There is a memorised next action '23'
There is no active form
Predicted next action using policy_2_MemoizationPolicy
Predicted next action 'action_identify_user' with prob 1.00.
Calling action endpoint to run action 'action_identify_user'.
Action 'action_identify_user' ended with events '['SlotSet(key: user, value: test)']'
Current tracker state [{}, {'prev_action_listen': 1.0, 'intent_greet': 1.0}, {'slot_user_0': 1.0, 'prev_action_identify_user': 1.0, 'intent_greet': 1.0}]
There is no memorised next action
There is no active form
Predicted next action using policy_0_KerasPolicy
Predicted next action 'utter_greet' with prob 1.00.
Action 'utter_greet' ended with events '[]'
Bot utterance 'BotUttered(text: Hi test, data: {
  ""elements"": null,
  ""buttons"": null,
  ""attachment"": null
})'
Current tracker state [{'prev_action_listen': 1.0, 'intent_greet': 1.0}, {'slot_user_0': 1.0, 'prev_action_identify_user': 1.0, 'intent_greet': 1.0}, {'prev_utter_greet': 1.0, 'slot_user_0': 1.0, 'intent_greet': 1.0}]
There is no memorised next action
There is no active form
```

**Command or request that led to error**:
I currently start the server as so,
```
rasa run -m models --endpoints endpoints.yml --port 5002 --credentials credentials.yml --debug
```
`rasa_core.log` gets generated by default, but as mentioned above, only contains a few lines of the server starting and nothing else.
",4d111f6f850ab60567553a8b017c95c55a3c4dc0,74253064a4254953e259b0be1d8c04fc75719d0e,https://github.com/rasahq/rasa/compare/4d111f6f850ab60567553a8b017c95c55a3c4dc0...74253064a4254953e259b0be1d8c04fc75719d0e,"diff --git a/rasa/cli/x.py b/rasa/cli/x.py
index 2b951fd7146..def77728310 100644
--- a/rasa/cli/x.py
+++ b/rasa/cli/x.py
@@ -208,7 +208,7 @@ def _configure_logging(args: argparse.Namespace):
     io_utils.configure_colored_logging(args.loglevel)
 
     set_log_level(log_level)
-    configure_file_logging(args.log_file)
+    configure_file_logging(logging.root, args.log_file)
 
     logging.getLogger(""werkzeug"").setLevel(logging.WARNING)
     logging.getLogger(""engineio"").setLevel(logging.WARNING)
diff --git a/rasa/core/run.py b/rasa/core/run.py
index b4b1308bd7f..bbda948154e 100644
--- a/rasa/core/run.py
+++ b/rasa/core/run.py
@@ -81,6 +81,8 @@ def configure_app(
     """"""Run the agent.""""""
     from rasa import server
 
+    configure_file_logging(logger, log_file)
+
     if enable_api:
         app = server.create_app(
             cors_origins=cors,
@@ -93,8 +95,6 @@ def configure_app(
         app = Sanic(__name__, configure_logging=False)
         CORS(app, resources={r""/*"": {""origins"": cors or """"}}, automatic_options=True)
 
-    configure_file_logging(log_file)
-
     if input_channels:
         rasa.core.channels.channel.register(input_channels, app, route=route)
     else:
diff --git a/rasa/core/utils.py b/rasa/core/utils.py
index ac8691b8361..0f09d95895c 100644
--- a/rasa/core/utils.py
+++ b/rasa/core/utils.py
@@ -31,12 +31,15 @@ if TYPE_CHECKING:
     from random import Random
 
 
-def configure_file_logging(log_file: Optional[Text]):
-    if log_file is not None:
-        formatter = logging.Formatter(""%(asctime)s [%(levelname)-5.5s]  %(message)s"")
-        file_handler = logging.FileHandler(log_file)
-        file_handler.setFormatter(formatter)
-        logger.addHandler(file_handler)
+def configure_file_logging(logger_obj: logging.Logger, log_file: Optional[Text]):
+    if not log_file:
+        return
+
+    formatter = logging.Formatter(""%(asctime)s [%(levelname)-5.5s]  %(message)s"")
+    file_handler = logging.FileHandler(log_file)
+    file_handler.setLevel(logger_obj.level)
+    file_handler.setFormatter(formatter)
+    logger_obj.addHandler(file_handler)
 
 
 def module_path_from_instance(inst: Any) -> Text:","['rasa/cli/x.py', 'rasa/core/utils.py', 'rasa/core/run.py']",{'.py': 3},3,0,0,3,3,1213825,255953,35745,175,882,183,21,3,3352,393,869,69,2,3,2019-07-17 15:39:02,16783,Python,"{'Python': 5614364, 'Dockerfile': 12239, 'Makefile': 11969, 'Shell': 5601, 'HCL': 4964, 'HTML': 3500, 'Jinja': 1233}",Apache License 2.0,"['rasa/core/trackers.py', 'rasa/core/processor.py', 'rasa/core/run.py', 'rasa/core/evaluate.py', 'rasa/core/visualize.py']","['rasa/core/trackers.py', 'rasa/core/processor.py', 'rasa/core/run.py', 'rasa/core/evaluate.py', 'rasa/core/visualize.py']","['```json\n{\n  ""files"": [\n    ""rasa/core/run.py"",\n    ""rasa/core/processor.py"",\n    ""rasa/core/trackers.py"",\n    ""rasa/core/visualize.py"",\n    ""rasa/core/evaluate.py""\n  ]\n}\n```']",1,1019.4740295410156
8876,pulumi/pulumi/11541/11542,pulumi,pulumi,https://github.com/pulumi/pulumi/issues/11542,https://github.com/pulumi/pulumi/pull/11541,https://github.com/pulumi/pulumi/pull/11541,1,fixes,"Python Lint failing on CI, blocking merges","Jobs have begun failing with errors in linting the Python SDK, specifically failing on running `mypy`: https://github.com/pulumi/pulumi/actions/runs/3624968763/jobs/6112540141

Logs:

```
. venv/*/activate && \\
	MYPYPATH=./stubs python -m mypy ./lib/pulumi --config-file=mypy.ini
lib/pulumi/runtime/invoke.py:[19](https://github.com/pulumi/pulumi/actions/runs/3624968763/jobs/6112540141#step:16:22)0: note: By default the bodies of untyped functions are not checked, consider using --check-untyped-defs  [annotation-unchecked]
lib/pulumi/runtime/invoke.py:236: note: By default the bodies of untyped functions are not checked, consider using --check-untyped-defs  [annotation-unchecked]
lib/pulumi/runtime/invoke.py:251: note: By default the bodies of untyped functions are not checked, consider using --check-untyped-defs  [annotation-unchecked]
lib/pulumi/runtime/rpc.py:5[21](https://github.com/pulumi/pulumi/actions/runs/3624968763/jobs/6112540141#step:16:24): error: Argument 1 to ""FileAsset"" has incompatible type ""Union[Struct, ListValue, str, float, bool, None]""; expected ""Union[str, PathLike[Any]]""  [arg-type]
lib/pulumi/runtime/rpc.py:5[23](https://github.com/pulumi/pulumi/actions/runs/3624968763/jobs/6112540141#step:16:26): error: Argument 1 to ""StringAsset"" has incompatible type ""Union[Struct, ListValue, str, float, bool, None]""; expected ""str""  [arg-type]
lib/pulumi/runtime/rpc.py:5[25](https://github.com/pulumi/pulumi/actions/runs/3624968763/jobs/6112540141#step:16:28): error: Argument 1 to ""RemoteAsset"" has incompatible type ""Union[Struct, ListValue, str, float, bool, None]""; expected ""str""  [arg-type]
lib/pulumi/runtime/rpc.py:534: error: Argument 1 to ""FileArchive"" has incompatible type ""Union[Struct, ListValue, str, float, bool, None]""; expected ""str""  [arg-type]
lib/pulumi/runtime/rpc.py:536: error: Argument 1 to ""RemoteArchive"" has incompatible type ""Union[Struct, ListValue, str, float, bool, None]""; expected ""str""  [arg-type]
lib/pulumi/runtime/rpc.py:577: error: Argument 1 to ""_parse_urn"" has incompatible type ""Union[Struct, ListValue, str, float, bool, None]""; expected ""str""  [arg-type]
lib/pulumi/runtime/rpc.py:586: error: Argument 2 to ""get_resource_package"" has incompatible type ""Union[Struct, ListValue, str, float, bool, None]""; expected ""str""  [arg-type]
lib/pulumi/runtime/rpc.py:589: error: Argument 3 to ""construct_provider"" of ""ResourcePackage"" has incompatible type ""Union[Struct, ListValue, str, float, bool, None]""; expected ""str""  [arg-type]
lib/pulumi/runtime/rpc.py:592: error: Argument 3 to ""get_resource_module"" has incompatible type ""Union[Struct, ListValue, str, float, bool, None]""; expected ""str""  [arg-type]
lib/pulumi/runtime/rpc.py:594: error: Argument 3 to ""construct"" of ""ResourceModule"" has incompatible type ""Union[Struct, ListValue, str, float, bool, None]""; expected ""str""  [arg-type]
lib/pulumi/runtime/rpc.py:601: error: Incompatible return value type (got ""Union[Struct, ListValue, str, float, bool, None]"", expected ""Resource"")  [return-value]
```",86e7d56df231760ebbfc64c809a7755b70cd8e6e,05ad7567cadc0ac3756ef700366244bed2452d50,https://github.com/pulumi/pulumi/compare/86e7d56df231760ebbfc64c809a7755b70cd8e6e...05ad7567cadc0ac3756ef700366244bed2452d50,"diff --git a/sdk/python/lib/pulumi/runtime/rpc.py b/sdk/python/lib/pulumi/runtime/rpc.py
index da9515e37..1bbce62c7 100644
--- a/sdk/python/lib/pulumi/runtime/rpc.py
+++ b/sdk/python/lib/pulumi/runtime/rpc.py
@@ -29,6 +29,7 @@ from typing import (
     Optional,
     Sequence,
     Set,
+    Union,
     TYPE_CHECKING,
     cast,
 )
@@ -45,7 +46,7 @@ from .. import urn as urn_util
 
 if TYPE_CHECKING:
     from ..output import Inputs, Input, Output
-    from ..resource import CustomResource, Resource, ProviderResource
+    from ..resource import Resource, CustomResource, ProviderResource
     from ..asset import (
         FileAsset,
         RemoteAsset,
@@ -518,11 +519,11 @@ def deserialize_properties(
         if props_struct[_special_sig_key] == _special_asset_sig:
             # This is an asset. Re-hydrate this object into an Asset.
             if ""path"" in props_struct:
-                return FileAsset(props_struct[""path""])
+                return FileAsset(str(props_struct[""path""]))
             if ""text"" in props_struct:
-                return StringAsset(props_struct[""text""])
+                return StringAsset(str(props_struct[""text""]))
             if ""uri"" in props_struct:
-                return RemoteAsset(props_struct[""uri""])
+                return RemoteAsset(str(props_struct[""uri""]))
             raise AssertionError(
                 ""Invalid asset encountered when unmarshalling resource property""
             )
@@ -531,9 +532,9 @@ def deserialize_properties(
             if ""assets"" in props_struct:
                 return AssetArchive(deserialize_property(props_struct[""assets""]))
             if ""path"" in props_struct:
-                return FileArchive(props_struct[""path""])
+                return FileArchive(str(props_struct[""path""]))
             if ""uri"" in props_struct:
-                return RemoteArchive(props_struct[""uri""])
+                return RemoteArchive(str(props_struct[""uri""]))
             raise AssertionError(
                 ""Invalid archive encountered when unmarshalling resource property""
             )
@@ -570,9 +571,11 @@ def deserialize_properties(
 
 def deserialize_resource(
     ref_struct: struct_pb2.Struct, keep_unknowns: Optional[bool] = None
-) -> ""Resource"":
-    urn = ref_struct[""urn""]
-    version = ref_struct[""packageVersion""] if ""packageVersion"" in ref_struct else """"
+) -> Union[""Resource"", str]:
+    urn = str(ref_struct[""urn""])
+    version = (
+        str(ref_struct[""packageVersion""]) if ""packageVersion"" in ref_struct else """"
+    )
 
     urn_parts = urn_util._parse_urn(urn)
     urn_name = urn_parts.urn_name",['sdk/python/lib/pulumi/runtime/rpc.py'],{'.py': 1},1,0,0,1,1,659666,147569,17119,75,1060,202,21,1,3049,279,874,22,5,1,2022-12-06 00:49:46,16729,Go,"{'Go': 8004317, 'Python': 1477211, 'TypeScript': 1405854, 'JavaScript': 925950, 'Shell': 40559, 'Makefile': 29399, 'F#': 6098, 'Dockerfile': 4626, 'C#': 1334, 'Assembly': 817, 'Batchfile': 816, 'Pascal': 89}",Apache License 2.0,"['sdk/python/lib/pulumi/runtime/rpc.py', 'sdk/python/lib/pulumi/runtime/invoke.py']","['sdk/python/lib/pulumi/runtime/rpc.py', 'sdk/python/lib/pulumi/runtime/invoke.py']","['```json\n{\n  ""files"": [\n    ""sdk/python/lib/pulumi/runtime/rpc.py"",\n    ""sdk/python/lib/pulumi/runtime/invoke.py""\n  ]\n}\n```']",1,773.3991146087646
5057,archivebox/archivebox/822/821,archivebox,archivebox,https://github.com/ArchiveBox/ArchiveBox/issues/821,https://github.com/ArchiveBox/ArchiveBox/pull/822,https://github.com/ArchiveBox/ArchiveBox/pull/822,1,fixes,Bug: Crash during Pinboard RSS import,"<!--
Please fill out the following information, 
feel free to delete sections if they're not applicable 
or if long issue templates annoy you.
(the only required section is the version information)
-->

#### Describe the bug
Using the Pinboard RSS parser results in a crash due to [an assertion in `index/schema.py`](https://github.com/ArchiveBox/ArchiveBox/blob/3d54b1321bf8c56627aaa50efcc809cd99caee52/archivebox/index/schema.py#L165). This assertion fails because `parsers/pinboard_rss.py` passes a `None` value as the `url` property of the `Link` object.

The `url` is set to `None` because the return value of `item.find()` is [coerced to a `bool` in `pinboard_rss.py`](https://github.com/ArchiveBox/ArchiveBox/blob/3d54b1321bf8c56627aaa50efcc809cd99caee52/archivebox/parsers/pinboard_rss.py#L24). The result of the coercion is always `False`, because the `<link>` element does not have any child elements, which is [the definition of `__bool__()` in `ElementTree.Element`](https://github.com/python/cpython/blob/3d8993a744813c5144851da5347d7b4b1885f234/Lib/xml/etree/ElementTree.py#L207). In fact, the [RSS 1.0 specification forbids any child elements of `<link>`](https://validator.w3.org/feed/docs/rss1.html#s5.5.2).

#### Steps to reproduce
<!--
For example:
1. Ran ArchiveBox with the following config '...'
2. Saw this output during archiving '....'
3. UI didn't show the thing I was expecting '....'
-->
1. Run `curl -sSL 'https://feeds.pinboard.in/rss/u:maciej/' | archivebox add --parser=pinboard_rss`
2. Python crashes with a backtrace, below.
    
#### Screenshots or log output
##### Backtrace
```logs
[X] Error while loading link! [1628081549.183792] None ""None""
Traceback (most recent call last):
  File ""./test_pinboard_rss.py"", line 18, in <module>
    main()
  File ""./test_pinboard_rss.py"", line 13, in main
    items = [item for item in parse_pinboard_rss_export(args.rss_file)]
  File ""./test_pinboard_rss.py"", line 13, in <listcomp>
    items = [item for item in parse_pinboard_rss_export(args.rss_file)]
  File ""/usr/local/lib/python3.8/site-packages/archivebox/parsers/pinboard_rss.py"", line 41, in parse_pinboard_rss_export
    yield Link(
  File ""<string>"", line 11, in __init__
  File ""/usr/local/lib/python3.8/site-packages/archivebox/index/schema.py"", line 141, in __post_init__
    self.typecheck()
  File ""/usr/local/lib/python3.8/site-packages/archivebox/index/schema.py"", line 165, in typecheck
    assert isinstance(self.url, str) and '://' in self.url
AssertionError
```
<!--
If applicable, post any relevant screenshots or copy/pasted terminal output from ArchiveBox.
If you're reporting a parsing / importing error, **you must paste a copy of your redacted import file here**.
-->

#### ArchiveBox version
*Running `dev` branch. Tested on commit 3d54b13.*
<!-- Run the `archivebox version` command locally then copy paste the result here: -->
```logs
ArchiveBox v0.6.3
Cpython FreeBSD FreeBSD-12.2-RELEASE-p2-amd64-64bit-ELF amd64
IN_DOCKER=False DEBUG=False IS_TTY=True TZ=UTC SEARCH_BACKEND_ENGINE=ripgrep

[i] Dependency versions:
 √  ARCHIVEBOX_BINARY     v0.6.3          valid     /usr/local/bin/archivebox
 √  PYTHON_BINARY         v3.8.10         valid     /usr/local/bin/python3.8
 √  DJANGO_BINARY         v3.1.13         valid     /usr/local/lib/python3.8/site-packages/django/bin/django-admin.py
 √  CURL_BINARY           v7.77.0         valid     /usr/local/bin/curl
 √  WGET_BINARY           v1.21           valid     /usr/local/bin/wget
 √  NODE_BINARY           v16.2.0         valid     /usr/local/bin/node
 √  SINGLEFILE_BINARY     v0.3.26         valid     ./node_modules/single-file/cli/single-file
 √  READABILITY_BINARY    v0.0.3          valid     ./node_modules/readability-extractor/readability-extractor
 √  MERCURY_BINARY        v1.0.0          valid     ./node_modules/@postlight/mercury-parser/cli.js
 √  GIT_BINARY            v2.32.0         valid     /usr/local/bin/git
 √  YOUTUBEDL_BINARY      v2021.06.06     valid     /usr/local/bin/youtube-dl
 √  CHROME_BINARY         v91.0.4472.164  valid     /usr/local/bin/chrome
 √  RIPGREP_BINARY        v13.0.0         valid     /usr/local/bin/rg

[i] Source-code locations:
 √  PACKAGE_DIR           23 files        valid     /usr/local/lib/python3.8/site-packages/archivebox
 √  TEMPLATES_DIR         3 files         valid     /usr/local/lib/python3.8/site-packages/archivebox/templates
 -  CUSTOM_TEMPLATES_DIR  -               disabled

[i] Secrets locations:
 -  CHROME_USER_DATA_DIR  -               disabled
 -  COOKIES_FILE          -               disabled

[i] Data locations:
 √  OUTPUT_DIR            11 files        valid     /usr/home/archivebox/data
 √  SOURCES_DIR           8 files         valid     ./sources
 √  LOGS_DIR              3 files         valid     ./logs
 √  ARCHIVE_DIR           877 files       valid     ./archive
 √  CONFIG_FILE           153.0 Bytes     valid     ./ArchiveBox.conf
 √  SQL_INDEX             6.8 MB          valid     ./index.sqlite3
```
<!-- Tickets without full version info will closed until it is provided,
we need the full output here to help you solve your issue -->
",3d54b1321bf8c56627aaa50efcc809cd99caee52,f6cf35a45d41f911e02d275398ef8b6a9efa51a5,https://github.com/archivebox/archivebox/compare/3d54b1321bf8c56627aaa50efcc809cd99caee52...f6cf35a45d41f911e02d275398ef8b6a9efa51a5,"diff --git a/archivebox/parsers/pinboard_rss.py b/archivebox/parsers/pinboard_rss.py
index b7a77a0..d12b219 100644
--- a/archivebox/parsers/pinboard_rss.py
+++ b/archivebox/parsers/pinboard_rss.py
@@ -21,13 +21,18 @@ def parse_pinboard_rss_export(rss_file: IO[str], **_kwargs) -> Iterable[Link]:
     root = ElementTree.parse(rss_file).getroot()
     items = root.findall(""{http://purl.org/rss/1.0/}item"")
     for item in items:
-        find = lambda p: item.find(p).text.strip() if item.find(p) else None    # type: ignore
+        find = lambda p: item.find(p).text.strip() if item.find(p) is not None else None    # type: ignore
 
         url = find(""{http://purl.org/rss/1.0/}link"")
         tags = find(""{http://purl.org/dc/elements/1.1/}subject"")
         title = find(""{http://purl.org/rss/1.0/}title"")
         ts_str = find(""{http://purl.org/dc/elements/1.1/}date"")
         
+        if url is None:
+            # Yielding a Link with no URL will
+            # crash on a URL validation assertion
+            continue
+
         # Pinboard includes a colon in its date stamp timezone offsets, which
         # Python can't parse. Remove it:
         if ts_str and ts_str[-3:-2] == "":"":",['archivebox/parsers/pinboard_rss.py'],{'.py': 1},1,0,0,1,1,417240,95946,12030,103,351,84,7,1,5230,496,1427,90,5,2,2021-08-04 15:06:55,16582,Python,"{'Python': 469963, 'HTML': 417329, 'Shell': 30497, 'CSS': 8208, 'Dockerfile': 5687, 'SCSS': 764}",MIT License,"['archivebox/index/schema.py', 'archivebox/parsers/pinboard_rss.py']","['archivebox/index/schema.py', 'archivebox/parsers/pinboard_rss.py']","['```json\n{\n  ""files"": [\n    ""archivebox/parsers/pinboard_rss.py"",\n    ""archivebox/index/schema.py""\n  ]\n}\n```']",1,842.1368598937988
6494,microsoft/recommenders/804/746,microsoft,recommenders,https://github.com/microsoft/recommenders/issues/746,https://github.com/recommenders-team/recommenders/pull/804,https://github.com/recommenders-team/recommenders/pull/804,1,fix,[BUG] in NNI integration test,"### Description
<!--- Describe your issue/bug/request in detail -->
```
tests/integration/test_movielens.py .........                            [ 62%]
tests/integration/test_notebooks_python.py .....F                        [100%]

=================================== FAILURES ===================================
_____________________________ test_nni_tuning_svd ______________________________

notebooks = {'als_deep_dive': '/data/home/recocat/cicd/7/s/notebooks/02_model/als_deep_dive.ipynb', 'als_pyspark': '/data/home/rec...baseline_deep_dive.ipynb', 'data_split': '/data/home/recocat/cicd/7/s/notebooks/01_prepare_data/data_split.ipynb', ...}
tmp = '/tmp/pytest-of-recocat/pytest-200/tmpuj9_hwzq'

    @pytest.mark.integration
    def test_nni_tuning_svd(notebooks, tmp):
        notebook_path = notebooks[""nni_tuning_svd""]
        # First stop NNI in case it is running
        subprocess.run([sys.prefix + '/bin/nnictl', 'stop'])
        check_stopped()
        pm.execute_notebook(notebook_path, OUTPUT_NOTEBOOK, kernel_name=KERNEL_NAME,
                            parameters=dict(MOVIELENS_DATA_SIZE=""100k"",
                                            SURPRISE_READER=""ml-100k"",
                                            TMP_DIR=tmp,
                                            MAX_TRIAL_NUM=1,
>                                           NUM_EPOCHS=1))

tests/integration/test_notebooks_python.py:164: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/anaconda/envs/nightly_reco_base/lib/python3.6/site-packages/papermill/execute.py:94: in execute_notebook
    raise_for_execution_errors(nb, output_path)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

nb = {'cells': [{'cell_type': 'code', 'metadata': {'inputHidden': True, 'hide_input': True}, 'execution_count': None, 'sour...d_time': '2019-04-18T12:09:01.272263', 'duration': 345.187067, 'exception': True}}, 'nbformat': 4, 'nbformat_minor': 2}
output_path = 'output.ipynb'

    def raise_for_execution_errors(nb, output_path):
        """"""Assigned parameters into the appropriate place in the input notebook
    
        Parameters
        ----------
        nb : NotebookNode
           Executable notebook object
        output_path : str
           Path to write executed notebook
        """"""
        error = None
        for cell in nb.cells:
            if cell.get(""outputs"") is None:
                continue
    
            for output in cell.outputs:
                if output.output_type == ""error"":
                    error = PapermillExecutionError(
                        exec_count=cell.execution_count,
                        source=cell.source,
                        ename=output.ename,
                        evalue=output.evalue,
                        traceback=output.traceback,
                    )
                    break
    
        if error:
            # Write notebook back out with the Error Message at the top of the Notebook.
            error_msg = ERROR_MESSAGE_TEMPLATE % str(error.exec_count)
            error_msg_cell = nbformat.v4.new_code_cell(
                source=""%%html\\n"" + error_msg,
                outputs=[
                    nbformat.v4.new_output(output_type=""display_data"", data={""text/html"": error_msg})
                ],
                metadata={""inputHidden"": True, ""hide_input"": True},
            )
            nb.cells = [error_msg_cell] + nb.cells
            write_ipynb(nb, output_path)
>           raise error
E           papermill.exceptions.PapermillExecutionError: 
E           ---------------------------------------------------------------------------
E           Exception encountered at ""In [32]"":
E           ---------------------------------------------------------------------------
E           RuntimeError                              Traceback (most recent call last)
E           <ipython-input-32-120fb8357fc9> in <module>
E                 1 t = time.time()
E           ----> 2 stop_and_restart()
E                 3 time_smac = time.time() - t
E           
E           <ipython-input-20-609ee7726ae6> in stop_and_restart()
E                 6     proc = subprocess.run([sys.prefix + '/bin/nnictl', 'create', '--config', config_path])
E                 7     if proc.returncode != 0:
E           ----> 8         raise RuntimeError(""'nnictl create' failed with code %d"" % proc.returncode)
E                 9     check_experiment_status(wait=WAITING_TIME, max_retries=MAX_RETRIES)
E           
E           RuntimeError: 'nnictl create' failed with code 1

/anaconda/envs/nightly_reco_base/lib/python3.6/site-packages/papermill/execute.py:241: PapermillExecutionError
```


### In which platform does it happen?
<!--- Describe the platform where the issue is happening (use a list if needed) -->
<!--- For example: -->
* Azure Data Science Virtual Machine.


### How do we replicate the issue?
<!--- Please be specific as possible (use a list if needed). -->
<!--- For example: -->
<!--- * Create a conda environment for pyspark -->
<!--- * Run unit test `test_sar_pyspark.py` with `pytest -m 'spark'` -->
<!--- * ... -->
run `tests/integration/test_notebooks_python.py`

### Expected behavior (i.e. solution)
<!--- For example:  -->
<!--- * The tests for SAR PySpark should pass successfully. -->

### Other Comments
",4040d065ee5df3752525e628194ef06d8b06e7ec,b5c9c8ea89f664bf5ee0a000a14041684d1460d3,https://github.com/microsoft/recommenders/compare/4040d065ee5df3752525e628194ef06d8b06e7ec...b5c9c8ea89f664bf5ee0a000a14041684d1460d3,"diff --git a/reco_utils/nni/svd_training.py b/reco_utils/nni/svd_training.py
index 578cb5ca..439942a6 100644
--- a/reco_utils/nni/svd_training.py
+++ b/reco_utils/nni/svd_training.py
@@ -7,11 +7,12 @@ import logging
 import numpy as np
 import os
 import pandas as pd
-
+import nni
 import surprise
+import sys
+sys.path.append(""../../"")
 
 import reco_utils.evaluation.python_evaluation as evaluation
-from reco_utils.nni.nni_utils import nni
 from reco_utils.recommender.surprise.surprise_utils import (
     compute_rating_predictions,
     compute_ranking_predictions,
diff --git a/tests/integration/test_notebooks_python.py b/tests/integration/test_notebooks_python.py
index d56bb114..537d86b1 100644
--- a/tests/integration/test_notebooks_python.py
+++ b/tests/integration/test_notebooks_python.py
@@ -149,8 +149,7 @@ def test_vw_deep_dive_integration(notebooks, size, expected_values):
 
 
 @pytest.mark.integration
-#@pytest.mark.skipif(sys.platform == ""win32"", reason=""nni not installable on windows"")
-@pytest.mark.skip(reason=""https://github.com/microsoft/recommenders/issues/746"")
+@pytest.mark.skipif(sys.platform == ""win32"", reason=""nni not installable on windows"")
 def test_nni_tuning_svd(notebooks, tmp):
     notebook_path = notebooks[""nni_tuning_svd""]
     pm.execute_notebook(notebook_path, OUTPUT_NOTEBOOK, kernel_name=KERNEL_NAME,","['reco_utils/nni/svd_training.py', 'tests/integration/test_notebooks_python.py']",{'.py': 2},2,0,0,2,2,441679,98500,12398,71,94,25,5,1,5456,476,1231,115,0,1,2019-05-29 14:32:55,16100,Python,"{'Python': 1411471, 'Scala': 12309, 'Dockerfile': 8103, 'C++': 6800, 'Jupyter Notebook': 2148}",MIT License,"['reco_utils/nni/svd_training.py', 'tests/integration/test_movielens.py', 'tests/integration/test_notebooks_python.py', 'reco_utils/common/notebook_utils.py', 'reco_utils/nni/nni_utils.py']","['reco_utils/nni/svd_training.py', 'reco_utils/common/notebook_utils.py', 'reco_utils/nni/nni_utils.py']","['```json\n{\n  ""files"": [\n    ""reco_utils/nni/nni_utils.py"",\n    ""reco_utils/nni/svd_training.py"",\n    ""tests/integration/test_movielens.py"",\n    ""tests/integration/test_notebooks_python.py"",\n    ""reco_utils/common/notebook_utils.py""\n  ]\n}\n```']",1,1625.232458114624
7532,joke2k/faker/671/667,joke2k,faker,https://github.com/joke2k/faker/issues/667,https://github.com/joke2k/faker/pull/671,https://github.com/joke2k/faker/pull/671,1,close,past_datetime() crashes when start_date is within one second of now,"I ran into a problem while generating a bunch of fake dates where I was calling `fake.past_datetime()` with the start date using the result of a previous `fake.past_datetime()` call (simulating a bunch of files being created as part of a collection). The first call could randomly return a value which is within one second of the current time, causing the second call to trigger an exception from `random.randint()` because the `a` and `b` values were the same.

This was pretty easy to solve simply by using `fake.date_time_between(start_date=previous_created_date)` but it might be useful if `past_datetime()` was safe to call like this.",fc7bbc43efc9adf923b58b43db6c979a3c17ac86,18fd7c05a3f56996859f08f66de75f202f4d03ef,https://github.com/joke2k/faker/compare/fc7bbc43efc9adf923b58b43db6c979a3c17ac86...18fd7c05a3f56996859f08f66de75f202f4d03ef,"diff --git a/faker/providers/date_time/__init__.py b/faker/providers/date_time/__init__.py
index 8d1d8ff6..5df3c699 100644
--- a/faker/providers/date_time/__init__.py
+++ b/faker/providers/date_time/__init__.py
@@ -1342,7 +1342,10 @@ class Provider(BaseProvider):
         """"""
         start_date = self._parse_date_time(start_date, tzinfo=tzinfo)
         end_date = self._parse_date_time(end_date, tzinfo=tzinfo)
-        ts = self.generator.random.randint(start_date, end_date)
+        if end_date - start_date <= 1:
+            ts = start_date + self.generator.random.random()
+        else:
+            ts = self.generator.random.randint(start_date, end_date)
         return datetime(1970, 1, 1, tzinfo=tzinfo) + timedelta(seconds=ts)
 
     def date_between(self, start_date='-30y', end_date='today'):
diff --git a/tests/providers/test_date_time.py b/tests/providers/test_date_time.py
index f34250e6..1c81f7c3 100644
--- a/tests/providers/test_date_time.py
+++ b/tests/providers/test_date_time.py
@@ -191,6 +191,10 @@ class TestDateTime(unittest.TestCase):
         self.assertTrue(datetime_start <= random_date)
         self.assertTrue(datetime_end >= random_date)
 
+    def test_past_datetime_within_second(self):
+        # Should not raise a ``ValueError``
+        self.factory.past_datetime(start_date='+1s')
+
     def test_date_between_dates(self):
         date_end = date.today()
         date_start = date_end - timedelta(days=10)","['tests/providers/test_date_time.py', 'faker/providers/date_time/__init__.py']",{'.py': 2},2,0,0,2,2,2038547,836798,53567,308,252,51,5,1,641,100,137,3,0,0,2018-01-05 18:03:46,16098,Python,"{'Python': 8020934, 'Shell': 384, 'Makefile': 291}",MIT License,"['faker/providers/date_time/__init__.py', 'faker/generator.py', 'faker/utils/datetime_safe.py']","['faker/providers/date_time/__init__.py', 'faker/generator.py', 'faker/utils/datetime_safe.py']","['```json\n{\n  ""files"": [\n    ""faker/generator.py"",\n    ""faker/providers/date_time/__init__.py"",\n    ""faker/utils/datetime_safe.py""\n  ]\n}\n```']",1,990.6785488128662
8426,manimcommunity/manim/229/228,manimcommunity,manim,https://github.com/ManimCommunity/manim/issues/228,https://github.com/ManimCommunity/manim/pull/229,https://github.com/ManimCommunity/manim/pull/229,1,fix,Unable to Render Point() Mobjects,"## Steps to reproduce the issue:

Run anything that renders a `Point()` .
e.g:
```python
class Test(Scene):
        def construct(self):
                self.add(Point()) 
                self.wait() 
```
## Unexpected Behaviour

This will result in a `NameError: name 'PRODUCTION_QUALITY_CAMERA_CONFIG' is not defined`.
I believe this is because somewhere along the line, `Camera.adjusted_thickness()` is called, which references `PRODUCTION_QUALITY_CAMERA_CONFIG[""pixel_width""]` and `PRODUCTION_QUALITY_CAMERA_CONFIG[""pixel_height""]`

https://github.com/ManimCommunity/manim/blob/6e5770a85f62877d476ef11c8a52d2c963aba8de/manim/camera/camera.py#L1095-L1096

Since `PRODUCTION_QUALITY_CAMERA_CONFIG` doesn't really exist anymore, it's unable to get the required `pixel_height` and `pixel_width`.

Full Traceback for your perusal:

```shell
Traceback (most recent call last):
  File ""/Users/aathishs/Python/ManimEnv/manim/manim/__main__.py"", line 160, in main
    scene = SceneClass()
  File ""/Users/aathishs/Python/ManimEnv/manim/manim/scene/scene.py"", line 72, in __init__
    self.construct()
  File ""<string>"", line 5, in construct
  File ""/Users/aathishs/Python/ManimEnv/manim/manim/scene/scene.py"", line 855, in wrapper
    func(self, *args, **kwargs)
  File ""/Users/aathishs/Python/ManimEnv/manim/manim/scene/scene.py"", line 1073, in wait
    self.update_frame()
  File ""/Users/aathishs/Python/ManimEnv/manim/manim/scene/scene.py"", line 250, in update_frame
    self.capture_mobjects_in_camera(mobjects, **kwargs)
  File ""/Users/aathishs/Python/ManimEnv/manim/manim/scene/scene.py"", line 212, in capture_mobjects_in_camera
    self.camera.capture_mobjects(mobjects, **kwargs)
  File ""/Users/aathishs/Python/ManimEnv/manim/manim/camera/camera.py"", line 509, in capture_mobjects
    func(batch, self.pixel_array)
  File ""/Users/aathishs/Python/ManimEnv/manim/manim/camera/camera.py"", line 866, in display_multiple_point_cloud_mobjects
    self.adjusted_thickness(pmobject.stroke_width),
  File ""/Users/aathishs/Python/ManimEnv/manim/manim/camera/camera.py"", line 1118, in adjusted_thickness
    PRODUCTION_QUALITY_CAMERA_CONFIG[""pixel_height""],
NameError: name 'PRODUCTION_QUALITY_CAMERA_CONFIG' is not defined
```",c4c4bc0d0dd0d520050dbfa0c9b6f3d0a0af0b7d,37b7b459684e38aa9a1749a43e6b7241ee9dda83,https://github.com/manimcommunity/manim/compare/c4c4bc0d0dd0d520050dbfa0c9b6f3d0a0af0b7d...37b7b459684e38aa9a1749a43e6b7241ee9dda83,"diff --git a/manim/camera/camera.py b/manim/camera/camera.py
index e5b4b03a..8dc65309 100644
--- a/manim/camera/camera.py
+++ b/manim/camera/camera.py
@@ -10,7 +10,7 @@ import cairo
 import numpy as np
 
 from ..constants import *
-from ..config import config
+from ..config import config, camera_config
 from ..logger import logger
 from ..mobject.types.image_mobject import AbstractImageMobject
 from ..mobject.mobject import Mobject
@@ -1092,8 +1092,7 @@ class Camera(object):
         """"""
         # TODO: This seems...unsystematic
         big_sum = op.add(
-            PRODUCTION_QUALITY_CAMERA_CONFIG[""pixel_height""],
-            PRODUCTION_QUALITY_CAMERA_CONFIG[""pixel_width""],
+            camera_config[""default_pixel_height""], camera_config[""default_pixel_width""],
         )
         this_sum = op.add(self.get_pixel_height(), self.get_pixel_width(),)
         factor = fdiv(big_sum, this_sum)
diff --git a/manim/config.py b/manim/config.py
index baec8299..1b228c21 100644
--- a/manim/config.py
+++ b/manim/config.py
@@ -34,6 +34,8 @@ def _parse_config(config_parser, args):
         section = config_parser[""CLI""]
     config = {opt: section.getint(opt) for opt in config_parser[flag]}
 
+    config[""default_pixel_height""] = default.getint(""pixel_height"")
+    config[""default_pixel_width""] = default.getint(""pixel_width"")
     # The -r, --resolution flag overrides the *_quality flags
     if args.resolution is not None:
         if "","" in args.resolution:
diff --git a/manim/scene/scene_file_writer.py b/manim/scene/scene_file_writer.py
index 57e7bf1a..10168e00 100644
--- a/manim/scene/scene_file_writer.py
+++ b/manim/scene/scene_file_writer.py
@@ -439,10 +439,10 @@ class SceneFileWriter(object):
             ""remove_non_integer_files"": True,
             ""extension"": file_writer_config[""movie_file_extension""],
         }
-        if file_writer_config['from_animation_number'] is not None:
-            kwargs[""min_index""] = file_writer_config['from_animation_number']
-        if file_writer_config['upto_animation_number'] not in [None, np.inf]:
-            kwargs[""max_index""] = file_writer_config['upto_animation_number']
+        if file_writer_config[""from_animation_number""] is not None:
+            kwargs[""min_index""] = file_writer_config[""from_animation_number""]
+        if file_writer_config[""upto_animation_number""] not in [None, np.inf]:
+            kwargs[""max_index""] = file_writer_config[""upto_animation_number""]
         else:
             kwargs[""remove_indices_greater_than""] = self.scene.num_plays - 1
         partial_movie_files = get_sorted_integer_files(","['manim/config.py', 'manim/camera/camera.py', 'manim/scene/scene_file_writer.py']",{'.py': 3},3,0,0,3,3,638809,144738,19616,81,1033,212,15,3,2261,163,622,44,1,2,2020-08-01 08:20:42,15368,Python,"{'Python': 2312393, 'GLSL': 48516, 'Dockerfile': 1697, 'Jupyter Notebook': 1541, 'TeX': 178}",MIT License,['manim/camera/camera.py'],['manim/camera/camera.py'],"['```json\n{\n  ""files"": [\n    ""manim/camera/camera.py""\n  ]\n}\n```']",1,531.0044288635254
9743,pydantic/pydantic/6541/6525,pydantic,pydantic,https://github.com/pydantic/pydantic/issues/6525,https://github.com/pydantic/pydantic/pull/6541,https://github.com/pydantic/pydantic/pull/6541,1,closes,Discriminator needs literal error when validating literal field,"### Initial Checks

- [X] I confirm that I'm using Pydantic V2 installed directly from the `main` branch, or equivalent

### Description

When defining a `field_validator` for a `Literal` field that is used in a discriminated union, A `PydanticUserError` is raised, prompting that the field needs to be of type `Literal`.

If the 2 `field_validator`s are commented out  in the example below, the models will be created without issue.

Is this expected, or is this a bug? I couldn't find any documentation referring to this edge case.

Thank you!

### Example Code

```Python
import typing as t

from pydantic import BaseModel, Field, field_validator


class AnimalModel(BaseModel):
    age_years: int


class CatModel(AnimalModel):
    name: t.Literal[""kitty"", ""cat""]
    favorite_lasagna_brand: str
    # comment out the 2 field validators and model will work!
    @field_validator(""name"", mode=""after"")
    def replace_name(cls, v):
        return ""cat""


class SparrowModel(AnimalModel):
    name: t.Literal[""sparrow"", ""birdie""]
    color: str
    # comment out the 2 field validators and model will work!
    @field_validator(""name"", mode=""after"")
    def replace_name(cls, v):
        return ""sparrow""


AllowedAnimalTypes = t.Annotated[
    CatModel | SparrowModel,
    Field(discriminator=""name""),
]


class ZooModel(BaseModel):
    zoo_name: str
    animals: t.List[AllowedAnimalTypes]


if __name__ == ""__main__"":
    cool_zoo = ZooModel(
        zoo_name=""Zoolandia"",
        animals=[
            SparrowModel(name=""birdie"", color=""red"", age_years=2),
            CatModel(name=""kitty"", favorite_lasagna_brand=""Tony's"", age_years=20),
        ],
    )

    # raises PydanticUserError(
    # pydantic.errors.PydanticUserError: Model 'CatModel' needs field 'name' to be of type `Literal`
    # For further information visit https://errors.pydantic.dev/2.0.2/u/discriminator-needs-literal
```


### Python, Pydantic & OS Version

```Text
❯ python -c ""import pydantic.version; print(pydantic.version.version_info())""
             pydantic version: 2.0.2
        pydantic-core version: 2.1.2 release build profile
                 install path: /home/aloustau/sandbox/pydantic2_learning/.venv/lib/python3.10/site-packages/pydantic
               python version: 3.10.6 (main, May 29 2023, 11:10:38) [GCC 11.3.0]
                     platform: Linux-5.15.90.1-microsoft-standard-WSL2-x86_64-with-glibc2.35
     optional deps. installed: ['typing-extensions']
```


Selected Assignee: @adriangb",9c4a54d5b5505ba2f7cf50b2a1fff4288d586ba1,c4333fe7e724a2f00c122bb3a271187e1ae96982,https://github.com/pydantic/pydantic/compare/9c4a54d5b5505ba2f7cf50b2a1fff4288d586ba1...c4333fe7e724a2f00c122bb3a271187e1ae96982,"diff --git a/pydantic/_internal/_discriminated_union.py b/pydantic/_internal/_discriminated_union.py
index 5f48e0257..13ac93dfc 100644
--- a/pydantic/_internal/_discriminated_union.py
+++ b/pydantic/_internal/_discriminated_union.py
@@ -429,7 +429,9 @@ class _ApplyInferredDiscriminator:
         elif schema['type'] == 'default':
             # This will happen if the field has a default value; we ignore it while extracting the discriminator values
             return self._infer_discriminator_values_for_inner_schema(schema['schema'], source)
-
+        elif _core_utils.is_function_with_inner_schema(schema):
+            # This happens if there is a `@field_validator` or similar wrapping the type
+            return self._infer_discriminator_values_for_inner_schema(schema['schema'], source)
         else:
             raise PydanticUserError(
                 f'{source} needs field {self.discriminator!r} to be of type `Literal`',
diff --git a/tests/test_discriminated_union.py b/tests/test_discriminated_union.py
index 0420acbd1..cb93ad304 100644
--- a/tests/test_discriminated_union.py
+++ b/tests/test_discriminated_union.py
@@ -8,7 +8,7 @@ from dirty_equals import HasRepr, IsStr
 from pydantic_core import SchemaValidator, core_schema
 from typing_extensions import Annotated, Literal
 
-from pydantic import BaseModel, ConfigDict, Field, TypeAdapter, ValidationError
+from pydantic import BaseModel, ConfigDict, Field, TypeAdapter, ValidationError, field_validator
 from pydantic._internal._discriminated_union import apply_discriminator
 from pydantic.errors import PydanticUserError
 
@@ -1232,3 +1232,72 @@ def test_union_in_submodel() -> None:
         'title': 'TestModel',
         'type': 'object',
     }
+
+
+def test_field_validator_wrapping_union() -> None:
+    """"""https://github.com/pydantic/pydantic/issues/6525""""""
+
+    class CatModel(BaseModel):
+        name: Literal['kitty', 'cat']
+
+        @field_validator('name', mode='after')
+        def replace_name(cls, v: str) -> str:
+            return 'cat'
+
+    class SparrowModel(BaseModel):
+        name: Literal['sparrow', 'birdie']
+
+        @field_validator('name', mode='after')
+        def replace_name(cls, v: str) -> str:
+            return 'sparrow'
+
+    Animal = Annotated[
+        Union[CatModel, SparrowModel],
+        Field(discriminator='name'),
+    ]
+
+    ta = TypeAdapter(Animal)
+
+    assert ta.validate_python({'name': 'kitty'}) == CatModel(name='cat')
+
+    with pytest.raises(ValidationError) as exc_info:
+        ta.validate_python({'name': 'rabbit'})
+
+    # insert_assert(exc_info.value.errors(include_url=False))
+    assert exc_info.value.errors(include_url=False) == [
+        {
+            'type': 'union_tag_invalid',
+            'loc': (),
+            'msg': ""Input tag 'rabbit' found using 'name' does not match any of the expected tags: 'kitty', 'cat', 'sparrow', 'birdie'"",  # noqa: E501
+            'input': {'name': 'rabbit'},
+            'ctx': {'discriminator': ""'name'"", 'tag': 'rabbit', 'expected_tags': ""'kitty', 'cat', 'sparrow', 'birdie'""},
+        }
+    ]
+
+    # insert_assert(ta.json_schema())
+    assert ta.json_schema() == {
+        '$defs': {
+            'CatModel': {
+                'properties': {'name': {'enum': ['kitty', 'cat'], 'title': 'Name', 'type': 'string'}},
+                'required': ['name'],
+                'title': 'CatModel',
+                'type': 'object',
+            },
+            'SparrowModel': {
+                'properties': {'name': {'enum': ['sparrow', 'birdie'], 'title': 'Name', 'type': 'string'}},
+                'required': ['name'],
+                'title': 'SparrowModel',
+                'type': 'object',
+            },
+        },
+        'discriminator': {
+            'mapping': {
+                'birdie': '#/$defs/SparrowModel',
+                'cat': '#/$defs/CatModel',
+                'kitty': '#/$defs/CatModel',
+                'sparrow': '#/$defs/SparrowModel',
+            },
+            'propertyName': 'name',
+        },
+        'oneOf': [{'$ref': '#/$defs/CatModel'}, {'$ref': '#/$defs/SparrowModel'}],
+    }","['tests/test_discriminated_union.py', 'pydantic/_internal/_discriminated_union.py']",{'.py': 2},2,0,0,2,2,1317801,298085,35242,95,252,49,4,1,2559,255,673,84,1,2,2023-07-09 18:01:17,15163,Python,"{'Python': 3010068, 'Makefile': 4489, 'Shell': 2632}",MIT License,"['pydantic/deprecated/decorator.py', 'pydantic/_internal/_discriminated_union.py', 'pydantic/fields.py', 'pydantic/validators.py', 'pydantic/deprecated/class_validators.py']","['pydantic/deprecated/decorator.py', 'pydantic/_internal/_discriminated_union.py', 'pydantic/fields.py', 'pydantic/validators.py', 'pydantic/deprecated/class_validators.py']","['```json\n{\n  ""files"": [\n    ""pydantic/_internal/_discriminated_union.py"",\n    ""pydantic/fields.py"",\n    ""pydantic/validators.py"",\n    ""pydantic/deprecated/decorator.py"",\n    ""pydantic/deprecated/class_validators.py""\n  ]\n}\n```']",1,841.1803245544434
7902,mlflow/mlflow/5720/5713,mlflow,mlflow,https://github.com/mlflow/mlflow/issues/5713,https://github.com/mlflow/mlflow/pull/5720,https://github.com/mlflow/mlflow/pull/5720,1,fixes,[BUG] Postgresql sqlalchemy.exc.DataError is not caught causing the server to hang for over 60 seconds,"Thank you for submitting an issue. Please refer to our [issue policy](https://www.github.com/mlflow/mlflow/blob/master/ISSUE_POLICY.md) for additional information about bug reports. For help with debugging your code, please refer to [Stack Overflow](https://stackoverflow.com/questions/tagged/mlflow).

**Please fill in this bug report template to ensure a timely and thorough response.**

### Willingness to contribute
The MLflow Community encourages bug fix contributions. Would you or another member of your organization be willing to contribute a fix for this bug to the MLflow code base?

- [ ] Yes. I can contribute a fix for this bug independently.
- [ ] Yes. I would be willing to contribute a fix for this bug with guidance from the MLflow community.
- [x] No. I cannot contribute a bug fix at this time.

### System information
- **Have I written custom code (as opposed to using a stock example script provided in MLflow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: CentOS Linux 7
- **MLflow installed from (source or binary)**: binary
- **MLflow version (run ``mlflow --version``)**: mlflow, version 1.23.1
- **Python version**: Python 3.9.5
- **npm version, if running the dev UI**: N/A
- **Exact command to reproduce**: 

1. Using the backend postgresql+psycopg2 (this error does not occur with sqllite)
2. Run this python method with a non-string/int experiment_id:
```
# this gives an unexpected error and makes the server unresponsive for over 60 seconds
mlflow.start_run(experiment_id={""test"":""test""}, run_name=""Hello World"")
```

### Describe the problem
Describe the problem clearly here. Include descriptions of the expected behavior and the actual behavior.

When I run `mlflow.start_run(experiment_id={""test"":""test""}, run_name=""Hello World"")` where the experiment id is a non-string or integer, instead of getting an expected input validation error, the request hangs for over 60 seconds effectively making the server go unresponsive, and finally returns the error: 
```
MlflowException: API request to http://localhost:5000/api/2.0/mlflow/runs/create failed with exception HTTPConnectionPool(host='localhost', port=5000): Max retries exceeded with url: /api/2.0/mlflow/runs/create (Caused by ResponseError('too many 500 error responses'))
```

This does not happen using the sqllite backend. 

Server Error: 
```
sqlalchemy.exc.DataError: (psycopg2.errors.InvalidTextRepresentation) invalid input syntax for type integer: ""{'test': 'test'}""
```
### Tracking information

<!-- This section is optional -->

For bugs related to the tracking features (e.g. mlflow should log a run in my database but it doesn't), please insert the following code in your python script / notebook where you encountered the bug and run it:

```python
print(""MLflow version:"", mlflow.__version__)
print(""Tracking URI:"", mlflow.get_tracking_uri())
print(""Artifact URI:"", mlflow.get_artifact_uri())
```

Then, make sure the printed out information matches what you expect and paste it (with sensitive information masked) in the box below:

```
MLflow version: 1.25.1
Tracking URI: http://localhost:5000/
Artifact URI: local-artifacts/0/68e0c4bee1a14515b03884c56e221f9b/artifacts
```

If you know the command that was used to launch your tracking server (e.g. `mlflow server -h 0.0.0.0 -p 5000`), please provide it:

```
mlflow server --backend-store-uri postgresql+psycopg2:user:secret@localhost/mlflow --default-artifact-root=local-artifacts --host 0.0.0.0

```

### Code to reproduce issue
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
```
# this breaks and makes the server unresponsive for over 60 seconds
mlflow.start_run(experiment_id={""test"":""test""}, run_name=""Hello World"")
```

### Other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.


### What component(s), interfaces, languages, and integrations does this bug affect?
Components 
- [ ] `area/artifacts`: Artifact stores and artifact logging
- [ ] `area/build`: Build and test infrastructure for MLflow
- [ ] `area/docs`: MLflow documentation pages
- [ ] `area/examples`: Example code
- [ ] `area/model-registry`: Model Registry service, APIs, and the fluent client calls for Model Registry
- [ ] `area/models`: MLmodel format, model serialization/deserialization, flavors
- [ ] `area/projects`: MLproject format, project running backends
- [ ] `area/scoring`: MLflow Model server, model deployment tools, Spark UDFs
- [X] `area/server-infra`: MLflow Tracking server backend
- [X] `area/tracking`: Tracking Service, tracking client APIs, autologging

Interface 
- [ ] `area/uiux`: Front-end, user experience, plotting, JavaScript, JavaScript dev server
- [ ] `area/docker`: Docker use across MLflow's components, such as MLflow Projects and MLflow Models
- [ ] `area/sqlalchemy`: Use of SQLAlchemy in the Tracking Service or Model Registry
- [ ] `area/windows`: Windows support

Language 
- [ ] `language/r`: R APIs and clients
- [ ] `language/java`: Java APIs and clients
- [ ] `language/new`: Proposals for new client languages

Integrations
- [ ] `integrations/azure`: Azure and Azure ML integrations
- [ ] `integrations/sagemaker`: SageMaker integrations
- [ ] `integrations/databricks`: Databricks integrations
",eba5fdc9d66a4e7289423dfed6c65957f9f73a40,01fefcba609320de66bec06af0d6fdcab307d9da,https://github.com/mlflow/mlflow/compare/eba5fdc9d66a4e7289423dfed6c65957f9f73a40...01fefcba609320de66bec06af0d6fdcab307d9da,"diff --git a/mlflow/tracking/fluent.py b/mlflow/tracking/fluent.py
index 5b6b5324f..2e0bb25c9 100644
--- a/mlflow/tracking/fluent.py
+++ b/mlflow/tracking/fluent.py
@@ -38,7 +38,7 @@ from mlflow.utils.mlflow_tags import (
     MLFLOW_RUN_NAME,
     MLFLOW_RUN_NOTE,
 )
-from mlflow.utils.validation import _validate_run_id
+from mlflow.utils.validation import _validate_run_id, _validate_experiment_id_type
 
 if TYPE_CHECKING:
     import pandas  # pylint: disable=unused-import
@@ -231,6 +231,7 @@ def start_run(
         0  78b3b0d264b44cd29e8dc389749bb4be          yes           CHILD_RUN
     """"""
     global _active_run_stack
+    _validate_experiment_id_type(experiment_id)
     # back compat for int experiment_id
     experiment_id = str(experiment_id) if isinstance(experiment_id, int) else experiment_id
     if len(_active_run_stack) > 0 and not nested:
diff --git a/mlflow/utils/validation.py b/mlflow/utils/validation.py
index abde1acbf..c92f9a774 100644
--- a/mlflow/utils/validation.py
+++ b/mlflow/utils/validation.py
@@ -345,6 +345,19 @@ def _validate_experiment_name(experiment_name):
         )
 
 
+def _validate_experiment_id_type(experiment_id):
+    """"""
+    Check that a user-provided experiment_id is either a string, int, or None and raise an
+    exception if it isn't.
+    """"""
+    if experiment_id is not None and not isinstance(experiment_id, (str, int)):
+        raise MlflowException(
+            f""Invalid experiment id: {experiment_id} of type {type(experiment_id)}. ""
+            ""Must be one of str, int, or None."",
+            error_code=INVALID_PARAMETER_VALUE,
+        )
+
+
 def _validate_model_name(model_name):
     if model_name is None or model_name == """":
         raise MlflowException(""Registered model name cannot be empty."", INVALID_PARAMETER_VALUE)
diff --git a/tests/tracking/fluent/test_fluent.py b/tests/tracking/fluent/test_fluent.py
index b2fe425c6..c69876bf0 100644
--- a/tests/tracking/fluent/test_fluent.py
+++ b/tests/tracking/fluent/test_fluent.py
@@ -487,6 +487,14 @@ def test_start_run_defaults_databricks_notebook(
         assert is_from_run(active_run, MlflowClient.create_run.return_value)
 
 
+@pytest.mark.parametrize(
+    ""experiment_id"", [(""a"", ""b""), {""a"", ""b""}, [""a"", ""b""], {""a"": 1}, [], (), {}]
+)
+def test_start_run_raises_invalid_experiment_id(experiment_id):
+    with pytest.raises(MlflowException, match=""Invalid experiment id: ""):
+        start_run(experiment_id=experiment_id)
+
+
 @pytest.mark.usefixtures(empty_active_run_stack.__name__)
 def test_start_run_creates_new_run_with_user_specified_tags():
     mock_experiment_id = mock.Mock()
@@ -553,7 +561,7 @@ def test_start_run_resumes_existing_run_and_sets_user_specified_tags():
 
 def test_start_run_with_parent():
     parent_run = mock.Mock()
-    mock_experiment_id = mock.Mock()
+    mock_experiment_id = ""123456""
     mock_source_name = mock.Mock()
 
     active_run_stack_patch = mock.patch(""mlflow.tracking.fluent._active_run_stack"", [parent_run])","['mlflow/tracking/fluent.py', 'tests/tracking/fluent/test_fluent.py', 'mlflow/utils/validation.py']",{'.py': 3},3,0,0,3,3,3019536,664333,75932,343,687,153,16,2,5498,735,1311,108,4,7,2022-04-19 02:08:08,14934,Python,"{'Python': 7988649, 'JavaScript': 2263223, 'TypeScript': 2124583, 'Java': 290414, 'R': 208805, 'Scala': 39820, 'Shell': 28522, 'CSS': 20429, 'HTML': 16445, 'Dockerfile': 1312, 'Mako': 1004, 'TSQL': 211}",Apache License 2.0,"['mlflow/utils/autologging_utils/events.py', 'mlflow/utils/autologging_utils/safety.py', 'mlflow/tracking/client.py', 'mlflow/utils/autologging_utils/logging_and_warnings.py', 'mlflow/utils/autologging_utils/client.py']","['mlflow/utils/autologging_utils/events.py', 'mlflow/utils/autologging_utils/safety.py', 'mlflow/tracking/client.py', 'mlflow/utils/autologging_utils/logging_and_warnings.py', 'mlflow/utils/autologging_utils/client.py']","['```json\n{\n  ""files"": [\n    ""mlflow/tracking/client.py"",\n    ""mlflow/utils/autologging_utils/client.py"",\n    ""mlflow/utils/autologging_utils/events.py"",\n    ""mlflow/utils/autologging_utils/logging_and_warnings.py"",\n    ""mlflow/utils/autologging_utils/safety.py""\n  ]\n}\n```']",1,1779.332160949707
5181,plotly/plotly.py/2208/2167,plotly,plotly.py,https://github.com/plotly/plotly.py/issues/2167,https://github.com/plotly/plotly.py/pull/2208,https://github.com/plotly/plotly.py/pull/2208,1,resolves,update_annotations: patch should not be required,"

`fig.update_annotations(text='yo')` should a) not error out and b) have the same effect as `fig.update_annotations(patch=dict(text='yo'))`

I think we're missing `patch=None` in the update_annotations/update_shapes/update_layout_image family of methods...",4a7465cbe6b767800f7abd8f57dd0b7462d335ca,0960f4c078921d3a1aa9b60b7830b37d4c67633e,https://github.com/plotly/plotly.py/compare/4a7465cbe6b767800f7abd8f57dd0b7462d335ca...0960f4c078921d3a1aa9b60b7830b37d4c67633e,"diff --git a/packages/python/plotly/codegen/figure.py b/packages/python/plotly/codegen/figure.py
index 1a0f073af..6c5d98fdf 100644
--- a/packages/python/plotly/codegen/figure.py
+++ b/packages/python/plotly/codegen/figure.py
@@ -473,7 +473,7 @@ class {fig_classname}({base_classname}):\\n""""""
 
     def update_{method_prefix}{plural_name}(
         self,
-        patch,
+        patch=None,
         selector=None,
         row=None,
         col=None,
diff --git a/packages/python/plotly/plotly/graph_objs/_figure.py b/packages/python/plotly/plotly/graph_objs/_figure.py
index e0077b125..d907b8634 100644
--- a/packages/python/plotly/plotly/graph_objs/_figure.py
+++ b/packages/python/plotly/plotly/graph_objs/_figure.py
@@ -17450,7 +17450,7 @@ class Figure(BaseFigure):
         return self
 
     def update_annotations(
-        self, patch, selector=None, row=None, col=None, secondary_y=None, **kwargs
+        self, patch=None, selector=None, row=None, col=None, secondary_y=None, **kwargs
     ):
         """"""
         Perform a property update operation on all annotations that satisfy the
@@ -17949,7 +17949,7 @@ class Figure(BaseFigure):
         return self
 
     def update_layout_images(
-        self, patch, selector=None, row=None, col=None, secondary_y=None, **kwargs
+        self, patch=None, selector=None, row=None, col=None, secondary_y=None, **kwargs
     ):
         """"""
         Perform a property update operation on all images that satisfy the
@@ -18221,7 +18221,7 @@ class Figure(BaseFigure):
         return self
 
     def update_shapes(
-        self, patch, selector=None, row=None, col=None, secondary_y=None, **kwargs
+        self, patch=None, selector=None, row=None, col=None, secondary_y=None, **kwargs
     ):
         """"""
         Perform a property update operation on all shapes that satisfy the
diff --git a/packages/python/plotly/plotly/graph_objs/_figurewidget.py b/packages/python/plotly/plotly/graph_objs/_figurewidget.py
index 89042ba66..bb8d57a1d 100644
--- a/packages/python/plotly/plotly/graph_objs/_figurewidget.py
+++ b/packages/python/plotly/plotly/graph_objs/_figurewidget.py
@@ -17450,7 +17450,7 @@ class FigureWidget(BaseFigureWidget):
         return self
 
     def update_annotations(
-        self, patch, selector=None, row=None, col=None, secondary_y=None, **kwargs
+        self, patch=None, selector=None, row=None, col=None, secondary_y=None, **kwargs
     ):
         """"""
         Perform a property update operation on all annotations that satisfy the
@@ -17949,7 +17949,7 @@ class FigureWidget(BaseFigureWidget):
         return self
 
     def update_layout_images(
-        self, patch, selector=None, row=None, col=None, secondary_y=None, **kwargs
+        self, patch=None, selector=None, row=None, col=None, secondary_y=None, **kwargs
     ):
         """"""
         Perform a property update operation on all images that satisfy the
@@ -18221,7 +18221,7 @@ class FigureWidget(BaseFigureWidget):
         return self
 
     def update_shapes(
-        self, patch, selector=None, row=None, col=None, secondary_y=None, **kwargs
+        self, patch=None, selector=None, row=None, col=None, secondary_y=None, **kwargs
     ):
         """"""
         Perform a property update operation on all shapes that satisfy the
diff --git a/packages/python/plotly/plotly/tests/test_core/test_update_objects/test_update_annotations.py b/packages/python/plotly/plotly/tests/test_core/test_update_objects/test_update_annotations.py
index 26e589603..0edd3cb64 100644
--- a/packages/python/plotly/plotly/tests/test_core/test_update_objects/test_update_annotations.py
+++ b/packages/python/plotly/plotly/tests/test_core/test_update_objects/test_update_annotations.py
@@ -219,6 +219,10 @@ class TestSelectForEachUpdateAnnotations(TestCase):
             ""annotations"", [4], patch=dict(showarrow=False), secondary_y=True
         )
 
+    def test_annotation_attributes(self):
+        self.fig.add_annotation(text=""this text"", yref=""paper"")
+        self.fig.update_annotations(text=""hi"")
+
     def test_update_shapes(self):
         (
             self.fig.add_shape(opacity=0.1, fillcolor=""red"")
@@ -237,6 +241,11 @@ class TestSelectForEachUpdateAnnotations(TestCase):
         self.assert_update(""shapes"", [2, 5], patch=dict(opacity=0), col=1)
         self.assert_update(""shapes"", [4], patch=dict(opacity=0), secondary_y=True)
 
+    def test_shape_attributes(self):
+
+        self.fig.add_shape(fillcolor=""blue"", opacity=0.3)
+        self.fig.update_shapes(fillcolor=""red"")
+
     def test_update_images(self):
         (
             self.fig.add_layout_image(opacity=0.1, source=""red"")
@@ -254,3 +263,7 @@ class TestSelectForEachUpdateAnnotations(TestCase):
         self.assert_update(""images"", [2, 3, 4], patch=dict(opacity=0), row=1)
         self.assert_update(""images"", [2, 5], patch=dict(opacity=0), col=1)
         self.assert_update(""images"", [4], patch=dict(opacity=0), secondary_y=True)
+
+    def test_image_attributes(self):
+        self.fig.add_layout_image(name=""my name"", x=1, y=2)
+        self.fig.update_layout_images(opacity=0.1)","['packages/python/plotly/plotly/graph_objs/_figurewidget.py', 'packages/python/plotly/plotly/graph_objs/_figure.py', 'packages/python/plotly/codegen/figure.py', 'packages/python/plotly/plotly/tests/test_core/test_update_objects/test_update_annotations.py']",{'.py': 4},4,0,0,4,4,24617768,5497101,685505,1311,1072,265,14,3,261,25,58,5,0,0,2020-02-17 20:08:10,13902,Python,"{'Python': 32436825, 'PostScript': 572749, 'TypeScript': 71866, 'JavaScript': 2074, 'CSS': 466}",MIT License,"['packages/python/plotly/plotly/graph_objs/layout/scene/yaxis/__init__.py', 'packages/python/plotly/plotly/graph_objs/layout/annotation/hoverlabel/__init__.py', 'packages/python/plotly/plotly/graph_objs/layout/scene/zaxis/__init__.py', 'packages/python/plotly/plotly/graph_objs/layout/scene/xaxis/__init__.py', 'packages/python/plotly/plotly/validators/treemap/marker/colorbar/title/font/__init__.py', 'packages/python/plotly/plotly/graph_objs/layout/scene/annotation/__init__.py', 'packages/python/plotly/plotly/graph_objs/layout/annotation/__init__.py']","['packages/python/plotly/plotly/graph_objs/layout/scene/yaxis/__init__.py', 'packages/python/plotly/plotly/graph_objs/layout/annotation/hoverlabel/__init__.py', 'packages/python/plotly/plotly/graph_objs/layout/scene/xaxis/__init__.py', 'packages/python/plotly/plotly/graph_objs/layout/scene/annotation/__init__.py', 'packages/python/plotly/plotly/graph_objs/layout/annotation/__init__.py']","['```json\n{\n  ""files"": [\n    ""packages/python/plotly/plotly/graph_objs/layout/annotation/__init__.py"",\n    ""packages/python/plotly/plotly/graph_objs/layout/annotation/__init__.py"",\n    ""packages/python/plotly/plotly/graph_objs/layout/annotation/__init__.py"",\n    ""packages/python/plotly/plotly/graph_objs/layout/annotation/__init__.py"",\n    ""packages/python/plotly/plotly/graph_objs/layout/annotation/__init__.py""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""packages/python/plotly/plotly/graph_objs/layout/annotation/hoverlabel/__init__.py"",\n    ""packages/python/plotly/plotly/graph_objs/layout/scene/annotation/__init__.py"",\n    ""packages/python/plotly/plotly/graph_objs/layout/scene/xaxis/__init__.py"",\n    ""packages/python/plotly/plotly/graph_objs/layout/scene/yaxis/__init__.py"",\n    ""packages/python/plotly/plotly/graph_objs/layout/scene/zaxis/__init__.py""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""packages/python/plotly/plotly/validators/treemap/marker/colorbar/title/font/__init__.py""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""packages/python/plotly/plotly/graph_objs/layout/annotation/__init__.py"",\n    ""packages/python/plotly/plotly/graph_objs/layout/annotation/hoverlabel/__init__.py"",\n    ""packages/python/plotly/plotly/graph_objs/layout/scene/annotation/__init__.py"",\n    ""packages/python/plotly/plotly/graph_objs/layout/scene/xaxis/__init__.py"",\n    ""packages/python/plotly/plotly/graph_objs/layout/scene/yaxis/__init__.py""\n  ]\n}\n```']",3,7965.967893600464
8262,rapptz/discord.py/1967/1862,rapptz,discord.py,https://github.com/Rapptz/discord.py/issues/1862,https://github.com/Rapptz/discord.py/pull/1967,https://github.com/Rapptz/discord.py/pull/1967,1,fixes,Unclosed Client Session... have yet to find this answer,"I know this has been asked about before... I've looked and looked and looked. So many people having this issue are simply bad at OOP but I've stripped it down to the bare essentials to see what is causing this issue and I just cannot figure it out. Some more experienced guidance would be HIGHLY appreciated!

File to run: **mybot.py**
```python
import discord
from discord.ext import commands
from discord.ext.commands import Bot
import asyncio

client = commands.Bot(command_prefix=""?"")

class MyBot():
  def __init__(self, bot):
    bot.load_extension(""mycog"")
    bot.run(TOKEN, bot=True, reconnect=True)

  @client.event
  async def on_ready():
    print(""Bot is listening..."")

  @client.event
  async def on_message(message):
    await client.process_commands(message)

if __name__ == ""__main__"": MyBot(client)
```

File to load: **mycog.py**
```python
from discord.ext import commands
import asyncio

class MyCog:
  def __init__(self, bot):
    self.bot = bot

  @commands.command()
  async def shutdown(self, ctx):
    await self.bot.close()
    return None

def setup(client): client.add_cog(MyCog(client))
```
Bot runs fine, I input command `?shutdown` and while it does shut down I get this error...
```
Unclosed client session
client_session: <aiohttp.client.ClientSession object at 0x000001BDA9A55EF0>
Unclosed connector
connections: ['[(<aiohttp.client_proto.ResponseHandler object at 0x000001BDA9BED1C8>, 181630.39)]']
connector: <aiohttp.connector.TCPConnector object at 0x000001BDA9A55F60>
```
But why? I thought using client.close() or .logout() would properly shut everything down. Is there any way to have everything gracefully exit?",42a7c4f7e5caa7baf555e86b52249419ce33acfc,8b8e9a619efa47fa97bf6daa4f0ec849544af437,https://github.com/rapptz/discord.py/compare/42a7c4f7e5caa7baf555e86b52249419ce33acfc...8b8e9a619efa47fa97bf6daa4f0ec849544af437,"diff --git a/discord/client.py b/discord/client.py
index 26e22df9..7f9e2c30 100644
--- a/discord/client.py
+++ b/discord/client.py
@@ -440,6 +440,7 @@ class Client:
         if self.is_closed():
             return
 
+        await self.http.close()
         self._closed.set()
 
         for voice in self.voice_clients:
@@ -452,8 +453,6 @@ class Client:
         if self.ws is not None and self.ws.open:
             await self.ws.close()
 
-
-        await self.http.close()
         self._ready.clear()
 
     def clear(self):",['discord/client.py'],{'.py': 1},1,0,0,1,1,750884,163219,22215,60,67,12,3,1,1705,198,417,52,0,3,2019-03-09 14:25:20,13277,Python,{'Python': 2593438},MIT License,"['mybot.py', 'mycog.py']",[],"['```json\n{\n  ""files"": [\n    ""mybot.py"",\n    ""mycog.py""\n  ]\n}\n```']",1,669.9032783508301
5073,netbox-community/netbox/10187/9895,netbox-community,netbox,https://github.com/netbox-community/netbox/issues/9895,https://github.com/netbox-community/netbox/pull/10187,https://github.com/netbox-community/netbox/pull/10187,1,fixes,"swagger/ipam/ip-addresses/: Invalid type for ""assigned_object""","### NetBox version

v3.2.6

### Python version

3.8

### Steps to Reproduce

Hi there,

the netbox swagger.yml states that the IP address list endpoint `/ipam/ip-addresses/` returns a value of type map[string]string for key `assigned_object ` instead of the correct type object. This causes issues for me since I use an auto-generated api client which will error out in case it receives something _not string-like_ - in this case e.g. a number as id.

Another similar issue has been opened here already: https://github.com/netbox-community/go-netbox/issues/133

What can we do about that? :)

Thanks a lot!

### Expected Behavior

Correct type stated in swagger.yml

### Observed Behavior

Incorrect type stated in swagger.yml",83db8d207208d9abe88a038f6114fc3247d163e5,4f7287fec5f7157cfc37096449cb7be2e104a56f,https://github.com/netbox-community/netbox/compare/83db8d207208d9abe88a038f6114fc3247d163e5...4f7287fec5f7157cfc37096449cb7be2e104a56f,"diff --git a/netbox/dcim/api/nested_serializers.py b/netbox/dcim/api/nested_serializers.py
index 1be8bb9dc..f5e06e155 100644
--- a/netbox/dcim/api/nested_serializers.py
+++ b/netbox/dcim/api/nested_serializers.py
@@ -316,6 +316,7 @@ class NestedModuleSerializer(WritableNestedSerializer):
 class NestedConsoleServerPortSerializer(WritableNestedSerializer):
     url = serializers.HyperlinkedIdentityField(view_name='dcim-api:consoleserverport-detail')
     device = NestedDeviceSerializer(read_only=True)
+    _occupied = serializers.BooleanField(required=False, read_only=True)
 
     class Meta:
         model = models.ConsoleServerPort
@@ -325,6 +326,7 @@ class NestedConsoleServerPortSerializer(WritableNestedSerializer):
 class NestedConsolePortSerializer(WritableNestedSerializer):
     url = serializers.HyperlinkedIdentityField(view_name='dcim-api:consoleport-detail')
     device = NestedDeviceSerializer(read_only=True)
+    _occupied = serializers.BooleanField(required=False, read_only=True)
 
     class Meta:
         model = models.ConsolePort
@@ -334,6 +336,7 @@ class NestedConsolePortSerializer(WritableNestedSerializer):
 class NestedPowerOutletSerializer(WritableNestedSerializer):
     url = serializers.HyperlinkedIdentityField(view_name='dcim-api:poweroutlet-detail')
     device = NestedDeviceSerializer(read_only=True)
+    _occupied = serializers.BooleanField(required=False, read_only=True)
 
     class Meta:
         model = models.PowerOutlet
@@ -343,6 +346,7 @@ class NestedPowerOutletSerializer(WritableNestedSerializer):
 class NestedPowerPortSerializer(WritableNestedSerializer):
     url = serializers.HyperlinkedIdentityField(view_name='dcim-api:powerport-detail')
     device = NestedDeviceSerializer(read_only=True)
+    _occupied = serializers.BooleanField(required=False, read_only=True)
 
     class Meta:
         model = models.PowerPort
@@ -352,6 +356,7 @@ class NestedPowerPortSerializer(WritableNestedSerializer):
 class NestedInterfaceSerializer(WritableNestedSerializer):
     device = NestedDeviceSerializer(read_only=True)
     url = serializers.HyperlinkedIdentityField(view_name='dcim-api:interface-detail')
+    _occupied = serializers.BooleanField(required=False, read_only=True)
 
     class Meta:
         model = models.Interface
@@ -361,6 +366,7 @@ class NestedInterfaceSerializer(WritableNestedSerializer):
 class NestedRearPortSerializer(WritableNestedSerializer):
     device = NestedDeviceSerializer(read_only=True)
     url = serializers.HyperlinkedIdentityField(view_name='dcim-api:rearport-detail')
+    _occupied = serializers.BooleanField(required=False, read_only=True)
 
     class Meta:
         model = models.RearPort
@@ -370,6 +376,7 @@ class NestedRearPortSerializer(WritableNestedSerializer):
 class NestedFrontPortSerializer(WritableNestedSerializer):
     device = NestedDeviceSerializer(read_only=True)
     url = serializers.HyperlinkedIdentityField(view_name='dcim-api:frontport-detail')
+    _occupied = serializers.BooleanField(required=False, read_only=True)
 
     class Meta:
         model = models.FrontPort
@@ -454,6 +461,7 @@ class NestedPowerPanelSerializer(WritableNestedSerializer):
 
 class NestedPowerFeedSerializer(WritableNestedSerializer):
     url = serializers.HyperlinkedIdentityField(view_name='dcim-api:powerfeed-detail')
+    _occupied = serializers.BooleanField(required=False, read_only=True)
 
     class Meta:
         model = models.PowerFeed
diff --git a/netbox/dcim/api/serializers.py b/netbox/dcim/api/serializers.py
index af806acb8..79f5339ad 100644
--- a/netbox/dcim/api/serializers.py
+++ b/netbox/dcim/api/serializers.py
@@ -579,7 +579,7 @@ class InventoryItemTemplateSerializer(ValidatedModelSerializer):
             'description', 'component_type', 'component_id', 'component', 'created', 'last_updated', '_depth',
         ]
 
-    @swagger_serializer_method(serializer_or_field=serializers.DictField)
+    @swagger_serializer_method(serializer_or_field=serializers.JSONField)
     def get_component(self, obj):
         if obj.component is None:
             return None
@@ -693,13 +693,13 @@ class DeviceWithConfigContextSerializer(DeviceSerializer):
             'local_context_data', 'tags', 'custom_fields', 'config_context', 'created', 'last_updated',
         ]
 
-    @swagger_serializer_method(serializer_or_field=serializers.DictField)
+    @swagger_serializer_method(serializer_or_field=serializers.JSONField)
     def get_config_context(self, obj):
         return obj.get_config_context()
 
 
 class DeviceNAPALMSerializer(serializers.Serializer):
-    method = serializers.DictField()
+    method = serializers.JSONField()
 
 
 #
@@ -975,7 +975,7 @@ class InventoryItemSerializer(NetBoxModelSerializer):
             'custom_fields', 'created', 'last_updated', '_depth',
         ]
 
-    @swagger_serializer_method(serializer_or_field=serializers.DictField)
+    @swagger_serializer_method(serializer_or_field=serializers.JSONField)
     def get_component(self, obj):
         if obj.component is None:
             return None
@@ -1046,7 +1046,7 @@ class CableTerminationSerializer(NetBoxModelSerializer):
             'id', 'url', 'display', 'cable', 'cable_end', 'termination_type', 'termination_id', 'termination'
         ]
 
-    @swagger_serializer_method(serializer_or_field=serializers.DictField)
+    @swagger_serializer_method(serializer_or_field=serializers.JSONField)
     def get_termination(self, obj):
         serializer = get_serializer_for_model(obj.termination, prefix=NESTED_SERIALIZER_PREFIX)
         context = {'request': self.context['request']}
diff --git a/netbox/extras/api/serializers.py b/netbox/extras/api/serializers.py
index 69792e88c..533238d36 100644
--- a/netbox/extras/api/serializers.py
+++ b/netbox/extras/api/serializers.py
@@ -192,7 +192,7 @@ class ImageAttachmentSerializer(ValidatedModelSerializer):
 
         return data
 
-    @swagger_serializer_method(serializer_or_field=serializers.DictField)
+    @swagger_serializer_method(serializer_or_field=serializers.JSONField)
     def get_parent(self, obj):
         serializer = get_serializer_for_model(obj.parent, prefix=NESTED_SERIALIZER_PREFIX)
         return serializer(obj.parent, context={'request': self.context['request']}).data
@@ -242,7 +242,7 @@ class JournalEntrySerializer(NetBoxModelSerializer):
 
         return data
 
-    @swagger_serializer_method(serializer_or_field=serializers.DictField)
+    @swagger_serializer_method(serializer_or_field=serializers.JSONField)
     def get_assigned_object(self, instance):
         serializer = get_serializer_for_model(instance.assigned_object_type.model_class(), prefix=NESTED_SERIALIZER_PREFIX)
         context = {'request': self.context['request']}
@@ -461,7 +461,7 @@ class ObjectChangeSerializer(BaseModelSerializer):
             'changed_object_id', 'changed_object', 'prechange_data', 'postchange_data',
         ]
 
-    @swagger_serializer_method(serializer_or_field=serializers.DictField)
+    @swagger_serializer_method(serializer_or_field=serializers.JSONField)
     def get_changed_object(self, obj):
         """"""
         Serialize a nested representation of the changed object.
diff --git a/netbox/ipam/api/serializers.py b/netbox/ipam/api/serializers.py
index 91a81d3b2..6244e5f04 100644
--- a/netbox/ipam/api/serializers.py
+++ b/netbox/ipam/api/serializers.py
@@ -143,7 +143,7 @@ class FHRPGroupAssignmentSerializer(NetBoxModelSerializer):
             'last_updated',
         ]
 
-    @swagger_serializer_method(serializer_or_field=serializers.DictField)
+    @swagger_serializer_method(serializer_or_field=serializers.JSONField)
     def get_interface(self, obj):
         if obj.interface is None:
             return None
@@ -373,7 +373,7 @@ class IPAddressSerializer(NetBoxModelSerializer):
             'custom_fields', 'created', 'last_updated',
         ]
 
-    @swagger_serializer_method(serializer_or_field=serializers.DictField)
+    @swagger_serializer_method(serializer_or_field=serializers.JSONField)
     def get_assigned_object(self, obj):
         if obj.assigned_object is None:
             return None
@@ -482,7 +482,7 @@ class L2VPNTerminationSerializer(NetBoxModelSerializer):
             'assigned_object', 'tags', 'custom_fields', 'created', 'last_updated'
         ]
 
-    @swagger_serializer_method(serializer_or_field=serializers.DictField)
+    @swagger_serializer_method(serializer_or_field=serializers.JSONField)
     def get_assigned_object(self, instance):
         serializer = get_serializer_for_model(instance.assigned_object, prefix=NESTED_SERIALIZER_PREFIX)
         context = {'request': self.context['request']}
diff --git a/netbox/netbox/api/serializers/generic.py b/netbox/netbox/api/serializers/generic.py
index 5016bdaab..f01e6995a 100644
--- a/netbox/netbox/api/serializers/generic.py
+++ b/netbox/netbox/api/serializers/generic.py
@@ -38,7 +38,7 @@ class GenericObjectSerializer(serializers.Serializer):
 
         return data
 
-    @swagger_serializer_method(serializer_or_field=serializers.DictField)
+    @swagger_serializer_method(serializer_or_field=serializers.JSONField)
     def get_object(self, obj):
         serializer = get_serializer_for_model(obj, prefix=NESTED_SERIALIZER_PREFIX)
         # context = {'request': self.context['request']}
diff --git a/netbox/netbox/settings.py b/netbox/netbox/settings.py
index 8c44ff015..ee91d057c 100644
--- a/netbox/netbox/settings.py
+++ b/netbox/netbox/settings.py
@@ -575,7 +575,6 @@ SWAGGER_SETTINGS = {
     'DEFAULT_AUTO_SCHEMA_CLASS': 'utilities.custom_inspectors.NetBoxSwaggerAutoSchema',
     'DEFAULT_FIELD_INSPECTORS': [
         'utilities.custom_inspectors.CustomFieldsDataFieldInspector',
-        'utilities.custom_inspectors.JSONFieldInspector',
         'utilities.custom_inspectors.NullableBooleanFieldInspector',
         'utilities.custom_inspectors.ChoiceFieldInspector',
         'utilities.custom_inspectors.SerializedPKRelatedFieldInspector',
@@ -585,6 +584,7 @@ SWAGGER_SETTINGS = {
         'drf_yasg.inspectors.ChoiceFieldInspector',
         'drf_yasg.inspectors.FileFieldInspector',
         'drf_yasg.inspectors.DictFieldInspector',
+        'drf_yasg.inspectors.JSONFieldInspector',
         'drf_yasg.inspectors.SerializerMethodFieldInspector',
         'drf_yasg.inspectors.SimpleFieldInspector',
         'drf_yasg.inspectors.StringDefaultFieldInspector',
diff --git a/netbox/tenancy/api/serializers.py b/netbox/tenancy/api/serializers.py
index f217fdaf8..d2c6801c6 100644
--- a/netbox/tenancy/api/serializers.py
+++ b/netbox/tenancy/api/serializers.py
@@ -107,7 +107,7 @@ class ContactAssignmentSerializer(NetBoxModelSerializer):
             'last_updated',
         ]
 
-    @swagger_serializer_method(serializer_or_field=serializers.DictField)
+    @swagger_serializer_method(serializer_or_field=serializers.JSONField)
     def get_object(self, instance):
         serializer = get_serializer_for_model(instance.content_type.model_class(), prefix=NESTED_SERIALIZER_PREFIX)
         context = {'request': self.context['request']}
diff --git a/netbox/utilities/custom_inspectors.py b/netbox/utilities/custom_inspectors.py
index 1a5ede23f..258399e86 100644
--- a/netbox/utilities/custom_inspectors.py
+++ b/netbox/utilities/custom_inspectors.py
@@ -1,4 +1,3 @@
-from django.contrib.postgres.fields import JSONField
 from drf_yasg import openapi
 from drf_yasg.inspectors import FieldInspector, NotHandled, PaginatorInspector, SwaggerAutoSchema
 from drf_yasg.utils import get_serializer_ref_name
@@ -131,15 +130,6 @@ class CustomFieldsDataFieldInspector(FieldInspector):
         return NotHandled
 
 
-class JSONFieldInspector(FieldInspector):
-    """"""Required because by default, Swagger sees a JSONField as a string and not dict
-    """"""
-    def process_result(self, result, method_name, obj, **kwargs):
-        if isinstance(result, openapi.Schema) and isinstance(obj, JSONField):
-            result.type = 'dict'
-        return result
-
-
 class NullablePaginatorInspector(PaginatorInspector):
     def process_result(self, result, method_name, obj, **kwargs):
         if method_name == 'get_paginated_response' and isinstance(result, openapi.Schema):
diff --git a/netbox/virtualization/api/serializers.py b/netbox/virtualization/api/serializers.py
index 903d89a07..b88bc7712 100644
--- a/netbox/virtualization/api/serializers.py
+++ b/netbox/virtualization/api/serializers.py
@@ -100,7 +100,7 @@ class VirtualMachineWithConfigContextSerializer(VirtualMachineSerializer):
             'tags', 'custom_fields', 'config_context', 'created', 'last_updated',
         ]
 
-    @swagger_serializer_method(serializer_or_field=serializers.DictField)
+    @swagger_serializer_method(serializer_or_field=serializers.JSONField)
     def get_config_context(self, obj):
         return obj.get_config_context()
 ","['netbox/ipam/api/serializers.py', 'netbox/utilities/custom_inspectors.py', 'netbox/dcim/api/serializers.py', 'netbox/netbox/api/serializers/generic.py', 'netbox/dcim/api/nested_serializers.py', 'netbox/extras/api/serializers.py', 'netbox/netbox/settings.py', 'netbox/tenancy/api/serializers.py', 'netbox/virtualization/api/serializers.py']",{'.py': 9},9,0,0,9,9,2534732,550345,75339,526,3119,587,48,9,734,108,167,27,1,0,2022-08-29 06:11:46,12954,Python,"{'Python': 4218674, 'HTML': 580902, 'TypeScript': 136406, 'SCSS': 65317, 'Shell': 7567, 'JavaScript': 6625}",Apache License 2.0,"['netbox/netbox/api/serializers/base.py', 'netbox/netbox/api/viewsets/__init__.py', 'netbox/netbox/api/serializers/features.py', 'netbox/ipam/api/serializers.py', 'netbox/netbox/api/serializers/nested.py']","['netbox/netbox/api/serializers/base.py', 'netbox/netbox/api/viewsets/__init__.py', 'netbox/netbox/api/serializers/features.py', 'netbox/ipam/api/serializers.py', 'netbox/netbox/api/serializers/nested.py']","['```json\n{\n  ""files"": [\n    ""netbox/ipam/api/serializers.py"",\n    ""netbox/netbox/api/serializers/base.py"",\n    ""netbox/netbox/api/serializers/features.py"",\n    ""netbox/netbox/api/serializers/nested.py"",\n    ""netbox/netbox/api/viewsets/__init__.py""\n  ]\n}\n```']",1,1614.6705150604248
4809,nltk/nltk/3042/3041,nltk,nltk,https://github.com/nltk/nltk/issues/3041,https://github.com/nltk/nltk/pull/3042,https://github.com/nltk/nltk/pull/3042,1,resolves,Sonority sequencing syllable tokenizer performs significantly slower on numbers than on words,"The sonority sequencing syllable tokenizer (`nltk.SyllableTokenizer`) performs significantly slower on numbers than on words. It seems that the time complexity for words is O(n), which is okay, but O(n^2) for numbers, which is not so good.

```
>>> timeit.timeit('t.tokenize(""99"")', setup='import nltk; t = nltk.SyllableTokenizer()', number = 100)
0.03364099999998871
>>> timeit.timeit('t.tokenize(""thisisanextremelylongword"")', setup='import nltk; t = nltk.SyllableTokenizer()', number = 100)
0.002708099999949809
>>> timeit.timeit('t.tokenize(""99"")', setup='import nltk; t = nltk.SyllableTokenizer()', number = 1000)
2.5833234000000402
>>> timeit.timeit('t.tokenize(""thisisanextremelylongword"")', setup='import nltk; t = nltk.SyllableTokenizer()', number = 1000)
0.023796200000106182
>>> timeit.timeit('t.tokenize(""99"")', setup='import nltk; t = nltk.SyllableTokenizer()', number = 10000)
264.43897390000006
>>> timeit.timeit('t.tokenize(""thisisanextremelylongword"")', setup='import nltk; t = nltk.SyllableTokenizer()', number = 10000)
0.24109669999984362
```

OS: Windows 10 x64
Python: 3.8.10 x64
NLTK: 3.7",13cea29c3f99db93296b10c6333368f88be4135d,3722cfee336955d00ca825f0d04739d647c72d2d,https://github.com/nltk/nltk/compare/13cea29c3f99db93296b10c6333368f88be4135d...3722cfee336955d00ca825f0d04739d647c72d2d,"diff --git a/nltk/test/unit/test_tokenize.py b/nltk/test/unit/test_tokenize.py
index 333761731..591ddbf7c 100644
--- a/nltk/test/unit/test_tokenize.py
+++ b/nltk/test/unit/test_tokenize.py
@@ -270,6 +270,15 @@ class TestTokenize:
         tokens = tokenizer.tokenize(""justification"")
         assert tokens == [""jus"", ""ti"", ""fi"", ""ca"", ""tion""]
 
+    def test_syllable_tokenizer_numbers(self):
+        """"""
+        Test SyllableTokenizer tokenizer.
+        """"""
+        tokenizer = SyllableTokenizer()
+        text = ""9"" * 10000
+        tokens = tokenizer.tokenize(text)
+        assert tokens == [text]
+
     def test_legality_principle_syllable_tokenizer(self):
         """"""
         Test LegalitySyllableTokenizer tokenizer.
diff --git a/nltk/tokenize/sonority_sequencing.py b/nltk/tokenize/sonority_sequencing.py
index 940370d58..1dc3538bc 100644
--- a/nltk/tokenize/sonority_sequencing.py
+++ b/nltk/tokenize/sonority_sequencing.py
@@ -98,14 +98,15 @@ class SyllableTokenizer(TokenizerI):
             try:
                 syllables_values.append((c, self.phoneme_map[c]))
             except KeyError:
-                if c not in punctuation:
+                if c not in ""0123456789"" and c not in punctuation:
                     warnings.warn(
                         ""Character not defined in sonority_hierarchy,""
                         "" assigning as vowel: '{}'"".format(c)
                     )
                     syllables_values.append((c, max(self.phoneme_map.values())))
-                    self.vowels += c
-                else:  # If it's a punctuation, assign -1.
+                    if c not in self.vowels:
+                        self.vowels += c
+                else:  # If it's a punctuation or numbers, assign -1.
                     syllables_values.append((c, -1))
         return syllables_values
 
@@ -122,11 +123,12 @@ class SyllableTokenizer(TokenizerI):
         """"""
         valid_syllables = []
         front = """"
+        vowel_pattern = re.compile(""|"".join(self.vowels))
         for i, syllable in enumerate(syllable_list):
             if syllable in punctuation:
                 valid_syllables.append(syllable)
                 continue
-            if not re.search(""|"".join(self.vowels), syllable):
+            if not vowel_pattern.search(syllable):
                 if len(valid_syllables) == 0:
                     front += syllable
                 else:","['nltk/tokenize/sonority_sequencing.py', 'nltk/test/unit/test_tokenize.py']",{'.py': 2},2,0,0,2,2,4516536,1071898,129444,297,541,122,10,1,1129,113,338,20,0,1,2022-09-01 09:44:48,12187,Python,"{'Python': 4859114, 'Jupyter Notebook': 55608, 'HTML': 24786, 'Makefile': 7983, 'Shell': 4707, 'CSS': 705}",Apache License 2.0,['nltk/tokenize/sonority_sequencing.py'],['nltk/tokenize/sonority_sequencing.py'],"['```json\n{\n  ""files"": [\n    ""nltk/tokenize/sonority_sequencing.py""\n  ]\n}\n```']",1,910.6888771057129
8272,spotdl/spotify-downloader/380/370,spotdl,spotify-downloader,https://github.com/spotDL/spotify-downloader/issues/370,https://github.com/spotDL/spotify-downloader/pull/380,https://github.com/spotDL/spotify-downloader/pull/380,1,closes,Having duplicates in track file messes up deletion of tracks from track file,"- [x] Using latest version as provided on the [master branch](https://github.com/ritiek/spotify-downloader/tree/master)
- [x] [Searched](https://github.com/ritiek/spotify-downloader/issues?utf8=%E2%9C%93&q=is%3Aissue) for similar issues including closed ones

#### What is the purpose of your *issue*?
- [x] Bug
- [ ] Feature Request
- [ ] Question
- [ ] Other

### Description
As the title says. Say we have a `track_file.txt`with (duplicate) tracks as below:
```
https://open.spotify.com/track/2DGa7iaidT5s0qnINlwMjJ
https://open.spotify.com/track/2DGa7iaidT5s0qnINlwMjJ
https://open.spotify.com/track/3SipFlNddvL0XNZRLXvdZD
```

On downloading these tracks we get:
```
$ spotdl -l=track_file.txt -d 
INFO: Preparing to download 2 songs

INFO: 1. Alan Walker ‒ The Spectre (Lyrics / Lyrics Video)[HD] (http://www.youtube.com/watch?v=8lPa0963LEc)

INFO: 2. Janji - Heroes Tonight (feat. Johnning) [Lyrics] (http://www.youtube.com/watch?v=7bI36Iu6M6s)
```

```
$ cat track_file.txt
https://open.spotify.com/track/3SipFlNddvL0XNZRLXvdZD
```

spotdl internally removes the duplicates from the track file but does not rewrite the unique tracks back to `track_file.txt`. So, when it successfully downloads the third track from the file in the above case, it deletes the second track instead of the third track and the third track lives on in `track_file.txt`

I can think of three solutions here:

- Fix this by filtering duplicates from track file and re-writing track file with unique tracks so that tracks from track file are deleted in proper order.

- Initially creating a new list of duplicate tracks in file and then take extra care to skip this track and remove it from file if it has been already downloaded once.

- Do nothing and let the script figure out on its own going with the `--overwrite` argument when the same track is being downloaded for the second time.",ac94cf4f3bcb071826d94346cb4b3cee7e6c897e,e076d11a19672b1b08119dce846358747c203df7,https://github.com/spotdl/spotify-downloader/compare/ac94cf4f3bcb071826d94346cb4b3cee7e6c897e...e076d11a19672b1b08119dce846358747c203df7,"diff --git a/spotdl/internals.py b/spotdl/internals.py
index ca8b6e44..76fc6d9d 100755
--- a/spotdl/internals.py
+++ b/spotdl/internals.py
@@ -158,6 +158,23 @@ def get_splits(url):
     return splits
 
 
+def get_unique_tracks(text_file):
+    """"""
+    Returns a list of unique tracks given a path to a
+    file containing tracks.
+    """"""
+
+    with open(text_file, 'r') as listed:
+        # Read tracks into a list and remove any duplicates
+        lines = listed.read().splitlines()
+
+    # Remove blank and strip whitespaces from lines (if any)
+    lines = [line.strip() for line in lines if line.strip()]
+    lines = remove_duplicates(lines)
+
+    return lines
+
+
 # a hacky way to user's localized music directory
 # (thanks @linusg, issue #203)
 def get_music_dir():
diff --git a/spotdl/spotdl.py b/spotdl/spotdl.py
index dc66fe70..b9cfbc03 100755
--- a/spotdl/spotdl.py
+++ b/spotdl/spotdl.py
@@ -65,15 +65,13 @@ def check_exists(music_file, raw_song, meta_tags):
 
 def download_list(text_file):
     """""" Download all songs from the list. """"""
-    with open(text_file, 'r') as listed:
-        # read tracks into a list and remove any duplicates
-        lines = listed.read().splitlines()
-        lines = internals.remove_duplicates(lines)
-    # ignore blank lines in text_file (if any)
-    try:
-        lines.remove('')
-    except ValueError:
-        pass
+
+    log.info('Checking and removing any duplicate tracks')
+    lines = internals.get_unique_tracks(text_file)
+
+    # override file with unique tracks
+    with open(text_file, 'w') as listed:
+        listed.write('\\n'.join(lines))
 
     log.info(u'Preparing to download {} songs'.format(len(lines)))
     downloaded_songs = []
diff --git a/test/test_internals.py b/test/test_internals.py
index 89e63808..2fcd1c8f 100644
--- a/test/test_internals.py
+++ b/test/test_internals.py
@@ -80,3 +80,39 @@ class TestGetSeconds:
             internals.get_sec('10*05')
         with pytest.raises(ValueError):
             internals.get_sec('02,28,46')
+
+
+duplicate_tracks_test_table = [
+    (('https://open.spotify.com/track/2DGa7iaidT5s0qnINlwMjJ',
+      'https://open.spotify.com/track/2DGa7iaidT5s0qnINlwMjJ'),
+     ('https://open.spotify.com/track/2DGa7iaidT5s0qnINlwMjJ',)),
+
+    (('https://open.spotify.com/track/2DGa7iaidT5s0qnINlwMjJ',
+      '',
+      'https://open.spotify.com/track/3SipFlNddvL0XNZRLXvdZD'),
+     ('https://open.spotify.com/track/2DGa7iaidT5s0qnINlwMjJ',
+      'https://open.spotify.com/track/3SipFlNddvL0XNZRLXvdZD')),
+
+    (('ncs fade',
+      'https://open.spotify.com/track/2DGa7iaidT5s0qnINlwMjJ',
+      '',
+      'ncs fade'),
+     ('ncs fade',
+      'https://open.spotify.com/track/2DGa7iaidT5s0qnINlwMjJ')),
+
+    (('ncs spectre ',
+      '  https://open.spotify.com/track/2DGa7iaidT5s0qnINlwMjJ',
+      ''),
+     ('ncs spectre',
+      'https://open.spotify.com/track/2DGa7iaidT5s0qnINlwMjJ'))
+]
+
+
+@pytest.mark.parametrize(""duplicates, expected"", duplicate_tracks_test_table)
+def test_get_unique_tracks(tmpdir, duplicates, expected):
+    file_path = os.path.join(str(tmpdir), 'test_duplicates.txt')
+    with open(file_path, 'w') as tin:
+        tin.write('\\n'.join(duplicates))
+
+    unique_tracks = internals.get_unique_tracks(file_path)
+    assert tuple(unique_tracks) == expected","['spotdl/spotdl.py', 'test/test_internals.py', 'spotdl/internals.py']",{'.py': 3},3,0,0,3,3,49508,11217,1379,10,1031,221,33,2,1907,256,525,41,8,3,2018-10-01 14:50:48,12182,Python,"{'Python': 403461, 'Shell': 1250, 'Dockerfile': 722}",MIT License,"['spotdl/spotdl.py', 'spotdl/handle.py', 'spotdl/spotify_tools.py']","['spotdl/spotdl.py', 'spotdl/handle.py', 'spotdl/spotify_tools.py']","['```json\n{\n  ""files"": [\n    ""spotdl/spotdl.py"",\n    ""spotdl/handle.py"",\n    ""spotdl/spotify_tools.py""\n  ]\n}\n```']",1,808.7320327758789
7971,iterative/dvc/1870/1869,iterative,dvc,https://github.com/iterative/dvc/issues/1869,https://github.com/iterative/dvc/pull/1870,https://github.com/iterative/dvc/pull/1870,1,fix,logger: logger.error() is not printing exception as it used to,"logger.error used to show the exception that it was caused by, but it doesn't anymore unless you are using logger.exception. Need to either replace logger.error() with logger.exception() where needed, or make logger.error() print exception too. E.g. see https://github.com/iterative/dvc/blob/0.34.0/dvc/remote/local.py#L511",50a8ad5ac30019be86c98af73a0399de0ff14772,059aef3ef06ab303f03097677975786394e0e481,https://github.com/iterative/dvc/compare/50a8ad5ac30019be86c98af73a0399de0ff14772...059aef3ef06ab303f03097677975786394e0e481,"diff --git a/dvc/remote/http.py b/dvc/remote/http.py
index 2132e1e55..b505eca50 100644
--- a/dvc/remote/http.py
+++ b/dvc/remote/http.py
@@ -90,7 +90,7 @@ class RemoteHTTP(RemoteBase):
 
             except Exception:
                 msg = ""failed to download '{}'"".format(from_info[""path""])
-                logger.error(msg)
+                logger.exception(msg)
                 continue
 
             if not no_progress_bar:
diff --git a/dvc/remote/local.py b/dvc/remote/local.py
index b5e84a5cc..112336365 100644
--- a/dvc/remote/local.py
+++ b/dvc/remote/local.py
@@ -272,7 +272,7 @@ class RemoteLOCAL(RemoteBase):
                 d = json.load(fd)
         except Exception:
             msg = ""Failed to load dir cache '{}'""
-            logger.error(msg.format(os.path.relpath(path)))
+            logger.exception(msg.format(os.path.relpath(path)))
             return []
 
         if not isinstance(d, list):
@@ -511,7 +511,7 @@ class RemoteLOCAL(RemoteBase):
                 copyfile(from_info[""path""], tmp_file, name=name)
                 os.rename(tmp_file, to_info[""path""])
             except Exception:
-                logger.error(
+                logger.exception(
                     ""failed to upload '{}' to '{}'"".format(
                         from_info[""path""], to_info[""path""]
                     )
@@ -555,7 +555,7 @@ class RemoteLOCAL(RemoteBase):
 
                 move(tmp_file, to_info[""path""])
             except Exception:
-                logger.error(
+                logger.exception(
                     ""failed to download '{}' to '{}'"".format(
                         from_info[""path""], to_info[""path""]
                     )
diff --git a/dvc/remote/s3.py b/dvc/remote/s3.py
index baef66c3e..a18e61a79 100644
--- a/dvc/remote/s3.py
+++ b/dvc/remote/s3.py
@@ -188,7 +188,7 @@ class RemoteS3(RemoteBase):
                 )
             except Exception:
                 msg = ""failed to upload '{}'"".format(from_info[""path""])
-                logger.error(msg)
+                logger.exception(msg)
                 continue
 
             progress.finish_target(name)
@@ -246,7 +246,7 @@ class RemoteS3(RemoteBase):
                 msg = ""failed to download '{}/{}'"".format(
                     from_info[""bucket""], from_info[""path""]
                 )
-                logger.error(msg)
+                logger.exception(msg)
                 continue
 
             move(tmp_file, to_info[""path""])
diff --git a/dvc/remote/ssh/__init__.py b/dvc/remote/ssh/__init__.py
index 7bcac9557..0ea9a90a5 100644
--- a/dvc/remote/ssh/__init__.py
+++ b/dvc/remote/ssh/__init__.py
@@ -160,7 +160,7 @@ class RemoteSSH(RemoteBase):
                     from_info[""path""], to_info[""path""], progress_title=name
                 )
             except Exception:
-                logger.error(
+                logger.exception(
                     ""failed to download '{host}/{path}' to '{dest}'"".format(
                         host=from_info[""host""],
                         path=from_info[""path""],","['dvc/remote/local.py', 'dvc/remote/ssh/__init__.py', 'dvc/remote/http.py', 'dvc/remote/s3.py']",{'.py': 4},4,0,0,4,4,432234,95758,14936,122,542,76,14,4,323,38,77,1,1,0,2019-04-10 21:23:13,11830,Python,"{'Python': 2391938, 'Inno Setup': 10158, 'PowerShell': 2686, 'Batchfile': 53, 'Shell': 35}",Apache License 2.0,['dvc/remote/local.py'],['dvc/remote/local.py'],"['```json\n{\n  ""files"": [\n    ""dvc/remote/local.py""\n  ]\n}\n```']",1,679.5575618743896
6247,beetbox/beets/3238/2790,beetbox,beets,https://github.com/beetbox/beets/issues/2790,https://github.com/beetbox/beets/pull/3238,https://github.com/beetbox/beets/pull/3238,1,fixes,acousticbrainz: Really small float values are stored as strings,"### Problem

Using the acousticbrainz plugin (I don't know if it's specific to it, it might be a wider issue), when storing really small values, they end up formatted in an exponential style, e.g. `1.82764233614e-05`. As a result, the whole (flexible, in this case) attribute ends up being treated as a string - which forbids using ranges in query, for example.

Here's an example with the recording `9dcdb20b-3bdf-4d1f-842f-d3cb545bea28` on MusicBrainz. The `mood_happy` probability is really low on AcousticBrainz: http://acousticbrainz.org/api/v1/9dcdb20b-3bdf-4d1f-842f-d3cb545bea28/high-level?n=0 (field value is `0.0000182764233614`). In beets, it ends up being stored as `1.82764233614e-05`:

```sh
$ beet -vv acousticbrainz M83 Ludivine -f
user configuration: /root/.config/beets/config.yaml
data directory: /root/.config/beets
plugin paths: /root/.config/beets/beets-alternatives/beetsplug
Sending event: pluginload
lyrics: Disabling google source: no API key configured.
inline: adding item field disc_with_title
inline: adding album field spinnin_catalognum
library database: /root/.config/beets/beets.blb
library directory: /media/sao/Musique
Sending event: library_opened
acousticbrainz: getting data for: M83 - Junk - Ludivine
acousticbrainz: fetching URL: https://acousticbrainz.org/9dcdb20b-3bdf-4d1f-842f-d3cb545bea28/low-level
acousticbrainz: fetching URL: https://acousticbrainz.org/9dcdb20b-3bdf-4d1f-842f-d3cb545bea28/high-level
acousticbrainz: attribute danceable of M83 - Junk - Ludivine set to 0.00766881043091
acousticbrainz: attribute gender of M83 - Junk - Ludivine set to male
acousticbrainz: attribute genre_rosamerica of M83 - Junk - Ludivine set to cla
acousticbrainz: attribute mood_acoustic of M83 - Junk - Ludivine set to 0.995353162289
acousticbrainz: attribute mood_aggressive of M83 - Junk - Ludivine set to 0.042748786509
acousticbrainz: attribute mood_electronic of M83 - Junk - Ludivine set to 0.0935237780213
acousticbrainz: attribute mood_happy of M83 - Junk - Ludivine set to 1.82764233614e-05
acousticbrainz: attribute mood_party of M83 - Junk - Ludivine set to 0.0153690651059
acousticbrainz: attribute mood_relaxed of M83 - Junk - Ludivine set to 0.987963736057
acousticbrainz: attribute mood_sad of M83 - Junk - Ludivine set to 0.956809282303
acousticbrainz: attribute rhythm of M83 - Junk - Ludivine set to Tango
acousticbrainz: attribute tonal of M83 - Junk - Ludivine set to 0.435981780291
acousticbrainz: attribute voice_instrumental of M83 - Junk - Ludivine set to instrumental
acousticbrainz: attribute average_loudness of M83 - Junk - Ludivine set to 0.753472864628
acousticbrainz: attribute bpm of M83 - Junk - Ludivine set to 106.67628479
acousticbrainz: attribute chords_changes_rate of M83 - Junk - Ludivine set to 0.0346172600985
acousticbrainz: attribute chords_key of M83 - Junk - Ludivine set to D
acousticbrainz: attribute chords_number_rate of M83 - Junk - Ludivine set to 0.00487567018718
acousticbrainz: attribute chords_scale of M83 - Junk - Ludivine set to major
acousticbrainz: attribute key_strength of M83 - Junk - Ludivine set to 0.704598069191
acousticbrainz: attribute initial_key of M83 - Junk - Ludivine set to F# minor
Sending event: database_change
Sending event: write
```

### Setup

* OS: Linux
* Python version: 3.6.4
* beets version: 1.4.6
* Turning off plugins made problem go away (yes/no): irrelevant, I guess

My configuration (output of `beet config`) is: probably irrelevant too, I just have the plugin enabled without any configuration.
",4d55e6dfbb6b3da5c731353bddbebf9423643104,62c1d37bcc44e86341388e595bdc5c2ed81a8d57,https://github.com/beetbox/beets/compare/4d55e6dfbb6b3da5c731353bddbebf9423643104...62c1d37bcc44e86341388e595bdc5c2ed81a8d57,"diff --git a/beets/dbcore/types.py b/beets/dbcore/types.py
index 935d03870..e08b417a7 100644
--- a/beets/dbcore/types.py
+++ b/beets/dbcore/types.py
@@ -173,14 +173,17 @@ class Id(Integer):
 
 
 class Float(Type):
-    """"""A basic floating-point type.
+    """"""A basic floating-point type. Supports padding.
     """"""
     sql = u'REAL'
     query = query.NumericQuery
     model_type = float
 
+    def __init__(self, digits=1):
+        self.digits = digits
+
     def format(self, value):
-        return u'{0:.1f}'.format(value or 0.0)
+        return u'{0:.{1}f}'.format(value or 0, self.digits)
 
 
 class NullFloat(Float):
diff --git a/beetsplug/acousticbrainz.py b/beetsplug/acousticbrainz.py
index f4960c301..01f3ac6ac 100644
--- a/beetsplug/acousticbrainz.py
+++ b/beetsplug/acousticbrainz.py
@@ -17,10 +17,12 @@
 """"""
 from __future__ import division, absolute_import, print_function
 
+from collections import defaultdict
+
 import requests
 
-from collections import defaultdict
 from beets import plugins, ui
+from beets.dbcore import types
 
 ACOUSTIC_BASE = ""https://acousticbrainz.org/""
 LEVELS = [""/low-level"", ""/high-level""]
@@ -104,6 +106,29 @@ ABSCHEME = {
 
 
 class AcousticPlugin(plugins.BeetsPlugin):
+    item_types = {
+        'average_loudness': types.Float(6),
+        'chords_changes_rate': types.Float(6),
+        'chords_key': types.STRING,
+        'chords_number_rate': types.Float(6),
+        'chords_scale': types.STRING,
+        'danceable': types.Float(6),
+        'gender': types.STRING,
+        'genre_rosamerica': types.STRING,
+        'initial_key': types.STRING,
+        'key_strength': types.Float(6),
+        'mood_acoustic': types.Float(6),
+        'mood_aggressive': types.Float(6),
+        'mood_electronic': types.Float(6),
+        'mood_happy': types.Float(6),
+        'mood_party': types.Float(6),
+        'mood_relaxed': types.Float(6),
+        'mood_sad': types.Float(6),
+        'rhythm': types.Float(6),
+        'tonal': types.Float(6),
+        'voice_instrumental': types.STRING,
+    }
+
     def __init__(self):
         super(AcousticPlugin, self).__init__()
 ","['beets/dbcore/types.py', 'beetsplug/acousticbrainz.py']",{'.py': 2},2,0,0,2,2,1240206,273401,35787,97,1212,313,34,2,3581,460,1090,55,3,1,2019-04-24 18:08:28,11800,Python,"{'Python': 2239450, 'JavaScript': 85948, 'Shell': 7448, 'HTML': 3306, 'CSS': 2951}",MIT License,['beetsplug/acousticbrainz.py'],['beetsplug/acousticbrainz.py'],"['```json\n{\n  ""files"": [\n    ""beetsplug/acousticbrainz.py""\n  ]\n}\n```']",1,722.9256629943848
10019,mikubill/sd-webui-controlnet/321/307,mikubill,sd-webui-controlnet,https://github.com/Mikubill/sd-webui-controlnet/issues/307,https://github.com/Mikubill/sd-webui-controlnet/pull/321,https://github.com/Mikubill/sd-webui-controlnet/pull/321,1,fix,Add Multi-ControlNet to Metadata,"I like to write down of my prompts / settings when generating images, or refer back to them via an image's metadata, but Multi-ControlNet doesn't seem to add the data for any additional ControlNets after the first. 

This means that if I go to a Multi-ControlNet image and copy its metadata to use in future generations, it will be missing the data I'd need to recreate it or create other images using the same settings. So it would be really nice if the data for ControlNet-1 and above were included. ",85dfc5b880c61f5babdde6ab30bc022695139528,194884327c6283182085c897c15a387dd11b2708,https://github.com/mikubill/sd-webui-controlnet/compare/85dfc5b880c61f5babdde6ab30bc022695139528...194884327c6283182085c897c15a387dd11b2708,"diff --git a/scripts/controlnet.py b/scripts/controlnet.py
index 88f6077..310def4 100644
--- a/scripts/controlnet.py
+++ b/scripts/controlnet.py
@@ -464,7 +464,10 @@ class Script(scripts.Script):
             if not enabled:
                 continue
             control_groups.append((module, model, params))
-            prefix = f""ControlNet-{idx}"" if idx > 1 else ""ControlNet""
+            if len(params_group) != 1:
+                prefix = f""ControlNet-{idx}""
+            else:
+                prefix = ""ControlNet""
             p.extra_generation_params.update({
                 f""{prefix} Enabled"": True,
                 f""{prefix} Module"": module,",['scripts/controlnet.py'],{'.py': 1},1,0,0,1,1,1998086,467105,54059,381,214,50,5,1,504,90,110,3,0,0,2023-02-23 11:54:04,11795,Python,"{'Python': 5485837, 'Cuda': 166914, 'C++': 90584, 'JavaScript': 25662, 'CMake': 6795, 'Shell': 4071, 'CSS': 2660, 'Jupyter Notebook': 1203, 'Dockerfile': 951}",MIT License,"['annotator/midas/midas/midas_net_custom.py', 'annotator/uniformer/mmcv/ops/assign_score_withk.py', 'annotator/midas/midas/transforms.py', 'scripts/controlnet.py', 'annotator/midas/midas/midas_net.py']","['annotator/midas/midas/midas_net_custom.py', 'annotator/uniformer/mmcv/ops/assign_score_withk.py', 'annotator/midas/midas/transforms.py', 'scripts/controlnet.py', 'annotator/midas/midas/midas_net.py']","['```json\n{\n  ""files"": [\n    ""scripts/controlnet.py"",\n    ""annotator/midas/midas/midas_net.py"",\n    ""annotator/midas/midas/midas_net_custom.py"",\n    ""annotator/midas/midas/transforms.py"",\n    ""annotator/uniformer/mmcv/ops/assign_score_withk.py""\n  ]\n}\n```']",1,1690.5174255371094
5581,microsoft/qlib/357/356,microsoft,qlib,https://github.com/microsoft/qlib/issues/356,https://github.com/microsoft/qlib/pull/357,https://github.com/microsoft/qlib/pull/357,1,fixes,yahoo collector returns error,"command:
`python .qlib/scripts/data_collector/yahoo/collector.py download_data --source_dir .csv-yahoo --region US --start 2021-03-18 --end 2021-03-19 --delay 0.1 --interval 1d`
Bug report:


```
Traceback (most recent call last):
  File "".qlib/scripts/data_collector/yahoo/collector.py"", line 642, in <module>
    fire.Fire(Run)
  File ""xxxxxxxxxxxxxxxx/.venv/lib/python3.7/site-packages/fire-0.3.1-py3.7.egg/fire/core.py"", line 138, in Fire
    component_trace = _Fire(component, args, parsed_flag_args, context, name)
  File ""xxxxxxxxxxxxxxxx/.venv/lib/python3.7/site-packages/fire-0.3.1-py3.7.egg/fire/core.py"", line 468, in _Fire
    target=component.__name__)
  File ""xxxxxxxxxxxxxxxx/.venv/lib/python3.7/site-packages/fire-0.3.1-py3.7.egg/fire/core.py"", line 672, in _CallAndUpdateTrace
    component = fn(*varargs, **kwargs)
  File "".qlib/scripts/data_collector/yahoo/collector.py"", line 622, in download_data
    super(Run, self).download_data(max_collector_count, delay, start, end, interval, check_data_length, limit_nums)
  File ""xxxxxxxxxxxxxxxx/.qlib/scripts/data_collector/base.py"", line 404, in download_data
    limit_nums=limit_nums,
TypeError: Can't instantiate abstract class YahooCollectorUS1d with abstract methods get_instrument_list

```",ba56e4071efd1c08003eaf7e23978aaf81376dd1,598ee875a03753f64491a378d40d1907102f10a3,https://github.com/microsoft/qlib/compare/ba56e4071efd1c08003eaf7e23978aaf81376dd1...598ee875a03753f64491a378d40d1907102f10a3,"diff --git a/scripts/data_collector/yahoo/collector.py b/scripts/data_collector/yahoo/collector.py
index eadc381e..f0e11069 100644
--- a/scripts/data_collector/yahoo/collector.py
+++ b/scripts/data_collector/yahoo/collector.py
@@ -185,7 +185,7 @@ class YahooCollector(BaseCollector):
 
 
 class YahooCollectorCN(YahooCollector, ABC):
-    def get_stock_list(self):
+    def get_instrument_list(self):
         logger.info(""get HS stock symbos......"")
         symbols = get_hs_stock_symbols()
         logger.info(f""get {len(symbols)} symbols."")
@@ -249,7 +249,7 @@ class YahooCollectorCN1min(YahooCollectorCN):
 
 
 class YahooCollectorUS(YahooCollector, ABC):
-    def get_stock_list(self):
+    def get_instrument_list(self):
         logger.info(""get US stock symbols......"")
         symbols = get_us_stock_symbols() + [
             ""^GSPC"",",['scripts/data_collector/yahoo/collector.py'],{'.py': 1},1,0,0,1,1,954208,214586,28306,126,133,30,4,1,1282,93,365,22,0,1,2021-03-22 02:32:51,11684,Python,"{'Python': 2321433, 'Shell': 18880, 'Cython': 10262}",MIT License,"['scripts/data_collector/base.py', 'scripts/data_collector/yahoo/collector.py']","['scripts/data_collector/base.py', 'scripts/data_collector/yahoo/collector.py']","['```json\n{\n  ""files"": [\n    ""scripts/data_collector/yahoo/collector.py"",\n    ""scripts/data_collector/base.py""\n  ]\n}\n```']",1,781.3224792480469
7090,edgedb/edgedb/5785/5725,edgedb,edgedb,https://github.com/edgedb/edgedb/issues/5725,https://github.com/edgedb/edgedb/pull/5785,https://github.com/edgedb/edgedb/pull/5785,1,fixes,Two computed properties with same name and no `property` keyword cause InternalServerError,"- EdgeDB Version: 3.0+e7d38e9
- EdgeDB CLI Version: 3.1.3+9fdca62
- OS Version: Windows 11

I'm rewriting part of Chapter 18 in Easy EdgeDB on currencies at the moment and came across a bug that happens when you mistakenly give two computed properties the same name. Here's a simplified example of what I was putting together:

Steps to Reproduce:

1. Create a schema that has two computables with the same name (i.e. a user typo) and no `property` keyword:

```
module default {

  type SimpleNumbers {
    required num1: int64;
    read_num1 := .num1;
    read_num1 := .num1;
  }
}
```

2. `edgedb migration create` to get this error:

```
edgedb error: InternalServerError: <QualName default::SimpleNumbers@read_num1>
  Hint: This is most likely a bug in EdgeDB. Please consider opening an issue ticket at https://github.com/edgedb/edgedb/issues/new?template=bug_report.md
  Server traceback:
      Traceback (most recent call last):
        File ""/home/edgedb/.local/share/edgedb/portable/3.0/lib/python3.11/site-packages/edb/server/compiler_pool/worker.py"", line 161, in compile
          units, cstate = COMPILER.compile(
                          ^^^^^^^^^^^^^^^^^
        File ""/home/edgedb/.local/share/edgedb/portable/3.0/lib/python3.11/site-packages/edb/server/compiler/compiler.py"", line 755, in compile
          unit_group = compile(ctx=ctx, source=source)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        File ""/home/edgedb/.local/share/edgedb/portable/3.0/lib/python3.11/site-packages/edb/server/compiler/compiler.py"", line 1944, in compile
          return _try_compile(ctx=ctx, source=source)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        File ""/home/edgedb/.local/share/edgedb/portable/3.0/lib/python3.11/site-packages/edb/server/compiler/compiler.py"", line 2012, in _try_compile
          comp, capabilities = _compile_dispatch_ql(
                               ^^^^^^^^^^^^^^^^^^^^^
        File ""/home/edgedb/.local/share/edgedb/portable/3.0/lib/python3.11/site-packages/edb/server/compiler/compiler.py"", line 1851, in _compile_dispatch_ql
          query = ddl.compile_dispatch_ql_migration(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        File ""/home/edgedb/.local/share/edgedb/portable/3.0/lib/python3.11/site-packages/edb/server/compiler/ddl.py"", line 382, in compile_dispatch_ql_migration
          return _start_migration(ctx, ql, in_script)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        File ""/home/edgedb/.local/share/edgedb/portable/3.0/lib/python3.11/site-packages/edb/server/compiler/ddl.py"", line 463, in _start_migration
          target_schema = s_ddl.apply_sdl(
                          ^^^^^^^^^^^^^^^^
        File ""/home/edgedb/.local/share/edgedb/portable/3.0/lib/python3.11/site-packages/edb/schema/ddl.py"", line 520, in apply_sdl
          ddl_stmts = s_decl.sdl_to_ddl(target_schema, documents)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        File ""/home/edgedb/.local/share/edgedb/portable/3.0/lib/python3.11/site-packages/edb/edgeql/declarative.py"", line 453, in sdl_to_ddl
          trace_dependencies(decl_ast, ctx=tracectx)
        File ""/home/edgedb/.local/share/edgedb/portable/3.0/lib/python3.11/functools.py"", line 909, in wrapper
          return dispatch(args[0].__class__)(*args, **kw)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        File ""/home/edgedb/.local/share/edgedb/portable/3.0/lib/python3.11/site-packages/edb/edgeql/declarative.py"", line 1055, in trace_default
          _register_item(node, ctx=ctx)
        File ""/home/edgedb/.local/share/edgedb/portable/3.0/lib/python3.11/site-packages/edb/edgeql/declarative.py"", line 1189, in _register_item
          trace_dependencies(cmd, ctx=ctx)
        File ""/home/edgedb/.local/share/edgedb/portable/3.0/lib/python3.11/functools.py"", line 909, in wrapper
          return dispatch(args[0].__class__)(*args, **kw)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        File ""/home/edgedb/.local/share/edgedb/portable/3.0/lib/python3.11/site-packages/edb/edgeql/declarative.py"", line 822, in trace_SetField
          _register_item(node, deps=deps, hard_dep_exprs=exprs, ctx=ctx)
        File ""/home/edgedb/.local/share/edgedb/portable/3.0/lib/python3.11/site-packages/edb/edgeql/declarative.py"", line 1080, in _register_item
          vn = get_verbosename_from_fqname(fq_name, ctx)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        File ""/home/edgedb/.local/share/edgedb/portable/3.0/lib/python3.11/site-packages/edb/edgeql/declarative.py"", line 235, in get_verbosename_from_fqname
          traceobj = ctx.objects[fq_name]
                     ~~~~~~~~~~~^^^^^^^^^
      KeyError: <QualName default::SimpleNumbers@read_num1>
```

If at least one of the computed properties has the keyword `property` then the compiler error is a normal one:

```
error: property 'read_num1' of object type 'default::SimpleNumbers' was already declared
  ┌─ c:\\rust\\anything\\dbschema\\default.esdl:6:5
  │
6 │     property read_num1 := .num1;
  │     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ error

edgedb error: cannot proceed until .esdl files are fixed
```",45e615135b227671025dd28d391d0a524e968b49,110ed676889c7464f886ee248dcdea801f952c22,https://github.com/edgedb/edgedb/compare/45e615135b227671025dd28d391d0a524e968b49...110ed676889c7464f886ee248dcdea801f952c22,"diff --git a/edb/edgeql/declarative.py b/edb/edgeql/declarative.py
index 8be2b7154..f0852a297 100644
--- a/edb/edgeql/declarative.py
+++ b/edb/edgeql/declarative.py
@@ -230,7 +230,7 @@ def ensure_pointer_kind(
 
 def get_verbosename_from_fqname(
     fq_name: s_name.QualName,
-    ctx: DepTraceContext,
+    ctx: DepTraceContext | LayoutTraceContext,
 ) -> str:
     traceobj = ctx.objects[fq_name]
     assert traceobj is not None
@@ -246,13 +246,15 @@ def get_verbosename_from_fqname(
     elif isinstance(traceobj, qltracer.ScalarType):
         clsname = 'scalar'
     elif isinstance(traceobj, qltracer.Function):
-        node = ctx.ddlgraph[fq_name].item
-        assert isinstance(node, qlast.FunctionCommand)
-        params = ','.join(
-            qlcodegen.generate_source(param, sdlmode=True)
-            for param in node.params
-        )
-        name = f""{str(fq_name).split('@@', 1)[0]}({params})""
+        name = str(fq_name).split('@@', 1)[0]
+        if isinstance(ctx, DepTraceContext):
+            node = ctx.ddlgraph[fq_name].item
+            assert isinstance(node, qlast.FunctionCommand)
+            params = ','.join(
+                qlcodegen.generate_source(param, sdlmode=True)
+                for param in node.params
+            )
+            name = f""{name}({params})""
     elif isinstance(traceobj, qltracer.Pointer):
         ofobj, name = str(fq_name).split('@', 1)
         ofobj = f"" of object type '{ofobj}'""
@@ -273,6 +275,11 @@ def get_verbosename_from_fqname(
         if name == str(s_indexes.DEFAULT_INDEX):
             name = ''
         ofobj = f"" of object type '{ofobj}'""
+    elif isinstance(traceobj, qltracer.Field):
+        clsname = 'field'
+        obj, name = fq_name.name.rsplit('@', 1)
+        ofobj = ' of ' + get_verbosename_from_fqname(
+            s_name.QualName(fq_name.module, obj), ctx)
 
     if name:
         return f""{clsname} '{name}'{ofobj}""
@@ -749,6 +756,22 @@ def _trace_item_layout(
             )
             ctx.objects[idx_name] = qltracer.ConcreteIndex(idx_name)
 
+        elif isinstance(decl, qlast.SetField):
+            field_name = s_name.QualName(
+                module=fq_name.module,
+                name=f'{fq_name.name}@{decl.name}',
+            )
+
+            # Trivial fields don't get added to the ddlgraph, which is
+            # where duplication checks are normally done, so do the
+            # check here instead.
+            if field_name in ctx.objects:
+                vn = get_verbosename_from_fqname(field_name, ctx)
+                msg = f'{vn} was already declared'
+                raise errors.InvalidDefinitionError(msg, context=decl.context)
+
+            ctx.objects[field_name] = qltracer.Field(field_name)
+
 
 RECURSION_GUARD: Set[s_name.QualName] = set()
 
@@ -1079,9 +1102,7 @@ def _register_item(
     if fq_name in ctx.ddlgraph:
         vn = get_verbosename_from_fqname(fq_name, ctx)
         msg = f'{vn} was already declared'
-
-        raise errors.InvalidDefinitionError(
-            msg, context=decl.context)
+        raise errors.InvalidDefinitionError(msg, context=decl.context)
 
     if deps:
         deps = set(deps)
@@ -1328,8 +1349,11 @@ def _get_pointer_deps(
     # is is important for properly doing cardinality inference
     # on expressions involving it.
     # PERF: We should avoid actually searching all the objects.
-    for propname in ctx.objects:
-        if str(propname).startswith(str(pointer) + '@'):
+    for propname, prop in ctx.objects.items():
+        if (
+            str(propname).startswith(str(pointer) + '@')
+            and not isinstance(prop, qltracer.Field)
+        ):
             result.add(propname)
 
     return result
diff --git a/edb/edgeql/tracer.py b/edb/edgeql/tracer.py
index 0afd2d1c5..068defdfe 100644
--- a/edb/edgeql/tracer.py
+++ b/edb/edgeql/tracer.py
@@ -88,6 +88,10 @@ class ConcreteIndex(NamedObject):
     pass
 
 
+class Field(NamedObject):
+    pass
+
+
 class Type(NamedObject):
     def is_scalar(self) -> bool:
         return False
diff --git a/tests/test_schema.py b/tests/test_schema.py
index 166e91119..d6b238981 100644
--- a/tests/test_schema.py
+++ b/tests/test_schema.py
@@ -837,6 +837,49 @@ class TestSchema(tb.BaseSchemaLoadTest):
             }
         """"""
 
+    @tb.must_fail(
+        errors.InvalidDefinitionError,
+        ""field 'default' .*was already declared""
+    )
+    def test_schema_field_dupe_01(self):
+        """"""
+        type SimpleNumbers {
+            property bar: str;
+            property foo: str {
+                default := '';
+                default := '';
+            }
+        }
+        """"""
+
+    @tb.must_fail(
+        errors.InvalidDefinitionError,
+        ""field 'default' .*was already declared""
+    )
+    def test_schema_field_dupe_02(self):
+        """"""
+        type SimpleNumbers {
+            property bar: str;
+            property foo: str {
+                default := .bar;
+                default := .bar;
+            }
+        }
+        """"""
+
+    @tb.must_fail(
+        errors.InvalidDefinitionError,
+        ""field 'foo' .*was already declared""
+    )
+    def test_schema_field_dupe_03(self):
+        """"""
+        type SimpleNumbers {
+            bar: str;
+            foo := .bar ++ ""!"";
+            foo := .bar ++ ""!"";
+        }
+        """"""
+
     @tb.must_fail(
         errors.InvalidFunctionDefinitionError,
         r""cannot create the `test::foo\\(VARIADIC bar: ""","['edb/edgeql/declarative.py', 'tests/test_schema.py', 'edb/edgeql/tracer.py']",{'.py': 3},3,0,0,3,3,6047361,1337285,189474,373,2167,478,54,2,5256,352,1453,86,1,3,2023-07-13 22:12:40,11428,Python,"{'Python': 11172749, 'Cython': 433911, 'Rust': 311824, 'JavaScript': 7481, 'HCL': 3760, 'Makefile': 1159}",Apache License 2.0,"['edb/edgeql/compiler/expr.py', 'edb/schema/objects.py', 'edb/edgeql/compiler/astutils.py', 'edb/edgeql/compiler/func.py', 'edb/edgeql/compiler/group.py']","['edb/edgeql/compiler/expr.py', 'edb/schema/objects.py', 'edb/edgeql/compiler/astutils.py', 'edb/edgeql/compiler/func.py', 'edb/edgeql/compiler/group.py']","['```json\n{\n  ""files"": [\n    ""edb/schema/objects.py"",\n    ""edb/edgeql/compiler/astutils.py"",\n    ""edb/edgeql/compiler/expr.py"",\n    ""edb/edgeql/compiler/func.py"",\n    ""edb/edgeql/compiler/group.py""\n  ]\n}\n```']",1,1350.6667613983154
8223,chia-network/chia-blockchain/16110/16039,chia-network,chia-blockchain,https://github.com/Chia-Network/chia-blockchain/issues/16039,https://github.com/Chia-Network/chia-blockchain/pull/16110,https://github.com/Chia-Network/chia-blockchain/pull/16110,1,resolves,[Bug] Cleanup output of `chia data create_data_store`,"### What happened?

The current output of `chia data create_data_store` is overly verbose and although appearing to be JSON is not proper JSON so it cannot be piped to `jq` or other json processing tools

example: 
```
❯ chia data create_data_store -m 0.01
{'id': '1a34a5b320767bcbba0d12f1204f2495aaddc4dca717f249a3a2253c7c67771c', 'success': True, 'txs': [{'additions': [{'amount': 1, 'parent_coin_info': '0x23ea7929e6842408f76ebef0de82e61d3e1faac149f6541b54b45a77d2b2dfa8', 'puzzle_hash': '0xeff07522495060c066f66f32acc2a77e3a3e737aca8baea4d1a64ea4cdc13da9'}, {'amount': 99972799999996, 'parent_coin_info': '0x23ea7929e6842408f76ebef0de82e61d3e1faac149f6541b54b45a77d2b2dfa8', 'puzzle_hash': '0x98f6821a24ee90d187e84ed49c2baee0ee2a6a712dd27c211f734852623cf443'}, {'amount': 1, 'parent_coin_info': '0x1a34a5b320767bcbba0d12f1204f2495aaddc4dca717f249a3a2253c7c67771c', 'puzzle_hash': '0x032bd9039f98a5b7e0c55295e6e33a6e7772d3505695ae7ea571a049ceb829ba'}], 'amount': 1, 'confirmed': False, 'confirmed_at_height': 0, 'created_at_time': 1692110896, 'fee_amount': 10000000000, 'memos': [], 'name': '0x9ed4b49a8ebd6506fda5068ccd594236cfc887bd63f48b45890be75b80ad4da8', 'removals': [{'amount': 99982799999997, 'parent_coin_info': '0x74762f2a1713edcbb1156293d04df593be64dc9dcf8b7321126199a98878625b', 'puzzle_hash': '0xde4b3b32688ccbd469d1865e8f1b410aa4e8ad6357dfa557f9a2f1c953d79f5f'}, {'amount': 1, 'parent_coin_info': '0x23ea7929e6842408f76ebef0de82e61d3e1faac149f6541b54b45a77d2b2dfa8', 'puzzle_hash': '0xeff07522495060c066f66f32acc2a77e3a3e737aca8baea4d1a64ea4cdc13da9'}], 'sent': 10, 'sent_to': [], 'spend_bundle': {'aggregated_signature': '0xad11f158801ad673af526dacf52498a0748f0d01b05ecee34cc6c7eb8334fa9a1223a413cc9b4560216ece6b22ca88620177e3d0647b19829873614d054085cc19b2eae18cd2d71f8be04846df6a37ed451e4fcc35d0e775ceba0097923d9448', 'coin_spends': [{'coin': {'amount': 99982799999997, 'parent_coin_info': '0x74762f2a1713edcbb1156293d04df593be64dc9dcf8b7321126199a98878625b', 'puzzle_hash': '0xde4b3b32688ccbd469d1865e8f1b410aa4e8ad6357dfa557f9a2f1c953d79f5f'}, 'puzzle_reveal': '0xff02ffff01ff02ffff01ff02ffff03ff0bffff01ff02ffff03ffff09ff05ffff1dff0bffff1effff0bff0bffff02ff06ffff04ff02ffff04ff17ff8080808080808080ffff01ff02ff17ff2f80ffff01ff088080ff0180ffff01ff04ffff04ff04ffff04ff05ffff04ffff02ff06ffff04ff02ffff04ff17ff80808080ff80808080ffff02ff17ff2f808080ff0180ffff04ffff01ff32ff02ffff03ffff07ff0580ffff01ff0bffff0102ffff02ff06ffff04ff02ffff04ff09ff80808080ffff02ff06ffff04ff02ffff04ff0dff8080808080ffff01ff0bffff0101ff058080ff0180ff018080ffff04ffff01b0a8fdae02f161cdf8ae2ac6c4d890da7fdd40bb61cde999288be8c9b57c5d58f2651e5c35f8414af4103ffc8a672dbdd7ff018080', 'solution': '0xff80ffff01ffff33ffa0eff07522495060c066f66f32acc2a77e3a3e737aca8baea4d1a64ea4cdc13da9ff0180ffff33ffa098f6821a24ee90d187e84ed49c2baee0ee2a6a712dd27c211f734852623cf443ff865aecbb3b2ffc80ffff34ff8502540be40080ffff3cffa0714e0b88f328cb8d64cd1c2e9b5ab0ee08e92c7e9c2844c0b04f79064f2e890980ffff3dffa0b6b9b6c5cbde6df6b8645900d87ed1d88dd63197cf76c1e4c1a4849ec6c258a38080ff8080'}, {'coin': {'amount': 1, 'parent_coin_info': '0x23ea7929e6842408f76ebef0de82e61d3e1faac149f6541b54b45a77d2b2dfa8', 'puzzle_hash': '0xeff07522495060c066f66f32acc2a77e3a3e737aca8baea4d1a64ea4cdc13da9'}, 'puzzle_reveal': '0xff02ffff01ff04ffff04ff04ffff04ff05ffff04ff0bff80808080ffff04ffff04ff0affff04ffff02ff0effff04ff02ffff04ffff04ff05ffff04ff0bffff04ff17ff80808080ff80808080ff808080ff808080ffff04ffff01ff33ff3cff02ffff03ffff07ff0580ffff01ff0bffff0102ffff02ff0effff04ff02ffff04ff09ff80808080ffff02ff0effff04ff02ffff04ff0dff8080808080ffff01ff0bffff0101ff058080ff0180ff018080', 'solution': '0xffa0032bd9039f98a5b7e0c55295e6e33a6e7772d3505695ae7ea571a049ceb829baff01ffffa00000000000000000000000000000000000000000000000000000000000000000ffa06c9f42ed51293771e85eee1ab942e6a35e2ee3d010139fb820446a2aa19868348080'}]}, 'to_puzzle_hash': '0x0202020202020202020202020202020202020202020202020202020202020202', 'trade_id': None, 'type': 0, 'wallet_id': 0}, {'additions': [{'amount': 1, 'parent_coin_info': '0x23ea7929e6842408f76ebef0de82e61d3e1faac149f6541b54b45a77d2b2dfa8', 'puzzle_hash': '0xeff07522495060c066f66f32acc2a77e3a3e737aca8baea4d1a64ea4cdc13da9'}, {'amount': 99972799999996, 'parent_coin_info': '0x23ea7929e6842408f76ebef0de82e61d3e1faac149f6541b54b45a77d2b2dfa8', 'puzzle_hash': '0x98f6821a24ee90d187e84ed49c2baee0ee2a6a712dd27c211f734852623cf443'}], 'amount': 1, 'confirmed': False, 'confirmed_at_height': 0, 'created_at_time': 1692110896, 'fee_amount': 10000000000, 'memos': [], 'name': '0x4de37649ff813721b33b439b33d7a5967da39058200b099d2566c58683d40f24', 'removals': [{'amount': 99982799999997, 'parent_coin_info': '0x74762f2a1713edcbb1156293d04df593be64dc9dcf8b7321126199a98878625b', 'puzzle_hash': '0xde4b3b32688ccbd469d1865e8f1b410aa4e8ad6357dfa557f9a2f1c953d79f5f'}], 'sent': 0, 'sent_to': [], 'spend_bundle': None, 'to_puzzle_hash': '0xeff07522495060c066f66f32acc2a77e3a3e737aca8baea4d1a64ea4cdc13da9', 'trade_id': None, 'type': 1, 'wallet_id': 1}]}
```

Following changes are recommended:

- [ ] Change default to only return the singleton id `{""id"": ""1a34a5b320767bcbba0d12f1204f2495aaddc4dca717f249a3a2253c7c67771c"", ""success"": True}`
- [ ] Add `--verbose` option to return all the rest of the items
- [ ] output legal JSON and not python object

### Version

All

### What platform are you using?

Windows

### What ui mode are you using?

CLI

### Relevant log output

```shell
N/A
```
",7b0bea4043c0912a726088436e844135bc6c67ed,a7fb495ca6b871b2a643ac04bf97a991779983df,https://github.com/chia-network/chia-blockchain/compare/7b0bea4043c0912a726088436e844135bc6c67ed...a7fb495ca6b871b2a643ac04bf97a991779983df,"diff --git a/chia/cmds/data.py b/chia/cmds/data.py
index c673e8627..db8d9f74c 100644
--- a/chia/cmds/data.py
+++ b/chia/cmds/data.py
@@ -108,13 +108,15 @@ def create_fee_option() -> Callable[[FC], FC]:
 @data_cmd.command(""create_data_store"", help=""Create a new data store"")
 @create_rpc_port_option()
 @create_fee_option()
+@click.option(""--verbose"", is_flag=True, help=""Enable verbose output."")
 def create_data_store(
     data_rpc_port: int,
     fee: Optional[str],
+    verbose: bool,
 ) -> None:
     from chia.cmds.data_funcs import create_data_store_cmd
 
-    run(create_data_store_cmd(data_rpc_port, fee))
+    run(create_data_store_cmd(data_rpc_port, fee, verbose))
 
 
 @data_cmd.command(""get_value"", help=""Get the value for a given key and store"")
diff --git a/chia/cmds/data_funcs.py b/chia/cmds/data_funcs.py
index 1be504f1f..23d498bba 100644
--- a/chia/cmds/data_funcs.py
+++ b/chia/cmds/data_funcs.py
@@ -14,11 +14,11 @@ from chia.util.default_root import DEFAULT_ROOT_PATH
 from chia.util.ints import uint64
 
 
-async def create_data_store_cmd(rpc_port: Optional[int], fee: Optional[str]) -> None:
+async def create_data_store_cmd(rpc_port: Optional[int], fee: Optional[str], verbose: bool) -> None:
     final_fee = None if fee is None else uint64(int(Decimal(fee) * units[""chia""]))
     async with get_any_service_client(DataLayerRpcClient, rpc_port) as (client, _):
-        res = await client.create_data_store(fee=final_fee)
-        print(res)
+        res = await client.create_data_store(fee=final_fee, verbose=verbose)
+        print(json.dumps(res, indent=4))
 
 
 async def get_value_cmd(rpc_port: Optional[int], store_id: str, key: str, root_hash: Optional[str]) -> None:
diff --git a/chia/rpc/data_layer_rpc_api.py b/chia/rpc/data_layer_rpc_api.py
index de187bf9a..e8f845800 100644
--- a/chia/rpc/data_layer_rpc_api.py
+++ b/chia/rpc/data_layer_rpc_api.py
@@ -112,8 +112,12 @@ class DataLayerRpcApi:
         if self.service is None:
             raise Exception(""Data layer not created"")
         fee = get_fee(self.service.config, request)
+        verbose = request.get(""verbose"", False)
         txs, value = await self.service.create_store(uint64(fee))
-        return {""txs"": txs, ""id"": value.hex()}
+        if verbose:
+            return {""txs"": txs, ""id"": value.hex()}
+        else:
+            return {""id"": value.hex()}
 
     async def get_owned_stores(self, request: Dict[str, Any]) -> EndpointResult:
         if self.service is None:
diff --git a/chia/rpc/data_layer_rpc_client.py b/chia/rpc/data_layer_rpc_client.py
index 6b5ab3836..6d0bcf13d 100644
--- a/chia/rpc/data_layer_rpc_client.py
+++ b/chia/rpc/data_layer_rpc_client.py
@@ -10,8 +10,8 @@ from chia.util.ints import uint64
 
 
 class DataLayerRpcClient(RpcClient):
-    async def create_data_store(self, fee: Optional[uint64]) -> Dict[str, Any]:
-        response = await self.fetch(""create_data_store"", {""fee"": fee})
+    async def create_data_store(self, fee: Optional[uint64], verbose: bool) -> Dict[str, Any]:
+        response = await self.fetch(""create_data_store"", {""fee"": fee, ""verbose"": verbose})
         return response
 
     async def get_value(self, store_id: bytes32, key: bytes, root_hash: Optional[bytes32]) -> Dict[str, Any]:
diff --git a/tests/core/data_layer/test_data_rpc.py b/tests/core/data_layer/test_data_rpc.py
index f46d7c78d..27ed347b0 100644
--- a/tests/core/data_layer/test_data_rpc.py
+++ b/tests/core/data_layer/test_data_rpc.py
@@ -712,7 +712,7 @@ async def offer_setup_fixture(
             )
             data_rpc_api = DataLayerRpcApi(data_layer)
 
-            create_response = await data_rpc_api.create_data_store({})
+            create_response = await data_rpc_api.create_data_store({""verbose"": True})
             await full_node_api.process_transaction_records(records=create_response[""txs""])
 
             store_setups.append(","['chia/cmds/data_funcs.py', 'chia/cmds/data.py', 'chia/rpc/data_layer_rpc_client.py', 'chia/rpc/data_layer_rpc_api.py', 'tests/core/data_layer/test_data_rpc.py']",{'.py': 5},5,0,0,5,5,4814014,1226626,114632,505,1158,278,20,4,5464,249,2476,34,0,2,2023-08-18 15:26:10,10949,Python,"{'Python': 8500472, 'Shell': 53259, 'PowerShell': 16600, 'Gnuplot': 1024, 'Jinja': 277}",Apache License 2.0,"['chia/data_layer/data_layer.py', 'chia/util/json_util.py', 'chia/wallet/puzzles/puzzle_utils.py']","['chia/data_layer/data_layer.py', 'chia/util/json_util.py', 'chia/wallet/puzzles/puzzle_utils.py']","['```json\n{\n  ""files"": [\n    ""chia/data_layer/data_layer.py"",\n    ""chia/util/json_util.py"",\n    ""chia/wallet/puzzles/puzzle_utils.py""\n  ]\n}\n```']",1,1205.1365375518799
8226,chia-network/chia-blockchain/11764/11628,chia-network,chia-blockchain,https://github.com/Chia-Network/chia-blockchain/issues/11628,https://github.com/Chia-Network/chia-blockchain/pull/11764,https://github.com/Chia-Network/chia-blockchain/pull/11764,2,fixes,[Bug] IPv6 RPC connections broken,"### What happened?

https://github.com/Chia-Network/chia-blockchain/pull/11578 broke IPv6 RPC connections by hard coding `0.0.0.0` for the host at https://github.com/Chia-Network/chia-blockchain/pull/11578/files#diff-926449f427065cf100c0af5785ac61529c768ab4cccbef25ccb86e82074b753fR270.  Initial exploration started in https://github.com/Chia-Network/chia-blockchain/pull/11623.  Actual fix being worked in https://github.com/Chia-Network/chia-blockchain/pull/11764.

### Version

main: https://github.com/Chia-Network/chia-blockchain/commit/817baa3096ee7cb4f820bf04599a2d231faeff94

### What platform are you using?

Linux

### What ui mode are you using?

CLI

### Relevant log output

```shell
2022-05-24T14:53:31.336 full_node chia.rpc.util           : WARNING  Error while handling message: Traceback (most recent call last):
  File ""chia\\rpc\\util.py"", line 16, in inner
  File ""chia\\rpc\\rpc_server.py"", line 172, in open_connection
ValueError: Start client failed, or server is not set
```
```
",5b49a574e4f3ea3d90f35bcf40908d0ff32614df,463e303c91a24ecc45dd74881bcdba2e8798b38c,https://github.com/chia-network/chia-blockchain/compare/5b49a574e4f3ea3d90f35bcf40908d0ff32614df...463e303c91a24ecc45dd74881bcdba2e8798b38c,"diff --git a/chia/rpc/rpc_server.py b/chia/rpc/rpc_server.py
index 9a7ff003b..fbd5e5072 100644
--- a/chia/rpc/rpc_server.py
+++ b/chia/rpc/rpc_server.py
@@ -14,6 +14,7 @@ from chia.types.peer_info import PeerInfo
 from chia.util.byte_types import hexstr_to_bytes
 from chia.util.ints import uint16
 from chia.util.json_util import dict_to_json_str
+from chia.util.network import select_port
 from chia.util.ws_message import create_payload, create_payload_dict, format_response, pong
 
 log = logging.getLogger(__name__)
@@ -328,7 +329,13 @@ async def start_rpc_server(
 
     site = web.TCPSite(runner, self_hostname, int(rpc_port), ssl_context=rpc_server.ssl_context)
     await site.start()
-    rpc_port = runner.addresses[0][1]
+
+    #
+    # On a dual-stack system, we want to get the (first) IPv4 port unless
+    # prefer_ipv6 is set in which case we use the IPv6 port
+    #
+    if rpc_port == 0:
+        rpc_port = select_port(root_path, runner.addresses)
 
     async def cleanup():
         await rpc_server.stop()
diff --git a/chia/server/server.py b/chia/server/server.py
index 326085fc9..f8c88976a 100644
--- a/chia/server/server.py
+++ b/chia/server/server.py
@@ -30,7 +30,7 @@ from chia.types.blockchain_format.sized_bytes import bytes32
 from chia.types.peer_info import PeerInfo
 from chia.util.errors import Err, ProtocolError
 from chia.util.ints import uint16
-from chia.util.network import is_in_network, is_localhost
+from chia.util.network import is_in_network, is_localhost, select_port
 from chia.util.ssl_check import verify_ssl_certs_and_keys
 
 max_message_size = 50 * 1024 * 1024  # 50MB
@@ -267,13 +267,19 @@ class ChiaServer:
         # this port from the socket itself and update self._port.
         self.site = web.TCPSite(
             self.runner,
-            host=""0.0.0.0"",
+            host="""",  # should listen to both IPv4 and IPv6 on a dual-stack system
             port=int(self._port),
             shutdown_timeout=3,
             ssl_context=ssl_context,
         )
         await self.site.start()
-        self._port = self.runner.addresses[0][1]
+        #
+        # On a dual-stack system, we want to get the (first) IPv4 port unless
+        # prefer_ipv6 is set in which case we use the IPv6 port
+        #
+        if self._port == 0:
+            self._port = select_port(self.root_path, self.runner.addresses)
+
         self.log.info(f""Started listening on port: {self._port}"")
 
     async def incoming_connection(self, request):
diff --git a/chia/util/network.py b/chia/util/network.py
index 3bce97ac5..bbf48a442 100644
--- a/chia/util/network.py
+++ b/chia/util/network.py
@@ -1,9 +1,11 @@
 import socket
+from pathlib import Path
 from ipaddress import ip_address, IPv4Network, IPv6Network
 from typing import Iterable, List, Tuple, Union, Any, Optional, Dict
 from chia.server.outbound_message import NodeType
 from chia.types.blockchain_format.sized_bytes import bytes32
 from chia.types.peer_info import PeerInfo
+from chia.util.config import load_config
 from chia.util.ints import uint16
 
 
@@ -84,3 +86,21 @@ def is_trusted_inner(peer_host: str, peer_node_id: bytes32, trusted_peers: Dict,
         return False
 
     return True
+
+
+def select_port(root_path: Path, addresses: List[Any]) -> uint16:
+    global_config = load_config(root_path, ""config.yaml"")
+    prefer_ipv6 = global_config.get(""prefer_ipv6"", False)
+    selected_port: uint16
+    for address_string, port, *_ in addresses:
+        address = ip_address(address_string)
+        if address.version == 6 and prefer_ipv6:
+            selected_port = port
+            break
+        elif address.version == 4 and not prefer_ipv6:
+            selected_port = port
+            break
+    else:
+        selected_port = addresses[0][1]  # no matches, just use the first one in the list
+
+    return selected_port","['chia/rpc/rpc_server.py', 'chia/server/server.py', 'chia/util/network.py']",{'.py': 3},3,0,0,3,3,2863469,620015,70495,395,1602,386,41,3,1025,89,311,26,5,1,2022-06-02 22:53:41,10949,Python,"{'Python': 8500472, 'Shell': 53259, 'PowerShell': 16600, 'Gnuplot': 1024, 'Jinja': 277}",Apache License 2.0,"['chia/rpc/rpc_server.py', 'chia/rpc/util.py']","['chia/rpc/rpc_server.py', 'chia/rpc/util.py']","['```json\n{\n  ""files"": [\n    ""chia/rpc/rpc_server.py"",\n    ""chia/rpc/util.py""\n  ]\n}\n```']",1,868.8209056854248
4314,pre-commit/pre-commit/1668/1658,pre-commit,pre-commit,https://github.com/pre-commit/pre-commit/issues/1658,https://github.com/pre-commit/pre-commit/pull/1668,https://github.com/pre-commit/pre-commit/pull/1668,2,resolves,rbenv FileNotFoundError when installing markdownlint hook,"I am trying to use https://github.com/markdownlint/markdownlint to lint my markdown files. I checked the issue tracker and [don't seem to see any related issues](https://github.com/pre-commit/pre-commit/issues?q=FileNotFoundError+rbenv). 

I have `.rbenv` installed on my system and am wondering if that could be interfering with `pre-commit`?

### .pre-commit-config.yaml
```
repos:
-   repo: https://github.com/markdownlint/markdownlint
    rev: master
    hooks:
    -   id: markdownlint
```

### version information

```
pre-commit version: 2.7.1
sys.version:
    3.9.0 (default, Oct  9 2020, 16:41:50) 
    [Clang 12.0.0 (clang-1200.0.32.2)]
sys.executable: /usr/local/Cellar/pre-commit/2.7.1_1/libexec/bin/python
os.name: posix
sys.platform: darwin
```

### error information

```
An unexpected error has occurred: FileNotFoundError: [Errno 2] No such file or directory: '/Users/adithyabalaji/.cache/pre-commit/repo09b5y8iv/rbenv-system/.install_state_v1staging'
```

```
Traceback (most recent call last):
  File ""/usr/local/Cellar/pre-commit/2.7.1_1/libexec/lib/python3.9/site-packages/pre_commit/error_handler.py"", line 63, in error_handler
    yield
  File ""/usr/local/Cellar/pre-commit/2.7.1_1/libexec/lib/python3.9/site-packages/pre_commit/main.py"", line 390, in main
    return run(args.config, store, args)
  File ""/usr/local/Cellar/pre-commit/2.7.1_1/libexec/lib/python3.9/site-packages/pre_commit/commands/run.py"", line 388, in run
    install_hook_envs(hooks, store)
  File ""/usr/local/Cellar/pre-commit/2.7.1_1/libexec/lib/python3.9/site-packages/pre_commit/repository.py"", line 206, in install_hook_envs
    _hook_install(hook)
  File ""/usr/local/Cellar/pre-commit/2.7.1_1/libexec/lib/python3.9/site-packages/pre_commit/repository.py"", line 92, in _hook_install
    _write_state(hook.prefix, venv, _state(hook.additional_dependencies))
  File ""/usr/local/Cellar/pre-commit/2.7.1_1/libexec/lib/python3.9/site-packages/pre_commit/repository.py"", line 48, in _write_state
    with open(staging, 'w') as state_file:
FileNotFoundError: [Errno 2] No such file or directory: '/Users/adithyabalaji/.cache/pre-commit/repo09b5y8iv/rbenv-system/.install_state_v1staging'

```",0c339e0647cd42d80e2cd0e80b0a86cf6571e9a3,7f9f66e542395ba743e243bdcd92df4e5500d57d,https://github.com/pre-commit/pre-commit/compare/0c339e0647cd42d80e2cd0e80b0a86cf6571e9a3...7f9f66e542395ba743e243bdcd92df4e5500d57d,"diff --git a/pre_commit/languages/helpers.py b/pre_commit/languages/helpers.py
index 01c65ab..69e1278 100644
--- a/pre_commit/languages/helpers.py
+++ b/pre_commit/languages/helpers.py
@@ -1,6 +1,7 @@
 import multiprocessing
 import os
 import random
+import re
 from typing import Any
 from typing import List
 from typing import Optional
@@ -10,6 +11,7 @@ from typing import Tuple
 from typing import TYPE_CHECKING
 
 import pre_commit.constants as C
+from pre_commit import parse_shebang
 from pre_commit.hook import Hook
 from pre_commit.prefix import Prefix
 from pre_commit.util import cmd_output_b
@@ -20,6 +22,25 @@ if TYPE_CHECKING:
 
 FIXED_RANDOM_SEED = 1542676187
 
+SHIMS_RE = re.compile(r'[/\\\\]shims[/\\\\]')
+
+
+def exe_exists(exe: str) -> bool:
+    found = parse_shebang.find_executable(exe)
+    if found is None:  # exe exists
+        return False
+
+    homedir = os.path.expanduser('~')
+    try:
+        common: Optional[str] = os.path.commonpath((found, homedir))
+    except ValueError:  # on windows, different drives raises ValueError
+        common = None
+
+    return (
+        not SHIMS_RE.search(found) and  # it is not in a /shims/ directory
+        common != homedir  # it is not in the home directory
+    )
+
 
 def run_setup_cmd(prefix: Prefix, cmd: Tuple[str, ...]) -> None:
     cmd_output_b(*cmd, cwd=prefix.prefix_dir)
diff --git a/pre_commit/languages/node.py b/pre_commit/languages/node.py
index 59e5340..8dc4e8b 100644
--- a/pre_commit/languages/node.py
+++ b/pre_commit/languages/node.py
@@ -7,7 +7,6 @@ from typing import Sequence
 from typing import Tuple
 
 import pre_commit.constants as C
-from pre_commit import parse_shebang
 from pre_commit.envcontext import envcontext
 from pre_commit.envcontext import PatchesT
 from pre_commit.envcontext import UNSET
@@ -31,7 +30,7 @@ def get_default_version() -> str:
         return C.DEFAULT
     # if node is already installed, we can save a bunch of setup time by
     # using the installed version
-    elif all(parse_shebang.find_executable(exe) for exe in ('node', 'npm')):
+    elif all(helpers.exe_exists(exe) for exe in ('node', 'npm')):
         return 'system'
     else:
         return C.DEFAULT
diff --git a/pre_commit/languages/ruby.py b/pre_commit/languages/ruby.py
index ef73961..b6c0bd7 100644
--- a/pre_commit/languages/ruby.py
+++ b/pre_commit/languages/ruby.py
@@ -8,7 +8,6 @@ from typing import Sequence
 from typing import Tuple
 
 import pre_commit.constants as C
-from pre_commit import parse_shebang
 from pre_commit.envcontext import envcontext
 from pre_commit.envcontext import PatchesT
 from pre_commit.envcontext import UNSET
@@ -26,7 +25,7 @@ healthy = helpers.basic_healthy
 
 @functools.lru_cache(maxsize=1)
 def get_default_version() -> str:
-    if all(parse_shebang.find_executable(exe) for exe in ('ruby', 'gem')):
+    if all(helpers.exe_exists(exe) for exe in ('ruby', 'gem')):
         return 'system'
     else:
         return C.DEFAULT
diff --git a/tests/languages/helpers_test.py b/tests/languages/helpers_test.py
index fa493cc..2e8277e 100644
--- a/tests/languages/helpers_test.py
+++ b/tests/languages/helpers_test.py
@@ -1,17 +1,60 @@
 import multiprocessing
-import os
+import os.path
 import sys
 from unittest import mock
 
 import pytest
 
 import pre_commit.constants as C
+from pre_commit import parse_shebang
 from pre_commit.languages import helpers
 from pre_commit.prefix import Prefix
 from pre_commit.util import CalledProcessError
 from testing.auto_namedtuple import auto_namedtuple
 
 
+@pytest.fixture
+def find_exe_mck():
+    with mock.patch.object(parse_shebang, 'find_executable') as mck:
+        yield mck
+
+
+@pytest.fixture
+def homedir_mck():
+    def fake_expanduser(pth):
+        assert pth == '~'
+        return os.path.normpath('/home/me')
+
+    with mock.patch.object(os.path, 'expanduser', fake_expanduser):
+        yield
+
+
+def test_exe_exists_does_not_exist(find_exe_mck, homedir_mck):
+    find_exe_mck.return_value = None
+    assert helpers.exe_exists('ruby') is False
+
+
+def test_exe_exists_exists(find_exe_mck, homedir_mck):
+    find_exe_mck.return_value = os.path.normpath('/usr/bin/ruby')
+    assert helpers.exe_exists('ruby') is True
+
+
+def test_exe_exists_false_if_shim(find_exe_mck, homedir_mck):
+    find_exe_mck.return_value = os.path.normpath('/foo/shims/ruby')
+    assert helpers.exe_exists('ruby') is False
+
+
+def test_exe_exists_false_if_homedir(find_exe_mck, homedir_mck):
+    find_exe_mck.return_value = os.path.normpath('/home/me/somedir/ruby')
+    assert helpers.exe_exists('ruby') is False
+
+
+def test_exe_exists_commonpath_raises_ValueError(find_exe_mck, homedir_mck):
+    find_exe_mck.return_value = os.path.normpath('/usr/bin/ruby')
+    with mock.patch.object(os.path, 'commonpath', side_effect=ValueError):
+        assert helpers.exe_exists('ruby') is True
+
+
 def test_basic_get_default_version():
     assert helpers.basic_get_default_version() == C.DEFAULT
 ","['pre_commit/languages/ruby.py', 'pre_commit/languages/node.py', 'tests/languages/helpers_test.py', 'pre_commit/languages/helpers.py']",{'.py': 4},4,0,0,4,4,185783,43602,5911,69,978,265,27,3,2230,166,652,48,3,4,2020-10-28 22:02:59,10726,Python,"{'Python': 527569, 'R': 12037, 'Shell': 3071, 'PowerShell': 744, 'Dockerfile': 406, 'C#': 399, 'Lua': 212, 'Ruby': 195, 'Swift': 181, 'Dart': 142, 'JavaScript': 128, 'Perl': 104, 'Go': 29, 'Rust': 13}",MIT License,"['pre_commit/commands/install_uninstall.py', 'pre_commit/commands/hook_impl.py', 'pre_commit/util.py', 'pre_commit/commands/run.py', 'pre_commit/repository.py']","['pre_commit/commands/install_uninstall.py', 'pre_commit/commands/hook_impl.py', 'pre_commit/util.py', 'pre_commit/commands/run.py', 'pre_commit/repository.py']","['```json\n{\n  ""files"": [\n    ""pre_commit/repository.py"",\n    ""pre_commit/commands/run.py"",\n    ""pre_commit/commands/install_uninstall.py"",\n    ""pre_commit/commands/hook_impl.py"",\n    ""pre_commit/util.py""\n  ]\n}\n```']",1,892.8236961364746
6878,aws/chalice/504/501,aws,chalice,https://github.com/aws/chalice/issues/501,https://github.com/aws/chalice/pull/504,https://github.com/aws/chalice/pull/504,1,fixes,Environment variables do not get passed to subprocess during package building,"When Chalice creates subprocesses to build the package it does not pass down the current set of environment variables down. This was introduced in https://github.com/aws/chalice/commit/d6b22b3e8932dd588bf5110d5e5b084d246681a4 so it is a regression over the previous behavior where the subprocess inherited the environment. This matters for any setup.py file that makes use of an environment variable.

Initial issue #497 ",a36ad3f9b413979da9416e1dec164bf787c7c0bf,5784fae3602227ba549b104e5803237180e611a1,https://github.com/aws/chalice/compare/a36ad3f9b413979da9416e1dec164bf787c7c0bf...5784fae3602227ba549b104e5803237180e611a1,"diff --git a/chalice/compat.py b/chalice/compat.py
index 1161027..14221a7 100644
--- a/chalice/compat.py
+++ b/chalice/compat.py
@@ -8,17 +8,6 @@ from six import StringIO
 
 if os.name == 'nt':
     # windows
-    # On windows running python in a subprocess with no environment variables
-    # will cause several issues. In order for our subprocess to run normally we
-    # manually copy the relevant environment variables from the parent process.
-    subprocess_python_base_environ = {
-        # http://bugs.python.org/issue8557
-        'PATH': os.environ['PATH']
-    }  # type: Dict[str, Any]
-    # http://bugs.python.org/issue20614
-    if 'SYSTEMROOT' in os.environ:
-        subprocess_python_base_environ['SYSTEMROOT'] = os.environ['SYSTEMROOT']
-
     # This is the actual patch used on windows to prevent distutils from
     # compiling C extensions. The msvc compiler base class has its compile
     # method overridden to raise a CompileError. This can be caught by
@@ -94,10 +83,6 @@ if os.name == 'nt':
     pip_no_compile_c_env_vars = {}  # type: Dict[str, Any]
 else:
     # posix
-    # On posix you can start python in a subprocess with no environment
-    # variables and it will run normally.
-    subprocess_python_base_environ = {}
-
     # On posix systems setuptools/distutils uses the CC env variable to
     # locate a C compiler for building C extensions. All we need to do is set
     # it to /var/false, and the module building process will fail to build.
diff --git a/chalice/deploy/packager.py b/chalice/deploy/packager.py
index 8a8d9c4..6caac0d 100644
--- a/chalice/deploy/packager.py
+++ b/chalice/deploy/packager.py
@@ -8,9 +8,8 @@ from email.message import Message  # noqa
 from zipfile import ZipFile  # noqa
 
 from typing import Any, Set, List, Optional, Tuple, Iterable, Callable  # noqa
-from typing import Dict  # noqa
+from typing import Dict, MutableMapping  # noqa
 from chalice.compat import lambda_abi
-from chalice.compat import subprocess_python_base_environ
 from chalice.compat import pip_no_compile_c_env_vars
 from chalice.compat import pip_no_compile_c_shim
 from chalice.utils import OSUtils
@@ -23,6 +22,7 @@ from chalice import app
 
 StrMap = Dict[str, Any]
 OptStrMap = Optional[StrMap]
+EnvVars = MutableMapping
 OptStr = Optional[str]
 OptBytes = Optional[bytes]
 
@@ -263,7 +263,7 @@ class DependencyBuilder(object):
         # type: (OSUtils, Optional[PipRunner]) -> None
         self._osutils = osutils
         if pip_runner is None:
-            pip_runner = PipRunner(SubprocessPip())
+            pip_runner = PipRunner(SubprocessPip(osutils))
         self._pip = pip_runner
 
     def _is_compatible_wheel_filename(self, filename):
@@ -576,13 +576,18 @@ class SDistMetadataFetcher(object):
 
 class SubprocessPip(object):
     """"""Wrapper around calling pip through a subprocess.""""""
+    def __init__(self, osutils=None):
+        # type: (Optional[OSUtils]) -> None
+        if osutils is None:
+            osutils = OSUtils()
+        self._osutils = osutils
+
     def main(self, args, env_vars=None, shim=None):
-        # type: (List[str], OptStrMap, OptStr) -> Tuple[int, Optional[bytes]]
+        # type: (List[str], EnvVars, OptStr) -> Tuple[int, Optional[bytes]]
         if env_vars is None:
-            env_vars = {}
+            env_vars = self._osutils.environ()
         if shim is None:
             shim = ''
-        env_vars.update(subprocess_python_base_environ)
         python_exe = sys.executable
         run_pip = 'import pip, sys; sys.exit(pip.main(%s))' % args
         exec_string = '%s%s' % (shim, run_pip)
@@ -597,12 +602,15 @@ class SubprocessPip(object):
 
 class PipRunner(object):
     """"""Wrapper around pip calls used by chalice.""""""
-    def __init__(self, pip):
-        # type: (SubprocessPip) -> None
+    def __init__(self, pip, osutils=None):
+        # type: (SubprocessPip, Optional[OSUtils]) -> None
+        if osutils is None:
+            osutils = OSUtils()
         self._wrapped_pip = pip
+        self._osutils = osutils
 
     def _execute(self, command, args, env_vars=None, shim=None):
-        # type: (str, List[str], OptStrMap, OptStr) -> Tuple[int, OptBytes]
+        # type: (str, List[str], EnvVars, OptStr) -> Tuple[int, OptBytes]
         """"""Execute a pip command with the given arguments.""""""
         main_args = [command] + args
         rc, err = self._wrapped_pip.main(main_args, env_vars=env_vars,
@@ -613,7 +621,7 @@ class PipRunner(object):
         # type: (str, str, bool) -> None
         """"""Build an sdist into a wheel file.""""""
         arguments = ['--no-deps', '--wheel-dir', directory, wheel]
-        env_vars = {}  # type: StrMap
+        env_vars = self._osutils.environ()
         shim = ''
         if not compile_c:
             env_vars.update(pip_no_compile_c_env_vars)
diff --git a/chalice/utils.py b/chalice/utils.py
index 8537aba..fc77b92 100644
--- a/chalice/utils.py
+++ b/chalice/utils.py
@@ -10,6 +10,7 @@ import tarfile
 import click
 from typing import IO, Dict, List, Any, Tuple, Iterator, BinaryIO  # noqa
 from typing import Optional  # noqa
+from typing import MutableMapping  # noqa
 
 from chalice.constants import WELCOME_PROMPT
 
@@ -78,6 +79,10 @@ def create_zip_file(source_dir, outfile):
 class OSUtils(object):
     ZIP_DEFLATED = zipfile.ZIP_DEFLATED
 
+    def environ(self):
+        # type: () -> MutableMapping
+        return os.environ
+
     def open(self, filename, mode):
         # type: (str, str) -> IO
         return open(filename, mode)
diff --git a/tests/functional/test_package.py b/tests/functional/test_package.py
index a4b476c..f2da879 100644
--- a/tests/functional/test_package.py
+++ b/tests/functional/test_package.py
@@ -54,6 +54,7 @@ class FakePip(object):
         self._side_effects = defaultdict(lambda: [])
 
     def main(self, args, env_vars=None, shim=None):
+
         cmd, args = args[0], args[1:]
         self._calls[cmd].append((args, env_vars, shim))
         try:
@@ -162,9 +163,17 @@ def osutils():
 
 
 @pytest.fixture
-def pip_runner():
+def empty_env_osutils():
+    class EmptyEnv(object):
+        def environ(self):
+            return {}
+    return EmptyEnv()
+
+
+@pytest.fixture
+def pip_runner(empty_env_osutils):
     pip = FakePip()
-    pip_runner = PipRunner(pip)
+    pip_runner = PipRunner(pip, osutils=empty_env_osutils)
     return pip, pip_runner
 
 
diff --git a/tests/unit/deploy/test_packager.py b/tests/unit/deploy/test_packager.py
index f3c1689..bc2dcfa 100644
--- a/tests/unit/deploy/test_packager.py
+++ b/tests/unit/deploy/test_packager.py
@@ -39,10 +39,29 @@ class FakePip(object):
 
 
 @pytest.fixture
-def pip_runner():
-    pip = FakePip()
-    pip_runner = PipRunner(pip)
-    return pip, pip_runner
+def pip_factory():
+    def create_pip_runner(osutils=None):
+        pip = FakePip()
+        pip_runner = PipRunner(pip, osutils=osutils)
+        return pip, pip_runner
+    return create_pip_runner
+
+
+class CustomEnv(OSUtils):
+    def __init__(self, env):
+        self._env = env
+
+    def environ(self):
+        return self._env
+
+
+@pytest.fixture
+def pip_runner_custom_env(custom_env_osutils):
+    def create_pip_runner(env):
+        pip = FakePip()
+        pip_runner = PipRunner(pip, osutils=custom_env_osutils(env))
+        return pip, pip_runner
+    return create_pip_runner
 
 
 @pytest.fixture
@@ -129,9 +148,20 @@ class TestSubprocessPip(object):
 
 
 class TestPipRunner(object):
-    def test_build_wheel(self, pip_runner):
+    def test_does_propagate_env_vars(self, pip_factory):
+        osutils = CustomEnv({'foo': 'bar'})
+        pip, runner = pip_factory(osutils)
+        wheel = 'foobar-1.2-py3-none-any.whl'
+        directory = 'directory'
+        runner.build_wheel(wheel, directory)
+        call = pip.calls[0]
+
+        assert 'foo' in call.env_vars
+        assert call.env_vars['foo'] == 'bar'
+
+    def test_build_wheel(self, pip_factory):
         # Test that `pip wheel` is called with the correct params
-        pip, runner = pip_runner
+        pip, runner = pip_factory()
         wheel = 'foobar-1.0-py3-none-any.whl'
         directory = 'directory'
         runner.build_wheel(wheel, directory)
@@ -140,13 +170,14 @@ class TestPipRunner(object):
         call = pip.calls[0]
         assert call.args == ['wheel', '--no-deps', '--wheel-dir',
                              directory, wheel]
-        assert call.env_vars == {}
+        for compile_env_var in pip_no_compile_c_env_vars:
+            assert compile_env_var not in call.env_vars
         assert call.shim == ''
 
-    def test_build_wheel_without_c_extensions(self, pip_runner):
+    def test_build_wheel_without_c_extensions(self, pip_factory):
         # Test that `pip wheel` is called with the correct params when we
         # call it with compile_c=False. These will differ by platform.
-        pip, runner = pip_runner
+        pip, runner = pip_factory()
         wheel = 'foobar-1.0-py3-none-any.whl'
         directory = 'directory'
         runner.build_wheel(wheel, directory, compile_c=False)
@@ -155,13 +186,14 @@ class TestPipRunner(object):
         call = pip.calls[0]
         assert call.args == ['wheel', '--no-deps', '--wheel-dir',
                              directory, wheel]
-        assert call.env_vars == pip_no_compile_c_env_vars
+        for compile_env_var in pip_no_compile_c_env_vars:
+            assert compile_env_var in call.env_vars
         assert call.shim == pip_no_compile_c_shim
 
-    def test_download_all_deps(self, pip_runner):
+    def test_download_all_deps(self, pip_factory):
         # Make sure that `pip download` is called with the correct arguments
         # for getting all sdists.
-        pip, runner = pip_runner
+        pip, runner = pip_factory()
         runner.download_all_dependencies('requirements.txt', 'directory')
 
         assert len(pip.calls) == 1
@@ -171,10 +203,10 @@ class TestPipRunner(object):
         assert call.env_vars is None
         assert call.shim is None
 
-    def test_download_wheels(self, pip_runner):
+    def test_download_wheels(self, pip_factory):
         # Make sure that `pip download` is called with the correct arguments
         # for getting lambda compatible wheels.
-        pip, runner = pip_runner
+        pip, runner = pip_factory()
         packages = ['foo', 'bar', 'baz']
         runner.download_manylinux_wheels(packages, 'directory')
         if sys.version_info[0] == 2:
@@ -190,13 +222,13 @@ class TestPipRunner(object):
             assert pip.calls[i].env_vars is None
             assert pip.calls[i].shim is None
 
-    def test_download_wheels_no_wheels(self, pip_runner):
-        pip, runner = pip_runner
+    def test_download_wheels_no_wheels(self, pip_factory):
+        pip, runner = pip_factory()
         runner.download_manylinux_wheels([], 'directory')
         assert len(pip.calls) == 0
 
-    def test_raise_no_such_package_error(self, pip_runner):
-        pip, runner = pip_runner
+    def test_raise_no_such_package_error(self, pip_factory):
+        pip, runner = pip_factory()
         pip.add_return((1, (b'Could not find a version that satisfies the '
                             b'requirement BadPackageName ')))
         with pytest.raises(NoSuchPackageError) as einfo:
@@ -204,15 +236,15 @@ class TestPipRunner(object):
         assert str(einfo.value) == ('Could not satisfy the requirement: '
                                     'BadPackageName')
 
-    def test_raise_other_unknown_error_during_downloads(self, pip_runner):
-        pip, runner = pip_runner
+    def test_raise_other_unknown_error_during_downloads(self, pip_factory):
+        pip, runner = pip_factory()
         pip.add_return((1, b'SomeNetworkingError: Details here.'))
         with pytest.raises(PackageDownloadError) as einfo:
             runner.download_all_dependencies('requirements.txt', 'directory')
         assert str(einfo.value) == 'SomeNetworkingError: Details here.'
 
-    def test_inject_unknown_error_if_no_stderr(self, pip_runner):
-        pip, runner = pip_runner
+    def test_inject_unknown_error_if_no_stderr(self, pip_factory):
+        pip, runner = pip_factory()
         pip.add_return((1, None))
         with pytest.raises(PackageDownloadError) as einfo:
             runner.download_all_dependencies('requirements.txt', 'directory')","['tests/functional/test_package.py', 'chalice/deploy/packager.py', 'tests/unit/deploy/test_packager.py', 'chalice/compat.py', 'chalice/utils.py']",{'.py': 5},5,0,0,5,5,263733,56746,6905,22,2096,507,48,3,423,56,97,3,1,0,2017-08-30 16:53:08,9897,Python,"{'Python': 1727482, 'Makefile': 1987, 'Shell': 1584}",Apache License 2.0,"['chalice/package.py', 'chalice/utils.py', 'chalice/deploy/packager.py', 'chalice/deploy/deployer.py', 'chalice/config.py']","['chalice/package.py', 'chalice/utils.py', 'chalice/deploy/packager.py', 'chalice/deploy/deployer.py', 'chalice/config.py']","['```json\n{\n  ""files"": [\n    ""chalice/package.py"",\n    ""chalice/deploy/packager.py"",\n    ""chalice/deploy/deployer.py"",\n    ""chalice/utils.py"",\n    ""chalice/config.py""\n  ]\n}\n```']",1,1256.7088603973389
6896,tweepy/tweepy/1262/1261,tweepy,tweepy,https://github.com/tweepy/tweepy/issues/1261,https://github.com/tweepy/tweepy/pull/1262,https://github.com/tweepy/tweepy/pull/1262,2,fix,Bug with list_direct_messages,"Hi,

I'm trying to use the list_direct_messages api but any time I try to iterate through the items it returns I get this error

Traceback (most recent call last):
  File ""reply_dm.py"", line 41, in <module>
    main()
  File ""reply_dm.py"", line 36, in main
    check_messages(api)
  File ""reply_dm.py"", line 29, in check_messages
    for message in tweepy.Cursor(api.list_direct_messages).items():
  File ""C:\\Python27\\bot\\twitter\\lib\\site-packages\\tweepy\\cursor.py"", line 195, in next
    self.current_page = self.page_iterator.next()
  File ""C:\\Python27\\bot\\twitter\\lib\\site-packages\\tweepy\\cursor.py"", line 73, in next
    **self.kargs)
  File ""C:\\Python27\\bot\\twitter\\lib\\site-packages\\tweepy\\binder.py"", line 250, in _call
    return method.execute()
  File ""C:\\Python27\\bot\\twitter\\lib\\site-packages\\tweepy\\binder.py"", line 233, in execute
    raise TweepError(error_msg, resp, api_code=api_error_code)
tweepy.error.TweepError: [{u'message': u'invalid cursor', u'code': 214}]

Now, I may be doing something wrong, but I tested a few other API methods such as followers and others and those worked (so I think I'm using cursors properly).

Can anyone confirm this is working in their version of Python?",7d17d6c54ff2a9e4bdef927d19c993a08c7c8b8c,3c4512993cc5c57fa444d17e5603b0177aeee3ef,https://github.com/tweepy/tweepy/compare/7d17d6c54ff2a9e4bdef927d19c993a08c7c8b8c...3c4512993cc5c57fa444d17e5603b0177aeee3ef,"diff --git a/tweepy/binder.py b/tweepy/binder.py
index 7d352a6..846cfbf 100644
--- a/tweepy/binder.py
+++ b/tweepy/binder.py
@@ -55,6 +55,7 @@ def bind_api(**config):
                                                  api.wait_on_rate_limit)
             self.wait_on_rate_limit_notify = kwargs.pop('wait_on_rate_limit_notify',
                                                         api.wait_on_rate_limit_notify)
+            self.return_cursors = kwargs.pop('return_cursors', False)
             self.parser = kwargs.pop('parser', api.parser)
             self.session.headers = kwargs.pop('headers', {})
             self.build_parameters(args, kwargs)
@@ -233,7 +234,8 @@ def bind_api(**config):
                     raise TweepError(error_msg, resp, api_code=api_error_code)
 
             # Parse the response payload
-            result = self.parser.parse(self, resp.text)
+            self.return_cursors = self.return_cursors or 'cursor' in self.session.params
+            result = self.parser.parse(self, resp.text, return_cursors=self.return_cursors)
 
             # Store result into cache if one is available.
             if self.use_cache and self.api.cache and self.method == 'GET' and result:
@@ -253,7 +255,10 @@ def bind_api(**config):
 
     # Set pagination mode
     if 'cursor' in APIMethod.allowed_param:
-        _call.pagination_mode = 'cursor'
+        if APIMethod.payload_type == 'direct_message':
+            _call.pagination_mode = 'dm_cursor'
+        else:
+            _call.pagination_mode = 'cursor'
     elif 'max_id' in APIMethod.allowed_param:
         if 'since_id' in APIMethod.allowed_param:
             _call.pagination_mode = 'id'
diff --git a/tweepy/cursor.py b/tweepy/cursor.py
index 1803c37..2a3d950 100644
--- a/tweepy/cursor.py
+++ b/tweepy/cursor.py
@@ -13,6 +13,8 @@ class Cursor(object):
         if hasattr(method, 'pagination_mode'):
             if method.pagination_mode == 'cursor':
                 self.iterator = CursorIterator(method, *args, **kwargs)
+            elif method.pagination_mode == 'dm_cursor':
+                self.iterator = DMCursorIterator(method, *args, **kwargs)
             elif method.pagination_mode == 'id':
                 self.iterator = IdIterator(method, *args, **kwargs)
             elif method.pagination_mode == 'page':
@@ -87,6 +89,28 @@ class CursorIterator(BaseIterator):
         return data
 
 
+class DMCursorIterator(BaseIterator):
+
+    def __init__(self, method, *args, **kwargs):
+        BaseIterator.__init__(self, method, *args, **kwargs)
+        self.next_cursor = self.kwargs.pop('cursor', None)
+        self.page_count = 0
+
+    def next(self):
+        if self.next_cursor == -1 or (self.limit and self.page_count == self.limit):
+            raise StopIteration
+        data = self.method(cursor=self.next_cursor, return_cursors=True, *self.args, **self.kwargs)
+        self.page_count += 1
+        if isinstance(data, tuple):
+            data, self.next_cursor = data
+        else:
+            self.next_cursor = -1
+        return data
+
+    def prev(self):
+        raise TweepError('This method does not allow backwards pagination')
+
+
 class IdIterator(BaseIterator):
 
     def __init__(self, method, *args, **kwargs):
@@ -193,6 +217,8 @@ class ItemIterator(BaseIterator):
         if self.current_page is None or self.page_index == len(self.current_page) - 1:
             # Reached end of current page, get the next page...
             self.current_page = self.page_iterator.next()
+            while len(self.current_page) == 0:
+                self.current_page = self.page_iterator.next()
             self.page_index = -1
         self.page_index += 1
         self.num_tweets += 1
diff --git a/tweepy/parsers.py b/tweepy/parsers.py
index 70fd978..7d09f63 100644
--- a/tweepy/parsers.py
+++ b/tweepy/parsers.py
@@ -10,7 +10,7 @@ from tweepy.models import ModelFactory
 
 class Parser(object):
 
-    def parse(self, method, payload):
+    def parse(self, method, payload, *args, **kwargs):
         """"""
         Parse the response payload and return the result.
         Returns a tuple that contains the result data and the cursors
@@ -32,7 +32,7 @@ class RawParser(Parser):
     def __init__(self):
         pass
 
-    def parse(self, method, payload):
+    def parse(self, method, payload, *args, **kwargs):
         return payload
 
     def parse_error(self, payload):
@@ -43,20 +43,20 @@ class JSONParser(Parser):
 
     payload_format = 'json'
 
-    def parse(self, method, payload):
+    def parse(self, method, payload, return_cursors=False):
         try:
             json = json_lib.loads(payload)
         except Exception as e:
             raise TweepError('Failed to parse JSON payload: %s' % e)
 
-        needs_cursors = 'cursor' in method.session.params
-        if needs_cursors and isinstance(json, dict) \\
-                and 'previous_cursor' in json \\
-                and 'next_cursor' in json:
-            cursors = json['previous_cursor'], json['next_cursor']
-            return json, cursors
-        else:
-            return json
+        if return_cursors and isinstance(json, dict):
+            if 'next_cursor' in json:
+                if 'previous_cursor' in json:
+                    cursors = json['previous_cursor'], json['next_cursor']
+                    return json, cursors
+                else:
+                    return json, json['next_cursor']
+        return json
 
     def parse_error(self, payload):
         error_object = json_lib.loads(payload)
@@ -79,7 +79,7 @@ class ModelParser(JSONParser):
         JSONParser.__init__(self)
         self.model_factory = model_factory or ModelFactory
 
-    def parse(self, method, payload):
+    def parse(self, method, payload, return_cursors=False):
         try:
             if method.payload_type is None:
                 return
@@ -88,7 +88,7 @@ class ModelParser(JSONParser):
             raise TweepError('No model for this payload type: '
                              '%s' % method.payload_type)
 
-        json = JSONParser.parse(self, method, payload)
+        json = JSONParser.parse(self, method, payload, return_cursors=return_cursors)
         if isinstance(json, tuple):
             json, cursors = json
         else:","['tweepy/binder.py', 'tweepy/parsers.py', 'tweepy/cursor.py']",{'.py': 3},3,0,0,3,3,144013,29940,4091,17,2768,590,61,3,1229,134,337,24,0,0,2019-08-25 10:13:27,9834,Python,{'Python': 618881},MIT License,"['tweepy/cursor.py', 'reply_dm.py', 'tweepy/binder.py']","['tweepy/cursor.py', 'tweepy/binder.py']","['```json\n{\n  ""files"": [\n    ""tweepy/cursor.py"",\n    ""tweepy/binder.py"",\n    ""reply_dm.py""\n  ]\n}\n```']",1,967.8277969360352
8065,openmined/pysyft/1908/1896,openmined,pysyft,https://github.com/OpenMined/PySyft/issues/1896,https://github.com/OpenMined/PySyft/pull/1908,https://github.com/OpenMined/PySyft/pull/1908,1,fix,Garbage Collection issue with in-place methods on tensors,"This triggers a KeyError. I suspect unexpected garbage collection.
```
buf = torch.tensor([[1., 2], [4., 2]]).send(bob)
buf.add_(buf)
buf.get()
```",0527cd54928c3174d387e7a8668da4a08c3c28d0,f84e8a95b5d5fb1bdb805986500bde010d07f36b,https://github.com/openmined/pysyft/compare/0527cd54928c3174d387e7a8668da4a08c3c28d0...f84e8a95b5d5fb1bdb805986500bde010d07f36b,"diff --git a/syft/frameworks/torch/hook.py b/syft/frameworks/torch/hook.py
index 33ecd0c23..dc07585bf 100644
--- a/syft/frameworks/torch/hook.py
+++ b/syft/frameworks/torch/hook.py
@@ -524,7 +524,7 @@ class TorchHook:
 
         return overloaded_syft_method
 
-    def get_hooked_method(hook_self, attr):
+    def get_hooked_method(hook_self, method_name):
         """"""
         Hook a method in order to replace all args/kwargs syft/torch tensors with
         their child attribute if they exist
@@ -535,45 +535,47 @@ class TorchHook:
         :return: the hooked method
         """"""
 
-        @wraps(attr)
+        @wraps(method_name)
         def overloaded_native_method(self, *args, **kwargs):
             """"""
             Operate the hooking
             """"""
 
             if not hasattr(self, ""child""):  # means that it's not a wrapper
-                cmd = getattr(self, f""native_{attr}"")
+                method = getattr(self, f""native_{method_name}"")
                 # Run the native function with the new args
 
                 try:
-
                     if isinstance(args, tuple):
-                        response = cmd(*args)
+                        response = method(*args)
                     else:
-                        response = cmd(args)
+                        response = method(args)
 
                 except BaseException as e:
                     # we can make some errors more descriptive with this method
                     raise route_method_exception(e, self, args, kwargs)
 
             else:  # means that there is a wrapper to remove
-
                 try:
                     # Replace all torch tensor with their child attribute
                     new_self, new_args = syft.frameworks.torch.hook_args.hook_method_args(
-                        attr, self, args
+                        method_name, self, args
                     )
                 except BaseException as e:
                     # we can make some errors more descriptive with this method
                     raise route_method_exception(e, self, args, kwargs)
 
                 # Send the new command to the appropriate class and get the response
-                cmd = getattr(new_self, attr)
-                response = cmd(*new_args, **kwargs)
+                method = getattr(new_self, method_name)
+                response = method(*new_args, **kwargs)
+
+                # For inplace methods, just directly return self
+                if syft.torch.is_inplace_method(method_name):
+                    return self
 
                 # Put back the wrappers where needed
                 response = syft.frameworks.torch.hook_args.hook_response(
-                    attr, response, wrap_type=type(self), new_self=self
+                    method_name, response, wrap_type=type(self), new_self=self
                 )
 
             return response
diff --git a/syft/frameworks/torch/torch_attributes.py b/syft/frameworks/torch/torch_attributes.py
index a6f40857c..f8fb47ae2 100644
--- a/syft/frameworks/torch/torch_attributes.py
+++ b/syft/frameworks/torch/torch_attributes.py
@@ -112,7 +112,6 @@ class TorchAttributes(object):
             ""is_tensor"",
             ""isfinite"",
             ""load"",
-            ""zeros_like"",
             ""randperm"",
         ]
 
@@ -159,6 +158,9 @@ class TorchAttributes(object):
 
         self.command_guard = self._command_guard
 
+        # Dict {method_name: <is_inplace:bool>
+        self.inplace_methods = {}
+
     def _command_guard(
         self, command: str, torch_domain: str, get_native: bool = False
     ) -> Union[Callable[..., Any], str]:
@@ -232,6 +234,19 @@ class TorchAttributes(object):
         native_func_name = ""."".join(parts)
         return native_func_name
 
+    def is_inplace_method(self, method_name):
+        """"""
+        Says if a method is inplace or not by test if it ends by _ and is not a __xx__
+        :param method_name: the name for the method
+        :return: boolean
+        """"""
+        try:
+            return self.inplace_methods[method_name]
+        except KeyError:
+            is_inplace = method_name[-1] == ""_"" and ""__"" not in method_name
+            self.inplace_methods[method_name] = is_inplace
+            return is_inplace
+
     @staticmethod
     def apply_fix16922(torch):
         """"""
diff --git a/syft/workers/base.py b/syft/workers/base.py
index 34544bb22..6cfe768a1 100644
--- a/syft/workers/base.py
+++ b/syft/workers/base.py
@@ -264,8 +264,11 @@ class BaseWorker(AbstractWorker):
         command = command.decode(""utf-8"")
         # Handle methods
         if _self is not None:
-
-            tensor = getattr(_self, command)(*args, **kwargs)
+            if sy.torch.is_inplace_method(command):
+                getattr(_self, command)(*args, **kwargs)
+                return
+            else:
+                tensor = getattr(_self, command)(*args, **kwargs)
         # Handle functions
         else:
             # At this point, the command is ALWAYS a path to a
@@ -304,7 +307,6 @@ class BaseWorker(AbstractWorker):
                 ptr_id=tensor.id,
                 garbage_collect_data=False,
             )
-
             return pointer
 
     def send_command(self, recipient, message):
diff --git a/test/torch/tensors/test_gc.py b/test/torch/tensors/test_gc.py
index 43b61f980..6724682b3 100644
--- a/test/torch/tensors/test_gc.py
+++ b/test/torch/tensors/test_gc.py
@@ -132,6 +132,18 @@ def test_implicit_garbage_collect_double_pointer(workers):
     # assert x.id not in workers[""alice""]._objects
 
 
+# TESTING IN PLACE METHODS
+
+
+def test_inplace_method_on_pointer(workers):
+    bob = workers[""bob""]
+    tensor = torch.tensor([[1.0, 2], [4.0, 2]])
+    pointer = tensor.send(bob)
+    pointer.add_(pointer)
+    tensor_back = pointer.get()
+    assert (tensor * 2 == tensor_back).all()
+
+
 # TESTING LOGGING TENSORS
 
 ","['syft/frameworks/torch/hook.py', 'syft/frameworks/torch/torch_attributes.py', 'syft/workers/base.py', 'test/torch/tensors/test_gc.py']",{'.py': 4},4,0,0,4,4,197658,42514,5670,34,1986,401,49,3,152,19,43,6,0,1,2019-02-14 10:45:48,8887,Python,"{'Python': 1731206, 'Jupyter Notebook': 643072, 'Svelte': 156414, 'TypeScript': 45201, 'Shell': 43948, 'JavaScript': 24781, 'Dockerfile': 10878, 'Makefile': 7605, 'HCL': 4438, 'CSS': 2107, 'Mako': 510, ""Cap'n Proto"": 363, 'HTML': 350, 'PowerShell': 161}",Apache License 2.0,"['syft/frameworks/torch/tensors/interpreters/abstract.py', 'syft/frameworks/torch/tensors/interpreters/utils.py', 'syft/frameworks/torch/tensors/interpreters/snn.py', 'syft/frameworks/torch/tensors/interpreters/native.py', 'syft/frameworks/torch/tensors/interpreters/plusisminus.py']","['syft/frameworks/torch/tensors/interpreters/abstract.py', 'syft/frameworks/torch/tensors/interpreters/utils.py', 'syft/frameworks/torch/tensors/interpreters/snn.py', 'syft/frameworks/torch/tensors/interpreters/native.py', 'syft/frameworks/torch/tensors/interpreters/plusisminus.py']","['```json\n{\n  ""files"": [\n    ""syft/frameworks/torch/tensors/interpreters/plusisminus.py"",\n    ""syft/frameworks/torch/tensors/interpreters/native.py"",\n    ""syft/frameworks/torch/tensors/interpreters/abstract.py"",\n    ""syft/frameworks/torch/tensors/interpreters/utils.py"",\n    ""syft/frameworks/torch/tensors/interpreters/snn.py""\n  ]\n}\n```']",1,1633.6336135864258
8254,pypa/pip/12140/12138,pypa,pip,https://github.com/pypa/pip/issues/12138,https://github.com/pypa/pip/pull/12140,https://github.com/pypa/pip/pull/12140,1,fix,`pip --use-deprecated legacy-resolver download ...` fails at b88addeaf5fde848733d7ef631caa522eb1cfa53,"### Description

I bisected to b88addeaf5fde848733d7ef631caa522eb1cfa53 (#11945) using:
```
PYTHONPATH=src python3.12 -mpip --use-deprecated legacy-resolver download setuptools==68.0.0
```

The error is:
```
$ PYTHONPATH=src python3.12 -mpip --use-deprecated legacy-resolver download setuptools==68.0.0
Collecting setuptools==68.0.0
  Obtaining dependency information for setuptools==68.0.0 from https://files.pythonhosted.org/packages/c7/42/be1c7bbdd83e1bfb160c94b9cafd8e25efc7400346cf7ccdbdb452c467fa/setuptools-68.0.0-py3-none-any.whl.metadata
  Using cached setuptools-68.0.0-py3-none-any.whl.metadata (6.4 kB)
ERROR: Exception:
Traceback (most recent call last):
  File ""/home/jsirois/dev/pypa/pip/src/pip/_internal/cli/base_command.py"", line 180, in exc_logging_wrapper
    status = run_func(*args)
  File ""/home/jsirois/dev/pypa/pip/src/pip/_internal/cli/req_command.py"", line 248, in wrapper
    return func(self, options, args)
  File ""/home/jsirois/dev/pypa/pip/src/pip/_internal/commands/download.py"", line 133, in run
    requirement_set.warn_legacy_versions_and_specifiers()
  File ""/home/jsirois/dev/pypa/pip/src/pip/_internal/req/req_set.py"", line 89, in warn_legacy_versions_and_specifiers
    version = req.get_dist().version
  File ""/home/jsirois/dev/pypa/pip/src/pip/_internal/req/req_install.py"", line 598, in get_dist
    raise AssertionError(
AssertionError: InstallRequirement setuptools==68.0.0 from https://files.pythonhosted.org/packages/c7/42/be1c7bbdd83e1bfb160c94b9cafd8e25efc7400346cf7ccdbdb452c467fa/setuptools-68.0.0-py3-none-any.whl has no metadata directory and no wheel: can't make a distribution.
```

### Expected behavior

No backtrace / blowup or else removal of `--use-deprecated` support for `legacy-resolver` as per: https://pip.pypa.io/en/latest/user_guide/#deprecation-timeline

### pip version

unreleased: main @ b88addeaf5fde848733d7ef631caa522eb1cfa53

### Python version

3.12 (but same with others)

### OS

Linux (Ubuntu 22.04)

### How to Reproduce

See above, but in a pypa/pip clone:
```
PYTHONPATH=src python -mpip --use-deprecated legacy-resolver download setuptools==68.0.0
```

### Output

```
$ PYTHONPATH=src python3.12 -mpip --use-deprecated legacy-resolver download setuptools==68.0.0
Collecting setuptools==68.0.0
  Obtaining dependency information for setuptools==68.0.0 from https://files.pythonhosted.org/packages/c7/42/be1c7bbdd83e1bfb160c94b9cafd8e25efc7400346cf7ccdbdb452c467fa/setuptools-68.0.0-py3-none-any.whl.metadata
  Using cached setuptools-68.0.0-py3-none-any.whl.metadata (6.4 kB)
ERROR: Exception:
Traceback (most recent call last):
  File ""/home/jsirois/dev/pypa/pip/src/pip/_internal/cli/base_command.py"", line 180, in exc_logging_wrapper
    status = run_func(*args)
  File ""/home/jsirois/dev/pypa/pip/src/pip/_internal/cli/req_command.py"", line 248, in wrapper
    return func(self, options, args)
  File ""/home/jsirois/dev/pypa/pip/src/pip/_internal/commands/download.py"", line 133, in run
    requirement_set.warn_legacy_versions_and_specifiers()
  File ""/home/jsirois/dev/pypa/pip/src/pip/_internal/req/req_set.py"", line 89, in warn_legacy_versions_and_specifiers
    version = req.get_dist().version
  File ""/home/jsirois/dev/pypa/pip/src/pip/_internal/req/req_install.py"", line 598, in get_dist
    raise AssertionError(
AssertionError: InstallRequirement setuptools==68.0.0 from https://files.pythonhosted.org/packages/c7/42/be1c7bbdd83e1bfb160c94b9cafd8e25efc7400346cf7ccdbdb452c467fa/setuptools-68.0.0-py3-none-any.whl has no metadata directory and no wheel: can't make a distribution.
```

### Code of Conduct

- [X] I agree to follow the [PSF Code of Conduct](https://www.python.org/psf/conduct/).",ea727e4d6ab598f34f97c50a22350febc1214a97,0cabefbce800b6bde91f869e83dc48bd0ea4aa64,https://github.com/pypa/pip/compare/ea727e4d6ab598f34f97c50a22350febc1214a97...0cabefbce800b6bde91f869e83dc48bd0ea4aa64,"diff --git a/src/pip/_internal/commands/download.py b/src/pip/_internal/commands/download.py
index 63bd53a50..54247a78a 100644
--- a/src/pip/_internal/commands/download.py
+++ b/src/pip/_internal/commands/download.py
@@ -130,7 +130,6 @@ class DownloadCommand(RequirementCommand):
         self.trace_basic_info(finder)
 
         requirement_set = resolver.resolve(reqs, check_supported_wheels=True)
-        requirement_set.warn_legacy_versions_and_specifiers()
 
         downloaded: List[str] = []
         for req in requirement_set.requirements.values():
@@ -138,6 +137,10 @@ class DownloadCommand(RequirementCommand):
                 assert req.name is not None
                 preparer.save_linked_requirement(req)
                 downloaded.append(req.name)
+
+        preparer.prepare_linked_requirements_more(requirement_set.requirements.values())
+        requirement_set.warn_legacy_versions_and_specifiers()
+
         if downloaded:
             write_output(""Successfully downloaded %s"", "" "".join(downloaded))
 
diff --git a/src/pip/_internal/commands/wheel.py b/src/pip/_internal/commands/wheel.py
index e6735bd8d..ed578aa25 100644
--- a/src/pip/_internal/commands/wheel.py
+++ b/src/pip/_internal/commands/wheel.py
@@ -145,7 +145,6 @@ class WheelCommand(RequirementCommand):
         self.trace_basic_info(finder)
 
         requirement_set = resolver.resolve(reqs, check_supported_wheels=True)
-        requirement_set.warn_legacy_versions_and_specifiers()
 
         reqs_to_build: List[InstallRequirement] = []
         for req in requirement_set.requirements.values():
@@ -154,6 +153,9 @@ class WheelCommand(RequirementCommand):
             elif should_build_for_wheel_command(req):
                 reqs_to_build.append(req)
 
+        preparer.prepare_linked_requirements_more(requirement_set.requirements.values())
+        requirement_set.warn_legacy_versions_and_specifiers()
+
         # build wheels
         build_successes, build_failures = build(
             reqs_to_build,
diff --git a/src/pip/_internal/resolution/resolvelib/resolver.py b/src/pip/_internal/resolution/resolvelib/resolver.py
index 47bbfecce..d5b238608 100644
--- a/src/pip/_internal/resolution/resolvelib/resolver.py
+++ b/src/pip/_internal/resolution/resolvelib/resolver.py
@@ -159,6 +159,9 @@ class Resolver(BaseResolver):
 
         reqs = req_set.all_requirements
         self.factory.preparer.prepare_linked_requirements_more(reqs)
+        for req in reqs:
+            req.prepared = True
+            req.needs_more_preparation = False
         return req_set
 
     def get_installation_order(","['src/pip/_internal/commands/download.py', 'src/pip/_internal/commands/wheel.py', 'src/pip/_internal/resolution/resolvelib/resolver.py']",{'.py': 3},3,0,0,3,3,5900636,1804968,181693,492,542,92,12,3,3735,275,1150,76,6,4,2023-07-11 18:59:40,8881,Python,"{'Python': 7286526, 'HTML': 3137, 'PowerShell': 2137, 'Jinja': 589}",MIT License,"['src/pip/_internal/req/req_install.py', 'src/pip/_internal/cli/base_command.py', 'src/pip/_internal/req/req_set.py', 'src/pip/_internal/cli/req_command.py', 'src/pip/_internal/commands/download.py']","['src/pip/_internal/req/req_install.py', 'src/pip/_internal/cli/base_command.py', 'src/pip/_internal/req/req_set.py', 'src/pip/_internal/cli/req_command.py', 'src/pip/_internal/commands/download.py']","['```json\n{\n  ""files"": [\n    ""src/pip/_internal/req/req_install.py"",\n    ""src/pip/_internal/req/req_set.py"",\n    ""src/pip/_internal/commands/download.py"",\n    ""src/pip/_internal/cli/req_command.py"",\n    ""src/pip/_internal/cli/base_command.py""\n  ]\n}\n```']",1,1553.3561706542969
7297,modin-project/modin/1657/1656,modin-project,modin,https://github.com/modin-project/modin/issues/1656,https://github.com/modin-project/modin/pull/1657,https://github.com/modin-project/modin/pull/1657,1,resolves,DataFrame.apply fails with function passed as string and added function parameters,"### System information
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04
- **Modin version** (`modin.__version__`): 0.7.3+153.g4f95b41
- **Python version**: 3.8.3
- **Code we can use to reproduce**:
```
import pandas
import modin.pandas as pd
import numpy as np

rows_number = 20

data = {""col1"": np.random.randint(0, 100, rows_number), ""col2"": np.random.randint(0, 100, rows_number)}
level_0 = np.random.choice([0, 1], rows_number)
level_1 = np.random.choice([2, 3], rows_number)
index = pd.MultiIndex.from_arrays([level_0, level_1])

func_kwargs = {""level"": 0}
df_modin = pd.DataFrame(data, index=index)
df_pandas = pandas.DataFrame(data, index=index)

pandas_output = df_pandas.apply(""count"", **func_kwargs)
print(""pandas_output:\\n"", pandas_output)

modin_output = df_modin.apply(""count"", **func_kwargs)
print(""modin_output:\\n"", modin_output)
```

### Describe the problem
Reproducer raises exception:
Traceback (most recent call last):
  File ""apply_reproducer.py"", line 19, in <module>
    modin_output = df_modin.apply(""count"", **func_kwargs)
  File ""/modin/modin/pandas/dataframe.py"", line 375, in apply
    if axis == 0 and result.name == self.index[0]:
ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()

### Source code / logs

",36695a7890f4c9325d4e681d51e0bdcf40801775,f7b9e00a46933fb888ce52d1d7701a6f5fe940bd,https://github.com/modin-project/modin/compare/36695a7890f4c9325d4e681d51e0bdcf40801775...f7b9e00a46933fb888ce52d1d7701a6f5fe940bd,"diff --git a/modin/backends/pandas/query_compiler.py b/modin/backends/pandas/query_compiler.py
index 0487e23a5..216ba62ef 100644
--- a/modin/backends/pandas/query_compiler.py
+++ b/modin/backends/pandas/query_compiler.py
@@ -1410,7 +1410,9 @@ class PandasQueryCompiler(BaseQueryCompiler):
         Returns:
             A new PandasQueryCompiler.
         """"""
-        if callable(func):
+        if isinstance(func, str):
+            return self._apply_text_func_elementwise(func, axis, *args, **kwargs)
+        elif callable(func):
             return self._callable_func(func, axis, *args, **kwargs)
         elif isinstance(func, dict):
             return self._dict_func(func, axis, *args, **kwargs)
@@ -1419,6 +1421,23 @@ class PandasQueryCompiler(BaseQueryCompiler):
         else:
             pass
 
+    def _apply_text_func_elementwise(self, func, axis, *args, **kwargs):
+        """"""Apply func passed as str across given axis in elementwise manner.
+
+        Args:
+            func: The function to apply.
+            axis: Target axis to apply the function along.
+
+        Returns:
+            A new PandasQueryCompiler.
+        """"""
+        assert isinstance(func, str)
+        kwargs[""axis""] = axis
+        new_modin_frame = self._modin_frame._apply_full_axis(
+            axis, lambda df: getattr(df, func)(**kwargs)
+        )
+        return self.__constructor__(new_modin_frame)
+
     def _dict_func(self, func, axis, *args, **kwargs):
         """"""Apply function to certain indices across given axis.
 
diff --git a/modin/pandas/base.py b/modin/pandas/base.py
index 14a03dd0a..6b1445ea5 100644
--- a/modin/pandas/base.py
+++ b/modin/pandas/base.py
@@ -577,10 +577,7 @@ class BasePandasDataset(object):
         axis = self._get_axis_number(axis)
         ErrorMessage.non_verified_udf()
         if isinstance(func, str):
-            if axis == 1:
-                kwds[""axis""] = axis
-            result = self._string_function(func, *args, **kwds)
-            # Sometimes we can return a scalar here
+            result = self._query_compiler.apply(func, axis=axis, *args, **kwds)
             if isinstance(result, BasePandasDataset):
                 return result._query_compiler
             return result
diff --git a/modin/pandas/dataframe.py b/modin/pandas/dataframe.py
index 0267195aa..4e851b497 100644
--- a/modin/pandas/dataframe.py
+++ b/modin/pandas/dataframe.py
@@ -360,7 +360,7 @@ class DataFrame(BasePandasDataset):
                 init_kwargs = {""columns"": self.columns}
             return_type = type(
                 getattr(pandas, self.__name__)(**init_kwargs).apply(
-                    func, axis=axis, raw=raw, result_type=result_type,
+                    func, axis=axis, raw=raw, result_type=result_type, args=args, **kwds
                 )
             ).__name__
         except Exception:
@@ -372,9 +372,9 @@ class DataFrame(BasePandasDataset):
                 query_compiler=query_compiler
             )
             if isinstance(result, Series):
-                if axis == 0 and result.name == self.index[0]:
+                if axis == 0 and result.name == self.index[0] or result.name == 0:
                     result.name = None
-                elif axis == 1 and result.name == self.columns[0]:
+                elif axis == 1 and result.name == self.columns[0] or result.name == 0:
                     result.name = None
             return result
 
diff --git a/modin/pandas/series.py b/modin/pandas/series.py
index fea7b6d72..22147f17b 100644
--- a/modin/pandas/series.py
+++ b/modin/pandas/series.py
@@ -493,9 +493,6 @@ class Series(BasePandasDataset):
             or return_type not in [""DataFrame"", ""Series""]
         ):
             query_compiler = super(Series, self).apply(func, *args, **kwds)
-            # Sometimes we can return a scalar here
-            if not isinstance(query_compiler, type(self._query_compiler)):
-                return query_compiler
         else:
             # handle ufuncs and lambdas
             if kwds or args and not isinstance(func, np.ufunc):
diff --git a/modin/pandas/test/test_dataframe.py b/modin/pandas/test/test_dataframe.py
index cdec8d5d5..e8d81c010 100644
--- a/modin/pandas/test/test_dataframe.py
+++ b/modin/pandas/test/test_dataframe.py
@@ -1727,6 +1727,24 @@ class TestDataFrameUDF:
             modin_result = modin_df.apply(func, axis)
             df_equals(modin_result, pandas_result)
 
+    @pytest.mark.parametrize(""axis"", [0, 1])
+    @pytest.mark.parametrize(""level"", [None, -1, 0, 1])
+    @pytest.mark.parametrize(""data"", test_data_values, ids=test_data_keys)
+    @pytest.mark.parametrize(""func"", [""count"", ""sum"", ""mean"", ""all"", ""kurt""])
+    def test_apply_text_func_with_level(self, level, data, func, axis):
+        func_kwargs = {""level"": level, ""axis"": axis}
+        rows_number = len(next(iter(data.values())))  # length of the first data column
+        level_0 = np.random.choice([0, 1, 2], rows_number)
+        level_1 = np.random.choice([3, 4, 5], rows_number)
+        index = pd.MultiIndex.from_arrays([level_0, level_1])
+
+        eval_general(
+            pd.DataFrame(data, index=index),
+            pandas.DataFrame(data, index=index),
+            lambda df, *args, **kwargs: df.apply(func, *args, **kwargs),
+            **func_kwargs,
+        )
+
     @pytest.mark.parametrize(""data"", test_data_values, ids=test_data_keys)
     @pytest.mark.parametrize(""axis"", axis_values, ids=axis_keys)
     def test_apply_args(self, data, axis):","['modin/pandas/dataframe.py', 'modin/backends/pandas/query_compiler.py', 'modin/pandas/test/test_dataframe.py', 'modin/pandas/base.py', 'modin/pandas/series.py']",{'.py': 5},5,0,0,5,5,957403,204274,26612,136,1670,369,35,4,1362,153,388,40,0,1,2020-06-24 16:42:11,8878,Python,"{'Python': 4474931, 'Shell': 2377, 'Dockerfile': 2330, 'JavaScript': 329}",Apache License 2.0,"['modin/pandas/dataframe.py', 'modin/data_management/functions/mapfunction.py', 'modin/data_management/functions/function.py']","['modin/pandas/dataframe.py', 'modin/data_management/functions/mapfunction.py', 'modin/data_management/functions/function.py']","['```json\n{\n  ""files"": [\n    ""modin/pandas/dataframe.py"",\n    ""modin/data_management/functions/mapfunction.py"",\n    ""modin/data_management/functions/function.py""\n  ]\n}\n```']",1,888.0791664123535
10191,dagger/dagger/3814/3813,dagger,dagger,https://github.com/dagger/dagger/issues/3813,https://github.com/dagger/dagger/pull/3814,https://github.com/dagger/dagger/pull/3814,1,fixes,🐞 Python SDK fails on Windows when trying to get the platform,"### What is the issue?

When trying to run the example for the Dagger Python SDK on Windows I am getting the error: `AttributeError: module 'os' has no attribute 'uname'`
Link to the place in the code: https://github.com/dagger/dagger/blob/main/sdk/python/src/dagger/connectors/docker.py#L26

I guess this is only related to Windows as it looks like this function is not present there.

### Log output

```
C:\\Users\\amuller20\\Miniconda3\\envs\\dagger-sdk\\python.exe C:\\Users\\amuller20\\PycharmProjects\\dagger-sdk\\main.py ""Simple is better than complex"" 
Traceback (most recent call last):
  File ""C:\\Users\\amuller20\\PycharmProjects\\dagger-sdk\\main.py"", line 38, in <module>
    anyio.run(main, sys.argv[1:])
  File ""C:\\Users\\amuller20\\Miniconda3\\envs\\dagger-sdk\\lib\\site-packages\\anyio\\_core\\_eventloop.py"", line 70, in run
    return asynclib.run(func, *args, **backend_options)
  File ""C:\\Users\\amuller20\\Miniconda3\\envs\\dagger-sdk\\lib\\site-packages\\anyio\\_backends\\_asyncio.py"", line 292, in run
    return native_run(wrapper(), debug=debug)
  File ""C:\\Users\\amuller20\\Miniconda3\\envs\\dagger-sdk\\lib\\asyncio\\runners.py"", line 44, in run
    return loop.run_until_complete(main)
  File ""C:\\Users\\amuller20\\Miniconda3\\envs\\dagger-sdk\\lib\\asyncio\\base_events.py"", line 646, in run_until_complete
    return future.result()
  File ""C:\\Users\\amuller20\\Miniconda3\\envs\\dagger-sdk\\lib\\site-packages\\anyio\\_backends\\_asyncio.py"", line 287, in wrapper
    return await func(*args)
  File ""C:\\Users\\amuller20\\PycharmProjects\\dagger-sdk\\main.py"", line 20, in main
    async with dagger.Connection() as client:
  File ""C:\\Users\\amuller20\\Miniconda3\\envs\\dagger-sdk\\lib\\site-packages\\dagger\\connection.py"", line 39, in __aenter__
    return await self.connector.connect()
  File ""C:\\Users\\amuller20\\Miniconda3\\envs\\dagger-sdk\\lib\\site-packages\\dagger\\connectors\\docker.py"", line 168, in connect
    await anyio.to_thread.run_sync(self.provision_sync)
  File ""C:\\Users\\amuller20\\Miniconda3\\envs\\dagger-sdk\\lib\\site-packages\\anyio\\to_thread.py"", line 31, in run_sync
    return await get_asynclib().run_sync_in_worker_thread(
  File ""C:\\Users\\amuller20\\Miniconda3\\envs\\dagger-sdk\\lib\\site-packages\\anyio\\_backends\\_asyncio.py"", line 937, in run_sync_in_worker_thread
    return await future
  File ""C:\\Users\\amuller20\\Miniconda3\\envs\\dagger-sdk\\lib\\site-packages\\anyio\\_backends\\_asyncio.py"", line 867, in run
    result = context.run(func, *args)
  File ""C:\\Users\\amuller20\\Miniconda3\\envs\\dagger-sdk\\lib\\site-packages\\dagger\\connectors\\docker.py"", line 184, in provision_sync
    self.engine.start()
  File ""C:\\Users\\amuller20\\Miniconda3\\envs\\dagger-sdk\\lib\\site-packages\\dagger\\connectors\\docker.py"", line 61, in start
    os_, arch = get_platform()
  File ""C:\\Users\\amuller20\\Miniconda3\\envs\\dagger-sdk\\lib\\site-packages\\dagger\\connectors\\docker.py"", line 26, in get_platform
    uname = os.uname()
AttributeError: module 'os' has no attribute 'uname'

Process finished with exit code 1
```

### Steps to reproduce

Create virtual environment with Python 3.10 and install dagger SDK
Run one of the Dagger samples (e.g. https://github.com/helderco/dagger-examples/blob/main/say.py)

### Dagger version

dagger SDK 0.1.1

### OS version

Windows 10",f74509711b55a10a4240c27a0f076cbd52965b32,a321f59b3a19c4d474df94793ba36eb1d7c0e78f,https://github.com/dagger/dagger/compare/f74509711b55a10a4240c27a0f076cbd52965b32...a321f59b3a19c4d474df94793ba36eb1d7c0e78f,"diff --git a/sdk/python/src/dagger/connectors/docker.py b/sdk/python/src/dagger/connectors/docker.py
index efaa4c80..eb06c3c1 100644
--- a/sdk/python/src/dagger/connectors/docker.py
+++ b/sdk/python/src/dagger/connectors/docker.py
@@ -1,5 +1,6 @@
 import logging
 import os
+import platform
 import subprocess
 import tempfile
 from pathlib import Path
@@ -23,11 +24,11 @@ def get_platform() -> tuple[str, str]:
         ""x86_64"": ""amd64"",
         ""aarch64"": ""arm64"",
     }
-    uname = os.uname()
-    os_ = uname.sysname.lower()
+    uname = platform.uname()
+    os_name = uname.system.lower()
     arch = uname.machine.lower()
     arch = normalized_arch.get(arch, arch)
-    return os_, arch
+    return os_name, arch
 
 
 class ImageRef:",['sdk/python/src/dagger/connectors/docker.py'],{'.py': 1},1,0,0,1,1,108218,24308,3593,27,187,47,7,1,3293,253,1005,59,2,1,2022-11-14 17:02:39,8746,Go,"{'Go': 1114633, 'Rust': 226105, 'Elixir': 155452, 'Python': 141082, 'TypeScript': 64367, 'JavaScript': 42602, 'SCSS': 34141, 'C#': 16461, 'Groovy': 13912, 'HTML': 12047, 'CSS': 7489, 'Handlebars': 6419, 'Dockerfile': 688, 'Shell': 630}",Apache License 2.0,['sdk/python/src/dagger/connectors/docker.py'],['sdk/python/src/dagger/connectors/docker.py'],"['```json\n{\n  ""files"": [\n    ""sdk/python/src/dagger/connectors/docker.py""\n  ]\n}\n```']",1,749.6850490570068
9034,paddlepaddle/paddlespeech/1432/1426,paddlepaddle,paddlespeech,https://github.com/PaddlePaddle/PaddleSpeech/issues/1426,https://github.com/PaddlePaddle/PaddleSpeech/pull/1432,https://github.com/PaddlePaddle/PaddleSpeech/pull/1432,1,fix,TypeError: resample() takes 1 positional argument but 3 were given,"ENV
Ubuntu 18.04.6 LTS
paddleaudio               0.1.0                    pypi_0    pypi
paddlenlp                 2.2.4                    pypi_0    pypi
paddlepaddle              2.2.2                    pypi_0    pypi
paddlespeech              0.1.1                    pypi_0    pypi
paddlespeech-ctcdecoders  0.1.1                    pypi_0    pypi
paddlespeech-feat         0.1.0                    pypi_0    pypi

I dont know why the same code and env can run on another server.


[2022-02-08 16:25:19,939] [   ERROR] - resample() takes 1 positional argument but 3 were given
Traceback (most recent call last):
  File ""/home/tianrking/anaconda3/envs/fastapi/lib/python3.7/site-packages/paddlespeech/cli/asr/infer.py"", line 414, in execute
    decode_method, force_yes, device)
  File ""/home/tianrking/anaconda3/envs/fastapi/lib/python3.7/site-packages/paddlespeech/cli/utils.py"", line 335, in _warpper
    return executor_func(self, *args, **kwargs)
  File ""/home/tianrking/anaconda3/envs/fastapi/lib/python3.7/site-packages/paddlespeech/cli/asr/infer.py"", line 439, in __call__
    self.preprocess(model, audio_file)
  File ""/home/tianrking/anaconda3/envs/fastapi/lib/python3.7/site-packages/paddlespeech/cli/asr/infer.py"", line 256, in preprocess
    self.sample_rate)
TypeError: resample() takes 1 positional argument but 3 were given


",e0280ff9495aa56e79db04f6e39bd268c9795ff1,9a55783aa0821a454b14feb3fa17b6bd5c8d9d44,https://github.com/paddlepaddle/paddlespeech/compare/e0280ff9495aa56e79db04f6e39bd268c9795ff1...9a55783aa0821a454b14feb3fa17b6bd5c8d9d44,"diff --git a/paddlespeech/cli/asr/infer.py b/paddlespeech/cli/asr/infer.py
index 6e14e0d6..ef769fbc 100644
--- a/paddlespeech/cli/asr/infer.py
+++ b/paddlespeech/cli/asr/infer.py
@@ -311,8 +311,10 @@ class ASRExecutor(BaseExecutor):
                     audio = audio[:, 0]
                 # pcm16 -> pcm 32
                 audio = self._pcm16to32(audio)
-                audio = librosa.resample(audio, audio_sample_rate,
-                                         self.sample_rate)
+                audio = librosa.resample(
+                    audio,
+                    orig_sr=audio_sample_rate,
+                    target_sr=self.sample_rate)
                 audio_sample_rate = self.sample_rate
                 # pcm32 -> pcm 16
                 audio = self._pcm32to16(audio)
diff --git a/paddlespeech/s2t/transform/perturb.py b/paddlespeech/s2t/transform/perturb.py
index 226885f3..9e41b824 100644
--- a/paddlespeech/s2t/transform/perturb.py
+++ b/paddlespeech/s2t/transform/perturb.py
@@ -90,7 +90,8 @@ class SpeedPerturbation():
 
         # Note1: resample requires the sampling-rate of input and output,
         #        but actually only the ratio is used.
-        y = librosa.resample(x, ratio, 1, res_type=self.res_type)
+        y = librosa.resample(
+            x, orig_sr=ratio, target_sr=1, res_type=self.res_type)
 
         if self.keep_length:
             diff = abs(len(x) - len(y))
diff --git a/paddlespeech/s2t/transform/spectrogram.py b/paddlespeech/s2t/transform/spectrogram.py
index a6346c34..988fd627 100644
--- a/paddlespeech/s2t/transform/spectrogram.py
+++ b/paddlespeech/s2t/transform/spectrogram.py
@@ -38,7 +38,7 @@ def stft(x,
     x = np.stack(
         [
             librosa.stft(
-                x[:, ch],
+                y=x[:, ch],
                 n_fft=n_fft,
                 hop_length=n_shift,
                 win_length=win_length,
@@ -67,7 +67,7 @@ def istft(x, n_shift, win_length=None, window=""hann"", center=True):
     x = np.stack(
         [
             librosa.istft(
-                x[:, ch].T,  # [Time, Freq] -> [Freq, Time]
+                y=x[:, ch].T,  # [Time, Freq] -> [Freq, Time]
                 hop_length=n_shift,
                 win_length=win_length,
                 window=window,
@@ -95,7 +95,8 @@ def stft2logmelspectrogram(x_stft,
     # spc: (Time, Channel, Freq) or (Time, Freq)
     spc = np.abs(x_stft)
     # mel_basis: (Mel_freq, Freq)
-    mel_basis = librosa.filters.mel(fs, n_fft, n_mels, fmin, fmax)
+    mel_basis = librosa.filters.mel(
+        sr=fs, n_fft=n_fft, n_mels=n_mels, fmin=fmin, fmax=fmax)
     # lmspc: (Time, Channel, Mel_freq) or (Time, Mel_freq)
     lmspc = np.log10(np.maximum(eps, np.dot(spc, mel_basis.T)))
 
diff --git a/paddlespeech/vector/exps/ge2e/audio_processor.py b/paddlespeech/vector/exps/ge2e/audio_processor.py
index 2d6bbe34..1ab0419e 100644
--- a/paddlespeech/vector/exps/ge2e/audio_processor.py
+++ b/paddlespeech/vector/exps/ge2e/audio_processor.py
@@ -127,7 +127,7 @@ def compute_partial_slices(n_samples: int,
     partial_utterance_n_frames : int
         the number of mel spectrogram frames in each partial utterance.
 
-    min_pad_coverage : int 
+    min_pad_coverage : int
         when reaching the last partial utterance, it may or may not have enough frames.
         If at least <min_pad_coverage> of <partial_utterance_n_frames> are present,
         then the last partial utterance will be considered, as if we padded the audio. Otherwise,
@@ -137,7 +137,7 @@ def compute_partial_slices(n_samples: int,
         by how much the partial utterance should overlap. If set to 0, the partial utterances are entirely disjoint.
     Returns
     ----------
-        the waveform slices and mel spectrogram slices as lists of array slices. 
+        the waveform slices and mel spectrogram slices as lists of array slices.
         Index respectively the waveform and the mel spectrogram with these slices to obtain the partialutterances.
     """"""
     assert 0 <= overlap < 1
@@ -206,7 +206,8 @@ class SpeakerVerificationPreprocessor(object):
 
         # Resample if numpy.array is passed and sr does not match
         if source_sr is not None and source_sr != self.sampling_rate:
-            wav = librosa.resample(wav, source_sr, self.sampling_rate)
+            wav = librosa.resample(
+                wav, orig_sr=source_sr, target_sr=self.sampling_rate)
 
         # loudness normalization
         wav = normalize_volume(
@@ -221,7 +222,7 @@ class SpeakerVerificationPreprocessor(object):
 
     def melspectrogram(self, wav):
         mel = librosa.feature.melspectrogram(
-            wav,
+            y=wav,
             sr=self.sampling_rate,
             n_fft=self.n_fft,
             hop_length=self.hop_length,","['paddlespeech/cli/asr/infer.py', 'paddlespeech/vector/exps/ge2e/audio_processor.py', 'paddlespeech/s2t/transform/perturb.py', 'paddlespeech/s2t/transform/spectrogram.py']",{'.py': 4},4,0,0,4,4,2936364,730562,81646,538,1250,301,25,4,1371,105,411,26,0,0,2022-02-09 09:49:19,8234,Python,"{'Python': 6020568, 'C++': 2010563, 'Shell': 238337, 'Perl': 168700, 'C': 99959, 'CMake': 73990, 'Java': 21998, 'Dockerfile': 6444, 'Jupyter Notebook': 4203, 'Makefile': 3395, 'Cython': 2067, 'Kotlin': 1480, 'Starlark': 782}",Apache License 2.0,"['paddlespeech/cli/asr/__init__.py', 'paddlespeech/cli/asr/infer.py', 'paddlespeech/s2t/frontend/augmentor/resample.py', 'paddlespeech/cli/utils.py']","['paddlespeech/cli/asr/__init__.py', 'paddlespeech/cli/asr/infer.py', 'paddlespeech/s2t/frontend/augmentor/resample.py', 'paddlespeech/cli/utils.py']","['```json\n{\n  ""files"": [\n    ""paddlespeech/cli/asr/infer.py"",\n    ""paddlespeech/cli/utils.py"",\n    ""paddlespeech/cli/asr/__init__.py"",\n    ""paddlespeech/s2t/frontend/augmentor/resample.py""\n  ]\n}\n```']",1,1824.2731094360352
157,square/okhttp/1254/1158,square,okhttp,https://github.com/square/okhttp/issues/1158,https://github.com/square/okhttp/pull/1254,https://github.com/square/okhttp/pull/1254,1,closes,Should okhttp be caching HTTP 307 (or 302) responses according to the w3 document?,"I am using retrofit and okhttp in my Android app to download documents, images and music files. The files are hosted on Amazon through a CDN so the URLs change often. My backend server will try to use redirects to decrease the need to have to constantly update my content on my mobile app every time the CDN url changes. The devices should also cache responses in the case that the device is offline. For this reason, I am using 301 redirects, which I don't know is the best idea.

I was reading the description for 307 redirect at http://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html

---

10.3.8 307 Temporary Redirect

The requested resource resides temporarily under a different URI. 
Since the redirection MAY be altered on occasion, the client SHOULD 
continue to use the Request-URI for future requests. 
This response is only cacheable if indicated by a Cache-Control or Expires header field.

---

At http://www.w3.org/Protocols/rfc2616/rfc2616-sec13.html,

---

13.4 - Response Cacheability

A response received with a status code of 200, 203, 206, 300, 301 or 410 
MAY be stored by a cache and used in reply to a subsequent request, 
subject to the expiration mechanism, unless a cache-control directive 
prohibits caching. However, a cache that does not support the Range and 
Content-Range headers MUST NOT cache 206 (Partial Content) responses.

A response received with any other status code 
(e.g. status codes 302 and 307) MUST NOT be returned in a reply to 
a subsequent request unless there are cache-control directives or another 
header(s) that explicitly allow it. For example, these include the 
following: an Expires header (section 14.21); a ""max-age"", ""s-maxage"", 
""must- revalidate"", ""proxy-revalidate"", ""public"" or ""private"" 
cache-control directive (section 14.9).

---

It seems that the description states that caching is possible. I haven't tried this yet, but I did notice that in okhttp's CacheStrategy.java class, it has the following code:

---

public static boolean isCacheable(Response response, Request request) {
    // Always go to network for uncacheable response codes (RFC 2616, 13.4),
    // This implementation doesn't support caching partial content.
    int responseCode = response.code();
    if (responseCode != HttpURLConnection.HTTP_OK // 200
        && responseCode != HttpURLConnection.HTTP_NOT_AUTHORITATIVE // 203
        && responseCode != HttpURLConnection.HTTP_MULT_CHOICE // 300
        && responseCode != HttpURLConnection.HTTP_MOVED_PERM / 301
        && responseCode != HttpURLConnection.HTTP_GONE) { // 410
    return false;
}

---

And to verify that caching isn't enabled for from 302-308, the unit tests from CacheTest.java states the following

---

for (int i = 302; i <= 308; ++i) {
  assertCached(false, i);
}

---

So the okhttp code explicitly ignores caching for 307, and also 302. I just wanted clarification for this. Is the spec for 307 wrong? Or is something wrong with caching 307 that it was deliberately excluded? If I were to set my own cache headers for 307, it would seem to still be skipped.

Just another background information. I know Amazon will support caching with proper cache headers. But since I have to redirect through my own backend, if I don't have caching ability, my offline access to my redirect URL will not respond that I have a cached version from CDN locally. Of course, if I didn't redirect from my backend and go straight to Amazon, then caching wouldn't be a problem through Amazon. Could you provide some advice in this scenario?
",64f2af812bef505b6cbc1693aa8b504d9dbbb42e,1d6f0e75d599e2cb02f0fe182f7dbf966cd5cb2b,https://github.com/square/okhttp/compare/64f2af812bef505b6cbc1693aa8b504d9dbbb42e...1d6f0e75d599e2cb02f0fe182f7dbf966cd5cb2b,"diff --git a/okhttp-tests/src/test/java/com/squareup/okhttp/CacheTest.java b/okhttp-tests/src/test/java/com/squareup/okhttp/CacheTest.java
index 9fba4601c..0fd174648 100644
--- a/okhttp-tests/src/test/java/com/squareup/okhttp/CacheTest.java
+++ b/okhttp-tests/src/test/java/com/squareup/okhttp/CacheTest.java
@@ -121,9 +121,12 @@ public final class CacheTest {
     assertCached(false, 207);
     assertCached(true, 300);
     assertCached(true, 301);
-    for (int i = 302; i <= 307; ++i) {
-      assertCached(false, i);
-    }
+    assertCached(true, 302);
+    assertCached(false, 303);
+    assertCached(false, 304);
+    assertCached(false, 305);
+    assertCached(false, 306);
+    assertCached(true, 307);
     assertCached(true, 308);
     for (int i = 400; i <= 406; ++i) {
       assertCached(false, i);
@@ -394,6 +397,63 @@ public final class CacheTest {
     assertEquals(2, cache.getHitCount());
   }
 
+  @Test public void foundCachedWithExpiresHeader() throws Exception {
+    temporaryRedirectCachedWithCachingHeader(302, ""Expires"", formatDate(1, TimeUnit.HOURS));
+  }
+
+  @Test public void foundCachedWithCacheControlHeader() throws Exception {
+    temporaryRedirectCachedWithCachingHeader(302, ""Cache-Control"", ""max-age=60"");
+  }
+
+  @Test public void temporaryRedirectCachedWithExpiresHeader() throws Exception {
+    temporaryRedirectCachedWithCachingHeader(307, ""Expires"", formatDate(1, TimeUnit.HOURS));
+  }
+
+  @Test public void temporaryRedirectCachedWithCacheControlHeader() throws Exception {
+    temporaryRedirectCachedWithCachingHeader(307, ""Cache-Control"", ""max-age=60"");
+  }
+
+  @Test public void foundNotCachedWithoutCacheHeader() throws Exception {
+    temporaryRedirectNotCachedWithoutCachingHeader(302);
+  }
+
+  @Test public void temporaryRedirectNotCachedWithoutCacheHeader() throws Exception {
+    temporaryRedirectNotCachedWithoutCachingHeader(307);
+  }
+
+  private void temporaryRedirectCachedWithCachingHeader(
+      int responseCode, String headerName, String headerValue) throws Exception {
+    server.enqueue(new MockResponse()
+        .setResponseCode(responseCode)
+        .addHeader(headerName, headerValue)
+        .addHeader(""Location"", ""/a""));
+    server.enqueue(new MockResponse()
+        .addHeader(headerName, headerValue)
+        .setBody(""a""));
+    server.enqueue(new MockResponse()
+        .setBody(""b""));
+    server.enqueue(new MockResponse()
+        .setBody(""c""));
+
+    URL url = server.getUrl(""/"");
+    assertEquals(""a"", get(url).body().string());
+    assertEquals(""a"", get(url).body().string());
+  }
+
+  private void temporaryRedirectNotCachedWithoutCachingHeader(int responseCode) throws Exception {
+    server.enqueue(new MockResponse()
+        .setResponseCode(responseCode)
+        .addHeader(""Location"", ""/a""));
+    server.enqueue(new MockResponse()
+        .setBody(""a""));
+    server.enqueue(new MockResponse()
+        .setBody(""b""));
+
+    URL url = server.getUrl(""/"");
+    assertEquals(""a"", get(url).body().string());
+    assertEquals(""b"", get(url).body().string());
+  }
+
   @Test public void serverDisconnectsPrematurelyWithContentLengthHeader() throws IOException {
     testServerPrematureDisconnect(TransferKind.FIXED_LENGTH);
   }
diff --git a/okhttp-urlconnection/src/test/java/com/squareup/okhttp/UrlConnectionCacheTest.java b/okhttp-urlconnection/src/test/java/com/squareup/okhttp/UrlConnectionCacheTest.java
index 800124bdf..79d73f4ee 100644
--- a/okhttp-urlconnection/src/test/java/com/squareup/okhttp/UrlConnectionCacheTest.java
+++ b/okhttp-urlconnection/src/test/java/com/squareup/okhttp/UrlConnectionCacheTest.java
@@ -132,9 +132,12 @@ public final class UrlConnectionCacheTest {
     assertCached(false, 207);
     assertCached(true, 300);
     assertCached(true, 301);
-    for (int i = 302; i <= 307; ++i) {
-      assertCached(false, i);
-    }
+    assertCached(true, 302);
+    assertCached(false, 303);
+    assertCached(false, 304);
+    assertCached(false, 305);
+    assertCached(false, 306);
+    assertCached(true, 307);
     assertCached(true, 308);
     for (int i = 400; i <= 406; ++i) {
       assertCached(false, i);
@@ -158,12 +161,12 @@ public final class UrlConnectionCacheTest {
 
   private void assertCached(boolean shouldPut, int responseCode) throws Exception {
     server = new MockWebServer();
-    MockResponse response =
-        new MockResponse().addHeader(""Last-Modified: "" + formatDate(-1, TimeUnit.HOURS))
-            .addHeader(""Expires: "" + formatDate(1, TimeUnit.HOURS))
-            .setResponseCode(responseCode)
-            .setBody(""ABCDE"")
-            .addHeader(""WWW-Authenticate: challenge"");
+    MockResponse response = new MockResponse()
+        .addHeader(""Last-Modified: "" + formatDate(-1, TimeUnit.HOURS))
+        .addHeader(""Expires: "" + formatDate(1, TimeUnit.HOURS))
+        .setResponseCode(responseCode)
+        .setBody(""ABCDE"")
+        .addHeader(""WWW-Authenticate: challenge"");
     if (responseCode == HttpURLConnection.HTTP_PROXY_AUTH) {
       response.addHeader(""Proxy-Authenticate: Basic realm=\\""protected area\\"""");
     } else if (responseCode == HttpURLConnection.HTTP_UNAUTHORIZED) {
diff --git a/okhttp/src/main/java/com/squareup/okhttp/internal/http/CacheStrategy.java b/okhttp/src/main/java/com/squareup/okhttp/internal/http/CacheStrategy.java
index 93c6d7e6d..69db3947f 100644
--- a/okhttp/src/main/java/com/squareup/okhttp/internal/http/CacheStrategy.java
+++ b/okhttp/src/main/java/com/squareup/okhttp/internal/http/CacheStrategy.java
@@ -7,8 +7,10 @@ import com.squareup.okhttp.Response;
 import java.util.Date;
 
 import static com.squareup.okhttp.internal.http.StatusLine.HTTP_PERM_REDIRECT;
+import static com.squareup.okhttp.internal.http.StatusLine.HTTP_TEMP_REDIRECT;
 import static java.net.HttpURLConnection.HTTP_GONE;
 import static java.net.HttpURLConnection.HTTP_MOVED_PERM;
+import static java.net.HttpURLConnection.HTTP_MOVED_TEMP;
 import static java.net.HttpURLConnection.HTTP_MULT_CHOICE;
 import static java.net.HttpURLConnection.HTTP_NOT_AUTHORITATIVE;
 import static java.net.HttpURLConnection.HTTP_OK;
@@ -39,26 +41,36 @@ public final class CacheStrategy {
    * request.
    */
   public static boolean isCacheable(Response response, Request request) {
-    // Always go to network for uncacheable response codes (RFC 2616, 13.4),
+    // Always go to network for uncacheable response codes (RFC 7231 section 6.1),
     // This implementation doesn't support caching partial content.
-    int responseCode = response.code();
-    if (responseCode != HTTP_OK
-        && responseCode != HTTP_NOT_AUTHORITATIVE
-        && responseCode != HTTP_MULT_CHOICE
-        && responseCode != HTTP_MOVED_PERM
-        && responseCode != HTTP_GONE
-        && responseCode != HTTP_PERM_REDIRECT) {
-      return false;
-    }
+    switch (response.code()) {
+      case HTTP_OK:
+      case HTTP_NOT_AUTHORITATIVE:
+      case HTTP_MULT_CHOICE:
+      case HTTP_MOVED_PERM:
+      case HTTP_GONE:
+      case HTTP_PERM_REDIRECT:
+        // These codes can be cached unless headers forbid it.
+        break;
+
+      case HTTP_MOVED_TEMP:
+      case HTTP_TEMP_REDIRECT:
+        // These codes can only be cached with the right response headers.
+        if (response.header(""Expires"") != null
+            || response.cacheControl().maxAgeSeconds() != -1
+            || response.cacheControl().sMaxAgeSeconds() != -1
+            || response.cacheControl().isPublic()) {
+          break;
+        }
+        // Fall-through.
 
-    // A 'no-store' directive on request or response prevents the response from being cached.
-    CacheControl responseCaching = response.cacheControl();
-    CacheControl requestCaching = request.cacheControl();
-    if (responseCaching.noStore() || requestCaching.noStore()) {
-      return false;
+      default:
+        // All other codes cannot be cached.
+        return false;
     }
 
-    return true;
+    // A 'no-store' directive on request or response prevents the response from being cached.
+    return !response.cacheControl().noStore() && !request.cacheControl().noStore();
   }
 
   public static class Factory {","['okhttp/src/main/java/com/squareup/okhttp/internal/http/CacheStrategy.java', 'okhttp-urlconnection/src/test/java/com/squareup/okhttp/UrlConnectionCacheTest.java', 'okhttp-tests/src/test/java/com/squareup/okhttp/CacheTest.java']",{'.java': 3},3,3,0,0,3,875001,202735,24643,132,1919,416,44,1,3541,539,802,69,2,0,2014-12-29 22:54:57,44252,Kotlin,"{'Kotlin': 3059143, 'Java': 744989, 'Shell': 2995}",Apache License 2.0,"['okhttp/src/main/java/com/squareup/okhttp/internal/http/OkHeaders.java', 'okhttp/src/main/java/com/squareup/okhttp/Request.java', 'okhttp/src/main/java/com/squareup/okhttp/internal/http/CacheStrategy.java', 'okhttp/src/main/java/com/squareup/okhttp/OkHttpClient.java', 'okhttp/src/main/java/com/squareup/okhttp/internal/http/HttpEngine.java']","['okhttp/src/main/java/com/squareup/okhttp/internal/http/OkHeaders.java', 'okhttp/src/main/java/com/squareup/okhttp/Request.java', 'okhttp/src/main/java/com/squareup/okhttp/internal/http/CacheStrategy.java', 'okhttp/src/main/java/com/squareup/okhttp/OkHttpClient.java', 'okhttp/src/main/java/com/squareup/okhttp/internal/http/HttpEngine.java']","['```json\n{\n  ""files"": [\n    ""okhttp/src/main/java/com/squareup/okhttp/internal/http/CacheStrategy.java"",\n    ""okhttp/src/main/java/com/squareup/okhttp/internal/http/OkHeaders.java"",\n    ""okhttp/src/main/java/com/squareup/okhttp/internal/http/HttpEngine.java"",\n    ""okhttp/src/main/java/com/squareup/okhttp/OkHttpClient.java"",\n    ""okhttp/src/main/java/com/squareup/okhttp/Request.java""\n  ]\n}\n```']",1,1992.1224117279053
688,dbeaver/dbeaver/12766/12765,dbeaver,dbeaver,https://github.com/dbeaver/dbeaver/issues/12765,https://github.com/dbeaver/dbeaver/pull/12766,https://github.com/dbeaver/dbeaver/pull/12766,1,fix,SqlServer FK between two schemas doesn't show on UI,"<!--
Thank you for reporting an issue.

*IMPORTANT* -  *before* creating a new issue please look around:
 - DBeaver documentation: https://github.com/dbeaver/dbeaver/wiki
 and
 - open issues in Github tracker: https://github.com/dbeaver/dbeaver/issues
  
If you cannot find a similar problem, then create a new issue. Short tips about new issues can be found here: https://github.com/dbeaver/dbeaver/wiki/Posting-issues

Please, do not create issue duplicates. If you find the same or similar issue, just add a comment or vote for this feature. It helps us to track the most popular requests and fix them faster.

Please fill in as much of the template as possible.
-->

#### System information: 
- Operating system: **Windows 10 Version 21H1 Build 19043.1023**
- DBeaver version **21.1.0.202105300349** Community
- Additional extensions 
  DBeaver Git support	1.0.46.202106012023	org.jkiss.dbeaver.git.feature.feature.group	DBeaver Corp
  DevStyle (includes Darkest Dark Theme)	1.11.0.202105260439	com.genuitec.eclipse.theming.core.feature.feature.group	Genuitec, LLC

#### Connection specification:
- Database name and version: **SqlServer Express Microsoft SQL Server 2017 (RTM-GDR) (KB4583456) - 14.0.2037.2 (X64)   Nov  2 2020 19:19:59   Copyright (C) 2017 Microsoft Corporation  Express Edition (64-bit) on Windows 10 Pro 10.0 <X64> (Build 19043: ) (Hypervisor)**
- Driver name **SQL Server**
- Do you use tunnels or proxies (SSH, SOCKS, etc)?  **No**

#### Describe the problem you're observing:
Creating foreign keys between two tables on two different schemas via UI or SQL Script does not show it on Foreign Keys Tab/SubGroup neither on the DDL source tab.

#### Steps to reproduce, if exist:
1. Create a SQL Server database 
2. Create two schemas
3. Create TableOne on schema1
4. Create TableTwo on schema2
5. Create FK from TableTwo to TableOne
6. If you create FK with UI from the Foreign Keys tab when click persist the FK disappear (but is still present on DB)
7. Execute the query `select * from sys.objects` to verify that the object is successfully created
",63aee4269a199deb69359f4913055615619a7666,0e820df3b91ff92f3c37db90335d30703afde0fd,https://github.com/dbeaver/dbeaver/compare/63aee4269a199deb69359f4913055615619a7666...0e820df3b91ff92f3c37db90335d30703afde0fd,"diff --git a/plugins/org.jkiss.dbeaver.ext.mssql/src/org/jkiss/dbeaver/ext/mssql/model/SQLServerSchema.java b/plugins/org.jkiss.dbeaver.ext.mssql/src/org/jkiss/dbeaver/ext/mssql/model/SQLServerSchema.java
index dac1924bb9..e41e19e4ef 100644
--- a/plugins/org.jkiss.dbeaver.ext.mssql/src/org/jkiss/dbeaver/ext/mssql/model/SQLServerSchema.java
+++ b/plugins/org.jkiss.dbeaver.ext.mssql/src/org/jkiss/dbeaver/ext/mssql/model/SQLServerSchema.java
@@ -216,10 +216,22 @@ public class SQLServerSchema implements DBSSchema, DBPSaveableObject, DBPQualifi
         return tableCache.getTypedObjects(monitor, this, SQLServerTable.class);
     }
 
+    @Nullable
     public SQLServerTableBase getTable(DBRProgressMonitor monitor, String name) throws DBException {
         return tableCache.getObject(monitor, this, name);
     }
 
+    @Nullable
+    public SQLServerTable getTable(DBRProgressMonitor monitor, long tableId) throws DBException {
+        for (SQLServerTableBase table : tableCache.getAllObjects(monitor, this)) {
+            if (table.getObjectId() == tableId && table instanceof SQLServerTable) {
+                return (SQLServerTable) table;
+            }
+        }
+        log.debug(""Table '"" + tableId + ""' not found in schema "" + getName());
+        return null;
+    }
+
     @Association
     public Collection<SQLServerView> getViews(DBRProgressMonitor monitor) throws DBException {
         return tableCache.getTypedObjects(monitor, this, SQLServerView.class);
@@ -659,7 +671,7 @@ public class SQLServerSchema implements DBSSchema, DBPSaveableObject, DBPQualifi
                 return null;
             }
             long refTableId = JDBCUtils.safeGetLong(dbResult, ""referenced_object_id"");
-            SQLServerTable refTable = getTable(monitor, refTableId);
+            SQLServerTable refTable = refSchema.getTable(monitor, refTableId);
             if (refTable == null) {
                 log.debug(""Ref table "" + refTableId + "" not found in schema "" + refSchema.getName());
                 return null;
@@ -684,17 +696,6 @@ public class SQLServerSchema implements DBSSchema, DBPSaveableObject, DBPQualifi
             return new SQLServerTableForeignKey(parent, fkName, null, refConstraint, deleteRule, updateRule, true);
         }
 
-        @Nullable
-        private SQLServerTable getTable(DBRProgressMonitor monitor, long tableId) throws DBException {
-            for (SQLServerTableBase table: tableCache.getAllObjects(monitor, SQLServerSchema.this)) {
-                if (table.getObjectId() == tableId && table instanceof SQLServerTable) {
-                    return (SQLServerTable) table;
-                }
-            }
-            log.debug(""Table '"" + tableId + ""' not found in schema "" + getName());
-            return null;
-        }
-
         @Nullable
         @Override
         protected SQLServerTableForeignKeyColumn[] fetchObjectRow(",['plugins/org.jkiss.dbeaver.ext.mssql/src/org/jkiss/dbeaver/ext/mssql/model/SQLServerSchema.java'],{'.java': 1},1,1,0,0,1,21252088,4358670,579957,4152,1158,240,25,1,2113,299,550,39,3,0,2021-06-07 21:56:46,33177,Java,"{'Java': 26145871, 'JavaScript': 139972, 'C++': 63113, 'ANTLR': 29768, 'CSS': 20674, 'HTML': 12246, 'XSLT': 8047, 'Batchfile': 2891, 'Shell': 202}",Apache License 2.0,"['plugins/org.jkiss.dbeaver.model/src/org/jkiss/dbeaver/model/navigator/DBNContainer.java', 'plugins/org.jkiss.dbeaver.ui.editors.base/src/org/jkiss/dbeaver/ui/editors/DatabaseEditorUtils.java', 'plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/SQLEditorContributions.java', 'plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/SQLEditorCommands.java', 'plugins/org.jkiss.dbeaver.ext.mssql.ui/src/org/jkiss/dbeaver/ext/mssql/ui/SQLServerTableManager.java', 'plugins/org.jkiss.dbeaver.ext.mssql/src/org/jkiss/dbeaver/ext/mssql/edit/SQLServerTableManager.java', 'plugins/org.jkiss.dbeaver.ext.mssql/src/org/jkiss/dbeaver/ext/mssql/edit/SQLServerTableTypeManager.java', 'plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/plan/simple/SQLPlanTreeViewer.java', 'plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/handlers/SQLEditorHandlerAssistTemplates.java', 'plugins/org.jkiss.dbeaver.ext.postgresql/src/org/jkiss/dbeaver/ext/postgresql/model/PostgreTableConstraint.java', 'plugins/org.jkiss.dbeaver.ext.db2.ui/src/org/jkiss/dbeaver/ext/db2/ui/config/DB2UniqueKeyConfigurator.java', 'plugins/org.jkiss.dbeaver.ext.db2.ui/src/org/jkiss/dbeaver/ext/db2/ui/config/DB2TablespaceChooser.java', 'plugins/org.jkiss.dbeaver.model/src/org/jkiss/dbeaver/model/sql/SQLSearchUtils.java', 'plugins/org.jkiss.dbeaver.model/src/org/jkiss/dbeaver/registry/DataSourceRegistry.java', 'plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/plan/simple/PlanNodesTree.java', 'plugins/org.jkiss.dbeaver.ext.generic/model/GenericTableColumn.java', 'plugins/org.jkiss.dbeaver.ui.editors.data/src/org/jkiss/dbeaver/ui/controls/resultset/ResultSetDataReceiver.java', 'plugins/org.jkiss.dbeaver.model.sql/src/org/jkiss/dbeaver/model/sql/parser/SQLWordPartDetector.java', 'plugins/org.jkiss.dbeaver.model/src/org/jkiss/dbeaver/model/navigator/DBNDatabaseNode.java', 'plugins/org.jkiss.dbeaver.model/src/org/jkiss/dbeaver/model/navigator/DBNNode.java', 'plugins/org.jkiss.dbeaver.ui.dialogs/connection/ConnectionWizardPage.java', 'plugins/org.jkiss.dbeaver.ui.dialogs/connection/EditConnectionDialog.java', 'plugins/org.jkiss.dbeaver.model/src/org/jkiss/dbeaver/model/navigator/DBNDatabaseItem.java', 'plugins/org.jkiss.dbeaver.ui.editors.base/src/org/jkiss/dbeaver/ui/editors/DatabaseEditorListener.java', 'plugins/org.jkiss.dbeaver.model.sql/src/org/jkiss/dbeaver/model/sql/parser/SQLParserContext.java', 'plugins/org.jkiss.dbeaver.model/src/org/jkiss/dbeaver/model/sql/SQLModelPreferences.java', 'plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/commands/OpenLinkInWindowHandler.java', 'plugins/org.jkiss.dbeaver.ui.dialogs/connection/NewConnectionWizard.java', 'plugins/org.jkiss.dbeaver.ext.generic/model/GenericTable.java', 'plugins/org.jkiss.dbeaver.ui.editors.data/src/org/jkiss/dbeaver/ui/controls/resultset/ResultSetFilterContentAdapter.java', 'plugins/org.jkiss.dbeaver.ui.editors.data/src/org/jkiss/dbeaver/ui/controls/resultset/view/PlainTextPresentation.java', 'plugins/org.jkiss.dbeaver.debug.core/src/org/jkiss/dbeaver/debug/core/model/DatabaseProcess.java', 'plugins/org.jkiss.dbeaver.ext.db2.ui/src/org/jkiss/dbeaver/ext/db2/ui/config/DB2SchemaConfigurator.java', 'plugins/org.jkiss.dbeaver.ext.postgresql/src/org/jkiss/dbeaver/ext/postgresql/model/plan/PostgreQueryPlaner.java', 'plugins/org.jkiss.dbeaver.debug.core/src/org/jkiss/dbeaver/debug/core/model/DatabaseVariable.java', 'plugins/org.jkiss.dbeaver.ext.postgresql/src/org/jkiss/dbeaver/ext/postgresql/edit/PostgreTableManager.java', 'plugins/org.jkiss.dbeaver.ext.postgresql/src/org/jkiss/dbeaver/ext/postgresql/model/PostgreTable.java', 'plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/preferences/format/SQLExternalFormatterConfigurationPage.java', 'plugins/org.jkiss.dbeaver.debug.core/src/org/jkiss/dbeaver/debug/core/model/DatabaseThread.java', 'plugins/org.jkiss.dbeaver.ext.generic/model/GenericTableForeignKey.java', 'plugins/org.jkiss.dbeaver.model.sql/src/org/jkiss/dbeaver/model/sql/parser/SQLRuleManager.java', 'plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/SQLEditor.java', 'plugins/org.jkiss.dbeaver.ext.generic/edit/GenericTableManager.java', 'plugins/org.jkiss.dbeaver.ext.postgresql/src/org/jkiss/dbeaver/ext/postgresql/model/plan/PostgreExecutionPlan.java', 'plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/plan/registry/SQLPlanViewRegistry.java', 'plugins/org.jkiss.dbeaver.ext.mssql.ui/src/org/jkiss/dbeaver/ext/mssql/ui/config/SQLServerDatabaseConfigurator.java', 'plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/handlers/SQLEditorHandlerNavigateQuery.java', 'plugins/org.jkiss.dbeaver.ext.generic/edit/GenericForeignKeyManager.java', 'plugins/org.jkiss.dbeaver.ext.mssql.ui/src/org/jkiss/dbeaver/ext/mssql/ui/config/SQLServerForeignKeyConfigurator.java', 'plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/SQLEditorContributor.java', 'plugins/org.jkiss.dbeaver.ext.postgresql/src/org/jkiss/dbeaver/ext/postgresql/model/plan/PostgrePlanNodeBase.java', 'plugins/org.jkiss.dbeaver.ui.editors.data/src/org/jkiss/dbeaver/ui/controls/resultset/view/ErrorDetailsPart.java', 'plugins/org.jkiss.dbeaver.ext.postgresql/src/org/jkiss/dbeaver/ext/postgresql/PostgreUtils.java', 'plugins/org.jkiss.dbeaver.ui.dialogs/connection/NewConnectionDialog.java', 'plugins/org.jkiss.dbeaver.ext.postgresql/src/org/jkiss/dbeaver/ext/postgresql/PostgreDataSourceProvider.java', 'plugins/org.jkiss.dbeaver.model.sql/src/org/jkiss/dbeaver/model/sql/parser/SQLScriptParser.java', 'plugins/org.jkiss.dbeaver.ui.editors.data/src/org/jkiss/dbeaver/ui/controls/resultset/ResultSetDataContainer.java', 'plugins/org.jkiss.dbeaver.ui.editors.data/src/org/jkiss/dbeaver/ui/controls/resultset/ResultSetDataContainerOptions.java', 'plugins/org.jkiss.dbeaver.ui.editors.data/src/org/jkiss/dbeaver/ui/controls/resultset/view/EmptyPresentation.java', 'plugins/org.jkiss.dbeaver.ui.editors.data/src/org/jkiss/dbeaver/ui/controls/resultset/view/ErrorPresentation.java', 'plugins/org.jkiss.dbeaver.ui.dialogs/connection/ConnectionWizard.java', 'plugins/org.jkiss.dbeaver.ui.editors.base/src/org/jkiss/dbeaver/ui/editors/DatabaseEditorInputFactory.java', 'plugins/org.jkiss.dbeaver.model.sql/src/org/jkiss/dbeaver/model/sql/parser/SQLParserPartitions.java', 'plugins/org.jkiss.dbeaver.debug.core/src/org/jkiss/dbeaver/debug/core/model/DatabaseValue.java', 'plugins/org.jkiss.dbeaver.ui.editors.base/src/org/jkiss/dbeaver/ui/editors/DatabaseEditorContext.java', 'plugins/org.jkiss.dbeaver.ui.editors.data/src/org/jkiss/dbeaver/ui/controls/resultset/view/StatisticsPresentation.java', 'plugins/org.jkiss.dbeaver.ext.postgresql/src/org/jkiss/dbeaver/ext/postgresql/edit/PostgreForeignKeyManager.java', 'plugins/org.jkiss.dbeaver.ui.editors.data/src/org/jkiss/dbeaver/ui/controls/resultset/ResultSetCopySettings.java', 'plugins/org.jkiss.dbeaver.debug.core/src/org/jkiss/dbeaver/debug/core/model/DatabaseDebugElement.java', 'plugins/org.jkiss.dbeaver.ui.editors.base/src/org/jkiss/dbeaver/ui/editors/DatabaseEditorInput.java', 'plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/SQLEditorBase.java', 'plugins/org.jkiss.dbeaver.ui/src/org/jkiss/dbeaver/ui/IDataSourceConnectionEditor.java', 'plugins/org.jkiss.dbeaver.model/src/org/jkiss/dbeaver/registry/DataSourceDescriptor.java', 'plugins/org.jkiss.dbeaver.ext.postgresql/src/org/jkiss/dbeaver/ext/postgresql/PostgreConstants.java', 'plugins/org.jkiss.dbeaver.ext.db2.ui/src/org/jkiss/dbeaver/ext/db2/ui/config/DB2ForeignKeyConfigurator.java', 'plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/commands/SQLCommandInclude.java', 'plugins/org.jkiss.dbeaver.ext.postgresql/src/org/jkiss/dbeaver/ext/postgresql/model/PostgreTableColumn.java', 'plugins/org.jkiss.dbeaver.model/src/org/jkiss/dbeaver/model/navigator/DBNDatabaseObject.java', 'plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/handlers/SQLEditorHandlerNavigateObject.java', 'plugins/org.jkiss.dbeaver.ext.mssql/src/org/jkiss/dbeaver/ext/mssql/edit/SQLServerTableForeignKey.java', 'plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/plan/simple/SQLPlanViewProviderSimple.java', 'plugins/org.jkiss.dbeaver.ext.mssql/src/org/jkiss/dbeaver/ext/mssql/edit/SQLServerTableTriggerManager.java', 'plugins/org.jkiss.dbeaver.ext.db2.ui/src/org/jkiss/dbeaver/ext/db2/ui/config/DB2IndexConfigurator.java']","['plugins/org.jkiss.dbeaver.ext.mssql.ui/src/org/jkiss/dbeaver/ext/mssql/ui/config/SQLServerDatabaseConfigurator.java', 'plugins/org.jkiss.dbeaver.ext.mssql/src/org/jkiss/dbeaver/ext/mssql/edit/SQLServerTableManager.java', 'plugins/org.jkiss.dbeaver.ext.mssql/src/org/jkiss/dbeaver/ext/mssql/edit/SQLServerTableTypeManager.java', 'plugins/org.jkiss.dbeaver.ext.mssql/src/org/jkiss/dbeaver/ext/mssql/edit/SQLServerTableTriggerManager.java', 'plugins/org.jkiss.dbeaver.ext.mssql.ui/src/org/jkiss/dbeaver/ext/mssql/ui/config/SQLServerForeignKeyConfigurator.java']","['```json\n{\n  ""files"": [\n    ""plugins/org.jkiss.dbeaver.model/src/org/jkiss/dbeaver/registry/DataSourceDescriptor.java"",\n    ""plugins/org.jkiss.dbeaver.model/src/org/jkiss/dbeaver/registry/DataSourceRegistry.java"",\n    ""plugins/org.jkiss.dbeaver.ui/src/org/jkiss/dbeaver/ui/IDataSourceConnectionEditor.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""plugins/org.jkiss.dbeaver.model/src/org/jkiss/dbeaver/model/sql/SQLSearchUtils.java"",\n    ""plugins/org.jkiss.dbeaver.model/src/org/jkiss/dbeaver/model/sql/SQLModelPreferences.java"",\n    ""plugins/org.jkiss.dbeaver.ext.postgresql/src/org/jkiss/dbeaver/ext/postgresql/PostgreConstants.java"",\n    ""plugins/org.jkiss.dbeaver.ext.postgresql/src/org/jkiss/dbeaver/ext/postgresql/PostgreDataSourceProvider.java"",\n    ""plugins/org.jkiss.dbeaver.ext.postgresql/src/org/jkiss/dbeaver/ext/postgresql/PostgreUtils.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""plugins/org.jkiss.dbeaver.model/src/org/jkiss/dbeaver/model/navigator/DBNDatabaseNode.java"",\n    ""plugins/org.jkiss.dbeaver.model/src/org/jkiss/dbeaver/model/navigator/DBNDatabaseObject.java"",\n    ""plugins/org.jkiss.dbeaver.model/src/org/jkiss/dbeaver/model/navigator/DBNDatabaseItem.java"",\n    ""plugins/org.jkiss.dbeaver.model/src/org/jkiss/dbeaver/model/navigator/DBNContainer.java"",\n    ""plugins/org.jkiss.dbeaver.model/src/org/jkiss/dbeaver/model/navigator/DBNNode.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""plugins/org.jkiss.dbeaver.ui.editors.base/src/org/jkiss/dbeaver/ui/editors/DatabaseEditorUtils.java"",\n    ""plugins/org.jkiss.dbeaver.ui.editors.base/src/org/jkiss/dbeaver/ui/editors/DatabaseEditorInput.java"",\n    ""plugins/org.jkiss.dbeaver.ui.editors.base/src/org/jkiss/dbeaver/ui/editors/DatabaseEditorInputFactory.java"",\n    ""plugins/org.jkiss.dbeaver.ui.editors.base/src/org/jkiss/dbeaver/ui/editors/DatabaseEditorContext.java"",\n    ""plugins/org.jkiss.dbeaver.ui.editors.base/src/org/jkiss/dbeaver/ui/editors/DatabaseEditorListener.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""plugins/org.jkiss.dbeaver.ui.dialogs/connection/EditConnectionDialog.java"",\n    ""plugins/org.jkiss.dbeaver.ui.dialogs/connection/ConnectionWizard.java"",\n    ""plugins/org.jkiss.dbeaver.ui.dialogs/connection/ConnectionWizardPage.java"",\n    ""plugins/org.jkiss.dbeaver.ui.dialogs/connection/NewConnectionDialog.java"",\n    ""plugins/org.jkiss.dbeaver.ui.dialogs/connection/NewConnectionWizard.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""plugins/org.jkiss.dbeaver.debug.core/src/org/jkiss/dbeaver/debug/core/model/DatabaseDebugElement.java"",\n    ""plugins/org.jkiss.dbeaver.debug.core/src/org/jkiss/dbeaver/debug/core/model/DatabaseThread.java"",\n    ""plugins/org.jkiss.dbeaver.debug.core/src/org/jkiss/dbeaver/debug/core/model/DatabaseProcess.java"",\n    ""plugins/org.jkiss.dbeaver.debug.core/src/org/jkiss/dbeaver/debug/core/model/DatabaseValue.java"",\n    ""plugins/org.jkiss.dbeaver.debug.core/src/org/jkiss/dbeaver/debug/core/model/DatabaseVariable.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""plugins/org.jkiss.dbeaver.ext.generic/edit/GenericForeignKeyManager.java"",\n    ""plugins/org.jkiss.dbeaver.ext.generic/edit/GenericTableManager.java"",\n    ""plugins/org.jkiss.dbeaver.ext.generic/model/GenericTable.java"",\n    ""plugins/org.jkiss.dbeaver.ext.generic/model/GenericTableColumn.java"",\n    ""plugins/org.jkiss.dbeaver.ext.generic/model/GenericTableForeignKey.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""plugins/org.jkiss.dbeaver.ext.mssql.ui/src/org/jkiss/dbeaver/ext/mssql/ui/SQLServerTableManager.java"",\n    ""plugins/org.jkiss.dbeaver.ext.mssql/src/org/jkiss/dbeaver/ext/mssql/edit/SQLServerTableManager.java"",\n    ""plugins/org.jkiss.dbeaver.ext.mssql/src/org/jkiss/dbeaver/ext/mssql/edit/SQLServerTableTriggerManager.java"",\n    ""plugins/org.jkiss.dbeaver.ext.mssql/src/org/jkiss/dbeaver/ext/mssql/edit/SQLServerTableTypeManager.java"",\n    ""plugins/org.jkiss.dbeaver.ext.mssql/src/org/jkiss/dbeaver/ext/mssql/edit/SQLServerTableForeignKey.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""plugins/org.jkiss.dbeaver.ext.postgresql/src/org/jkiss/dbeaver/ext/postgresql/edit/PostgreForeignKeyManager.java"",\n    ""plugins/org.jkiss.dbeaver.ext.postgresql/src/org/jkiss/dbeaver/ext/postgresql/edit/PostgreTableManager.java"",\n    ""plugins/org.jkiss.dbeaver.ext.postgresql/src/org/jkiss/dbeaver/ext/postgresql/model/PostgreTable.java"",\n    ""plugins/org.jkiss.dbeaver.ext.postgresql/src/org/jkiss/dbeaver/ext/postgresql/model/PostgreTableColumn.java"",\n    ""plugins/org.jkiss.dbeaver.ext.postgresql/src/org/jkiss/dbeaver/ext/postgresql/model/PostgreTableConstraint.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""plugins/org.jkiss.dbeaver.model.sql/src/org/jkiss/dbeaver/model/sql/parser/SQLParserContext.java"",\n    ""plugins/org.jkiss.dbeaver.model.sql/src/org/jkiss/dbeaver/model/sql/parser/SQLParserPartitions.java"",\n    ""plugins/org.jkiss.dbeaver.model.sql/src/org/jkiss/dbeaver/model/sql/parser/SQLScriptParser.java"",\n    ""plugins/org.jkiss.dbeaver.model.sql/src/org/jkiss/dbeaver/model/sql/parser/SQLRuleManager.java"",\n    ""plugins/org.jkiss.dbeaver.model.sql/src/org/jkiss/dbeaver/model/sql/parser/SQLWordPartDetector.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""plugins/org.jkiss.dbeaver.ui.editors.data/src/org/jkiss/dbeaver/ui/controls/resultset/ResultSetFilterContentAdapter.java"",\n    ""plugins/org.jkiss.dbeaver.ui.editors.data/src/org/jkiss/dbeaver/ui/controls/resultset/ResultSetDataReceiver.java"",\n    ""plugins/org.jkiss.dbeaver.ui.editors.data/src/org/jkiss/dbeaver/ui/controls/resultset/ResultSetDataContainerOptions.java"",\n    ""plugins/org.jkiss.dbeaver.ui.editors.data/src/org/jkiss/dbeaver/ui/controls/resultset/ResultSetDataContainer.java"",\n    ""plugins/org.jkiss.dbeaver.ui.editors.data/src/org/jkiss/dbeaver/ui/controls/resultset/ResultSetCopySettings.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/SQLEditor.java"",\n    ""plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/SQLEditorBase.java"",\n    ""plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/SQLEditorCommands.java"",\n    ""plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/SQLEditorContributions.java"",\n    ""plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/SQLEditorContributor.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""plugins/org.jkiss.dbeaver.ext.db2.ui/src/org/jkiss/dbeaver/ext/db2/ui/config/DB2ForeignKeyConfigurator.java"",\n    ""plugins/org.jkiss.dbeaver.ext.db2.ui/src/org/jkiss/dbeaver/ext/db2/ui/config/DB2IndexConfigurator.java"",\n    ""plugins/org.jkiss.dbeaver.ext.db2.ui/src/org/jkiss/dbeaver/ext/db2/ui/config/DB2SchemaConfigurator.java"",\n    ""plugins/org.jkiss.dbeaver.ext.db2.ui/src/org/jkiss/dbeaver/ext/db2/ui/config/DB2TablespaceChooser.java"",\n    ""plugins/org.jkiss.dbeaver.ext.db2.ui/src/org/jkiss/dbeaver/ext/db2/ui/config/DB2UniqueKeyConfigurator.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""plugins/org.jkiss.dbeaver.ext.mssql.ui/src/org/jkiss/dbeaver/ext/mssql/ui/config/SQLServerForeignKeyConfigurator.java"",\n    ""plugins/org.jkiss.dbeaver.ext.mssql.ui/src/org/jkiss/dbeaver/ext/mssql/ui/config/SQLServerDatabaseConfigurator.java"",\n    ""plugins/org.jkiss.dbeaver.ext.postgresql/src/org/jkiss/dbeaver/ext/postgresql/model/plan/PostgreQueryPlaner.java"",\n    ""plugins/org.jkiss.dbeaver.ext.postgresql/src/org/jkiss/dbeaver/ext/postgresql/model/plan/PostgreExecutionPlan.java"",\n    ""plugins/org.jkiss.dbeaver.ext.postgresql/src/org/jkiss/dbeaver/ext/postgresql/model/plan/PostgrePlanNodeBase.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""plugins/org.jkiss.dbeaver.ui.editors.data/src/org/jkiss/dbeaver/ui/controls/resultset/view/EmptyPresentation.java"",\n    ""plugins/org.jkiss.dbeaver.ui.editors.data/src/org/jkiss/dbeaver/ui/controls/resultset/view/ErrorPresentation.java"",\n    ""plugins/org.jkiss.dbeaver.ui.editors.data/src/org/jkiss/dbeaver/ui/controls/resultset/view/StatisticsPresentation.java"",\n    ""plugins/org.jkiss.dbeaver.ui.editors.data/src/org/jkiss/dbeaver/ui/controls/resultset/view/ErrorDetailsPart.java"",\n    ""plugins/org.jkiss.dbeaver.ui.editors.data/src/org/jkiss/dbeaver/ui/controls/resultset/view/PlainTextPresentation.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/commands/SQLCommandInclude.java"",\n    ""plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/commands/OpenLinkInWindowHandler.java"",\n    ""plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/handlers/SQLEditorHandlerAssistTemplates.java"",\n    ""plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/handlers/SQLEditorHandlerNavigateObject.java"",\n    ""plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/handlers/SQLEditorHandlerNavigateQuery.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/plan/simple/SQLPlanViewProviderSimple.java"",\n    ""plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/plan/simple/SQLPlanTreeViewer.java"",\n    ""plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/plan/simple/PlanNodesTree.java"",\n    ""plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/plan/registry/SQLPlanViewRegistry.java"",\n    ""plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/preferences/format/SQLExternalFormatterConfigurationPage.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""plugins/org.jkiss.dbeaver.ext.mssql/src/org/jkiss/dbeaver/ext/mssql/edit/SQLServerTableManager.java"",\n    ""plugins/org.jkiss.dbeaver.ext.mssql/src/org/jkiss/dbeaver/ext/mssql/edit/SQLServerTableTypeManager.java"",\n    ""plugins/org.jkiss.dbeaver.ext.mssql.ui/src/org/jkiss/dbeaver/ext/mssql/ui/config/SQLServerDatabaseConfigurator.java"",\n    ""plugins/org.jkiss.dbeaver.ext.mssql.ui/src/org/jkiss/dbeaver/ext/mssql/ui/config/SQLServerForeignKeyConfigurator.java"",\n    ""plugins/org.jkiss.dbeaver.ext.mssql/src/org/jkiss/dbeaver/ext/mssql/edit/SQLServerTableTriggerManager.java""\n  ]\n}\n```']",17,45946.189880371094
673,dbeaver/dbeaver/20881/20529,dbeaver,dbeaver,https://github.com/dbeaver/dbeaver/issues/20529,https://github.com/dbeaver/dbeaver/pull/20881,https://github.com/dbeaver/dbeaver/pull/20881,1,closes,"SSH connection defaults to OS login, if server login not saved in settings","### Description

It's related to credential popup changes from #18017 - now if SSH is set to use encrypted certificates there will be a popup asking for certificate password, but there's no way to enter server login. If the login is stored in settings - it will work - but in case the login is left empty, the connection will default to OS login.

### DBeaver Version

Community Edition 23.1.2

### Operating System

Windows 10

### Database and driver

_No response_

### Steps to reproduce

1. Configure SSH with jump server (probably without the jump server will be the same)
2. Use encrypted certificate as auth, leave passphrases blank
3. Leave the ""user name"" blank
4. Try to connect
The connection will ask for passphrase, but not for login and then it will default to using OS user name as SSH server login.

### Additional context

_No response_",1ad21c12ab285733bdf877024ebb4d6d071617b1,41addd796eaf82905bfb7d587214542b8990c50d,https://github.com/dbeaver/dbeaver/compare/1ad21c12ab285733bdf877024ebb4d6d071617b1...41addd796eaf82905bfb7d587214542b8990c50d,"diff --git a/plugins/org.jkiss.dbeaver.net.ssh.ui/src/org/jkiss/dbeaver/ui/net/ssh/SSHTunnelConfiguratorUI.java b/plugins/org.jkiss.dbeaver.net.ssh.ui/src/org/jkiss/dbeaver/ui/net/ssh/SSHTunnelConfiguratorUI.java
index ffd49fbb4f..7f59eee123 100644
--- a/plugins/org.jkiss.dbeaver.net.ssh.ui/src/org/jkiss/dbeaver/ui/net/ssh/SSHTunnelConfiguratorUI.java
+++ b/plugins/org.jkiss.dbeaver.net.ssh.ui/src/org/jkiss/dbeaver/ui/net/ssh/SSHTunnelConfiguratorUI.java
@@ -256,7 +256,7 @@ public class SSHTunnelConfiguratorUI implements IObjectPropertyConfigurator<Obje
                     ? SSHUIMessages.model_ssh_dialog_credentials_passphrase
                     : SSHUIMessages.model_ssh_dialog_credentials_password,
                 password,
-                type.equals(SSHConstants.AuthType.PUBLIC_KEY),
+                false,
                 false
             );
         } catch (Exception e) {
@@ -298,9 +298,7 @@ public class SSHTunnelConfiguratorUI implements IObjectPropertyConfigurator<Obje
                         DBPAuthInfo dbpAuthInfo = promptCredentialsDialog(authType, configuration.getUserName(),
                             configuration.getPassword());
                         if (dbpAuthInfo != null) {
-                            if (authType.equals(SSHConstants.AuthType.PASSWORD)) {
-                                configuration.setUserName(dbpAuthInfo.getUserName());
-                            }
+                            configuration.setUserName(dbpAuthInfo.getUserName());
                             configuration.setPassword(dbpAuthInfo.getUserPassword());
                         }
                         checkJumpServerConfiguration(tunnel);
@@ -337,19 +335,18 @@ public class SSHTunnelConfiguratorUI implements IObjectPropertyConfigurator<Obje
                     );
                     if (tunnel.getRequiredCredentials(configuration, getJumpServerSettingsPrefix())
                         != DBWTunnel.AuthCredentials.NONE) {
-                        DBPAuthInfo dbpAuthInfo = promptCredentialsDialog(authType,
-                            configuration.getStringProperty(getJumpServerSettingsPrefix()
-                                                            + DBConstants.PROP_ID_NAME),
-                            configuration.getSecureProperty(getJumpServerSettingsPrefix()
-                                                            + DBConstants.PROP_FEATURE_PASSWORD)
+                        DBPAuthInfo dbpAuthInfo = promptCredentialsDialog(
+                            authType,
+                            configuration.getStringProperty(getJumpServerSettingsPrefix() + DBConstants.PROP_ID_NAME),
+                            configuration.getSecureProperty(
+                                getJumpServerSettingsPrefix() + DBConstants.PROP_FEATURE_PASSWORD)
                         );
                         if (dbpAuthInfo != null) {
-                            if (authType.equals(SSHConstants.AuthType.PASSWORD)) {
-                                configuration.setProperty(getJumpServerSettingsPrefix() + DBConstants.PROP_ID_NAME,
-                                    dbpAuthInfo.getUserName()
-                                );
-                            }
-                            configuration.setSecureProperty(getJumpServerSettingsPrefix() + DBConstants.PROP_FEATURE_PASSWORD,
+                            configuration.setProperty(getJumpServerSettingsPrefix() + DBConstants.PROP_ID_NAME,
+                                dbpAuthInfo.getUserName()
+                            );
+                            configuration.setSecureProperty(
+                                getJumpServerSettingsPrefix() + DBConstants.PROP_FEATURE_PASSWORD,
                                 dbpAuthInfo.getUserPassword()
                             );
                         }
diff --git a/plugins/org.jkiss.dbeaver.registry/src/org/jkiss/dbeaver/registry/DataSourceDescriptor.java b/plugins/org.jkiss.dbeaver.registry/src/org/jkiss/dbeaver/registry/DataSourceDescriptor.java
index 2aec12602b..0194debc58 100644
--- a/plugins/org.jkiss.dbeaver.registry/src/org/jkiss/dbeaver/registry/DataSourceDescriptor.java
+++ b/plugins/org.jkiss.dbeaver.registry/src/org/jkiss/dbeaver/registry/DataSourceDescriptor.java
@@ -1928,9 +1928,7 @@ public class DataSourceDescriptor
         }
 
         if (networkHandler != null) {
-            if (authType == DBWTunnel.AuthCredentials.CREDENTIALS) {
-                networkHandler.setUserName(authInfo.getUserName());
-            }
+            networkHandler.setUserName(authInfo.getUserName());
             networkHandler.setPassword(authInfo.getUserPassword());
             networkHandler.setSavePassword(authInfo.isSavePassword());
             actualConfig.updateHandler(networkHandler);
@@ -1989,7 +1987,7 @@ public class DataSourceDescriptor
             authType == DBWTunnel.AuthCredentials.PASSWORD
                 ? RegistryMessages.dialog_connection_auth_passphrase
                 : RegistryMessages.dialog_connection_auth_password, password,
-            authType != DBWTunnel.AuthCredentials.CREDENTIALS,
+            false,
             canSavePassword
         );
         return authInfo;","['plugins/org.jkiss.dbeaver.registry/src/org/jkiss/dbeaver/registry/DataSourceDescriptor.java', 'plugins/org.jkiss.dbeaver.net.ssh.ui/src/org/jkiss/dbeaver/ui/net/ssh/SSHTunnelConfiguratorUI.java']",{'.java': 2},2,2,0,0,2,25916171,5294862,697820,4986,2351,325,33,2,858,148,190,27,0,0,2023-08-14 10:28:38,33177,Java,"{'Java': 26145871, 'JavaScript': 139972, 'C++': 63113, 'ANTLR': 29768, 'CSS': 20674, 'HTML': 12246, 'XSLT': 8047, 'Batchfile': 2891, 'Shell': 202}",Apache License 2.0,"['plugins/org.jkiss.dbeaver.ui.editors.connection/src/org/jkiss/dbeaver/ui/dialogs/BaseAuthDialog.java', 'plugins/org.jkiss.dbeaver.ext.snowflake.core/src/org/jkiss/dbeaver/ext/snowflake/model/auth/AuthModelSnowflakeCredentials.java', 'plugins/org.jkiss.dbeaver.net.ssh/src/org/jkiss/dbeaver/model/net/ssh/config/SSHHostConfiguration.java', 'plugins/org.jkiss.dbeaver.ext.ssh/src/org/jkiss/dbeaver/ext/ssh/model/impl/SSHImplementationAbstract.java', 'plugins/org.jkiss.dbeaver.ext.snowflake.core/src/org/jkiss/dbeaver/ext/snowflake/model/auth/SnowflakeAuthModelSnowflake.java', 'plugins/org.jkiss.dbeaver.net.ssh/src/org/jkiss/dbeaver/model/net/ssh/SSHUtils.java', 'plugins/org.jkiss.dbeaver.ext.ssh/src/org/jkiss/dbeaver/ext/ssh/SSHUtils.java', 'plugins/org.jkiss.dbeaver.ui.editors.connection/src/org/jkiss/dbeaver/ui/actions/ChangeUserPasswordPropertyTester.java', 'plugins/org.jkiss.dbeaver.model/src/org/jkiss/dbeaver/model/impl/net/SSLHandlerImpl.java', 'plugins/org.jkiss.dbeaver.core/src/org/jkiss/dbeaver/ui/preferences/PrefPageConnectionClient.java', 'plugins/org.jkiss.dbeaver.ext.mssql/src/org/jkiss/dbeaver/ext/mssql/auth/SQLServerAuthModelAbstract.java', 'plugins/org.jkiss.dbeaver.ext.generic/model/GenericSQLDialect.java', 'plugins/org.jkiss.dbeaver.ext.generic/src/org/jkiss/dbeaver/ext/generic/model/meta/GenericMetaModelDescriptor.java', 'plugins/org.jkiss.dbeaver.ext.snowflake.ui/src/org/jkiss/dbeaver/ext/snowflake/ui/internal/SnowflakeUIActivator.java', 'plugins/org.jkiss.dbeaver.ext.mssql/src/org/jkiss/dbeaver/ext/mssql/auth/SQLServerAuthModelWindows.java', 'plugins/org.jkiss.dbeaver.ext.mssql/src/org/jkiss/dbeaver/ext/mssql/auth/SQLServerAuthModelADPassword.java', 'plugins/org.jkiss.dbeaver.core/src/org/jkiss/dbeaver/ui/preferences/PrefPageDatabaseUserInterface.java', 'plugins/org.jkiss.dbeaver.ui.editors.connection/src/org/jkiss/dbeaver/ui/dialogs/connection/ConnectionPageAbstract.java', 'plugins/org.jkiss.dbeaver.core/src/org/jkiss/dbeaver/ui/dialogs/connection/ConnectionPageNetworkHandler.java', 'plugins/org.jkiss.dbeaver.model/src/org/jkiss/dbeaver/model/impl/net/SSLHandlerTrustStoreImpl.java', 'plugins/org.jkiss.dbeaver.model/src/org/jkiss/dbeaver/model/impl/net/SocksProxyImpl.java', 'plugins/org.jkiss.dbeaver.ui/src/org/jkiss/dbeaver/ui/controls/autorefresh/AutoRefreshConfigDialog.java', 'plugins/org.jkiss.dbeaver.model.sm/src/org/jkiss/dbeaver/model/auth/AuthPropertyDescriptor.java', 'plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/preferences/format/tokenized/SQLTokenizedFormatterConfigurationPage.java', 'plugins/org.jkiss.dbeaver.model/src/org/jkiss/dbeaver/registry/DataSourceDescriptor.java', 'plugins/org.jkiss.dbeaver.ext.generic/model/GenericTable.java', 'plugins/org.jkiss.dbeaver.ext.hana.ui/src/org/jkiss/dbeaver/ext/hana/ui/config/HANASchemaConfigurator.java', 'plugins/org.jkiss.dbeaver.ext.mssql/src/org/jkiss/dbeaver/ext/mssql/auth/SQLServerAuthModelDatabase.java', 'plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/convert/impl/JavaSQLConverter.java', 'plugins/org.jkiss.dbeaver.model/src/org/jkiss/dbeaver/registry/network/NetworkHandlerRegistry.java', 'plugins/org.jkiss.dbeaver.ext.generic/model/GenericDataSourceInfo.java', 'plugins/org.jkiss.dbeaver.ext.generic/src/org/jkiss/dbeaver/ext/generic/model/meta/GenericMetaModel.java', 'plugins/org.jkiss.dbeaver.core/src/org/jkiss/dbeaver/ui/preferences/PrefPageErrorLogs.java', 'plugins/org.jkiss.dbeaver.model/src/org/jkiss/dbeaver/model/impl/net/SSLConfigurationMethod.java', 'plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/convert/impl/UnformattedSQLConverter.java', 'plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/preferences/format/SQLExternalFormatterConfigurationPage.java', 'plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/preferences/format/SQLFormatterConfigurator.java', 'plugins/org.jkiss.dbeaver.model/src/org/jkiss/dbeaver/registry/network/NetworkHandlerDescriptor.java', 'plugins/org.jkiss.dbeaver.ext.hana.ui/src/org/jkiss/dbeaver/ext/hana/ui/views/HANAConnectionPage.java', 'plugins/org.jkiss.dbeaver.model.sm/src/org/jkiss/dbeaver/model/auth/SMAuthInfo.java', 'plugins/org.jkiss.dbeaver.ui.editors.connection/src/org/jkiss/dbeaver/ui/dialogs/ConnectionLostDialog.java', 'plugins/org.jkiss.dbeaver.model/src/org/jkiss/dbeaver/model/impl/net/HTTPTunnelImpl.java', 'plugins/org.jkiss.dbeaver.ext.snowflake.ui/src/org/jkiss/dbeaver/ext/snowflake/ui/internal/SnowflakeMessages.java', 'plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/preferences/format/BaseFormatterConfigurationPage.java', 'plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/convert/impl/CPPSQLConverter.java', 'plugins/org.jkiss.dbeaver.ui.editors.connection/src/org/jkiss/dbeaver/ui/dialogs/connection/ConnectionPageWithAuth.java', 'plugins/org.jkiss.dbeaver.ext.generic/model/GenericTableManager.java', 'plugins/org.jkiss.dbeaver.ui.editors.connection/src/org/jkiss/dbeaver/ui/actions/ChangePasswordDialogHandler.java', 'plugins/org.jkiss.dbeaver.model.sm/src/org/jkiss/dbeaver/model/auth/AuthPropertyEncryption.java', 'plugins/org.jkiss.dbeaver.core/src/org/jkiss/dbeaver/ui/dialogs/connection/ConnectionPageNetwork.java', 'plugins/org.jkiss.dbeaver.core/src/org/jkiss/dbeaver/ui/preferences/PrefPageConnectionsGeneral.java', 'plugins/org.jkiss.dbeaver.ext.generic/model/GenericDataSource.java', 'plugins/org.jkiss.dbeaver.net.ssh/src/org/jkiss/dbeaver/model/net/ssh/config/SSHAuthConfiguration.java', 'plugins/org.jkiss.dbeaver.ext.generic/src/org/jkiss/dbeaver/ext/generic/model/meta/GenericMetaObject.java', 'plugins/org.jkiss.dbeaver.model.sm/src/org/jkiss/dbeaver/model/auth/SMAuthProvider.java', 'plugins/org.jkiss.dbeaver.model.sm/src/org/jkiss/dbeaver/model/auth/SMAuthCredentialsManager.java', 'plugins/org.jkiss.dbeaver.ext.snowflake.ui/src/org/jkiss/dbeaver/ext/snowflake/ui/config/SnowflakeAuthSnowflakeConfigurator.java', 'plugins/org.jkiss.dbeaver.core/src/org/jkiss/dbeaver/ui/preferences/PrefPageErrorHandle.java', 'plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/convert/impl/PythonCodeConverter.java', 'plugins/org.jkiss.dbeaver.ui/src/org/jkiss/dbeaver/ui/controls/autorefresh/AutoRefreshControl.java', 'plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/plan/simple/SQLPlanViewProviderSimple.java', 'plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/convert/impl/SourceCodeSQLConverter.java', 'plugins/org.jkiss.dbeaver.core/src/org/jkiss/dbeaver/DBeaverPreferences.java', 'plugins/org.jkiss.dbeaver.ext.mssql/src/org/jkiss/dbeaver/ext/mssql/auth/SQLServerAuthModelCustom.java', 'plugins/org.jkiss.dbeaver.ui.editors.connection/src/org/jkiss/dbeaver/ui/dialogs/EditUserDialog.java']","['plugins/org.jkiss.dbeaver.ui.editors.connection/src/org/jkiss/dbeaver/ui/dialogs/connection/ConnectionPageAbstract.java', 'plugins/org.jkiss.dbeaver.net.ssh/src/org/jkiss/dbeaver/model/net/ssh/SSHUtils.java', 'plugins/org.jkiss.dbeaver.ui.editors.connection/src/org/jkiss/dbeaver/ui/dialogs/connection/ConnectionPageNetworkHandler.java', 'plugins/org.jkiss.dbeaver.ui.editors.connection/src/org/jkiss/dbeaver/ui/dialogs/connection/ConnectionPageWithAuth.java', 'plugins/org.jkiss.dbeaver.net.ssh/src/org/jkiss/dbeaver/model/net/ssh/config/SSHHostConfiguration.java']","['```json\n{\n  ""files"": [\n    ""plugins/org.jkiss.dbeaver.core/src/org/jkiss/dbeaver/DBeaverPreferences.java"",\n    ""plugins/org.jkiss.dbeaver.model/src/org/jkiss/dbeaver/registry/DataSourceDescriptor.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""plugins/org.jkiss.dbeaver.core/src/org/jkiss/dbeaver/ui/preferences/PrefPageConnectionClient.java"",\n    ""plugins/org.jkiss.dbeaver.core/src/org/jkiss/dbeaver/ui/preferences/PrefPageConnectionsGeneral.java"",\n    ""plugins/org.jkiss.dbeaver.core/src/org/jkiss/dbeaver/ui/preferences/PrefPageDatabaseUserInterface.java"",\n    ""plugins/org.jkiss.dbeaver.core/src/org/jkiss/dbeaver/ui/preferences/PrefPageErrorHandle.java"",\n    ""plugins/org.jkiss.dbeaver.core/src/org/jkiss/dbeaver/ui/preferences/PrefPageErrorLogs.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""plugins/org.jkiss.dbeaver.model.sm/src/org/jkiss/dbeaver/model/auth/AuthPropertyDescriptor.java"",\n    ""plugins/org.jkiss.dbeaver.model.sm/src/org/jkiss/dbeaver/model/auth/AuthPropertyEncryption.java"",\n    ""plugins/org.jkiss.dbeaver.model.sm/src/org/jkiss/dbeaver/model/auth/SMAuthCredentialsManager.java"",\n    ""plugins/org.jkiss.dbeaver.model.sm/src/org/jkiss/dbeaver/model/auth/SMAuthInfo.java"",\n    ""plugins/org.jkiss.dbeaver.model.sm/src/org/jkiss/dbeaver/model/auth/SMAuthProvider.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""plugins/org.jkiss.dbeaver.model/src/org/jkiss/dbeaver/registry/network/NetworkHandlerDescriptor.java"",\n    ""plugins/org.jkiss.dbeaver.model/src/org/jkiss/dbeaver/registry/network/NetworkHandlerRegistry.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""plugins/org.jkiss.dbeaver.ui.editors.connection/src/org/jkiss/dbeaver/ui/actions/ChangePasswordDialogHandler.java"",\n    ""plugins/org.jkiss.dbeaver.ui.editors.connection/src/org/jkiss/dbeaver/ui/actions/ChangeUserPasswordPropertyTester.java"",\n    ""plugins/org.jkiss.dbeaver.ui.editors.connection/src/org/jkiss/dbeaver/ui/dialogs/BaseAuthDialog.java"",\n    ""plugins/org.jkiss.dbeaver.ui.editors.connection/src/org/jkiss/dbeaver/ui/dialogs/ConnectionLostDialog.java"",\n    ""plugins/org.jkiss.dbeaver.ui.editors.connection/src/org/jkiss/dbeaver/ui/dialogs/EditUserDialog.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""plugins/org.jkiss.dbeaver.core/src/org/jkiss/dbeaver/ui/dialogs/connection/ConnectionPageNetwork.java"",\n    ""plugins/org.jkiss.dbeaver.core/src/org/jkiss/dbeaver/ui/dialogs/connection/ConnectionPageNetworkHandler.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""plugins/org.jkiss.dbeaver.ext.generic/model/GenericDataSource.java"",\n    ""plugins/org.jkiss.dbeaver.ext.generic/model/GenericDataSourceInfo.java"",\n    ""plugins/org.jkiss.dbeaver.ext.generic/model/GenericSQLDialect.java"",\n    ""plugins/org.jkiss.dbeaver.ext.generic/model/GenericTable.java"",\n    ""plugins/org.jkiss.dbeaver.ext.generic/model/GenericTableManager.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""plugins/org.jkiss.dbeaver.ext.mssql/src/org/jkiss/dbeaver/ext/mssql/auth/SQLServerAuthModelAbstract.java"",\n    ""plugins/org.jkiss.dbeaver.ext.mssql/src/org/jkiss/dbeaver/ext/mssql/auth/SQLServerAuthModelCustom.java"",\n    ""plugins/org.jkiss.dbeaver.ext.mssql/src/org/jkiss/dbeaver/ext/mssql/auth/SQLServerAuthModelDatabase.java"",\n    ""plugins/org.jkiss.dbeaver.ext.mssql/src/org/jkiss/dbeaver/ext/mssql/auth/SQLServerAuthModelWindows.java"",\n    ""plugins/org.jkiss.dbeaver.ext.mssql/src/org/jkiss/dbeaver/ext/mssql/auth/SQLServerAuthModelADPassword.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""plugins/org.jkiss.dbeaver.ext.ssh/src/org/jkiss/dbeaver/ext/ssh/SSHUtils.java"",\n    ""plugins/org.jkiss.dbeaver.ext.ssh/src/org/jkiss/dbeaver/ext/ssh/model/impl/SSHImplementationAbstract.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""plugins/org.jkiss.dbeaver.model/src/org/jkiss/dbeaver/model/impl/net/HTTPTunnelImpl.java"",\n    ""plugins/org.jkiss.dbeaver.model/src/org/jkiss/dbeaver/model/impl/net/SSLHandlerImpl.java"",\n    ""plugins/org.jkiss.dbeaver.model/src/org/jkiss/dbeaver/model/impl/net/SSLHandlerTrustStoreImpl.java"",\n    ""plugins/org.jkiss.dbeaver.model/src/org/jkiss/dbeaver/model/impl/net/SSLConfigurationMethod.java"",\n    ""plugins/org.jkiss.dbeaver.model/src/org/jkiss/dbeaver/model/impl/net/SocksProxyImpl.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""plugins/org.jkiss.dbeaver.net.ssh/src/org/jkiss/dbeaver/model/net/ssh/SSHUtils.java"",\n    ""plugins/org.jkiss.dbeaver.ui.editors.connection/src/org/jkiss/dbeaver/ui/dialogs/connection/ConnectionPageAbstract.java"",\n    ""plugins/org.jkiss.dbeaver.ui.editors.connection/src/org/jkiss/dbeaver/ui/dialogs/connection/ConnectionPageWithAuth.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""plugins/org.jkiss.dbeaver.ui/src/org/jkiss/dbeaver/ui/controls/autorefresh/AutoRefreshConfigDialog.java"",\n    ""plugins/org.jkiss.dbeaver.ui/src/org/jkiss/dbeaver/ui/controls/autorefresh/AutoRefreshControl.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""plugins/org.jkiss.dbeaver.ext.generic/src/org/jkiss/dbeaver/ext/generic/model/meta/GenericMetaModel.java"",\n    ""plugins/org.jkiss.dbeaver.ext.generic/src/org/jkiss/dbeaver/ext/generic/model/meta/GenericMetaModelDescriptor.java"",\n    ""plugins/org.jkiss.dbeaver.ext.generic/src/org/jkiss/dbeaver/ext/generic/model/meta/GenericMetaObject.java"",\n    ""plugins/org.jkiss.dbeaver.ext.hana.ui/src/org/jkiss/dbeaver/ext/hana/ui/config/HANASchemaConfigurator.java"",\n    ""plugins/org.jkiss.dbeaver.ext.hana.ui/src/org/jkiss/dbeaver/ext/hana/ui/views/HANAConnectionPage.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""plugins/org.jkiss.dbeaver.ext.snowflake.core/src/org/jkiss/dbeaver/ext/snowflake/model/auth/AuthModelSnowflakeCredentials.java"",\n    ""plugins/org.jkiss.dbeaver.ext.snowflake.core/src/org/jkiss/dbeaver/ext/snowflake/model/auth/SnowflakeAuthModelSnowflake.java"",\n    ""plugins/org.jkiss.dbeaver.ext.snowflake.ui/src/org/jkiss/dbeaver/ext/snowflake/ui/config/SnowflakeAuthSnowflakeConfigurator.java"",\n    ""plugins/org.jkiss.dbeaver.ext.snowflake.ui/src/org/jkiss/dbeaver/ext/snowflake/ui/internal/SnowflakeMessages.java"",\n    ""plugins/org.jkiss.dbeaver.ext.snowflake.ui/src/org/jkiss/dbeaver/ext/snowflake/ui/internal/SnowflakeUIActivator.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""plugins/org.jkiss.dbeaver.net.ssh/src/org/jkiss/dbeaver/model/net/ssh/config/SSHAuthConfiguration.java"",\n    ""plugins/org.jkiss.dbeaver.net.ssh/src/org/jkiss/dbeaver/model/net/ssh/config/SSHHostConfiguration.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/convert/impl/SourceCodeSQLConverter.java"",\n    ""plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/convert/impl/UnformattedSQLConverter.java"",\n    ""plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/convert/impl/JavaSQLConverter.java"",\n    ""plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/convert/impl/PythonCodeConverter.java"",\n    ""plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/convert/impl/CPPSQLConverter.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/preferences/format/SQLExternalFormatterConfigurationPage.java"",\n    ""plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/preferences/format/SQLFormatterConfigurator.java"",\n    ""plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/preferences/format/tokenized/SQLTokenizedFormatterConfigurationPage.java"",\n    ""plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/preferences/format/BaseFormatterConfigurationPage.java"",\n    ""plugins/org.jkiss.dbeaver.ui.editors.sql/src/org/jkiss/dbeaver/ui/editors/sql/plan/simple/SQLPlanViewProviderSimple.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""plugins/org.jkiss.dbeaver.net.ssh/src/org/jkiss/dbeaver/model/net/ssh/config/SSHHostConfiguration.java"",\n    ""plugins/org.jkiss.dbeaver.net.ssh/src/org/jkiss/dbeaver/model/net/ssh/SSHUtils.java"",\n    ""plugins/org.jkiss.dbeaver.ui.editors.connection/src/org/jkiss/dbeaver/ui/dialogs/connection/ConnectionPageWithAuth.java"",\n    ""plugins/org.jkiss.dbeaver.ui.editors.connection/src/org/jkiss/dbeaver/ui/dialogs/connection/ConnectionPageAbstract.java"",\n    ""plugins/org.jkiss.dbeaver.ui.editors.connection/src/org/jkiss/dbeaver/ui/dialogs/connection/ConnectionPageNetworkHandler.java""\n  ]\n}\n```']",17,39547.34802246094
1658,square/leakcanary/458/449,square,leakcanary,https://github.com/square/leakcanary/issues/449,https://github.com/square/leakcanary/pull/458,https://github.com/square/leakcanary/pull/458,1,fixes,NullPointerException in LeakCanaryInternals.isInServiceProcess(),"It looks like ActivityManager.getRunningAppProcesses can return null: http://developer.android.com/reference/android/app/ActivityManager.html#getRunningAppProcesses()

LeakCanaryInternals.isInServiceProcess() doesn't seem to check for this case.

Stack trace excerpt:

java.lang.RuntimeException: Unable to create application [...]: java.lang.NullPointerException: Attempt to invoke interface method 'java.util.Iterator java.util.List.iterator()' on a null object reference
    at android.app.ActivityThread.handleBindApplication(ActivityThread.java:4710)
    at android.app.ActivityThread.-wrap1(ActivityThread.java)
    at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1405)
    at android.os.Handler.dispatchMessage(Handler.java:102)
    at android.os.Looper.loop(Looper.java:148)
    at android.app.ActivityThread.main(ActivityThread.java:5417)
    at java.lang.reflect.Method.invoke(Native Method)
    at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:726)
    at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:616)
Caused by: java.lang.NullPointerException: Attempt to invoke interface method 'java.util.Iterator java.util.List.iterator()' on a null object reference
    at com.squareup.leakcanary.internal.LeakCanaryInternals.isInServiceProcess(LeakCanaryInternals.java:117)
    at com.squareup.leakcanary.LeakCanary.isInAnalyzerProcess(LeakCanary.java:237)
    at com.squareup.leakcanary.LeakCanary.install(LeakCanary.java:77)
    at com.squareup.leakcanary.LeakCanary.install(LeakCanary.java:42)
[...]
",462561d249bddf5a28439bc588a7cb026a8425bf,efa41ac38b4fa4d48df06d011730a7ffdc8eb0d0,https://github.com/square/leakcanary/compare/462561d249bddf5a28439bc588a7cb026a8425bf...efa41ac38b4fa4d48df06d011730a7ffdc8eb0d0,"diff --git a/leakcanary-android/src/main/java/com/squareup/leakcanary/internal/LeakCanaryInternals.java b/leakcanary-android/src/main/java/com/squareup/leakcanary/internal/LeakCanaryInternals.java
index b334079f4..973b1b84d 100644
--- a/leakcanary-android/src/main/java/com/squareup/leakcanary/internal/LeakCanaryInternals.java
+++ b/leakcanary-android/src/main/java/com/squareup/leakcanary/internal/LeakCanaryInternals.java
@@ -29,6 +29,7 @@ import android.content.pm.ServiceInfo;
 import com.squareup.leakcanary.CanaryLog;
 import com.squareup.leakcanary.R;
 import java.lang.reflect.Method;
+import java.util.List;
 import java.util.concurrent.Executor;
 import java.util.concurrent.Executors;
 
@@ -114,10 +115,14 @@ public final class LeakCanaryInternals {
     ActivityManager activityManager =
         (ActivityManager) context.getSystemService(Context.ACTIVITY_SERVICE);
     ActivityManager.RunningAppProcessInfo myProcess = null;
-    for (ActivityManager.RunningAppProcessInfo process : activityManager.getRunningAppProcesses()) {
-      if (process.pid == myPid) {
-        myProcess = process;
-        break;
+    List<ActivityManager.RunningAppProcessInfo> runningProcesses =
+        activityManager.getRunningAppProcesses();
+    if (runningProcesses != null) {
+      for (ActivityManager.RunningAppProcessInfo process : runningProcesses) {
+        if (process.pid == myPid) {
+          myProcess = process;
+          break;
+        }
       }
     }
     if (myProcess == null) {",['leakcanary-android/src/main/java/com/squareup/leakcanary/internal/LeakCanaryInternals.java'],{'.java': 1},1,1,0,0,1,170559,37251,4662,43,540,112,13,1,1565,81,361,23,1,0,2016-03-20 00:29:29,28557,Kotlin,"{'Kotlin': 1363625, 'Java': 4762, 'Shell': 481, 'AIDL': 203}",Apache License 2.0,"['leakcanary-android/src/main/java/com/squareup/leakcanary/internal/LeakCanaryInternals.java', 'leakcanary-android/src/main/java/com/squareup/leakcanary/LeakCanary.java']","['leakcanary-android/src/main/java/com/squareup/leakcanary/internal/LeakCanaryInternals.java', 'leakcanary-android/src/main/java/com/squareup/leakcanary/LeakCanary.java']","['```json\n{\n  ""files"": [\n    ""leakcanary-android/src/main/java/com/squareup/leakcanary/internal/LeakCanaryInternals.java"",\n    ""leakcanary-android/src/main/java/com/squareup/leakcanary/LeakCanary.java""\n  ]\n}\n```']",1,958.547830581665
985,alibaba/spring-cloud-alibaba/46/42,alibaba,spring-cloud-alibaba,https://github.com/alibaba/spring-cloud-alibaba/issues/42,https://github.com/alibaba/spring-cloud-alibaba/pull/46,https://github.com/alibaba/spring-cloud-alibaba/pull/46,1,fixes,Setting false on autoRegister of @EnableDiscoveryClient will throw exception and application failed to start,"Description:

Field nacosRegistration in org.springframework.cloud.alibaba.nacos.NacosDiscoveryClient required a bean of type 'org.springframework.cloud.alibaba.nacos.registry.NacosRegistration' that could not be found.
	- Bean method 'nacosRegistration' not loaded because @ConditionalOnProperty (spring.cloud.service-registry.auto-registration.enabled) found different value in property 'spring.cloud.service-registry.auto-registration.enabled'",0f444a40abbe830b108478e9e18f9a74d845f862,27ddaa68a81214832a0351db439eabbef9aed7ec,https://github.com/alibaba/spring-cloud-alibaba/compare/0f444a40abbe830b108478e9e18f9a74d845f862...27ddaa68a81214832a0351db439eabbef9aed7ec,"diff --git a/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryAutoConfiguration.java b/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryAutoConfiguration.java
index 78c7ddcc..6e087422 100644
--- a/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryAutoConfiguration.java
+++ b/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryAutoConfiguration.java
@@ -16,7 +16,6 @@
 
 package org.springframework.cloud.alibaba.nacos;
 
-import org.springframework.boot.autoconfigure.condition.ConditionalOnMissingBean;
 import org.springframework.boot.autoconfigure.AutoConfigureBefore;
 import org.springframework.boot.autoconfigure.condition.ConditionalOnBean;
 import org.springframework.boot.autoconfigure.condition.ConditionalOnClass;
@@ -48,12 +47,6 @@ public class NacosDiscoveryAutoConfiguration {
 		return new NacosServiceRegistry();
 	}
 
-	@Bean
-	@ConditionalOnMissingBean
-	public NacosDiscoveryProperties nacosProperties() {
-		return new NacosDiscoveryProperties();
-	}
-
 	@Bean
 	@ConditionalOnBean(AutoServiceRegistrationProperties.class)
 	public NacosRegistration nacosRegistration() {
diff --git a/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryClient.java b/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryClient.java
index f9acd947..bab4b1a2 100644
--- a/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryClient.java
+++ b/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryClient.java
@@ -19,13 +19,15 @@ package org.springframework.cloud.alibaba.nacos;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 import org.springframework.beans.factory.annotation.Autowired;
-import org.springframework.cloud.alibaba.nacos.registry.NacosRegistration;
+import org.springframework.cloud.client.DefaultServiceInstance;
 import org.springframework.cloud.client.ServiceInstance;
 import org.springframework.cloud.client.discovery.DiscoveryClient;
+import org.springframework.core.env.Environment;
 
-import java.net.URI;
 import java.util.*;
 
+import javax.annotation.PostConstruct;
+
 import com.alibaba.nacos.api.naming.NamingService;
 import com.alibaba.nacos.api.naming.pojo.Instance;
 import com.alibaba.nacos.api.naming.pojo.ListView;
@@ -40,52 +42,37 @@ public class NacosDiscoveryClient implements DiscoveryClient {
 	public static final String DESCRIPTION = ""Spring Cloud Nacos Discovery Client"";
 
 	@Autowired
-	private NacosRegistration nacosRegistration;
+	private NacosDiscoveryProperties discoveryProperties;
+
+	@Autowired
+	private Environment environment;
+
+	private NamingService namingService;
 
 	@Override
 	public String description() {
 		return DESCRIPTION;
 	}
 
+	@PostConstruct
+	public void init() {
+		discoveryProperties.overrideFromEnv(environment);
+		namingService = discoveryProperties.getNamingService();
+	}
+
 	@Override
 	public ServiceInstance getLocalServiceInstance() {
-		return new ServiceInstance() {
-			@Override
-			public String getServiceId() {
-				return nacosRegistration.getServiceId();
-			}
-
-			@Override
-			public String getHost() {
-				return nacosRegistration.getHost();
-			}
-
-			@Override
-			public int getPort() {
-				return nacosRegistration.getPort();
-			}
-
-			@Override
-			public boolean isSecure() {
-				return nacosRegistration.isSecure();
-			}
-
-			@Override
-			public URI getUri() {
-				return nacosRegistration.getUri();
-			}
-
-			@Override
-			public Map<String, String> getMetadata() {
-				return nacosRegistration.getMetadata();
-			}
-		};
+		String serviceId = discoveryProperties.getService();
+		String host = discoveryProperties.getIp();
+		int port = discoveryProperties.getPort();
+		boolean secure = discoveryProperties.isSecure();
+		Map<String, String> metadata = discoveryProperties.getMetadata();
+		return new DefaultServiceInstance(serviceId, host, port, secure, metadata);
 	}
 
 	@Override
 	public List<ServiceInstance> getInstances(String serviceId) {
 		try {
-			NamingService namingService = nacosRegistration.getNacosNamingService();
 			List<Instance> instances = namingService.getAllInstances(serviceId);
 			return hostToServiceInstanceList(instances, serviceId);
 		}
@@ -126,7 +113,6 @@ public class NacosDiscoveryClient implements DiscoveryClient {
 	public List<String> getServices() {
 
 		try {
-			NamingService namingService = nacosRegistration.getNacosNamingService();
 			ListView<String> services = namingService.getServicesOfServer(1,
 					Integer.MAX_VALUE);
 			return services.getData();
@@ -137,4 +123,7 @@ public class NacosDiscoveryClient implements DiscoveryClient {
 		}
 	}
 
+	public NamingService getNamingService() {
+		return namingService;
+	}
 }
diff --git a/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryClientAutoConfiguration.java b/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryClientAutoConfiguration.java
index 2563cbe6..05049f4b 100644
--- a/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryClientAutoConfiguration.java
+++ b/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryClientAutoConfiguration.java
@@ -36,4 +36,10 @@ public class NacosDiscoveryClientAutoConfiguration {
 		return new NacosDiscoveryClient();
 	}
 
+	@Bean
+	@ConditionalOnMissingBean
+	public NacosDiscoveryProperties nacosProperties() {
+		return new NacosDiscoveryProperties();
+	}
+
 }
diff --git a/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryProperties.java b/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryProperties.java
index 43b6a5c7..aa9271a8 100644
--- a/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryProperties.java
+++ b/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryProperties.java
@@ -16,6 +16,8 @@
 
 package org.springframework.cloud.alibaba.nacos;
 
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
 import org.springframework.beans.factory.annotation.Autowired;
 import org.springframework.beans.factory.annotation.Value;
 import org.springframework.boot.context.properties.ConfigurationProperties;
@@ -33,6 +35,18 @@ import java.util.Enumeration;
 import java.util.HashMap;
 import java.util.Map;
 import java.util.Objects;
+import java.util.Properties;
+
+import com.alibaba.nacos.api.NacosFactory;
+import com.alibaba.nacos.api.naming.NamingService;
+import com.alibaba.nacos.client.naming.utils.UtilAndComs;
+
+import static com.alibaba.nacos.api.PropertyKeyConst.ACCESS_KEY;
+import static com.alibaba.nacos.api.PropertyKeyConst.CLUSTER_NAME;
+import static com.alibaba.nacos.api.PropertyKeyConst.ENDPOINT;
+import static com.alibaba.nacos.api.PropertyKeyConst.NAMESPACE;
+import static com.alibaba.nacos.api.PropertyKeyConst.SECRET_KEY;
+import static com.alibaba.nacos.api.PropertyKeyConst.SERVER_ADDR;
 
 /**
  * @author dungu.zpf
@@ -42,6 +56,9 @@ import java.util.Objects;
 @ConfigurationProperties(""spring.cloud.nacos.discovery"")
 public class NacosDiscoveryProperties {
 
+	private static final Logger LOGGER = LoggerFactory
+			.getLogger(NacosDiscoveryProperties.class);
+
 	/**
 	 * nacos discovery server address
 	 */
@@ -333,4 +350,22 @@ public class NacosDiscoveryProperties {
 		}
 	}
 
+	public NamingService getNamingService() {
+		Properties properties = new Properties();
+		properties.put(SERVER_ADDR, serverAddr);
+		properties.put(NAMESPACE, namespace);
+		properties.put(UtilAndComs.NACOS_NAMING_LOG_NAME, logName);
+		properties.put(ENDPOINT, endpoint);
+		properties.put(ACCESS_KEY, accessKey);
+		properties.put(SECRET_KEY, secretKey);
+		properties.put(CLUSTER_NAME, clusterName);
+		try {
+			return NacosFactory.createNamingService(properties);
+		}
+		catch (Exception e) {
+			LOGGER.error(""create naming service error!properties={},e=,"", this, e);
+			return null;
+		}
+	}
+
 }
diff --git a/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/endpoint/NacosDiscoveryEndpoint.java b/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/endpoint/NacosDiscoveryEndpoint.java
index a68f6300..dfa1fbb6 100644
--- a/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/endpoint/NacosDiscoveryEndpoint.java
+++ b/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/endpoint/NacosDiscoveryEndpoint.java
@@ -28,8 +28,8 @@ import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 import org.springframework.beans.factory.annotation.Autowired;
 import org.springframework.boot.actuate.endpoint.AbstractEndpoint;
+import org.springframework.cloud.alibaba.nacos.NacosDiscoveryClient;
 import org.springframework.cloud.alibaba.nacos.NacosDiscoveryProperties;
-import org.springframework.cloud.alibaba.nacos.registry.NacosRegistration;
 
 /**
  * Endpoint for nacos discovery, get nacos properties and subscribed services
@@ -44,7 +44,7 @@ public class NacosDiscoveryEndpoint extends AbstractEndpoint<Map<String, Object>
 	private NacosDiscoveryProperties nacosDiscoveryProperties;
 
 	@Autowired
-	private NacosRegistration nacosRegistration;
+	private NacosDiscoveryClient discoveryClient;
 
 	public NacosDiscoveryEndpoint() {
 		super(""nacos_discovery"", false);
@@ -58,7 +58,7 @@ public class NacosDiscoveryEndpoint extends AbstractEndpoint<Map<String, Object>
 		Map<String, Object> result = new HashMap<>();
 		result.put(""NacosDiscoveryProperties"", nacosDiscoveryProperties);
 
-		NamingService namingService = nacosRegistration.getNacosNamingService();
+		NamingService namingService = discoveryClient.getNamingService();
 		List<ServiceInfo> subscribe = Collections.emptyList();
 
 		try {
diff --git a/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/endpoint/NacosDiscoveryEndpointAutoConfiguration.java b/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/endpoint/NacosDiscoveryEndpointAutoConfiguration.java
index 5278cd3b..eab95411 100644
--- a/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/endpoint/NacosDiscoveryEndpointAutoConfiguration.java
+++ b/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/endpoint/NacosDiscoveryEndpointAutoConfiguration.java
@@ -26,7 +26,6 @@ import org.springframework.context.annotation.Configuration;
  * @author xiaojing
  */
 @Configuration
-@ConditionalOnProperty(value = ""spring.cloud.service-registry.auto-registration.enabled"", matchIfMissing = true)
 @ConditionalOnClass(name = ""org.springframework.boot.actuate.endpoint.AbstractEndpoint"")
 public class NacosDiscoveryEndpointAutoConfiguration {
 
diff --git a/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/registry/NacosRegistration.java b/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/registry/NacosRegistration.java
index 1fc12d7f..872d7dd8 100644
--- a/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/registry/NacosRegistration.java
+++ b/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/registry/NacosRegistration.java
@@ -28,15 +28,10 @@ import org.springframework.util.StringUtils;
 
 import java.net.URI;
 import java.util.Map;
-import java.util.Properties;
 
 import javax.annotation.PostConstruct;
 
-import com.alibaba.nacos.api.NacosFactory;
 import com.alibaba.nacos.api.naming.NamingService;
-import com.alibaba.nacos.client.naming.utils.UtilAndComs;
-
-import static com.alibaba.nacos.api.PropertyKeyConst.*;
 
 /**
  * @author xiaojing
@@ -60,22 +55,7 @@ public class NacosRegistration implements Registration, ServiceInstance {
 
 		Environment env = context.getEnvironment();
 		nacosDiscoveryProperties.overrideFromEnv(context.getEnvironment());
-
-		Properties properties = new Properties();
-		properties.put(SERVER_ADDR, nacosDiscoveryProperties.getServerAddr());
-		properties.put(NAMESPACE, nacosDiscoveryProperties.getNamespace());
-		properties.put(UtilAndComs.NACOS_NAMING_LOG_NAME,
-				nacosDiscoveryProperties.getLogName());
-		properties.put(ENDPOINT, nacosDiscoveryProperties.getEndpoint());
-		properties.put(ACCESS_KEY, nacosDiscoveryProperties.getAccessKey());
-		properties.put(SECRET_KEY, nacosDiscoveryProperties.getSecretKey());
-		properties.put(CLUSTER_NAME, nacosDiscoveryProperties.getClusterName());
-		try {
-			nacosNamingService = NacosFactory.createNamingService(properties);
-		}
-		catch (Exception e) {
-
-		}
+		nacosNamingService = nacosDiscoveryProperties.getNamingService();
 
 		Integer managementPort = ManagementServerPortUtils.getPort(context);
 		if (null != managementPort) {
diff --git a/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/ribbon/NacosServerList.java b/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/ribbon/NacosServerList.java
index 3eb43bbc..c85339c3 100644
--- a/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/ribbon/NacosServerList.java
+++ b/spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/ribbon/NacosServerList.java
@@ -19,7 +19,9 @@ package org.springframework.cloud.alibaba.nacos.ribbon;
 import com.netflix.client.config.IClientConfig;
 import com.netflix.loadbalancer.AbstractServerList;
 import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.cloud.alibaba.nacos.NacosDiscoveryClient;
 import org.springframework.cloud.alibaba.nacos.registry.NacosRegistration;
+import org.springframework.cloud.client.discovery.DiscoveryClient;
 
 import java.util.ArrayList;
 import java.util.List;
@@ -32,7 +34,7 @@ import com.alibaba.nacos.api.naming.pojo.Instance;
 public class NacosServerList extends AbstractServerList<NacosServer> {
 
 	@Autowired
-	private NacosRegistration registration;
+	private NacosDiscoveryClient discoveryClient;
 
 	private String serviceId;
 
@@ -55,7 +57,7 @@ public class NacosServerList extends AbstractServerList<NacosServer> {
 
 	private List<NacosServer> getServers() {
 		try {
-			List<Instance> instances = registration.getNacosNamingService()
+			List<Instance> instances = discoveryClient.getNamingService()
 					.getAllInstances(serviceId);
 			return instancesToServerList(instances);
 		}
diff --git a/spring-cloud-alibaba-nacos-discovery/src/test/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryAutoConfigurationTests.java b/spring-cloud-alibaba-nacos-discovery/src/test/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryAutoConfigurationTests.java
index 1fe9fdaa..4be0dd92 100644
--- a/spring-cloud-alibaba-nacos-discovery/src/test/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryAutoConfigurationTests.java
+++ b/spring-cloud-alibaba-nacos-discovery/src/test/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryAutoConfigurationTests.java
@@ -42,6 +42,7 @@ public class NacosDiscoveryAutoConfigurationTests {
 	@Before
 	public void setUp() throws Exception {
 		this.context = new SpringApplicationBuilder(NacosDiscoveryTestConfiguration.class,
+				NacosDiscoveryClientAutoConfiguration.class,
 				NacosDiscoveryAutoConfiguration.class).web(false).run(
 						""--spring.cloud.nacos.discovery.server-addr=127.0.0.1:8080"",
 						""--spring.cloud.nacos.discovery.port=18080"",
diff --git a/spring-cloud-alibaba-nacos-discovery/src/test/java/org/springframework/cloud/alibaba/nacos/ribbon/NacosRibbonClientConfigurationTests.java b/spring-cloud-alibaba-nacos-discovery/src/test/java/org/springframework/cloud/alibaba/nacos/ribbon/NacosRibbonClientConfigurationTests.java
index f0354b34..c0f808d9 100644
--- a/spring-cloud-alibaba-nacos-discovery/src/test/java/org/springframework/cloud/alibaba/nacos/ribbon/NacosRibbonClientConfigurationTests.java
+++ b/spring-cloud-alibaba-nacos-discovery/src/test/java/org/springframework/cloud/alibaba/nacos/ribbon/NacosRibbonClientConfigurationTests.java
@@ -9,6 +9,7 @@ import org.springframework.boot.autoconfigure.EnableAutoConfiguration;
 import org.springframework.boot.autoconfigure.condition.ConditionalOnMissingBean;
 import org.springframework.boot.builder.SpringApplicationBuilder;
 import org.springframework.cloud.alibaba.nacos.NacosDiscoveryAutoConfiguration;
+import org.springframework.cloud.alibaba.nacos.NacosDiscoveryClientAutoConfiguration;
 import org.springframework.cloud.alibaba.nacos.NacosDiscoveryProperties;
 import org.springframework.cloud.client.discovery.EnableDiscoveryClient;
 import org.springframework.cloud.client.loadbalancer.LoadBalanced;
@@ -33,6 +34,7 @@ public class NacosRibbonClientConfigurationTests {
 	public void setUp() throws Exception {
 		this.context = new SpringApplicationBuilder(NacosRibbonTestConfiguration.class,
 				NacosDiscoveryAutoConfiguration.class,
+				NacosDiscoveryClientAutoConfiguration.class,
 				NacosRibbonClientConfiguration.class, RibbonNacosAutoConfiguration.class)
 						.web(false).run(""--server.port=18080"",
 								""--spring.cloud.nacos.discovery.server-addr=127.0.0.1:8080"",","['spring-cloud-alibaba-nacos-discovery/src/test/java/org/springframework/cloud/alibaba/nacos/ribbon/NacosRibbonClientConfigurationTests.java', 'spring-cloud-alibaba-nacos-discovery/src/test/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryAutoConfigurationTests.java', 'spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryAutoConfiguration.java', 'spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/ribbon/NacosServerList.java', 'spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryClient.java', 'spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryClientAutoConfiguration.java', 'spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/endpoint/NacosDiscoveryEndpoint.java', 'spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/registry/NacosRegistration.java', 'spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/endpoint/NacosDiscoveryEndpointAutoConfiguration.java', 'spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryProperties.java']",{'.java': 10},10,10,0,0,10,178400,36270,5846,73,5326,1079,144,8,449,31,81,4,0,0,2018-10-17 04:38:34,26133,Java,"{'Java': 1218311, 'HTML': 9491, 'Shell': 2729, 'Dockerfile': 1686, 'JavaScript': 860}",Apache License 2.0,"['spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryAutoConfiguration.java', 'spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryClientAutoConfiguration.java', 'spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/registry/NacosServiceRegistry.java', 'spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/registry/NacosAutoServiceRegistration.java', 'spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/registry/NacosRegistration.java']","['spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryAutoConfiguration.java', 'spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryClientAutoConfiguration.java', 'spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/registry/NacosServiceRegistry.java', 'spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/registry/NacosAutoServiceRegistration.java', 'spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/registry/NacosRegistration.java']","['```json\n{\n  ""files"": [\n    ""spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/registry/NacosAutoServiceRegistration.java"",\n    ""spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/registry/NacosRegistration.java"",\n    ""spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/registry/NacosServiceRegistry.java"",\n    ""spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryAutoConfiguration.java"",\n    ""spring-cloud-alibaba-nacos-discovery/src/main/java/org/springframework/cloud/alibaba/nacos/NacosDiscoveryClientAutoConfiguration.java""\n  ]\n}\n```']",1,2463.2248878479004
564,google/gson/2364/904,google,gson,https://github.com/google/gson/issues/904,https://github.com/google/gson/pull/2364,https://github.com/google/gson/pull/2364,1,fixes,BigDecimal equals problem,"Dear developers, it looks like the primitive's equals to did not handle BigDecimal's comparison. The following test will fail:

```
  public void testUnequalDecimals() {
      JsonPrimitive small = new JsonPrimitive(1.0);
      JsonPrimitive large = new JsonPrimitive(2.0);
      assertFalse(""small = large"", small.equals(large));

      BigDecimal dmax = BigDecimal.valueOf(Double.MAX_VALUE);
      JsonPrimitive smallBD =        // dmax + 100.0
          new JsonPrimitive(dmax.add(new BigDecimal(""100.0"")));
      JsonPrimitive largeBD =        // dmax + 200.0
          new JsonPrimitive(dmax.add(new BigDecimal(""200.0"")));
      assertFalse(""small = large"", smallBD.equals(largeBD));
  }
```

Could you consider a fix for this, so it can support big decimal comparisons, too?

Thanks!
",051cb43fd9040a432626ef53523f1e7db7ab52c1,3c364b9c945c0e337b51b59fa60fc32355519ed7,https://github.com/google/gson/compare/051cb43fd9040a432626ef53523f1e7db7ab52c1...3c364b9c945c0e337b51b59fa60fc32355519ed7,"diff --git a/gson/src/main/java/com/google/gson/JsonPrimitive.java b/gson/src/main/java/com/google/gson/JsonPrimitive.java
index 827de959..f143da97 100644
--- a/gson/src/main/java/com/google/gson/JsonPrimitive.java
+++ b/gson/src/main/java/com/google/gson/JsonPrimitive.java
@@ -290,11 +290,10 @@ public final class JsonPrimitive extends JsonElement {
           : this.getAsNumber().longValue() == other.getAsNumber().longValue();
     }
     if (value instanceof Number && other.value instanceof Number) {
-      double a = getAsNumber().doubleValue();
-      // Java standard types other than double return true for two NaN. So, need
-      // special handling for double.
-      double b = other.getAsNumber().doubleValue();
-      return a == b || (Double.isNaN(a) && Double.isNaN(b));
+      return this.value instanceof BigDecimal && other.value instanceof BigDecimal
+          ? this.getAsBigDecimal().compareTo(other.getAsBigDecimal()) == 0
+          : this.getAsDouble() == other.getAsDouble()
+              || (Double.isNaN(this.getAsDouble()) && Double.isNaN(other.getAsDouble()));
     }
     return value.equals(other.value);
   }
diff --git a/gson/src/test/java/com/google/gson/JsonPrimitiveTest.java b/gson/src/test/java/com/google/gson/JsonPrimitiveTest.java
index 24947012..959313ad 100644
--- a/gson/src/test/java/com/google/gson/JsonPrimitiveTest.java
+++ b/gson/src/test/java/com/google/gson/JsonPrimitiveTest.java
@@ -316,4 +316,31 @@ public class JsonPrimitiveTest {
     JsonPrimitive a = new JsonPrimitive(""a"");
     assertThat(a).isSameInstanceAs(a.deepCopy()); // Primitives are immutable!
   }
+
+  @Test
+  public void testBigDecimalEquals() {
+    JsonPrimitive small = new JsonPrimitive(1.0);
+    JsonPrimitive large = new JsonPrimitive(2.0);
+    assertThat(small.equals(large)).isFalse();
+
+    BigDecimal doubleMax = BigDecimal.valueOf(Double.MAX_VALUE);
+    JsonPrimitive smallBD = new JsonPrimitive(doubleMax.add(new BigDecimal(""100.0"")));
+    JsonPrimitive largeBD = new JsonPrimitive(doubleMax.add(new BigDecimal(""200.0"")));
+    assertThat(smallBD.equals(largeBD)).isFalse();
+  }
+
+  @Test
+  public void testBigDecimalEqualsZero() {
+    assertThat(new JsonPrimitive(new BigDecimal(""0.0""))
+        .equals(new JsonPrimitive(new BigDecimal(""0.00"")))).isTrue();
+
+    assertThat(new JsonPrimitive(new BigDecimal(""0.00""))
+        .equals(new JsonPrimitive(Double.valueOf(""0.00"")))).isTrue();
+  }
+
+  @Test
+  public void testEqualsDoubleNaNAndBigDecimal() {
+    assertThat(new JsonPrimitive(Double.NaN)
+        .equals(new JsonPrimitive(new BigDecimal(""1.0"")))).isFalse();
+  }
 }","['gson/src/test/java/com/google/gson/JsonPrimitiveTest.java', 'gson/src/main/java/com/google/gson/JsonPrimitive.java']",{'.java': 2},2,2,0,0,2,703753,158568,19868,100,588,119,9,1,790,84,183,21,0,1,2023-04-01 16:10:29,22315,Java,{'Java': 1674830},Apache License 2.0,['gson/src/main/java/com/google/gson/JsonPrimitive.java'],['gson/src/main/java/com/google/gson/JsonPrimitive.java'],"['```json\n{\n  ""files"": [\n    ""gson/src/main/java/com/google/gson/JsonPrimitive.java""\n  ]\n}\n```']",1,841.6612148284912
227,libgdx/libgdx/856/798,libgdx,libgdx,https://github.com/libgdx/libgdx/issues/798,https://github.com/libgdx/libgdx/pull/856,https://github.com/libgdx/libgdx/pull/856,1,fixes,Image are flipped in Particle Editor preview window,"To Reproduce:
- open particle editor
- open any image
- image is shown flipped upside down

However, when particle is saved then loaded from file image is shown normal.

It's also mentioned in this thread:
http://www.badlogicgames.com/forum/viewtopic.php?f=11&t=3370&p=16574&hilit=particle+flipped#p16574
",956c5671356974cab234cc1f8368f1ef583456a5,cf01bc29946f1b3bd9ab3e4f1c6f99078944da02,https://github.com/libgdx/libgdx/compare/956c5671356974cab234cc1f8368f1ef583456a5...cf01bc29946f1b3bd9ab3e4f1c6f99078944da02,"diff --git a/extensions/gdx-tools/src/com/badlogic/gdx/tools/particleeditor/EffectPanel.java b/extensions/gdx-tools/src/com/badlogic/gdx/tools/particleeditor/EffectPanel.java
index 04fa9b42d..9cb496f2f 100644
--- a/extensions/gdx-tools/src/com/badlogic/gdx/tools/particleeditor/EffectPanel.java
+++ b/extensions/gdx-tools/src/com/badlogic/gdx/tools/particleeditor/EffectPanel.java
@@ -65,7 +65,6 @@ class EffectPanel extends JPanel {
 		emitter.getTint().setColors(new float[] {1, 0.12156863f, 0.047058824f});
 		emitter.getTransparency().setHigh(1);
 
-		emitter.setFlip(false, true);
 		emitter.setMaxParticleCount(25);
 		emitter.setImagePath(""particle.png"");
 
@@ -107,7 +106,6 @@ class EffectPanel extends JPanel {
 		emitter.getTransparency().setTimeline(new float[] {0, 0.2f, 0.8f, 1});
 		emitter.getTransparency().setScaling(new float[] {0, 1, 0.75f, 0});
 		
-		emitter.setFlip(false, true);
 		emitter.setMaxParticleCount(200);
 		emitter.setImagePath(""particle.png"");
 		",['extensions/gdx-tools/src/com/badlogic/gdx/tools/particleeditor/EffectPanel.java'],{'.java': 1},1,1,0,0,1,10173648,2601633,291201,1754,67,19,2,1,305,37,79,10,1,0,2013-10-22 11:21:46,21772,Java,"{'Java': 15083440, 'C++': 10753718, 'C': 1692234, 'SWIG': 162005, 'GLSL': 124461, 'CSS': 58715, 'Assembly': 53505, 'CMake': 31706, 'Ragel': 30666, 'OpenEdge ABL': 17727, 'Lua': 1682, 'HTML': 1193, 'Shell': 1102}",Apache License 2.0,"['extensions/gdx-tools/src/com/badlogic/gdx/tools/particleeditor/ImagePanel.java', 'gdx/src/com/badlogic/gdx/graphics/g2d/ParticleEffect.java', 'gdx/src/com/badlogic/gdx/physics/bullet/btMotionState.java', 'com/badlogic/gdx/graphics/g2d/ParticleEmitter.java', 'gdx/src/com/badlogic/gdx/graphics/g2d/ParticleEmitterBox2D.java', 'backends/gdx-backends-gwt/src/com/badlogic/gdx/backends/gwt/emu/com/badlogic/gdx/physics/box2d/joints/WheelJointDef.java', 'gdx/src/com/badlogic/gdx/physics/bullet/btRigidBodyConstructionInfo.java', 'com/badlogic/gdx/graphics/g2d/ParticleEffectLoader.java', 'gdx/src/com/badlogic/gdx/graphics/g2d/ParticleEmitter.java', 'gdx/src/com/badlogic/gdx/physics/bullet/btRigidBody.java', 'gdx/src/com/badlogic/gdx/physics/bullet/btDefaultMotionState.java', 'com/badlogic/gdx/graphics/g2d/ParticleEffect.java', 'extensions/gdx-tools/src/com/badlogic/gdx/tools/particleeditor/ParticleEditor.java', 'gdx/src/com/badlogic/gdx/physics/bullet/btRigidBodyDoubleData.java', 'com/badlogic/gdx/graphics/g2d/ParticleEmitterLoader.java']","['gdx/src/com/badlogic/gdx/graphics/g2d/ParticleEmitter.java', 'extensions/gdx-tools/src/com/badlogic/gdx/tools/particleeditor/ImagePanel.java', 'gdx/src/com/badlogic/gdx/graphics/g2d/ParticleEffect.java', 'extensions/gdx-tools/src/com/badlogic/gdx/tools/particleeditor/ParticleEditor.java']","['```json\n{\n  ""files"": [\n    ""gdx/src/com/badlogic/gdx/graphics/g2d/ParticleEffect.java"",\n    ""gdx/src/com/badlogic/gdx/graphics/g2d/ParticleEmitter.java"",\n    ""gdx/src/com/badlogic/gdx/graphics/g2d/ParticleEmitterBox2D.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""extensions/gdx-tools/src/com/badlogic/gdx/tools/particleeditor/ParticleEditor.java"",\n    ""extensions/gdx-tools/src/com/badlogic/gdx/tools/particleeditor/ImagePanel.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""gdx/src/com/badlogic/gdx/physics/bullet/btRigidBody.java"",\n    ""gdx/src/com/badlogic/gdx/physics/bullet/btRigidBodyDoubleData.java"",\n    ""gdx/src/com/badlogic/gdx/physics/bullet/btRigidBodyConstructionInfo.java"",\n    ""gdx/src/com/badlogic/gdx/physics/bullet/btMotionState.java"",\n    ""gdx/src/com/badlogic/gdx/physics/bullet/btDefaultMotionState.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""com/badlogic/gdx/graphics/g2d/ParticleEffect.java"",\n    ""com/badlogic/gdx/graphics/g2d/ParticleEffectLoader.java"",\n    ""com/badlogic/gdx/graphics/g2d/ParticleEmitter.java"",\n    ""com/badlogic/gdx/graphics/g2d/ParticleEmitterLoader.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""backends/gdx-backends-gwt/src/com/badlogic/gdx/backends/gwt/emu/com/badlogic/gdx/physics/box2d/joints/WheelJointDef.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""extensions/gdx-tools/src/com/badlogic/gdx/tools/particleeditor/ImagePanel.java"",\n    ""extensions/gdx-tools/src/com/badlogic/gdx/tools/particleeditor/ParticleEditor.java"",\n    ""gdx/src/com/badlogic/gdx/graphics/g2d/ParticleEmitter.java"",\n    ""gdx/src/com/badlogic/gdx/graphics/g2d/ParticleEffect.java""\n  ]\n}\n```']",5,10068.508386611938
3484,apache/shardingsphere/2352/2343,apache,shardingsphere,https://github.com/apache/shardingsphere/issues/2343,https://github.com/apache/shardingsphere/pull/2352,https://github.com/apache/shardingsphere/pull/2352,1,fixes,"Sharding-proxy Query result :extraneous data in ""D"" message ,reason: have chinese","## Bug Report

**For English only**, other languages will not accept.

Before report a bug, make sure you have:

- Searched open and closed [GitHub issues](https://github.com/sharding-sphere/sharding-sphere/issues).
- Read documentation: [ShardingSphere Doc](http://shardingsphere.io/document/current/en/overview/).

Please pay attention on issues you submitted, because we maybe need more details. 
If no response **more than 7 days** and we cannot reproduce it on current information, we will **close it**.

Please answer these questions before submitting your issue. Thanks!

### Which version of ShardingSphere did you use?
4.0.0-RC1
### Which project did you use? Sharding-JDBC or Sharding-Proxy?
Sharding-Proxy 
### Expected behavior
table data have Chinese .select * from table show error message :
extraneous data in ""D"" message
### Actual behavior
proxy backend POSTGRES , frontend postgres 
### Reason analyze (If you can)
reason Chinese , Postgres server_encoding ,client_encoding UTF-8
### Steps to reproduce the behavior, such as: SQL to execute, sharding rule configuration, when exception occur etc.
any table ,have Chinese is error.
### Example codes for reproduce this issue (such as a github link).",6c49107d434c31e5f95365bb1bfcbcd52f7f4585,a4adf6df82926c267a74fb287249106a9582715d,https://github.com/apache/shardingsphere/compare/6c49107d434c31e5f95365bb1bfcbcd52f7f4585...a4adf6df82926c267a74fb287249106a9582715d,"diff --git a/sharding-proxy/sharding-proxy-transport/sharding-proxy-transport-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/transport/postgresql/packet/command/query/text/PostgreSQLDataRowPacket.java b/sharding-proxy/sharding-proxy-transport/sharding-proxy-transport-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/transport/postgresql/packet/command/query/text/PostgreSQLDataRowPacket.java
index ee4b0ac0032..9eabe5a9c31 100644
--- a/sharding-proxy/sharding-proxy-transport/sharding-proxy-transport-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/transport/postgresql/packet/command/query/text/PostgreSQLDataRowPacket.java
+++ b/sharding-proxy/sharding-proxy-transport/sharding-proxy-transport-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/transport/postgresql/packet/command/query/text/PostgreSQLDataRowPacket.java
@@ -50,7 +50,7 @@ public final class PostgreSQLDataRowPacket implements PostgreSQLPacket {
                     payload.writeBytes((byte[]) each);
                 } else {
                     String columnData = each.toString();
-                    payload.writeInt4(columnData.length());
+                    payload.writeInt4(columnData.getBytes().length);
                     payload.writeStringEOF(columnData);
                 }
             }",['sharding-proxy/sharding-proxy-transport/sharding-proxy-transport-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/transport/postgresql/packet/command/query/text/PostgreSQLDataRowPacket.java'],{'.java': 1},1,1,0,0,1,3278405,662802,82927,1137,130,18,2,1,1243,169,277,28,2,0,2019-05-08 09:25:56,18658,Java,"{'Java': 22772685, 'ANTLR': 1011078, 'FreeMarker': 120878, 'Shell': 14522, 'Dockerfile': 13922, 'Batchfile': 3214}",Apache License 2.0,"['sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/communication/DatabaseCommunicationEngineFactory.java', 'sharding-proxy/sharding-proxy-transport/sharding-proxy-transport-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/transport/postgresql/constant/PostgreSQLColumnType.java', 'sharding-proxy/sharding-proxy-frontend/sharding-proxy-frontend-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/frontend/postgresql/auth/PostgreSQLAuthenticationEngine.java', 'sharding-proxy/sharding-proxy-transport/sharding-proxy-transport-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/transport/postgresql/packet/command/query/binary/bind/protocol/PostgreSQLInt4BinaryProtocolValue.java', 'sharding-proxy/sharding-proxy-transport/sharding-proxy-transport-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/transport/postgresql/packet/command/query/binary/bind/protocol/PostgreSQLStringBinaryProtocolValue.java', 'sharding-proxy/sharding-proxy-frontend/sharding-proxy-frontend-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/frontend/postgresql/command/PostgreSQLCommandExecuteEngine.java', 'sharding-proxy/sharding-proxy-transport/sharding-proxy-transport-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/transport/postgresql/packet/command/query/binary/bind/protocol/PostgreSQLDoubleBinaryProtocolValue.java', 'sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/communication/jdbc/recognizer/impl/PostgreSQLRecognizer.java', 'sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/communication/DatabaseCommunicationEngine.java', 'sharding-proxy/sharding-proxy-frontend/sharding-proxy-frontend-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/frontend/postgresql/command/query/text/PostgreSQLComQueryExecutor.java', 'sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/text/TextProtocolBackendHandler.java', 'sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/response/BackendResponse.java', 'sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/text/TextProtocolBackendHandlerFactory.java', 'sharding-proxy-transport-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/transport/postgresql/packet/command/query/binary/bind/protocol/PostgreSQLTimeBinaryProtocolValue.java', 'sharding-proxy/sharding-proxy-frontend/sharding-proxy-frontend-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/frontend/postgresql/codec/PostgreSQLPacketCodecEngine.java', 'sharding-proxy/sharding-proxy-frontend/sharding-proxy-frontend-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/frontend/postgresql/command/PostgreSQLCommandExecutorFactory.java', 'sharding-proxy/sharding-proxy-transport/sharding-proxy-transport-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/transport/postgresql/packet/PostgreSQLPacket.java', 'sharding-proxy/sharding-proxy-transport/sharding-proxy-transport-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/transport/postgresql/packet/command/query/binary/bind/protocol/PostgreSQLInt8BinaryProtocolValue.java', 'sharding-proxy/sharding-proxy-frontend/sharding-proxy-frontend-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/frontend/postgresql/constant/PostgreSQLColumnType.java', 'sharding-proxy/sharding-proxy-transport/sharding-proxy-transport-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/transport/postgresql/payload/PostgreSQLPacketPayload.java', 'sharding-proxy/sharding-proxy-transport/sharding-proxy-transport-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/transport/postgresql/packet/command/query/binary/bind/protocol/PostgreSQLInt2BinaryProtocolValue.java']","['sharding-proxy/sharding-proxy-frontend/sharding-proxy-frontend-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/frontend/postgresql/command/query/text/PostgreSQLComQueryExecutor.java', 'sharding-proxy/sharding-proxy-transport/sharding-proxy-transport-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/transport/postgresql/packet/command/query/binary/bind/protocol/PostgreSQLInt4BinaryProtocolValue.java', 'sharding-proxy/sharding-proxy-transport/sharding-proxy-transport-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/transport/postgresql/packet/command/query/binary/bind/protocol/PostgreSQLStringBinaryProtocolValue.java', 'sharding-proxy/sharding-proxy-frontend/sharding-proxy-frontend-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/frontend/postgresql/command/PostgreSQLCommandExecuteEngine.java', 'sharding-proxy/sharding-proxy-frontend/sharding-proxy-frontend-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/frontend/postgresql/auth/PostgreSQLAuthenticationEngine.java']","['```json\n{\n  ""files"": [\n    ""sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/communication/DatabaseCommunicationEngine.java"",\n    ""sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/communication/DatabaseCommunicationEngineFactory.java"",\n    ""sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/response/BackendResponse.java"",\n    ""sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/text/TextProtocolBackendHandler.java"",\n    ""sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/text/TextProtocolBackendHandlerFactory.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""sharding-proxy/sharding-proxy-frontend/sharding-proxy-frontend-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/frontend/postgresql/auth/PostgreSQLAuthenticationEngine.java"",\n    ""sharding-proxy/sharding-proxy-frontend/sharding-proxy-frontend-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/frontend/postgresql/command/PostgreSQLCommandExecuteEngine.java"",\n    ""sharding-proxy/sharding-proxy-frontend/sharding-proxy-frontend-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/frontend/postgresql/command/PostgreSQLCommandExecutorFactory.java"",\n    ""sharding-proxy/sharding-proxy-frontend/sharding-proxy-frontend-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/frontend/postgresql/codec/PostgreSQLPacketCodecEngine.java"",\n    ""sharding-proxy/sharding-proxy-frontend/sharding-proxy-frontend-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/frontend/postgresql/constant/PostgreSQLColumnType.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""sharding-proxy/sharding-proxy-transport/sharding-proxy-transport-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/transport/postgresql/constant/PostgreSQLColumnType.java"",\n    ""sharding-proxy/sharding-proxy-transport/sharding-proxy-transport-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/transport/postgresql/packet/PostgreSQLPacket.java"",\n    ""sharding-proxy/sharding-proxy-transport/sharding-proxy-transport-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/transport/postgresql/payload/PostgreSQLPacketPayload.java"",\n    ""sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/communication/jdbc/recognizer/impl/PostgreSQLRecognizer.java"",\n    ""sharding-proxy/sharding-proxy-frontend/sharding-proxy-frontend-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/frontend/postgresql/command/query/text/PostgreSQLComQueryExecutor.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""sharding-proxy/sharding-proxy-transport/sharding-proxy-transport-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/transport/postgresql/packet/command/query/binary/bind/protocol/PostgreSQLStringBinaryProtocolValue.java"",\n    ""sharding-proxy/sharding-proxy-transport/sharding-proxy-transport-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/transport/postgresql/packet/command/query/binary/bind/protocol/PostgreSQLInt8BinaryProtocolValue.java"",\n    ""sharding-proxy/sharding-proxy-transport/sharding-proxy-transport-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/transport/postgresql/packet/command/query/binary/bind/protocol/PostgreSQLInt4BinaryProtocolValue.java"",\n    ""sharding-proxy/sharding-proxy-transport/sharding-proxy-transport-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/transport/postgresql/packet/command/query/binary/bind/protocol/PostgreSQLInt2BinaryProtocolValue.java"",\n    ""sharding-proxy/sharding-proxy-transport/sharding-proxy-transport-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/transport/postgresql/packet/command/query/binary/bind/protocol/PostgreSQLDoubleBinaryProtocolValue.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""sharding-proxy-transport-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/transport/postgresql/packet/command/query/binary/bind/protocol/PostgreSQLTimeBinaryProtocolValue.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""sharding-proxy/sharding-proxy-frontend/sharding-proxy-frontend-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/frontend/postgresql/auth/PostgreSQLAuthenticationEngine.java"",\n    ""sharding-proxy/sharding-proxy-frontend/sharding-proxy-frontend-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/frontend/postgresql/command/PostgreSQLCommandExecuteEngine.java"",\n    ""sharding-proxy/sharding-proxy-frontend/sharding-proxy-frontend-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/frontend/postgresql/command/query/text/PostgreSQLComQueryExecutor.java"",\n    ""sharding-proxy/sharding-proxy-transport/sharding-proxy-transport-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/transport/postgresql/packet/command/query/binary/bind/protocol/PostgreSQLInt4BinaryProtocolValue.java"",\n    ""sharding-proxy/sharding-proxy-transport/sharding-proxy-transport-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/transport/postgresql/packet/command/query/binary/bind/protocol/PostgreSQLStringBinaryProtocolValue.java""\n  ]\n}\n```']",5,16260.226249694824
3494,apache/shardingsphere/1987/1985,apache,shardingsphere,https://github.com/apache/shardingsphere/issues/1985,https://github.com/apache/shardingsphere/pull/1987,https://github.com/apache/shardingsphere/pull/1987,1,fixes,Exception fired during concurrently query,"## Bug Report

**For English only**, other languages will not accept.

Before report a bug, make sure you have:

- Searched open and closed [GitHub issues](https://github.com/sharding-sphere/sharding-sphere/issues).
- Read documentation: [ShardingSphere Doc](http://shardingsphere.io/document/current/en/overview/).

Please pay attention on issues you submitted, because we maybe need more details. 
If no response **more than 7 days** and we cannot reproduce it on current information, we will **close it**.

Please answer these questions before submitting your issue. Thanks!

### Which version of ShardingSphere did you use?
4.0.0-M1
### Which project did you use? Sharding-JDBC or Sharding-Proxy?
Sharding-Proxy
### Expected behavior
Execute query correctly.
### Actual behavior

Exception 1:
java.lang.NullPointerException: null
        at com.mysql.jdbc.ResultSetImpl.checkColumnBounds(ResultSetImpl.java:766)
        at com.mysql.jdbc.ResultSetImpl.getObject(ResultSetImpl.java:4420)
        at com.zaxxer.hikari.pool.HikariProxyResultSet.getObject(HikariProxyResultSet.java)
        at org.apache.shardingsphere.core.executor.sql.execute.result.StreamQueryResult.getValue(StreamQueryResult.java:75)
        at org.apache.shardingsphere.core.merger.dql.common.StreamMergedResult.getValue(StreamMergedResult.java:49)
        at org.apache.shardingsphere.shardingproxy.backend.communication.jdbc.JDBCDatabaseCommunicationEngine.getQueryData(JDBCDatabaseCommunicationEngine.java:149)
        at org.apache.shardingsphere.shardingproxy.transport.mysql.packet.command.query.binary.execute.MySQLQueryComStmtExecutePacketExecutor.getQueryData(MySQLQueryComStmtExecutePacketExecutor.java:1
13)
        at org.apache.shardingsphere.shardingproxy.transport.mysql.packet.command.query.binary.execute.MySQLQueryComStmtExecutePacketExecutor.getQueryData(MySQLQueryComStmtExecutePacketExecutor.java:5
3)
        at org.apache.shardingsphere.shardingproxy.frontend.mysql.MySQLFrontendEngine.writeMoreResults(MySQLFrontendEngine.java:152)
        at org.apache.shardingsphere.shardingproxy.frontend.mysql.MySQLFrontendEngine.writePackets(MySQLFrontendEngine.java:133)
        at org.apache.shardingsphere.shardingproxy.frontend.mysql.MySQLFrontendEngine.executeCommand(MySQLFrontendEngine.java:108)
        at org.apache.shardingsphere.shardingproxy.frontend.common.netty.FrontendChannelInboundHandler$1.run(FrontendChannelInboundHandler.java:70)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)










Exception 2:
java.sql.SQLException: Operation not allowed after ResultSet closed
        at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:965)
        at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:898)
        at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:887)
        at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:861)
        at com.mysql.jdbc.ResultSetImpl.checkClosed(ResultSetImpl.java:743)
        at com.mysql.jdbc.ResultSetImpl.next(ResultSetImpl.java:6289)
        at com.zaxxer.hikari.pool.HikariProxyResultSet.next(HikariProxyResultSet.java)
        at org.apache.shardingsphere.core.executor.sql.execute.result.StreamQueryResult.next(StreamQueryResult.java:68)
        at org.apache.shardingsphere.core.merger.dql.iterator.IteratorStreamMergedResult.next(IteratorStreamMergedResult.java:43)
        at org.apache.shardingsphere.shardingproxy.backend.communication.jdbc.JDBCDatabaseCommunicationEngine.next(JDBCDatabaseCommunicationEngine.java:141)
        at org.apache.shardingsphere.shardingproxy.transport.mysql.packet.command.query.binary.execute.MySQLQueryComStmtExecutePacketExecutor.next(MySQLQueryComStmtExecutePacketExecutor.java:108)
        at org.apache.shardingsphere.shardingproxy.frontend.mysql.MySQLFrontendEngine.writeMoreResults(MySQLFrontendEngine.java:147)
        at org.apache.shardingsphere.shardingproxy.frontend.mysql.MySQLFrontendEngine.writePackets(MySQLFrontendEngine.java:134)
        at org.apache.shardingsphere.shardingproxy.frontend.mysql.MySQLFrontendEngine.executeCommand(MySQLFrontendEngine.java:108)
        at org.apache.shardingsphere.shardingproxy.frontend.common.netty.FrontendChannelInboundHandler$1.run(FrontendChannelInboundHandler.java:70)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)












Exception 3:
[ERROR] 18:30:44.867 [ShardingSphere-Command-20] o.a.s.s.f.c.n.FrontendChannelInboundHandler - Exception occur:
java.sql.SQLException: null
        at org.apache.shardingsphere.shardingproxy.backend.communication.jdbc.connection.BackendConnection.throwSQLExceptionIfNecessary(BackendConnection.java:296)
        at org.apache.shardingsphere.shardingproxy.backend.communication.jdbc.connection.BackendConnection.close(BackendConnection.java:246)
        at org.apache.shardingsphere.shardingproxy.backend.communication.jdbc.connection.BackendConnection.close(BackendConnection.java:228)
        at org.apache.shardingsphere.shardingproxy.frontend.common.netty.FrontendChannelInboundHandler$1.run(FrontendChannelInboundHandler.java:73)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:748)

### Reason analyze (If you can)
MySQL connection closed during query. Defect of BackendConnection status management.
### Steps to reproduce the behavior, such as: SQL to execute, sharding rule configuration, when exception occur etc.
200 connections concurrently execute SQLs.
### Example codes for reproduce this issue (such as a github link).
",9494940d8f0460c782331abb6117eba90ba3fd11,18f80bbbe4d12cd8a47267647fd68cf9d5f2b15e,https://github.com/apache/shardingsphere/compare/9494940d8f0460c782331abb6117eba90ba3fd11...18f80bbbe4d12cd8a47267647fd68cf9d5f2b15e,"diff --git a/sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/communication/jdbc/connection/BackendConnection.java b/sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/communication/jdbc/connection/BackendConnection.java
index 36099314411..0a1b6e687e6 100644
--- a/sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/communication/jdbc/connection/BackendConnection.java
+++ b/sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/communication/jdbc/connection/BackendConnection.java
@@ -132,7 +132,6 @@ public final class BackendConnection implements AutoCloseable {
      * @throws SQLException SQL exception
      */
     public List<Connection> getConnections(final ConnectionMode connectionMode, final String dataSourceName, final int connectionSize) throws SQLException {
-        stateHandler.setRunningStatusIfNecessary();
         if (stateHandler.isInTransaction()) {
             return getConnectionsWithTransaction(connectionMode, dataSourceName, connectionSize);
         } else {
diff --git a/sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/communication/jdbc/connection/ConnectionStateHandler.java b/sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/communication/jdbc/connection/ConnectionStateHandler.java
index 18dc8bea4d4..213f785fd30 100644
--- a/sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/communication/jdbc/connection/ConnectionStateHandler.java
+++ b/sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/communication/jdbc/connection/ConnectionStateHandler.java
@@ -57,8 +57,8 @@ public class ConnectionStateHandler {
     /**
      * Change connection status to running if necessary.
      */
-    void setRunningStatusIfNecessary() {
-        if (ConnectionStatus.TRANSACTION != status.get()) {
+    public void setRunningStatusIfNecessary() {
+        if (ConnectionStatus.TRANSACTION != status.get() && ConnectionStatus.RUNNING != status.get()) {
             status.getAndSet(ConnectionStatus.RUNNING);
         }
     }
diff --git a/sharding-proxy/sharding-proxy-backend/src/test/java/org/apache/shardingsphere/shardingproxy/backend/communication/jdbc/connection/BackendConnectionTest.java b/sharding-proxy/sharding-proxy-backend/src/test/java/org/apache/shardingsphere/shardingproxy/backend/communication/jdbc/connection/BackendConnectionTest.java
index 3e9ab27416f..04db6ff0a7a 100644
--- a/sharding-proxy/sharding-proxy-backend/src/test/java/org/apache/shardingsphere/shardingproxy/backend/communication/jdbc/connection/BackendConnectionTest.java
+++ b/sharding-proxy/sharding-proxy-backend/src/test/java/org/apache/shardingsphere/shardingproxy/backend/communication/jdbc/connection/BackendConnectionTest.java
@@ -158,7 +158,8 @@ public final class BackendConnectionTest {
             backendConnection.setCurrentSchema(""schema_0"");
             when(backendDataSource.getConnections((ConnectionMode) any(), anyString(), eq(12), eq(TransactionType.LOCAL))).thenReturn(MockConnectionUtil.mockNewConnections(12));
             backendConnection.getConnections(ConnectionMode.MEMORY_STRICTLY, ""ds1"", 12);
-            assertThat(backendConnection.getStateHandler().getStatus(), is(ConnectionStatus.RUNNING));
+            assertThat(backendConnection.getStateHandler().getStatus(), is(ConnectionStatus.INIT));
+            backendConnection.getStateHandler().setRunningStatusIfNecessary();
             mockResultSetAndStatement(backendConnection);
             actual = backendConnection;
         }
diff --git a/sharding-proxy/sharding-proxy-frontend/sharding-proxy-frontend-core/src/main/java/org/apache/shardingsphere/shardingproxy/frontend/command/CommandExecutorTask.java b/sharding-proxy/sharding-proxy-frontend/sharding-proxy-frontend-core/src/main/java/org/apache/shardingsphere/shardingproxy/frontend/command/CommandExecutorTask.java
index 1ecf27029fb..b6117210b1c 100644
--- a/sharding-proxy/sharding-proxy-frontend/sharding-proxy-frontend-core/src/main/java/org/apache/shardingsphere/shardingproxy/frontend/command/CommandExecutorTask.java
+++ b/sharding-proxy/sharding-proxy-frontend/sharding-proxy-frontend-core/src/main/java/org/apache/shardingsphere/shardingproxy/frontend/command/CommandExecutorTask.java
@@ -62,6 +62,7 @@ public final class CommandExecutorTask implements Runnable {
         try (BackendConnection backendConnection = this.backendConnection;
              PacketPayload payload = databaseFrontendEngine.getCodecEngine().createPacketPayload((ByteBuf) message)) {
             backendConnection.getStateHandler().waitUntilConnectionReleasedIfNecessary();
+            backendConnection.getStateHandler().setRunningStatusIfNecessary();
             isNeedFlush = executeCommand(context, payload, backendConnection);
             connectionSize = backendConnection.getConnectionSize();
             // CHECKSTYLE:OFF","['sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/communication/jdbc/connection/ConnectionStateHandler.java', 'sharding-proxy/sharding-proxy-frontend/sharding-proxy-frontend-core/src/main/java/org/apache/shardingsphere/shardingproxy/frontend/command/CommandExecutorTask.java', 'sharding-proxy/sharding-proxy-backend/src/test/java/org/apache/shardingsphere/shardingproxy/backend/communication/jdbc/connection/BackendConnectionTest.java', 'sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/communication/jdbc/connection/BackendConnection.java']",{'.java': 4},4,4,0,0,4,3235152,653522,81725,1093,387,77,6,3,6095,257,1317,100,2,0,2019-03-07 04:34:42,18658,Java,"{'Java': 22772685, 'ANTLR': 1011078, 'FreeMarker': 120878, 'Shell': 14522, 'Dockerfile': 13922, 'Batchfile': 3214}",Apache License 2.0,"['sharding-core/src/main/java/org/apache/shardingsphere/core/merger/dql/common/StreamMergedResult.java', 'sharding-proxy/sharding-proxy-transport/sharding-proxy-transport-mysql/src/main/java/org/apache/shardingsphere/shardingproxy/transport/mysql/packet/command/query/binary/execute/MySQLQueryComStmtExecutePacketExecutor.java', 'sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/communication/jdbc/JDBCDatabaseCommunicationEngine.java', 'sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/communication/jdbc/connection/BackendConnection.java', 'sharding-proxy/sharding-proxy-frontend/sharding-proxy-frontend-mysql/src/main/java/org/apache/shardingsphere/shardingproxy/frontend/mysql/command/MySQLCommandExecuteEngine.java', 'sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/communication/jdbc/execute/JDBCExecuteEngine.java', 'sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/response/query/QueryData.java', 'sharding-proxy-transport-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/transport/postgresql/packet/command/query/binary/bind/protocol/PostgreSQLTimeBinaryProtocolValue.java', 'sharding-core/src/main/java/org/apache/shardingsphere/core/executor/sql/execute/SQLExecuteCallback.java', 'sharding-proxy/sharding-proxy-frontend/sharding-proxy-frontend-mysql/src/main/java/org/apache/shardingsphere/shardingproxy/frontend/mysql/MySQLFrontendEngine.java', 'sharding-proxy/sharding-proxy-transport/sharding-proxy-transport-mysql/src/main/java/org/apache/shardingsphere/shardingproxy/transport/mysql/packet/command/query/binary/execute/protocol/MySQLDateBinaryProtocolValue.java', 'sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/communication/jdbc/connection/ConnectionStateHandler.java', 'sharding-core/src/main/java/org/apache/shardingsphere/core/executor/sql/execute/result/StreamQueryResult.java', 'sharding-core/src/main/java/org/apache/shardingsphere/core/merger/dql/iterator/IteratorStreamMergedResult.java', 'sharding-proxy/sharding-proxy-transport/sharding-proxy-transport-mysql/src/main/java/org/apache/shardingsphere/shardingproxy/transport/mysql/packet/command/query/binary/execute/protocol/MySQLBinaryProtocolValue.java', 'sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/communication/DatabaseCommunicationEngine.java', 'sharding-proxy/sharding-proxy-transport/sharding-proxy-transport-mysql/src/main/java/org/apache/shardingsphere/shardingproxy/transport/mysql/packet/command/query/binary/execute/protocol/MySQLDoubleBinaryProtocolValue.java', 'sharding-proxy/sharding-proxy-transport/sharding-proxy-transport-mysql/src/main/java/org/apache/shardingsphere/shardingproxy/transport/mysql/packet/command/query/binary/execute/protocol/MySQLFloatBinaryProtocolValue.java']","['sharding-core/src/main/java/org/apache/shardingsphere/core/merger/dql/common/StreamMergedResult.java', 'sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/communication/jdbc/JDBCDatabaseCommunicationEngine.java', 'sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/communication/jdbc/connection/BackendConnection.java', 'sharding-proxy/sharding-proxy-frontend/sharding-proxy-frontend-mysql/src/main/java/org/apache/shardingsphere/shardingproxy/frontend/mysql/command/MySQLCommandExecuteEngine.java', 'sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/communication/jdbc/execute/JDBCExecuteEngine.java']","['```json\n{\n  ""files"": [\n    ""sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/communication/jdbc/JDBCDatabaseCommunicationEngine.java"",\n    ""sharding-core/src/main/java/org/apache/shardingsphere/core/executor/sql/execute/result/StreamQueryResult.java"",\n    ""sharding-core/src/main/java/org/apache/shardingsphere/core/merger/dql/common/StreamMergedResult.java"",\n    ""sharding-core/src/main/java/org/apache/shardingsphere/core/merger/dql/iterator/IteratorStreamMergedResult.java"",\n    ""sharding-core/src/main/java/org/apache/shardingsphere/core/executor/sql/execute/SQLExecuteCallback.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/communication/jdbc/JDBCDatabaseCommunicationEngine.java"",\n    ""sharding-core/src/main/java/org/apache/shardingsphere/core/executor/sql/execute/result/StreamQueryResult.java"",\n    ""sharding-core/src/main/java/org/apache/shardingsphere/core/merger/dql/common/StreamMergedResult.java"",\n    ""sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/communication/DatabaseCommunicationEngine.java"",\n    ""sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/response/query/QueryData.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""sharding-proxy/sharding-proxy-frontend/sharding-proxy-frontend-mysql/src/main/java/org/apache/shardingsphere/shardingproxy/frontend/mysql/MySQLFrontendEngine.java"",\n    ""sharding-proxy/sharding-proxy-frontend/sharding-proxy-frontend-mysql/src/main/java/org/apache/shardingsphere/shardingproxy/frontend/mysql/command/MySQLCommandExecuteEngine.java"",\n    ""sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/communication/jdbc/connection/BackendConnection.java"",\n    ""sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/communication/jdbc/connection/ConnectionStateHandler.java"",\n    ""sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/communication/jdbc/execute/JDBCExecuteEngine.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""sharding-proxy/sharding-proxy-transport/sharding-proxy-transport-mysql/src/main/java/org/apache/shardingsphere/shardingproxy/transport/mysql/packet/command/query/binary/execute/MySQLQueryComStmtExecutePacketExecutor.java"",\n    ""sharding-proxy/sharding-proxy-transport/sharding-proxy-transport-mysql/src/main/java/org/apache/shardingsphere/shardingproxy/transport/mysql/packet/command/query/binary/execute/protocol/MySQLBinaryProtocolValue.java"",\n    ""sharding-proxy/sharding-proxy-transport/sharding-proxy-transport-mysql/src/main/java/org/apache/shardingsphere/shardingproxy/transport/mysql/packet/command/query/binary/execute/protocol/MySQLDateBinaryProtocolValue.java"",\n    ""sharding-proxy/sharding-proxy-transport/sharding-proxy-transport-mysql/src/main/java/org/apache/shardingsphere/shardingproxy/transport/mysql/packet/command/query/binary/execute/protocol/MySQLDoubleBinaryProtocolValue.java"",\n    ""sharding-proxy/sharding-proxy-transport/sharding-proxy-transport-mysql/src/main/java/org/apache/shardingsphere/shardingproxy/transport/mysql/packet/command/query/binary/execute/protocol/MySQLFloatBinaryProtocolValue.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""sharding-proxy-transport-postgresql/src/main/java/org/apache/shardingsphere/shardingproxy/transport/postgresql/packet/command/query/binary/bind/protocol/PostgreSQLTimeBinaryProtocolValue.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/communication/jdbc/connection/BackendConnection.java"",\n    ""sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/communication/jdbc/JDBCDatabaseCommunicationEngine.java"",\n    ""sharding-proxy/sharding-proxy-backend/src/main/java/org/apache/shardingsphere/shardingproxy/backend/communication/jdbc/execute/JDBCExecuteEngine.java"",\n    ""sharding-proxy/sharding-proxy-frontend/sharding-proxy-frontend-mysql/src/main/java/org/apache/shardingsphere/shardingproxy/frontend/mysql/command/MySQLCommandExecuteEngine.java"",\n    ""sharding-core/src/main/java/org/apache/shardingsphere/core/merger/dql/common/StreamMergedResult.java""\n  ]\n}\n```']",5,14870.765447616577
120,ibotpeaches/apktool/1570/1564,ibotpeaches,apktool,https://github.com/iBotPeaches/Apktool/issues/1564,https://github.com/iBotPeaches/Apktool/pull/1570,https://github.com/iBotPeaches/Apktool/pull/1570,1,fixes,Could not decode res(arsc),"### Information
1. **Apktool Version (`2.2.3`)** -
2. **Operating System (Windows)** -
3. **APK From? I don't know.** -

### Stacktrace/Logcat
```
I: Using Apktool 2.2.3 on test.zip
I: Loading resource table...
W: null
Exception in thread ""main"" java.lang.NullPointerException
        at brut.androlib.res.data.value.ResValueFactory.factory(ResValueFactory.java:74)
        at brut.androlib.res.decoder.ARSCDecoder.readValue(ARSCDecoder.java:315)
        at brut.androlib.res.decoder.ARSCDecoder.readEntry(ARSCDecoder.java:241)
        at brut.androlib.res.decoder.ARSCDecoder.readTableType(ARSCDecoder.java:226)
        at brut.androlib.res.decoder.ARSCDecoder.readTableTypeSpec(ARSCDecoder.java:156)
        at brut.androlib.res.decoder.ARSCDecoder.readTablePackage(ARSCDecoder.java:118)
        at brut.androlib.res.decoder.ARSCDecoder.readTableHeader(ARSCDecoder.java:80)
        at brut.androlib.res.decoder.ARSCDecoder.decode(ARSCDecoder.java:47)
        at brut.androlib.res.AndrolibResources.getResPackagesFromApk(AndrolibResources.java:562)
        at brut.androlib.res.AndrolibResources.loadMainPkg(AndrolibResources.java:72)
        at brut.androlib.res.AndrolibResources.getResTable(AndrolibResources.java:64)
        at brut.androlib.Androlib.getResTable(Androlib.java:68)
        at brut.androlib.ApkDecoder.setTargetSdkVersion(ApkDecoder.java:207)
        at brut.androlib.ApkDecoder.decode(ApkDecoder.java:109)
        at brut.apktool.Main.cmdDecode(Main.java:166)
        at brut.apktool.Main.main(Main.java:81)
```

### Steps to Reproduce
1. `apktool d -s test.zip `


### APK
[test.zip](https://github.com/iBotPeaches/Apktool/files/1157951/test.zip)

",ad59fdd378fe56fb108a53be2a89c9c05b1018d1,15bc16c6bd40eec1ce5de6177fa178675ac5b9fa,https://github.com/ibotpeaches/apktool/compare/ad59fdd378fe56fb108a53be2a89c9c05b1018d1...15bc16c6bd40eec1ce5de6177fa178675ac5b9fa,"diff --git a/brut.apktool/apktool-lib/src/main/java/brut/androlib/res/data/value/ResValueFactory.java b/brut.apktool/apktool-lib/src/main/java/brut/androlib/res/data/value/ResValueFactory.java
index c8d30b85..e3db655f 100644
--- a/brut.apktool/apktool-lib/src/main/java/brut/androlib/res/data/value/ResValueFactory.java
+++ b/brut.apktool/apktool-lib/src/main/java/brut/androlib/res/data/value/ResValueFactory.java
@@ -71,6 +71,9 @@ public class ResValueFactory {
     }
 
     public ResIntBasedValue factory(String value, int rawValue) {
+        if (value == null) {
+            return new ResFileValue("""", rawValue);
+        }
         if (value.startsWith(""res/"")) {
             return new ResFileValue(value, rawValue);
         }",['brut.apktool/apktool-lib/src/main/java/brut/androlib/res/data/value/ResValueFactory.java'],{'.java': 1},1,1,0,0,1,474222,106474,13907,97,92,20,3,1,1706,85,465,37,1,1,2017-07-27 10:57:19,16931,Java,"{'Java': 703364, 'Kotlin': 10370, 'Shell': 4847, 'Smali': 3679, 'Batchfile': 1154}",Apache License 2.0,"['brut.androlib.res.data.value.ResValueFactory.java', 'brut.androlib.ApkDecoder.java', 'brut.androlib.res.decoder.ARSCDecoder.java', 'brut.apktool/Main.java', 'brut.androlib.res.AndrolibResources.java']",[],"['```json\n{\n  ""files"": [\n    ""brut.androlib.res.data.value.ResValueFactory.java"",\n    ""brut.androlib.res.decoder.ARSCDecoder.java"",\n    ""brut.androlib.res.AndrolibResources.java"",\n    ""brut.androlib.ApkDecoder.java"",\n    ""brut.apktool/Main.java""\n  ]\n}\n```']",1,1381.270170211792
8685,appium/appium/1145/1140,appium,appium,https://github.com/appium/appium/issues/1140,https://github.com/appium/appium/pull/1145,https://github.com/appium/appium/pull/1145,1,fix,catch NullPointerExceptions instead of crashing,"As reported on the mailing list:

```
info: [ADB STDOUT] java.lang.NullPointerException
info: [ADB STDOUT] at io.appium.android.bootstrap.handler.Click.execute(Click.java:42)
```

The server methods should never crash on a NullPointerException. The fix is to add NullPointerException to the existing try/catch blocks on every command.
",868a3202bfe7c99966c9760dde4c0b12780cd95b,935e12bf6fae07eccdf3ed4970eca771376950c0,https://github.com/appium/appium/compare/868a3202bfe7c99966c9760dde4c0b12780cd95b...935e12bf6fae07eccdf3ed4970eca771376950c0,"diff --git a/android/bootstrap/src/io/appium/android/bootstrap/handler/Clear.java b/android/bootstrap/src/io/appium/android/bootstrap/handler/Clear.java
index 095b19255..a8871bdf1 100644
--- a/android/bootstrap/src/io/appium/android/bootstrap/handler/Clear.java
+++ b/android/bootstrap/src/io/appium/android/bootstrap/handler/Clear.java
@@ -43,8 +43,10 @@ public class Clear extends CommandHandler {
       } catch (final ElementNotInHashException e) {
         return new AndroidCommandResult(WDStatus.NO_SUCH_ELEMENT,
             e.getMessage());
+      } catch (final Exception e) { // handle NullPointerException
+        return getErrorResult(""Unknown error clearing text"");
       }
     }
-    return getErrorResult(""Unknown error clearing text"");
+    return getErrorResult(""Unknown error"");
   }
 }
diff --git a/android/bootstrap/src/io/appium/android/bootstrap/handler/Click.java b/android/bootstrap/src/io/appium/android/bootstrap/handler/Click.java
index 599184020..9700a348c 100644
--- a/android/bootstrap/src/io/appium/android/bootstrap/handler/Click.java
+++ b/android/bootstrap/src/io/appium/android/bootstrap/handler/Click.java
@@ -47,6 +47,8 @@ public class Click extends CommandHandler {
       } catch (final ElementNotInHashException e) {
         return new AndroidCommandResult(WDStatus.NO_SUCH_ELEMENT,
             e.getMessage());
+      } catch (final Exception e) { // handle NullPointerException
+        return getErrorResult(""Unknown error"");
       }
     } else {
       final Hashtable<String, Object> params = command.params();
diff --git a/android/bootstrap/src/io/appium/android/bootstrap/handler/Drag.java b/android/bootstrap/src/io/appium/android/bootstrap/handler/Drag.java
index 596bc3c97..a6717556f 100644
--- a/android/bootstrap/src/io/appium/android/bootstrap/handler/Drag.java
+++ b/android/bootstrap/src/io/appium/android/bootstrap/handler/Drag.java
@@ -50,9 +50,10 @@ public class Drag extends CommandHandler {
         if (params.get(""elementId"") != JSONObject.NULL) {
           el = command.getElement();
         }
-      } catch (final ElementNotInHashException e) {
+      } catch (final Exception e) {
         el = null;
       }
+
       try {
         if (params.get(""destElId"") != JSONObject.NULL) {
           destEl = command.getDestElement();
diff --git a/android/bootstrap/src/io/appium/android/bootstrap/handler/Flick.java b/android/bootstrap/src/io/appium/android/bootstrap/handler/Flick.java
index 3d360d446..63bcf8778 100644
--- a/android/bootstrap/src/io/appium/android/bootstrap/handler/Flick.java
+++ b/android/bootstrap/src/io/appium/android/bootstrap/handler/Flick.java
@@ -5,7 +5,6 @@ import io.appium.android.bootstrap.AndroidCommandResult;
 import io.appium.android.bootstrap.AndroidElement;
 import io.appium.android.bootstrap.CommandHandler;
 import io.appium.android.bootstrap.Logger;
-import io.appium.android.bootstrap.exceptions.ElementNotInHashException;
 import io.appium.android.bootstrap.exceptions.InvalidCoordinatesException;
 import io.appium.android.bootstrap.utils.Point;
 
@@ -14,7 +13,6 @@ import java.util.Hashtable;
 import org.json.JSONException;
 
 import com.android.uiautomator.core.UiDevice;
-import com.android.uiautomator.core.UiObjectNotFoundException;
 
 /**
  * This handler is used to flick elements in the Android UI.
@@ -83,11 +81,7 @@ public class Flick extends CommandHandler {
         end.x = start.x + xoffset;
         end.y = start.y + yoffset;
 
-      } catch (final ElementNotInHashException e) {
-        return getErrorResult(e.getMessage());
-      } catch (final UiObjectNotFoundException e) {
-        return getErrorResult(e.getMessage());
-      } catch (final InvalidCoordinatesException e) {
+      } catch (final Exception e) {
         return getErrorResult(e.getMessage());
       }
     } else {
diff --git a/android/bootstrap/src/io/appium/android/bootstrap/handler/GetAttribute.java b/android/bootstrap/src/io/appium/android/bootstrap/handler/GetAttribute.java
index 20f19a8fe..092346fd3 100644
--- a/android/bootstrap/src/io/appium/android/bootstrap/handler/GetAttribute.java
+++ b/android/bootstrap/src/io/appium/android/bootstrap/handler/GetAttribute.java
@@ -54,7 +54,7 @@ public class GetAttribute extends CommandHandler {
       } catch (final ElementNotInHashException e) {
         return new AndroidCommandResult(WDStatus.NO_SUCH_ELEMENT,
             e.getMessage());
-      } catch (final NullPointerException e) { // el is null
+      } catch (final Exception e) { // el is null
         return new AndroidCommandResult(WDStatus.NO_SUCH_ELEMENT,
             e.getMessage());
       }
diff --git a/android/bootstrap/src/io/appium/android/bootstrap/handler/GetName.java b/android/bootstrap/src/io/appium/android/bootstrap/handler/GetName.java
index c50db3ba6..623e5f121 100644
--- a/android/bootstrap/src/io/appium/android/bootstrap/handler/GetName.java
+++ b/android/bootstrap/src/io/appium/android/bootstrap/handler/GetName.java
@@ -41,6 +41,8 @@ public class GetName extends CommandHandler {
       return new AndroidCommandResult(WDStatus.NO_SUCH_ELEMENT, e.getMessage());
     } catch (final ElementNotInHashException e) {
       return new AndroidCommandResult(WDStatus.NO_SUCH_ELEMENT, e.getMessage());
+    } catch (final Exception e) { // handle NullPointerException
+      return getErrorResult(""Unknown error"");
     }
   }
 }
diff --git a/android/bootstrap/src/io/appium/android/bootstrap/handler/GetSize.java b/android/bootstrap/src/io/appium/android/bootstrap/handler/GetSize.java
index 7436fb413..3c2e65fe5 100644
--- a/android/bootstrap/src/io/appium/android/bootstrap/handler/GetSize.java
+++ b/android/bootstrap/src/io/appium/android/bootstrap/handler/GetSize.java
@@ -48,6 +48,8 @@ public class GetSize extends CommandHandler {
       } catch (final ElementNotInHashException e) {
         return new AndroidCommandResult(WDStatus.NO_SUCH_ELEMENT,
             e.getMessage());
+      } catch (final Exception e) { // handle NullPointerException
+        return getErrorResult(""Unknown error"");
       }
       return getSuccessResult(res);
     } else {
diff --git a/android/bootstrap/src/io/appium/android/bootstrap/handler/GetText.java b/android/bootstrap/src/io/appium/android/bootstrap/handler/GetText.java
index e6b048461..61af00218 100644
--- a/android/bootstrap/src/io/appium/android/bootstrap/handler/GetText.java
+++ b/android/bootstrap/src/io/appium/android/bootstrap/handler/GetText.java
@@ -41,6 +41,8 @@ public class GetText extends CommandHandler {
       } catch (final ElementNotInHashException e) {
         return new AndroidCommandResult(WDStatus.NO_SUCH_ELEMENT,
             e.getMessage());
+      } catch (final Exception e) { // handle NullPointerException
+        return getErrorResult(""Unknown error"");
       }
     } else {
       return getErrorResult(""Unable to get text without an element."");
diff --git a/android/bootstrap/src/io/appium/android/bootstrap/handler/SetAttribute.java b/android/bootstrap/src/io/appium/android/bootstrap/handler/SetAttribute.java
index de5bef203..8a91c9c18 100644
--- a/android/bootstrap/src/io/appium/android/bootstrap/handler/SetAttribute.java
+++ b/android/bootstrap/src/io/appium/android/bootstrap/handler/SetAttribute.java
@@ -46,7 +46,10 @@ public class SetAttribute extends CommandHandler {
       } catch (final ElementNotInHashException e) {
         return new AndroidCommandResult(WDStatus.NO_SUCH_ELEMENT,
             e.getMessage());
+      } catch (final Exception e) { // handle NullPointerException
+        return getErrorResult(""Unknown error"");
       }
+
     } else {
       final Hashtable<String, Object> params = command.params();
 
diff --git a/android/bootstrap/src/io/appium/android/bootstrap/handler/SetText.java b/android/bootstrap/src/io/appium/android/bootstrap/handler/SetText.java
index d4939d2ac..30b48a4f2 100644
--- a/android/bootstrap/src/io/appium/android/bootstrap/handler/SetText.java
+++ b/android/bootstrap/src/io/appium/android/bootstrap/handler/SetText.java
@@ -58,6 +58,8 @@ public class SetText extends CommandHandler {
       } catch (final ElementNotInHashException e) {
         return new AndroidCommandResult(WDStatus.NO_SUCH_ELEMENT,
             e.getMessage());
+      } catch (final Exception e) { // handle NullPointerException
+        return getErrorResult(""Unknown error"");
       }
     } else {
       return getErrorResult(""Unable to set text without an element."");
diff --git a/android/bootstrap/src/io/appium/android/bootstrap/handler/Swipe.java b/android/bootstrap/src/io/appium/android/bootstrap/handler/Swipe.java
index ae09f3749..5d2fe87e9 100644
--- a/android/bootstrap/src/io/appium/android/bootstrap/handler/Swipe.java
+++ b/android/bootstrap/src/io/appium/android/bootstrap/handler/Swipe.java
@@ -55,6 +55,8 @@ public class Swipe extends CommandHandler {
         return getErrorResult(e.getMessage());
       } catch (final InvalidCoordinatesException e) {
         return getErrorResult(e.getMessage());
+      } catch (final Exception e) { // handle NullPointerException
+        return getErrorResult(""Unknown error"");
       }
     } else {
       try {","['android/bootstrap/src/io/appium/android/bootstrap/handler/SetAttribute.java', 'android/bootstrap/src/io/appium/android/bootstrap/handler/Drag.java', 'android/bootstrap/src/io/appium/android/bootstrap/handler/GetName.java', 'android/bootstrap/src/io/appium/android/bootstrap/handler/GetSize.java', 'android/bootstrap/src/io/appium/android/bootstrap/handler/Click.java', 'android/bootstrap/src/io/appium/android/bootstrap/handler/Clear.java', 'android/bootstrap/src/io/appium/android/bootstrap/handler/GetAttribute.java', 'android/bootstrap/src/io/appium/android/bootstrap/handler/Flick.java', 'android/bootstrap/src/io/appium/android/bootstrap/handler/Swipe.java', 'android/bootstrap/src/io/appium/android/bootstrap/handler/GetText.java', 'android/bootstrap/src/io/appium/android/bootstrap/handler/SetText.java']",{'.java': 11},11,11,0,0,11,121861,26622,3916,52,1678,333,32,11,335,40,70,9,0,1,2013-09-11 16:34:27,16649,JavaScript,"{'JavaScript': 1508008, 'TypeScript': 514934, 'Java': 28622, 'C#': 18579, 'HTML': 15974, 'Shell': 13107, 'RobotFramework': 7582, 'Handlebars': 2875, 'Python': 783, 'Ruby': 680, 'CSS': 122}",Apache License 2.0,"['android/bootstrap/src/io/appium/android/bootstrap/handler/SetText.java', 'android/bootstrap/src/io/appium/android/bootstrap/handler/TouchLongClick.java', 'android/bootstrap/src/io/appium/android/bootstrap/handler/Click.java', 'android/bootstrap/src/io/appium/android/bootstrap/handler/Find.java', 'android/bootstrap/src/io/appium/android/bootstrap/handler/GetText.java']","['android/bootstrap/src/io/appium/android/bootstrap/handler/SetText.java', 'android/bootstrap/src/io/appium/android/bootstrap/handler/TouchLongClick.java', 'android/bootstrap/src/io/appium/android/bootstrap/handler/Click.java', 'android/bootstrap/src/io/appium/android/bootstrap/handler/Find.java', 'android/bootstrap/src/io/appium/android/bootstrap/handler/GetText.java']","['```json\n{\n  ""files"": [\n    ""android/bootstrap/src/io/appium/android/bootstrap/handler/Click.java"",\n    ""android/bootstrap/src/io/appium/android/bootstrap/handler/TouchLongClick.java"",\n    ""android/bootstrap/src/io/appium/android/bootstrap/handler/SetText.java"",\n    ""android/bootstrap/src/io/appium/android/bootstrap/handler/GetText.java"",\n    ""android/bootstrap/src/io/appium/android/bootstrap/handler/Find.java""\n  ]\n}\n```']",1,1571.8317031860352
8687,appium/appium/1104/1100,appium,appium,https://github.com/appium/appium/issues/1100,https://github.com/appium/appium/pull/1104,https://github.com/appium/appium/pull/1104,2,fix,Android button click returns false on success,"When clicking a button on Android, uiautomator always returns false even though it was a successful click. Other buttons return the expected `true` value when clicked.
",88f8bb47d82cacde31a2344808d31a0ce51a52f5,6844140adfe04167bee66dd27b196e8b2fc8e909,https://github.com/appium/appium/compare/88f8bb47d82cacde31a2344808d31a0ce51a52f5...6844140adfe04167bee66dd27b196e8b2fc8e909,"diff --git a/android/bootstrap/src/io/appium/android/bootstrap/handler/Click.java b/android/bootstrap/src/io/appium/android/bootstrap/handler/Click.java
index ee0e21e6d..599184020 100644
--- a/android/bootstrap/src/io/appium/android/bootstrap/handler/Click.java
+++ b/android/bootstrap/src/io/appium/android/bootstrap/handler/Click.java
@@ -39,8 +39,8 @@ public class Click extends CommandHandler {
     if (command.isElementCommand()) {
       try {
         final AndroidElement el = command.getElement();
-        final boolean res = el.click();
-        return getSuccessResult(res);
+        el.click();
+        return getSuccessResult(true);
       } catch (final UiObjectNotFoundException e) {
         return new AndroidCommandResult(WDStatus.NO_SUCH_ELEMENT,
             e.getMessage());",['android/bootstrap/src/io/appium/android/bootstrap/handler/Click.java'],{'.java': 1},1,1,0,0,1,121880,26626,3916,52,140,26,4,1,168,26,34,2,0,0,2013-09-04 17:56:06,16649,JavaScript,"{'JavaScript': 1508008, 'TypeScript': 514934, 'Java': 28622, 'C#': 18579, 'HTML': 15974, 'Shell': 13107, 'RobotFramework': 7582, 'Handlebars': 2875, 'Python': 783, 'Ruby': 680, 'CSS': 122}",Apache License 2.0,"['android/bootstrap/src/io/appium/android/bootstrap/handler/Click.java', 'android/bootstrap/src/io/appium/android/bootstrap/AndroidCommand.java']","['android/bootstrap/src/io/appium/android/bootstrap/handler/Click.java', 'android/bootstrap/src/io/appium/android/bootstrap/AndroidCommand.java']","['```json\n{\n  ""files"": [\n    ""android/bootstrap/src/io/appium/android/bootstrap/handler/Click.java"",\n    ""android/bootstrap/src/io/appium/android/bootstrap/AndroidCommand.java""\n  ]\n}\n```']",1,899.601936340332
988,williamfiset/algorithms/98/59,williamfiset,algorithms,https://github.com/williamfiset/Algorithms/issues/59,https://github.com/williamfiset/Algorithms/pull/98,https://github.com/williamfiset/Algorithms/pull/98,1,solved,Cut polygon additional points,"The [cut polygon](https://github.com/williamfiset/Algorithms/blob/master/Geometry/ConvexPolygonCutWithLineSegment.java) snippet seems to provide additional points when a cut operation is performed which probably shouldn't be there. 

For example, when the following runs the additional point (2,2) appears out of nowhere.

```java
    Pt[] squarePolygon = {new Pt(0, 0), new Pt(0, 4), new Pt(4, 0), new Pt(4, 4)};
    Pt p1 = new Pt(-1, -1);
    Pt p2 = new Pt(5, 5);

    Pt[] poly1 = cut(squarePolygon, p1, p2);
    Pt[] poly2 = cut(squarePolygon, p2, p1);

    System.out.println(""First polygon:"");
    for (Pt pt : poly1) System.out.println(pt);
    // Prints:
    // First polygon:
    // (4.0,4.0)
    // (0.0,0.0)
    // (0.0,4.0)
    // (2.0,2.0) <-- Probably should not be here?
    
    System.out.println(""\\nSecond polygon:"");
    for (Pt pt : poly2) System.out.println(pt);
    // Second polygon:
    // (4.0,4.0)
    // (0.0,0.0)
    // (2.0,2.0) <-- Probably should not be here?
    // (4.0,0.0)
```

@FinnLidbetter assigning you since made this snippet right? Perhaps you can offer some insight.",dcf94d6cef0100a83acab2349a4ca9194d7056ba,2e4f2521663be0fd068ebdae4c313b35a5cc178e,https://github.com/williamfiset/algorithms/compare/dcf94d6cef0100a83acab2349a4ca9194d7056ba...2e4f2521663be0fd068ebdae4c313b35a5cc178e,"diff --git a/com/williamfiset/algorithms/geometry/ConvexPolygonCutWithLineSegment.java b/com/williamfiset/algorithms/geometry/ConvexPolygonCutWithLineSegment.java
index cc75a61..df72ad7 100644
--- a/com/williamfiset/algorithms/geometry/ConvexPolygonCutWithLineSegment.java
+++ b/com/williamfiset/algorithms/geometry/ConvexPolygonCutWithLineSegment.java
@@ -1,13 +1,14 @@
 /**
- * This algorithm cuts a convex polygon with a line segment and returns the two resulting pieces.
+ * This algorithm cuts a ordered convex polygon with a line segment and returns the two resulting pieces.
  *
- * <p>Time Complexity: O(n)
+ * <p>Time Complexity: O(nlogn)
  *
  * @author Finn Lidbetter
  */
 package com.williamfiset.algorithms.geometry;
 
 import java.util.*;
+import java.lang.*; 
 
 public class ConvexPolygonCutWithLineSegment {
 
@@ -27,6 +28,29 @@ public class ConvexPolygonCutWithLineSegment {
       return ""("" + x + "","" + y + "")"";
     }
   }
+  
+  
+  //sorts the points in CW direction.
+  public static List<Pt> sortCW(List<Pt> poly){
+      
+      int l = poly.size();
+      double centroidX = 0;
+      double centroidY = 0;
+      for(int i = 0; i<l; i++){
+          centroidX+= poly.get(i).x;
+          centroidY+= poly.get(i).y;
+      }
+      centroidX = centroidX/l;
+      centroidY = centroidY/l;
+      Pt center = new Pt(centroidX, centroidY);
+      
+      Collections.sort(poly, (a, b) -> {
+        double a1 = (Math.toDegrees(Math.atan2(a.x - center.x, a.y - center.y)) + 360) % 360;
+        double a2 = (Math.toDegrees(Math.atan2(b.x - center.x, b.y - center.y)) + 360) % 360;
+        return (int) (a1 - a2);
+    });
+    return poly;
+  }
 
   // Cuts a convex polygon by a specified line and returns one part
   // of the polygon (swapping the endpoints p1 and p2 of the line
@@ -61,14 +85,38 @@ public class ConvexPolygonCutWithLineSegment {
     double cross = bx * cy - by * cx;
     return cross < -EPS ? -1 : cross > EPS ? 1 : 0;
   }
+  
+  //takes Pt[] as an argument and returns List<Pt>
+  public static List<Pt> makeList(Pt[] squarePolygon){
+    List<Pt> list = new ArrayList<Pt>();
+    for (int i=0; i<squarePolygon.length; i++){
+        list.add(squarePolygon[i]);
+    }
+    return list;
+  }
+  
+  //takes List<Pt> as an argument and returns Pt[]
+  public static Pt[] makeArray(List<Pt> list){
+      int l = list.size();
+      Pt[] temp = new Pt[l];
+      for (int i=0; i<l; i++){
+        temp[i] = list.get(i);
+    }
+    return temp;
+  }
 
   // Example usage
   public static void main(String[] args) {
-
-    Pt[] squarePolygon = {new Pt(0, 0), new Pt(0, 4), new Pt(4, 0), new Pt(4, 4)};
+    
+    Pt[] squarePolygon = {new Pt(0, 0), new Pt(0, 4), new Pt(4, 0), new Pt(4, 4), new Pt(0, 2)};
     Pt p1 = new Pt(-1, -1);
     Pt p2 = new Pt(5, 5);
-
+    
+    int l = squarePolygon.length;
+    List list = makeList(squarePolygon);
+    list = sortCW(list);
+    squarePolygon = makeArray(list);
+    
     Pt[] poly1 = cut(squarePolygon, p1, p2);
     Pt[] poly2 = cut(squarePolygon, p2, p1);
 
@@ -76,18 +124,18 @@ public class ConvexPolygonCutWithLineSegment {
     for (Pt pt : poly1) System.out.println(pt);
     // Prints:
     // First polygon:
+    // (0.0,4.0)
     // (4.0,4.0)
     // (0.0,0.0)
-    // (0.0,4.0)
-    // (2.0,2.0) <-- Probably should not be here?
+    // (0.0,2.0)
 
     System.out.println(""\\nSecond polygon:"");
     for (Pt pt : poly2) System.out.println(pt);
+    //Prints:
     // Second polygon:
     // (4.0,4.0)
-    // (0.0,0.0)
-    // (2.0,2.0) <-- Probably should not be here?
     // (4.0,0.0)
+    // (0.0,0.0)
 
   }
 }",['com/williamfiset/algorithms/geometry/ConvexPolygonCutWithLineSegment.java'],{'.java': 1},1,1,0,0,1,763745,213584,26065,197,2093,644,66,1,1140,141,357,31,1,1,2019-10-23 07:13:47,15090,Java,"{'Java': 1436763, 'JavaScript': 9310, 'Kotlin': 2635, 'Python': 755}",MIT License,['com/williamfiset/algorithms/geometry/ConvexPolygonCutWithLineSegment.java'],['com/williamfiset/algorithms/geometry/ConvexPolygonCutWithLineSegment.java'],"['```json\n{\n  ""files"": [\n    ""com/williamfiset/algorithms/geometry/ConvexPolygonCutWithLineSegment.java""\n  ]\n}\n```']",1,1067.9676532745361
187,prestodb/presto/6427/6379,prestodb,presto,https://github.com/prestodb/presto/issues/6379,https://github.com/prestodb/presto/pull/6427,https://github.com/prestodb/presto/pull/6427,1,fixes,Incorrect results when GROUPING SETS refer to columns derived from same column,"This query:

``` sql
WITH
   t (v) AS (VALUES 1, 2),
   u (v1, v2) AS (SELECT v v1, v v2 FROM t)
SELECT v1, v2
FROM u
GROUP BY GROUPING SETS ((v1), (v2))
```

incorrectly produces:

```
 v1 | v2
----+----
  1 |  1
  2 |  2
  1 |  1
  2 |  2
(4 rows)
```

The expected result is:

```
  v1  |  v2
------+------
    1 | NULL
    2 | NULL
 NULL |    1
 NULL |    2
(4 rows)
```
",fa726a95f9f279df415275ae66b90ad8252dae07,8548ba813f2d426911062e59efa079ed296d44a6,https://github.com/prestodb/presto/compare/fa726a95f9f279df415275ae66b90ad8252dae07...8548ba813f2d426911062e59efa079ed296d44a6,"diff --git a/presto-main/src/main/java/com/facebook/presto/operator/GroupIdOperator.java b/presto-main/src/main/java/com/facebook/presto/operator/GroupIdOperator.java
index 18653de108..30588fe289 100644
--- a/presto-main/src/main/java/com/facebook/presto/operator/GroupIdOperator.java
+++ b/presto-main/src/main/java/com/facebook/presto/operator/GroupIdOperator.java
@@ -22,14 +22,11 @@ import com.facebook.presto.spi.type.Type;
 import com.facebook.presto.sql.planner.plan.PlanNodeId;
 import com.google.common.collect.ImmutableList;
 
-import java.util.BitSet;
-import java.util.Collection;
+import java.util.Arrays;
 import java.util.List;
-import java.util.Set;
+import java.util.Map;
 
 import static com.facebook.presto.spi.type.BigintType.BIGINT;
-import static com.facebook.presto.util.ImmutableCollectors.toImmutableSet;
-import static com.google.common.base.Preconditions.checkArgument;
 import static com.google.common.base.Preconditions.checkState;
 import static java.util.Objects.requireNonNull;
 
@@ -42,9 +39,7 @@ public class GroupIdOperator
         private final int operatorId;
         private final PlanNodeId planNodeId;
         private final List<Type> outputTypes;
-        private final List<List<Integer>> groupingSetChannels;
-        private final List<Integer> groupingChannels;
-        private final List<Integer> copyChannels;
+        private final List<Map<Integer, Integer>> groupingSetMappings;
 
         private boolean closed;
 
@@ -52,16 +47,12 @@ public class GroupIdOperator
                 int operatorId,
                 PlanNodeId planNodeId,
                 List<? extends Type> outputTypes,
-                List<List<Integer>> groupingSetChannels,
-                List<Integer> groupingChannels,
-                List<Integer> copyChannels)
+                List<Map<Integer, Integer>> groupingSetMappings)
         {
             this.operatorId = operatorId;
             this.planNodeId = requireNonNull(planNodeId, ""planNodeId is null"");
             this.outputTypes = ImmutableList.copyOf(requireNonNull(outputTypes));
-            this.groupingSetChannels = ImmutableList.copyOf(requireNonNull(groupingSetChannels));
-            this.groupingChannels = ImmutableList.copyOf(requireNonNull(groupingChannels));
-            this.copyChannels = ImmutableList.copyOf(requireNonNull(copyChannels));
+            this.groupingSetMappings = ImmutableList.copyOf(requireNonNull(groupingSetMappings));
         }
 
         @Override
@@ -76,48 +67,35 @@ public class GroupIdOperator
             checkState(!closed, ""Factory is already closed"");
             OperatorContext operatorContext = driverContext.addOperatorContext(operatorId, planNodeId, GroupIdOperator.class.getSimpleName());
 
-            Set<Integer> allGroupingColumns = groupingSetChannels.stream()
-                    .flatMap(Collection::stream)
-                    .collect(toImmutableSet());
-
-            // create an array of bitset for fast lookup of which columns are part of a given grouping set
-            // will have a 'true' for every channel that should be set to null for each grouping set
-            BitSet[] groupingSetNullChannels = new BitSet[groupingSetChannels.size()];
-            for (int i = 0; i < groupingSetChannels.size(); i++) {
-                groupingSetNullChannels[i] = new BitSet(groupingChannels.size() + copyChannels.size());
-                // first set all grouping columns to true
-                for (int groupingColumn : allGroupingColumns) {
-                    groupingSetNullChannels[i].set(groupingColumn, true);
-                }
-                // then set all the columns in this grouping set to false
-                for (int nonNullGroupingColumn : groupingSetChannels.get(i)) {
-                    groupingSetNullChannels[i].set(nonNullGroupingColumn, false);
+            // create an int array for fast lookup of input columns for every grouping set
+            int[][] groupingSetInputs = new int[groupingSetMappings.size()][outputTypes.size() - 1];
+            for (int i = 0; i < groupingSetMappings.size(); i++) {
+                // -1 means the output column is null
+                Arrays.fill(groupingSetInputs[i], -1);
+
+                // anything else is an input column to copy
+                for (int outputChannel : groupingSetMappings.get(i).keySet()) {
+                    groupingSetInputs[i][outputChannel] = groupingSetMappings.get(i).get(outputChannel);
                 }
             }
 
-            // create null blocks for every grouping channel
-            Block[] nullBlocks = new Block[groupingChannels.size()];
-            for (int i = 0; i < groupingChannels.size(); i++) {
+            // it's easier to create null blocks for every output column even though we only null out some grouping column outputs
+            Block[] nullBlocks = new Block[outputTypes.size()];
+            for (int i = 0; i < outputTypes.size(); i++) {
                 nullBlocks[i] = outputTypes.get(i).createBlockBuilder(new BlockBuilderStatus(), 1)
                         .appendNull()
                         .build();
             }
 
             // create groupid blocks for every group
-            Block[] groupIdBlocks = new Block[groupingSetNullChannels.length];
-            for (int i = 0; i < groupingSetNullChannels.length; i++) {
+            Block[] groupIdBlocks = new Block[groupingSetMappings.size()];
+            for (int i = 0; i < groupingSetMappings.size(); i++) {
                 BlockBuilder builder = BIGINT.createBlockBuilder(new BlockBuilderStatus(), 1);
                 BIGINT.writeLong(builder, i);
                 groupIdBlocks[i] = builder.build();
             }
 
-            // create array of input channels for every grouping channel
-            int[] groupInputs = groupingChannels.stream().mapToInt(Integer::intValue).toArray();
-
-            // create array of input channels for every copy channel
-            int[] copyInputs = copyChannels.stream().mapToInt(Integer::intValue).toArray();
-
-            return new GroupIdOperator(operatorContext, outputTypes, groupingSetNullChannels, nullBlocks, groupIdBlocks, groupInputs, copyInputs);
+            return new GroupIdOperator(operatorContext, outputTypes, groupingSetInputs, nullBlocks, groupIdBlocks);
         }
 
         @Override
@@ -129,17 +107,15 @@ public class GroupIdOperator
         @Override
         public OperatorFactory duplicate()
         {
-            return new GroupIdOperatorFactory(operatorId, planNodeId, outputTypes, groupingSetChannels, groupingChannels, copyChannels);
+            return new GroupIdOperatorFactory(operatorId, planNodeId, outputTypes, groupingSetMappings);
         }
     }
 
     private final OperatorContext operatorContext;
     private final List<Type> types;
-    private final BitSet[] groupingSetNullChannels;
+    private final int[][] groupingSetInputs;
     private final Block[] nullBlocks;
     private final Block[] groupIdBlocks;
-    private final int[] groupInputs;
-    private final int[] copyInputs;
 
     private Page currentPage = null;
     private int currentGroupingSet = 0;
@@ -148,20 +124,15 @@ public class GroupIdOperator
     public GroupIdOperator(
             OperatorContext operatorContext,
             List<Type> types,
-            BitSet[] groupingSetNullChannels,
+            int[][] groupingSetInputs,
             Block[] nullBlocks,
-            Block[] groupIdBlocks,
-            int[] groupInputs,
-            int[] copyInputs)
+            Block[] groupIdBlocks)
     {
         this.operatorContext = requireNonNull(operatorContext, ""operatorContext is null"");
-        this.types = requireNonNull(types, ""types is null"");
-        this.groupingSetNullChannels =  requireNonNull(groupingSetNullChannels, ""groupingSetNullChannels is null"");
-        this.nullBlocks = requireNonNull(nullBlocks);
-        this.groupIdBlocks = requireNonNull(groupIdBlocks);
-        checkArgument(groupIdBlocks.length == groupingSetNullChannels.length, ""groupIdBlocks and groupingSetNullChannels must have the same length"");
-        this.groupInputs = requireNonNull(groupInputs);
-        this.copyInputs = requireNonNull(copyInputs);
+        this.types = ImmutableList.copyOf(requireNonNull(types, ""types is null""));
+        this.groupingSetInputs =  requireNonNull(groupingSetInputs, ""groupingSetInputs is null"");
+        this.nullBlocks = requireNonNull(nullBlocks, ""nullBlocks is null"");
+        this.groupIdBlocks = requireNonNull(groupIdBlocks,  ""groupIdBlocks is null"");
     }
 
     @Override
@@ -218,21 +189,17 @@ public class GroupIdOperator
         // generate 'n' pages for every input page, where n is the number of grouping sets
         Block[] outputBlocks = new Block[types.size()];
 
-        for (int i = 0; i < groupInputs.length; i++) {
-            if (groupingSetNullChannels[currentGroupingSet].get(groupInputs[i])) {
+        for (int i = 0; i < groupingSetInputs[currentGroupingSet].length; i++) {
+            if (groupingSetInputs[currentGroupingSet][i] == -1) {
                 outputBlocks[i] = new RunLengthEncodedBlock(nullBlocks[i], currentPage.getPositionCount());
             }
             else {
-                outputBlocks[i] = currentPage.getBlock(groupInputs[i]);
+                outputBlocks[i] = currentPage.getBlock(groupingSetInputs[currentGroupingSet][i]);
             }
         }
 
-        for (int i = 0; i < copyInputs.length; i++) {
-            outputBlocks[groupInputs.length + i] = currentPage.getBlock(copyInputs[i]);
-        }
-
         outputBlocks[outputBlocks.length - 1] = new RunLengthEncodedBlock(groupIdBlocks[currentGroupingSet], currentPage.getPositionCount());
-        currentGroupingSet = (currentGroupingSet + 1) % groupingSetNullChannels.length;
+        currentGroupingSet = (currentGroupingSet + 1) % groupingSetInputs.length;
         Page outputPage = new Page(currentPage.getPositionCount(), outputBlocks);
 
         if (currentGroupingSet == 0) {
diff --git a/presto-main/src/main/java/com/facebook/presto/sql/planner/LocalExecutionPlanner.java b/presto-main/src/main/java/com/facebook/presto/sql/planner/LocalExecutionPlanner.java
index 24acf28fe5..b3a4d5344a 100644
--- a/presto-main/src/main/java/com/facebook/presto/sql/planner/LocalExecutionPlanner.java
+++ b/presto-main/src/main/java/com/facebook/presto/sql/planner/LocalExecutionPlanner.java
@@ -832,42 +832,50 @@ public class LocalExecutionPlanner
         public PhysicalOperation visitGroupId(GroupIdNode node, LocalExecutionPlanContext context)
         {
             PhysicalOperation source = node.getSource().accept(this, context);
-            ImmutableMap.Builder<Symbol, Integer> newLayout = ImmutableMap.builder();
+            Map<Symbol, Integer> newLayout = new HashMap<>();
             ImmutableList.Builder<Type> outputTypes = ImmutableList.builder();
 
             int outputChannel = 0;
 
-            ImmutableList.Builder<Integer> groupingChannels = ImmutableList.builder();
-            for (Symbol inputSymbol : node.getDistinctGroupingColumns()) {
-                int inputChannel = source.getLayout().get(inputSymbol);
-                newLayout.put(inputSymbol, outputChannel++);
-                outputTypes.add(source.getTypes().get(inputChannel));
-                groupingChannels.add(inputChannel);
+            for (Symbol output : node.getGroupingSets().stream().flatMap(Collection::stream).collect(Collectors.toSet())) {
+                newLayout.put(output, outputChannel++);
+                outputTypes.add(source.getTypes().get(source.getLayout().get(node.getGroupingSetMappings().get(output))));
             }
 
-            ImmutableList.Builder<Integer> copyChannels = ImmutableList.builder();
-            for (Symbol inputSymbol : node.getIdentityMappings().keySet()) {
-                int inputChannel = source.getLayout().get(inputSymbol);
-                newLayout.put(node.getIdentityMappings().get(inputSymbol), outputChannel++);
+            Map<Symbol, Integer> argumentMappings = new HashMap<>();
+            for (Symbol output : node.getArgumentMappings().keySet()) {
+                int inputChannel = source.getLayout().get(node.getArgumentMappings().get(output));
+
+                newLayout.put(output, outputChannel++);
                 outputTypes.add(source.getTypes().get(inputChannel));
-                copyChannels.add(inputChannel);
+                argumentMappings.put(output, inputChannel);
+            }
+
+            // for every grouping set, create a mapping of all output to input channels (including arguments)
+            ImmutableList.Builder<Map<Integer, Integer>> mappings = ImmutableList.builder();
+            for (List<Symbol> groupingSet : node.getGroupingSets()) {
+                ImmutableMap.Builder<Integer, Integer> setMapping = ImmutableMap.builder();
+
+                for (Symbol output : groupingSet) {
+                    setMapping.put(newLayout.get(output), source.getLayout().get(node.getGroupingSetMappings().get(output)));
+                }
+
+                for (Symbol output : argumentMappings.keySet()) {
+                    setMapping.put(newLayout.get(output), argumentMappings.get(output));
+                }
+
+                mappings.add(setMapping.build());
             }
 
             newLayout.put(node.getGroupIdSymbol(), outputChannel);
             outputTypes.add(BIGINT);
 
-            List<List<Integer>> groupingSetChannels = node.getGroupingSets().stream()
-                    .map(groupingSet -> getChannelsForSymbols(groupingSet, source.getLayout()))
-                    .collect(toImmutableList());
-
             OperatorFactory groupIdOperatorFactory = new GroupIdOperator.GroupIdOperatorFactory(context.getNextOperatorId(),
                     node.getId(),
                     outputTypes.build(),
-                    groupingSetChannels,
-                    groupingChannels.build(),
-                    copyChannels.build());
+                    mappings.build());
 
-            return new PhysicalOperation(groupIdOperatorFactory, newLayout.build(), source);
+            return new PhysicalOperation(groupIdOperatorFactory, newLayout, source);
         }
 
         @Override
diff --git a/presto-main/src/main/java/com/facebook/presto/sql/planner/PlanPrinter.java b/presto-main/src/main/java/com/facebook/presto/sql/planner/PlanPrinter.java
index b22f3d5665..84092bcff7 100644
--- a/presto-main/src/main/java/com/facebook/presto/sql/planner/PlanPrinter.java
+++ b/presto-main/src/main/java/com/facebook/presto/sql/planner/PlanPrinter.java
@@ -523,7 +523,23 @@ public class PlanPrinter
         @Override
         public Void visitGroupId(GroupIdNode node, Integer indent)
         {
-            print(indent, ""- GroupId%s => [%s]"", node.getGroupingSets(), formatOutputs(node.getOutputSymbols()));
+            // grouping sets are easier to understand in terms of inputs
+            List<List<Symbol>> inputGroupingSetSymbols = node.getGroupingSets().stream()
+                    .map(set -> set.stream()
+                            .map(symbol -> node.getGroupingSetMappings().get(symbol))
+                            .collect(Collectors.toList()))
+                    .collect(Collectors.toList());
+
+            print(indent, ""- GroupId%s => [%s]"", inputGroupingSetSymbols, formatOutputs(node.getOutputSymbols()));
+            printStats(indent + 2, node.getId());
+
+            for (Map.Entry<Symbol, Symbol> mapping : node.getGroupingSetMappings().entrySet()) {
+                print(indent + 2, ""%s := %s"", mapping.getKey(), mapping.getValue());
+            }
+            for (Map.Entry<Symbol, Symbol> argument : node.getArgumentMappings().entrySet()) {
+                print(indent + 2, ""%s := %s"", argument.getKey(), argument.getValue());
+            }
+
             return processChildren(node, indent + 1);
         }
 
diff --git a/presto-main/src/main/java/com/facebook/presto/sql/planner/QueryPlanner.java b/presto-main/src/main/java/com/facebook/presto/sql/planner/QueryPlanner.java
index 3c5978bedf..323048bc9f 100644
--- a/presto-main/src/main/java/com/facebook/presto/sql/planner/QueryPlanner.java
+++ b/presto-main/src/main/java/com/facebook/presto/sql/planner/QueryPlanner.java
@@ -60,6 +60,7 @@ import com.google.common.collect.ImmutableMap;
 import com.google.common.collect.ImmutableSet;
 import com.google.common.collect.Iterables;
 
+import java.util.ArrayList;
 import java.util.Collection;
 import java.util.HashMap;
 import java.util.Iterator;
@@ -383,47 +384,81 @@ class QueryPlanner
 
         // 2. Aggregate
 
-        // 2.a. Rewrite group by expressions in terms of pre-projected inputs
-        TranslationMap translations = new TranslationMap(subPlan.getRelationPlan(), analysis);
-        ImmutableList.Builder<List<Symbol>> groupingSetsSymbolsBuilder = ImmutableList.builder();
+        // 2.a. Rewrite aggregate arguments
+        TranslationMap argumentTranslations = new TranslationMap(subPlan.getRelationPlan(), analysis);
+        ImmutableMap.Builder<Symbol, Symbol> argumentMappingBuilder = ImmutableMap.builder();
+        for (Expression argument : arguments) {
+            Expression parametersReplaced = ExpressionTreeRewriter.rewriteWith(new ParameterRewriter(analysis.getParameters(), analysis), argument);
+            argumentTranslations.addIntermediateMapping(argument, parametersReplaced);
+            Symbol input = subPlan.translate(parametersReplaced);
+
+            if (!argumentTranslations.containsSymbol(parametersReplaced)) {
+                Symbol output = symbolAllocator.newSymbol(parametersReplaced, analysis.getTypeWithCoercions(parametersReplaced), ""arg"");
+                argumentMappingBuilder.put(output, input);
+                argumentTranslations.put(parametersReplaced, output);
+            }
+        }
+        Map<Symbol, Symbol> argumentMappings  = argumentMappingBuilder.build();
+
+        // 2.b. Rewrite grouping columns
+        TranslationMap groupingTranslations = new TranslationMap(subPlan.getRelationPlan(), analysis);
+        Map<Symbol, Symbol> groupingSetMappings = new HashMap<>();
+        List<List<Symbol>> groupingSymbols = new ArrayList<>();
+
         for (List<Expression> groupingSet : groupingSets) {
-            ImmutableList.Builder<Symbol> groupingColumns = ImmutableList.builder();
+            ImmutableList.Builder<Symbol> symbols = ImmutableList.builder();
             for (Expression expression : groupingSet) {
-                Expression rewritten = ExpressionTreeRewriter.rewriteWith(new ParameterRewriter(analysis.getParameters(), analysis), expression);
-                translations.addIntermediateMapping(expression, rewritten);
-                Symbol symbol = subPlan.translate(rewritten);
-                groupingColumns.add(symbol);
-                translations.put(rewritten, symbol);
+                Expression parametersReplaced = ExpressionTreeRewriter.rewriteWith(new ParameterRewriter(analysis.getParameters(), analysis), expression);
+                groupingTranslations.addIntermediateMapping(expression, parametersReplaced);
+                Symbol input = subPlan.translate(expression);
+
+                Symbol output;
+                if (!groupingTranslations.containsSymbol(parametersReplaced)) {
+                    output = symbolAllocator.newSymbol(parametersReplaced, analysis.getTypeWithCoercions(expression), ""gid"");
+                    groupingTranslations.put(parametersReplaced, output);
+                }
+                else {
+                    output = groupingTranslations.get(parametersReplaced);
+                }
+
+                groupingSetMappings.put(output, input);
+                symbols.add(output);
             }
-            groupingSetsSymbolsBuilder.add(groupingColumns.build());
+            groupingSymbols.add(symbols.build());
         }
 
-        // 2.b. Add a groupIdNode and groupIdSymbol if there are multiple grouping sets
+        // 2.c. Generate GroupIdNode (multiple grouping sets) or ProjectNode (single grouping set)
         Optional<Symbol> groupIdSymbol = Optional.empty();
-        List<List<Symbol>> groupingSetsSymbols = groupingSetsSymbolsBuilder.build();
         if (groupingSets.size() > 1) {
-            ImmutableMap.Builder<Symbol, Symbol> identityMapping = ImmutableMap.builder();
-            for (Expression argument : ImmutableSet.copyOf(arguments)) {
-                Symbol output = symbolAllocator.newSymbol(argument, analysis.getTypeWithCoercions(argument), ""id"");
-                identityMapping.put(subPlan.translate(argument), output);
+            groupIdSymbol = Optional.of(symbolAllocator.newSymbol(""groupId"", BIGINT));
+            GroupIdNode groupId = new GroupIdNode(idAllocator.getNextId(), subPlan.getRoot(), groupingSymbols, groupingSetMappings, argumentMappings, groupIdSymbol.get());
+            subPlan = new PlanBuilder(groupingTranslations, groupId, analysis.getParameters());
+        }
+        else {
+            Map<Symbol, Expression> projections = new HashMap<>();
+            for (Symbol output : argumentMappings.keySet()) {
+                projections.putIfAbsent(output, argumentMappings.get(output).toSymbolReference());
+            }
 
-                // relies on the fact that group by expressions have already been re-written, and will not be affected by this mapping change
-                subPlan.getTranslations().put(argument, output);
+            for (Symbol output : groupingSetMappings.keySet()) {
+                projections.putIfAbsent(output, groupingSetMappings.get(output).toSymbolReference());
             }
 
-            groupIdSymbol = Optional.of(symbolAllocator.newSymbol(""groupId"", BIGINT));
-            GroupIdNode groupId = new GroupIdNode(idAllocator.getNextId(), subPlan.getRoot(), groupingSetsSymbols, identityMapping.build(), groupIdSymbol.get());
-            subPlan = subPlan.withNewRoot(groupId);
+            ProjectNode project = new ProjectNode(idAllocator.getNextId(), subPlan.getRoot(), projections);
+            subPlan = new PlanBuilder(groupingTranslations, project, analysis.getParameters());
         }
 
-        // 2.c. Rewrite aggregates in terms of pre-projected inputs
+        TranslationMap aggregationTranslations = new TranslationMap(subPlan.getRelationPlan(), analysis);
+        aggregationTranslations.copyMappingsFrom(groupingTranslations);
+
+        // 2.d. Rewrite aggregates
         ImmutableMap.Builder<Symbol, FunctionCall> aggregationAssignments = ImmutableMap.builder();
         ImmutableMap.Builder<Symbol, Signature> functions = ImmutableMap.builder();
         boolean needPostProjectionCoercion = false;
         for (FunctionCall aggregate : analysis.getAggregates(node)) {
             Expression parametersReplaced = ExpressionTreeRewriter.rewriteWith(new ParameterRewriter(analysis.getParameters(), analysis), aggregate);
-            translations.addIntermediateMapping(aggregate, parametersReplaced);
-            Expression rewritten = subPlan.rewrite(parametersReplaced);
+            aggregationTranslations.addIntermediateMapping(aggregate, parametersReplaced);
+            Expression rewritten = argumentTranslations.rewrite(parametersReplaced);
             Symbol newSymbol = symbolAllocator.newSymbol(rewritten, analysis.getType(aggregate));
 
             // TODO: this is a hack, because we apply coercions to the output of expressions, rather than the arguments to expressions.
@@ -433,12 +468,12 @@ class QueryPlanner
                 needPostProjectionCoercion = true;
             }
             aggregationAssignments.put(newSymbol, (FunctionCall) rewritten);
-            translations.put(parametersReplaced, newSymbol);
+            aggregationTranslations.put(parametersReplaced, newSymbol);
 
             functions.put(newSymbol, analysis.getFunctionSignature(aggregate));
         }
 
-        // 2.d. Mark distinct rows for each aggregate that has DISTINCT
+        // 2.e. Mark distinct rows for each aggregate that has DISTINCT
         // Map from aggregate function arguments to marker symbols, so that we can reuse the markers, if two aggregates have the same argument
         Map<Set<Expression>, Symbol> argumentMarkers = new HashMap<>();
         // Map from aggregate functions to marker symbols
@@ -446,7 +481,7 @@ class QueryPlanner
         for (FunctionCall aggregate : Iterables.filter(analysis.getAggregates(node), FunctionCall::isDistinct)) {
             Set<Expression> args = ImmutableSet.copyOf(aggregate.getArguments());
             Symbol marker = argumentMarkers.get(args);
-            Symbol aggregateSymbol = translations.get(aggregate);
+            Symbol aggregateSymbol = aggregationTranslations.get(aggregate);
             if (marker == null) {
                 if (args.size() == 1) {
                     marker = symbolAllocator.newSymbol(getOnlyElement(args), BOOLEAN, ""distinct"");
@@ -462,14 +497,14 @@ class QueryPlanner
 
         for (Map.Entry<Set<Expression>, Symbol> entry : argumentMarkers.entrySet()) {
             ImmutableList.Builder<Symbol> builder = ImmutableList.builder();
-            builder.addAll(groupingSetsSymbols.stream()
+            builder.addAll(groupingSymbols.stream()
                     .flatMap(Collection::stream)
                     .distinct()
                     .collect(Collectors.toList()));
             groupIdSymbol.ifPresent(builder::add);
 
             for (Expression expression : entry.getKey()) {
-                builder.add(subPlan.translate(expression));
+                builder.add(argumentTranslations.get(expression));
             }
             subPlan = subPlan.withNewRoot(
                     new MarkDistinctNode(
@@ -486,12 +521,12 @@ class QueryPlanner
                 aggregationAssignments.build(),
                 functions.build(),
                 masks,
-                groupingSetsSymbols,
+                groupingSymbols,
                 AggregationNode.Step.SINGLE,
                 Optional.empty(),
                 groupIdSymbol);
 
-        subPlan = new PlanBuilder(translations, aggregationNode, analysis.getParameters());
+        subPlan = new PlanBuilder(aggregationTranslations, aggregationNode, analysis.getParameters());
 
         // 3. Post-projection
         // Add back the implicit casts that we removed in 2.a
diff --git a/presto-main/src/main/java/com/facebook/presto/sql/planner/SymbolExtractor.java b/presto-main/src/main/java/com/facebook/presto/sql/planner/SymbolExtractor.java
index 61c18e2263..129fee725e 100644
--- a/presto-main/src/main/java/com/facebook/presto/sql/planner/SymbolExtractor.java
+++ b/presto-main/src/main/java/com/facebook/presto/sql/planner/SymbolExtractor.java
@@ -113,7 +113,8 @@ public final class SymbolExtractor
             node.getSource().accept(this, context);
 
             builder.add(node.getGroupIdSymbol());
-            builder.addAll(node.getIdentityMappings().values());
+            builder.addAll(node.getGroupingSetMappings().keySet());
+            builder.addAll(node.getArgumentMappings().keySet());
 
             return null;
         }
diff --git a/presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/AddExchanges.java b/presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/AddExchanges.java
index a444ff1d20..86bac59425 100644
--- a/presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/AddExchanges.java
+++ b/presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/AddExchanges.java
@@ -312,15 +312,13 @@ public class AddExchanges
 
         private Function<Symbol, Optional<Symbol>> translateGroupIdSymbols(GroupIdNode node)
         {
-            Map<Symbol, Symbol> invertedMappings = ImmutableBiMap.copyOf(node.getIdentityMappings()).inverse();
-            List<Symbol> commonGroupingColumns = node.getCommonGroupingColumns();
             return symbol -> {
-                if (invertedMappings.containsKey(symbol)) {
-                    return Optional.of(invertedMappings.get(symbol));
+                if (node.getArgumentMappings().containsKey(symbol)) {
+                    return Optional.of(node.getArgumentMappings().get(symbol));
                 }
 
-                if (commonGroupingColumns.contains(symbol)) {
-                    return Optional.of(symbol);
+                if (node.getCommonGroupingColumns().contains(symbol)) {
+                    return Optional.of(node.getGroupingSetMappings().get(symbol));
                 }
 
                 return Optional.empty();
diff --git a/presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/PredicatePushDown.java b/presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/PredicatePushDown.java
index 2753a999b2..3495784790 100644
--- a/presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/PredicatePushDown.java
+++ b/presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/PredicatePushDown.java
@@ -30,7 +30,6 @@ import com.facebook.presto.sql.planner.Symbol;
 import com.facebook.presto.sql.planner.SymbolAllocator;
 import com.facebook.presto.sql.planner.plan.AggregationNode;
 import com.facebook.presto.sql.planner.plan.AssignUniqueId;
-import com.facebook.presto.sql.planner.plan.ChildReplacer;
 import com.facebook.presto.sql.planner.plan.ExchangeNode;
 import com.facebook.presto.sql.planner.plan.FilterNode;
 import com.facebook.presto.sql.planner.plan.GroupIdNode;
@@ -221,26 +220,25 @@ public class PredicatePushDown
         {
             checkState(!DependencyExtractor.extractUnique(context.get()).contains(node.getGroupIdSymbol()), ""groupId symbol cannot be referenced in predicate"");
 
-            List<Symbol> commonGroupingSymbols = node.getCommonGroupingColumns();
+            Map<Symbol, SymbolReference> commonGroupingSymbolMapping = node.getGroupingSetMappings().entrySet().stream()
+                    .filter(entry -> node.getCommonGroupingColumns().contains(entry.getKey()))
+                    .collect(Collectors.toMap(Map.Entry::getKey, entry -> entry.getValue().toSymbolReference()));
+
             Predicate<Expression> pushdownEligiblePredicate = conjunct -> DependencyExtractor.extractUnique(conjunct).stream()
-                    .allMatch(commonGroupingSymbols::contains);
+                    .allMatch(commonGroupingSymbolMapping.keySet()::contains);
 
             Map<Boolean, List<Expression>> conjuncts = extractConjuncts(context.get()).stream().collect(Collectors.partitioningBy(pushdownEligiblePredicate));
 
-            // Push down conjuncts from the inherited predicate that apply to the common grouping columns, or don't apply to any grouping columns
-            PlanNode rewrittenSource = context.rewrite(node.getSource(), combineConjuncts(conjuncts.get(true)));
-
-            PlanNode output = node;
-            if (rewrittenSource != node.getSource()) {
-                output = ChildReplacer.replaceChildren(node, ImmutableList.of(rewrittenSource));
-            }
+            // Push down conjuncts from the inherited predicate that apply to common grouping symbols
+            PlanNode rewrittenNode = context.defaultRewrite(node,
+                    ExpressionTreeRewriter.rewriteWith(new ExpressionSymbolInliner(commonGroupingSymbolMapping), combineConjuncts(conjuncts.get(true))));
 
             // All other conjuncts, if any, will be in the filter node.
             if (!conjuncts.get(false).isEmpty()) {
-                output = new FilterNode(idAllocator.getNextId(), output, combineConjuncts(conjuncts.get(false)));
+                rewrittenNode = new FilterNode(idAllocator.getNextId(), rewrittenNode, combineConjuncts(conjuncts.get(false)));
             }
 
-            return output;
+            return rewrittenNode;
         }
 
         @Override
diff --git a/presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/PropertyDerivations.java b/presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/PropertyDerivations.java
index 0d8aa9d9a5..8c8f3537df 100644
--- a/presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/PropertyDerivations.java
+++ b/presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/PropertyDerivations.java
@@ -76,7 +76,6 @@ import java.util.List;
 import java.util.Map;
 import java.util.Optional;
 import java.util.Set;
-import java.util.function.Function;
 
 import static com.facebook.presto.SystemSessionProperties.planWithTableNodePartitioning;
 import static com.facebook.presto.spi.predicate.TupleDomain.extractFixedValues;
@@ -222,23 +221,22 @@ class PropertyDerivations
         @Override
         public ActualProperties visitGroupId(GroupIdNode node, List<ActualProperties> inputProperties)
         {
-            return Iterables.getOnlyElement(inputProperties).translate(translateGroupIdSymbols(node));
-        }
-
-        private Function<Symbol, Optional<Symbol>> translateGroupIdSymbols(GroupIdNode node)
-        {
-            List<Symbol> commonGroupingColumns = node.getCommonGroupingColumns();
-            return symbol -> {
-                if (node.getIdentityMappings().containsKey(symbol)) {
-                    return Optional.of(node.getIdentityMappings().get(symbol));
+            Map<Symbol, Symbol> inputToOutputMappings = new HashMap<>();
+            for (Map.Entry<Symbol, Symbol> setMapping : node.getGroupingSetMappings().entrySet()) {
+                if (node.getCommonGroupingColumns().contains(setMapping.getKey())) {
+                    // TODO: Add support for translating a property on a single column to multiple columns
+                    // when GroupIdNode is copying a single input grouping column into multiple output grouping columns (i.e. aliases), this is basically picking one arbitrarily
+                    inputToOutputMappings.putIfAbsent(setMapping.getValue(), setMapping.getKey());
                 }
+            }
 
-                if (commonGroupingColumns.contains(symbol)) {
-                    return Optional.of(symbol);
-                }
+            // TODO: Add support for translating a property on a single column to multiple columns
+            // this is deliberately placed after the grouping columns, because preserving properties has a bigger perf impact
+            for (Map.Entry<Symbol, Symbol> argumentMapping : node.getArgumentMappings().entrySet()) {
+                inputToOutputMappings.putIfAbsent(argumentMapping.getValue(), argumentMapping.getKey());
+            }
 
-                return Optional.empty();
-            };
+            return Iterables.getOnlyElement(inputProperties).translate(column -> Optional.ofNullable(inputToOutputMappings.get(column)));
         }
 
         @Override
diff --git a/presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/PruneUnreferencedOutputs.java b/presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/PruneUnreferencedOutputs.java
index 9658c59f7f..41eb36742b 100644
--- a/presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/PruneUnreferencedOutputs.java
+++ b/presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/PruneUnreferencedOutputs.java
@@ -68,15 +68,16 @@ import com.google.common.collect.Sets;
 
 import java.util.ArrayList;
 import java.util.Collection;
+import java.util.HashMap;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
 import java.util.Optional;
 import java.util.Set;
+import java.util.stream.Collectors;
 
 import static com.facebook.presto.util.ImmutableCollectors.toImmutableList;
 import static com.facebook.presto.util.ImmutableCollectors.toImmutableSet;
-import static com.google.common.base.Preconditions.checkState;
 import static com.google.common.base.Predicates.in;
 import static com.google.common.collect.Iterables.concat;
 import static java.util.Objects.requireNonNull;
@@ -408,23 +409,31 @@ public class PruneUnreferencedOutputs
         @Override
         public PlanNode visitGroupId(GroupIdNode node, RewriteContext<Set<Symbol>> context)
         {
-            checkState(node.getDistinctGroupingColumns().stream().allMatch(column -> context.get().contains(column)));
+            ImmutableSet.Builder<Symbol> expectedInputs = ImmutableSet.builder();
 
-            ImmutableMap.Builder<Symbol, Symbol> identityMappingBuilder = ImmutableMap.builder();
-            for (Map.Entry<Symbol, Symbol> entry : node.getIdentityMappings().entrySet()) {
-                if (context.get().contains(entry.getValue())) {
-                    identityMappingBuilder.put(entry);
-                }
-            }
+            Map<Symbol, Symbol> newArgumentMappings = node.getArgumentMappings().entrySet().stream()
+                    .filter(entry -> context.get().contains(entry.getKey()))
+                    .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));
+            expectedInputs.addAll(newArgumentMappings.values());
+
+            ImmutableList.Builder<List<Symbol>> newGroupingSets = ImmutableList.builder();
+            Map<Symbol, Symbol> newGroupingMapping = new HashMap<>();
 
-            Map<Symbol, Symbol> identityMapping = identityMappingBuilder.build();
+            for (List<Symbol> groupingSet : node.getGroupingSets()) {
+                ImmutableList.Builder<Symbol> newGroupingSet = ImmutableList.builder();
 
-            PlanNode source = context.rewrite(node.getSource(), ImmutableSet.<Symbol>builder()
-                    .addAll(identityMapping.keySet())
-                    .addAll(node.getDistinctGroupingColumns())
-                    .build());
+                for (Symbol output : groupingSet) {
+                    if (context.get().contains(output)) {
+                        newGroupingSet.add(output);
+                        newGroupingMapping.putIfAbsent(output, node.getGroupingSetMappings().get(output));
+                        expectedInputs.add(node.getGroupingSetMappings().get(output));
+                    }
+                }
+                newGroupingSets.add(newGroupingSet.build());
+            }
 
-            return new GroupIdNode(node.getId(), source, node.getGroupingSets(), identityMapping, node.getGroupIdSymbol());
+            PlanNode source = context.rewrite(node.getSource(), expectedInputs.build());
+            return new GroupIdNode(node.getId(), source, newGroupingSets.build(), newGroupingMapping, newArgumentMappings, node.getGroupIdSymbol());
         }
 
         @Override
diff --git a/presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/StreamPropertyDerivations.java b/presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/StreamPropertyDerivations.java
index 62c639e66f..c0977978f1 100644
--- a/presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/StreamPropertyDerivations.java
+++ b/presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/StreamPropertyDerivations.java
@@ -307,23 +307,22 @@ final class StreamPropertyDerivations
         @Override
         public StreamProperties visitGroupId(GroupIdNode node, List<StreamProperties> inputProperties)
         {
-            return Iterables.getOnlyElement(inputProperties).translate(translateGroupIdSymbols(node));
-        }
-
-        private Function<Symbol, Optional<Symbol>> translateGroupIdSymbols(GroupIdNode node)
-        {
-            List<Symbol> commonGroupingColumns = node.getCommonGroupingColumns();
-            return symbol -> {
-                if (node.getIdentityMappings().containsKey(symbol)) {
-                    return Optional.of(node.getIdentityMappings().get(symbol));
+            Map<Symbol, Symbol> inputToOutputMappings = new HashMap<>();
+            for (Map.Entry<Symbol, Symbol> setMapping : node.getGroupingSetMappings().entrySet()) {
+                if (node.getCommonGroupingColumns().contains(setMapping.getKey())) {
+                    // TODO: Add support for translating a property on a single column to multiple columns
+                    // when GroupIdNode is copying a single input grouping column into multiple output grouping columns (i.e. aliases), this is basically picking one arbitrarily
+                    inputToOutputMappings.putIfAbsent(setMapping.getValue(), setMapping.getKey());
                 }
+            }
 
-                if (commonGroupingColumns.contains(symbol)) {
-                    return Optional.of(symbol);
-                }
+            // TODO: Add support for translating a property on a single column to multiple columns
+            // this is deliberately placed after the grouping columns, because preserving properties has a bigger perf impact
+            for (Map.Entry<Symbol, Symbol> argumentMapping : node.getArgumentMappings().entrySet()) {
+                inputToOutputMappings.putIfAbsent(argumentMapping.getValue(), argumentMapping.getKey());
+            }
 
-                return Optional.empty();
-            };
+            return Iterables.getOnlyElement(inputProperties).translate(column -> Optional.ofNullable(inputToOutputMappings.get(column)));
         }
 
         @Override
diff --git a/presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/UnaliasSymbolReferences.java b/presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/UnaliasSymbolReferences.java
index 3761439cae..153bd13229 100644
--- a/presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/UnaliasSymbolReferences.java
+++ b/presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/UnaliasSymbolReferences.java
@@ -81,7 +81,6 @@ import java.util.List;
 import java.util.Map;
 import java.util.Optional;
 import java.util.Set;
-import java.util.stream.Collectors;
 
 import static com.facebook.presto.util.ImmutableCollectors.toImmutableList;
 import static com.facebook.presto.util.ImmutableCollectors.toImmutableSet;
@@ -157,16 +156,31 @@ public class UnaliasSymbolReferences
         public PlanNode visitGroupId(GroupIdNode node, RewriteContext<Void> context)
         {
             PlanNode source = context.rewrite(node.getSource());
-            List<List<Symbol>> groupingSetsSymbols = node.getGroupingSets().stream()
-                    .map(this::canonicalize)
-                    .collect(Collectors.toList());
 
-            ImmutableMap.Builder<Symbol, Symbol> newPassthroughMap = ImmutableMap.builder();
-            for (Symbol inputSymbol : node.getIdentityMappings().keySet()) {
-                newPassthroughMap.put(canonicalize(inputSymbol), canonicalize(node.getIdentityMappings().get(inputSymbol)));
+            Map<Symbol, Symbol> newGroupingMappings = new HashMap<>();
+            ImmutableList.Builder<List<Symbol>> newGroupingSets = ImmutableList.builder();
+
+            for (List<Symbol> groupingSet : node.getGroupingSets()) {
+                ImmutableList.Builder<Symbol> newGroupingSet = ImmutableList.builder();
+                for (Symbol output : groupingSet) {
+                    newGroupingMappings.putIfAbsent(canonicalize(output), canonicalize(node.getGroupingSetMappings().get(output)));
+                    newGroupingSet.add(canonicalize(output));
+                }
+                newGroupingSets.add(newGroupingSet.build());
+            }
+
+            Map<Symbol, Symbol> newArgumentMappings = new HashMap<>();
+            for (Symbol output : node.getArgumentMappings().keySet()) {
+                Symbol canonicalOutput = canonicalize(output);
+                if (newArgumentMappings.containsKey(canonicalOutput)) {
+                    map(output, canonicalOutput);
+                }
+                else {
+                    newArgumentMappings.put(canonicalOutput, canonicalize(node.getArgumentMappings().get(output)));
+                }
             }
 
-            return new GroupIdNode(node.getId(), source, groupingSetsSymbols, newPassthroughMap.build(), canonicalize(node.getGroupIdSymbol()));
+            return new GroupIdNode(node.getId(), source, newGroupingSets.build(), newGroupingMappings, newArgumentMappings, canonicalize(node.getGroupIdSymbol()));
         }
 
         @Override
diff --git a/presto-main/src/main/java/com/facebook/presto/sql/planner/plan/ChildReplacer.java b/presto-main/src/main/java/com/facebook/presto/sql/planner/plan/ChildReplacer.java
index 41f8c140f5..a760186471 100644
--- a/presto-main/src/main/java/com/facebook/presto/sql/planner/plan/ChildReplacer.java
+++ b/presto-main/src/main/java/com/facebook/presto/sql/planner/plan/ChildReplacer.java
@@ -169,7 +169,7 @@ public class ChildReplacer
     @Override
     public PlanNode visitGroupId(GroupIdNode node, List<PlanNode> newChildren)
     {
-        return new GroupIdNode(node.getId(), Iterables.getOnlyElement(newChildren), node.getGroupingSets(), node.getIdentityMappings(), node.getGroupIdSymbol());
+        return new GroupIdNode(node.getId(), Iterables.getOnlyElement(newChildren), node.getGroupingSets(), node.getGroupingSetMappings(), node.getArgumentMappings(), node.getGroupIdSymbol());
     }
 
     @Override
diff --git a/presto-main/src/main/java/com/facebook/presto/sql/planner/plan/GroupIdNode.java b/presto-main/src/main/java/com/facebook/presto/sql/planner/plan/GroupIdNode.java
index daf3560ced..1dc5bb48d4 100644
--- a/presto-main/src/main/java/com/facebook/presto/sql/planner/plan/GroupIdNode.java
+++ b/presto-main/src/main/java/com/facebook/presto/sql/planner/plan/GroupIdNode.java
@@ -19,6 +19,7 @@ import com.fasterxml.jackson.annotation.JsonProperty;
 import com.google.common.collect.ImmutableList;
 import com.google.common.collect.ImmutableMap;
 import com.google.common.collect.ImmutableSet;
+import com.google.common.collect.Sets;
 
 import javax.annotation.concurrent.Immutable;
 
@@ -27,39 +28,53 @@ import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
+import java.util.stream.Collectors;
 
+import static com.google.common.base.Preconditions.checkArgument;
 import static java.util.Objects.requireNonNull;
-import static java.util.stream.Collectors.toList;
+import static java.util.stream.Collectors.toSet;
 
 @Immutable
 public class GroupIdNode
         extends PlanNode
 {
     private final PlanNode source;
+
+    // in terms of output symbols
     private final List<List<Symbol>> groupingSets;
-    private final Map<Symbol, Symbol> identityMappings;
+
+    // from output to input symbols
+    private final Map<Symbol, Symbol> groupingSetMappings;
+    private final Map<Symbol, Symbol> argumentMappings;
+
     private final Symbol groupIdSymbol;
 
     @JsonCreator
     public GroupIdNode(@JsonProperty(""id"") PlanNodeId id,
             @JsonProperty(""source"") PlanNode source,
             @JsonProperty(""groupingSets"") List<List<Symbol>> groupingSets,
-            @JsonProperty(""identityMappings"") Map<Symbol, Symbol> identityMappings,
+            @JsonProperty(""groupingSetMappings"") Map<Symbol, Symbol> groupingSetMappings,
+            @JsonProperty(""argumentMappings"") Map<Symbol, Symbol> argumentMappings,
             @JsonProperty(""groupIdSymbol"") Symbol groupIdSymbol)
     {
         super(id);
         this.source = requireNonNull(source);
         this.groupingSets = ImmutableList.copyOf(requireNonNull(groupingSets));
-        this.identityMappings = ImmutableMap.copyOf(requireNonNull(identityMappings));
+        this.groupingSetMappings = ImmutableMap.copyOf(requireNonNull(groupingSetMappings));
+        this.argumentMappings = ImmutableMap.copyOf(requireNonNull(argumentMappings));
         this.groupIdSymbol = requireNonNull(groupIdSymbol);
+
+        checkArgument(Sets.intersection(groupingSetMappings.keySet(), argumentMappings.keySet()).isEmpty(), ""argument outputs and grouping outputs must be a disjoint set"");
     }
 
     @Override
     public List<Symbol> getOutputSymbols()
     {
         return ImmutableList.<Symbol>builder()
-                .addAll(getDistinctGroupingColumns())
-                .addAll(identityMappings.values())
+                .addAll(groupingSets.stream()
+                        .flatMap(Collection::stream)
+                        .collect(toSet()))
+                .addAll(argumentMappings.keySet())
                 .add(groupIdSymbol)
                 .build();
     }
@@ -76,14 +91,6 @@ public class GroupIdNode
         return source;
     }
 
-    public Set<Symbol> getInputSymbols()
-    {
-        return ImmutableSet.<Symbol>builder()
-                .addAll(identityMappings.keySet())
-                .addAll(getDistinctGroupingColumns())
-                .build();
-    }
-
     @JsonProperty
     public List<List<Symbol>> getGroupingSets()
     {
@@ -91,26 +98,15 @@ public class GroupIdNode
     }
 
     @JsonProperty
-    public Map<Symbol, Symbol> getIdentityMappings()
+    public Map<Symbol, Symbol> getGroupingSetMappings()
     {
-        return identityMappings;
+        return groupingSetMappings;
     }
 
-    public List<Symbol> getDistinctGroupingColumns()
+    @JsonProperty
+    public Map<Symbol, Symbol> getArgumentMappings()
     {
-        return groupingSets.stream()
-                .flatMap(Collection::stream)
-                .distinct()
-                .collect(toList());
-    }
-
-    public List<Symbol> getCommonGroupingColumns()
-    {
-        Set<Symbol> intersection = new HashSet<>(groupingSets.get(0));
-        for (int i = 1; i < getGroupingSets().size(); i++) {
-            intersection.retainAll(groupingSets.get(i));
-        }
-        return ImmutableList.copyOf(intersection);
+        return argumentMappings;
     }
 
     @JsonProperty
@@ -124,4 +120,26 @@ public class GroupIdNode
     {
         return visitor.visitGroupId(this, context);
     }
+
+    public Set<Symbol> getInputSymbols()
+    {
+        return ImmutableSet.<Symbol>builder()
+                .addAll(argumentMappings.values())
+                .addAll(groupingSets.stream()
+                        .map(set -> set.stream()
+                                .map(groupingSetMappings::get).collect(Collectors.toList()))
+                        .flatMap(Collection::stream)
+                        .collect(toSet()))
+                .build();
+    }
+
+    // returns the common grouping columns in terms of output symbols
+    public Set<Symbol> getCommonGroupingColumns()
+    {
+        Set<Symbol> intersection = new HashSet<>(groupingSets.get(0));
+        for (int i = 1; i < groupingSets.size(); i++) {
+            intersection.retainAll(groupingSets.get(i));
+        }
+        return ImmutableSet.copyOf(intersection);
+    }
 }
diff --git a/presto-main/src/main/java/com/facebook/presto/util/GraphvizPrinter.java b/presto-main/src/main/java/com/facebook/presto/util/GraphvizPrinter.java
index eb7703171e..c5b7677248 100644
--- a/presto-main/src/main/java/com/facebook/presto/util/GraphvizPrinter.java
+++ b/presto-main/src/main/java/com/facebook/presto/util/GraphvizPrinter.java
@@ -332,11 +332,14 @@ public final class GraphvizPrinter
         @Override
         public Void visitGroupId(GroupIdNode node, Void context)
         {
-            List<String> groupingSets = node.getGroupingSets().stream()
-                    .map(groupingSet -> ""("" + Joiner.on("", "").join(groupingSet) + "")"")
+            // grouping sets are easier to understand in terms of inputs
+            List<String> inputGroupingSetSymbols = node.getGroupingSets().stream()
+                    .map(set -> ""("" + Joiner.on("", "").join(set.stream()
+                            .map(symbol -> node.getGroupingSetMappings().get(symbol))
+                            .collect(Collectors.toList())) + "")"")
                     .collect(Collectors.toList());
 
-            printNode(node, ""GroupId"", Joiner.on("", "").join(groupingSets), NODE_COLORS.get(NodeType.AGGREGATE));
+            printNode(node, ""GroupId"", Joiner.on("", "").join(inputGroupingSetSymbols), NODE_COLORS.get(NodeType.AGGREGATE));
             return node.getSource().accept(this, context);
         }
 
diff --git a/presto-main/src/test/java/com/facebook/presto/operator/TestGroupIdOperator.java b/presto-main/src/test/java/com/facebook/presto/operator/TestGroupIdOperator.java
index e366afa8bc..53efa7593c 100644
--- a/presto-main/src/test/java/com/facebook/presto/operator/TestGroupIdOperator.java
+++ b/presto-main/src/test/java/com/facebook/presto/operator/TestGroupIdOperator.java
@@ -19,6 +19,7 @@ import com.facebook.presto.spi.Page;
 import com.facebook.presto.sql.planner.plan.PlanNodeId;
 import com.facebook.presto.testing.MaterializedResult;
 import com.google.common.collect.ImmutableList;
+import com.google.common.collect.ImmutableMap;
 import org.testng.annotations.AfterMethod;
 import org.testng.annotations.BeforeMethod;
 import org.testng.annotations.Test;
@@ -72,9 +73,7 @@ public class TestGroupIdOperator
                 new GroupIdOperatorFactory(0,
                         new PlanNodeId(""test""),
                         ImmutableList.of(VARCHAR, BOOLEAN, BIGINT, BIGINT, BIGINT),
-                        ImmutableList.of(ImmutableList.of(1, 2), ImmutableList.of(3)),
-                        ImmutableList.of(1, 2, 3),
-                        ImmutableList.of(0));
+                        ImmutableList.of(ImmutableMap.of(0, 1, 1, 2, 3, 0), ImmutableMap.of(2, 3, 3, 0)));
 
         MaterializedResult expected = resultBuilder(driverContext.getSession(), VARCHAR, BOOLEAN, BIGINT, BIGINT, BIGINT)
                 .row(""400"", true, null, 100L, 0L)
diff --git a/presto-tests/src/main/java/com/facebook/presto/tests/AbstractTestQueries.java b/presto-tests/src/main/java/com/facebook/presto/tests/AbstractTestQueries.java
index bfbd609fb5..adbff45529 100644
--- a/presto-tests/src/main/java/com/facebook/presto/tests/AbstractTestQueries.java
+++ b/presto-tests/src/main/java/com/facebook/presto/tests/AbstractTestQueries.java
@@ -1516,6 +1516,19 @@ public abstract class AbstractTestQueries
                         ""SELECT SUM(CAST(quantity AS BIGINT)) FROM lineitem WHERE quantity < 0"");
     }
 
+    @Test
+    public void testGroupingSetsAliasedGroupingColumns()
+            throws Exception
+    {
+        assertQuery(""SELECT lna, lnb, SUM(quantity) "" +
+                        ""FROM (SELECT linenumber lna, linenumber lnb, CAST(quantity AS BIGINT) quantity FROM lineitem) "" +
+                        ""GROUP BY GROUPING SETS ((lna, lnb), (lna), (lnb), ())"",
+                ""SELECT linenumber, linenumber, SUM(CAST(quantity AS BIGINT)) FROM lineitem GROUP BY linenumber UNION ALL "" +
+                        ""SELECT linenumber, NULL, SUM(CAST(quantity AS BIGINT)) FROM lineitem GROUP BY linenumber UNION ALL "" +
+                        ""SELECT NULL, linenumber, SUM(CAST(quantity AS BIGINT)) FROM lineitem GROUP BY linenumber UNION ALL "" +
+                        ""SELECT NULL, NULL, SUM(CAST(quantity AS BIGINT)) FROM lineitem"");
+    }
+
     @Test
     public void testGroupingSetMixedExpressionAndColumn()
             throws Exception","['presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/StreamPropertyDerivations.java', 'presto-main/src/main/java/com/facebook/presto/sql/planner/plan/ChildReplacer.java', 'presto-tests/src/main/java/com/facebook/presto/tests/AbstractTestQueries.java', 'presto-main/src/main/java/com/facebook/presto/util/GraphvizPrinter.java', 'presto-main/src/main/java/com/facebook/presto/sql/planner/LocalExecutionPlanner.java', 'presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/PropertyDerivations.java', 'presto-main/src/test/java/com/facebook/presto/operator/TestGroupIdOperator.java', 'presto-main/src/main/java/com/facebook/presto/sql/planner/QueryPlanner.java', 'presto-main/src/main/java/com/facebook/presto/sql/planner/SymbolExtractor.java', 'presto-main/src/main/java/com/facebook/presto/operator/GroupIdOperator.java', 'presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/PruneUnreferencedOutputs.java', 'presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/AddExchanges.java', 'presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/PredicatePushDown.java', 'presto-main/src/main/java/com/facebook/presto/sql/planner/plan/GroupIdNode.java', 'presto-main/src/main/java/com/facebook/presto/sql/planner/PlanPrinter.java', 'presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/UnaliasSymbolReferences.java']",{'.java': 16},16,16,0,0,16,13206161,2625166,367003,2655,33178,6037,506,14,375,80,171,35,0,3,2016-10-24 16:11:10,14935,Java,"{'Java': 53409077, 'C++': 959227, 'JavaScript': 286856, 'Shell': 61154, 'Roff': 52281, 'Python': 39357, 'ANTLR': 33548, 'CMake': 33259, 'HTML': 29601, 'CSS': 28319, 'Mustache': 17803, 'Makefile': 17213, 'Thrift': 14675, 'NASL': 13553, 'Dockerfile': 8372, 'Batchfile': 795, 'PLSQL': 85}",Apache License 2.0,"['presto-spi/src/main/java/com/facebook/presto/spi/connector/classloader/ClassLoaderSafeConnectorSplitManager.java', 'presto-parser/src/main/java/com/facebook/presto/sql/ExpressionFormatter.java', 'presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/TypeValidator.java', 'presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/ValidateDependenciesChecker.java', 'presto-main/src/main/java/com/facebook/presto/operator/MultiChannelGroupByHash.java', 'presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/PlanNodeSearcher.java', 'presto-parser/src/main/java/com/facebook/presto/sql/tree/GroupingElement.java', 'presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/PlanSanityChecker.java', 'presto-parser/src/main/java/com/facebook/presto/sql/tree/GroupingSets.java', 'presto-parser/src/main/java/com/facebook/presto/sql/QueryUtil.java', 'presto-main/src/main/java/com/facebook/presto/operator/HashAggregationOperator.java', 'presto-parser/src/main/java/com/facebook/presto/sql/SqlFormatter.java', 'presto-spi/src/main/java/com/facebook/presto/spi/ErrorCodeSupplier.java', 'presto-main/src/main/java/com/facebook/presto/operator/GroupByIdBlock.java', 'presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/PlanOptimizer.java', 'presto-main/src/main/java/com/facebook/presto/operator/GroupByHash.java', 'presto-spi/src/main/java/com/facebook/presto/spi/ErrorCode.java', 'presto-spi/src/main/java/com/facebook/presto/spi/connector/classloader/ClassLoaderSafeNodePartitioningProvider.java', 'presto-main/src/main/java/com/facebook/presto/operator/GroupIdOperator.java']","['presto-main/src/main/java/com/facebook/presto/operator/MultiChannelGroupByHash.java', 'presto-main/src/main/java/com/facebook/presto/operator/HashAggregationOperator.java', 'presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/PlanNodeSearcher.java', 'presto-main/src/main/java/com/facebook/presto/operator/GroupByHash.java', 'presto-main/src/main/java/com/facebook/presto/operator/GroupByIdBlock.java']","['```json\n{\n  ""files"": [\n    ""presto-main/src/main/java/com/facebook/presto/operator/GroupByHash.java"",\n    ""presto-main/src/main/java/com/facebook/presto/operator/GroupByIdBlock.java"",\n    ""presto-main/src/main/java/com/facebook/presto/operator/GroupIdOperator.java"",\n    ""presto-main/src/main/java/com/facebook/presto/operator/HashAggregationOperator.java"",\n    ""presto-main/src/main/java/com/facebook/presto/operator/MultiChannelGroupByHash.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""presto-parser/src/main/java/com/facebook/presto/sql/QueryUtil.java"",\n    ""presto-parser/src/main/java/com/facebook/presto/sql/ExpressionFormatter.java"",\n    ""presto-parser/src/main/java/com/facebook/presto/sql/SqlFormatter.java"",\n    ""presto-spi/src/main/java/com/facebook/presto/spi/ErrorCodeSupplier.java"",\n    ""presto-spi/src/main/java/com/facebook/presto/spi/ErrorCode.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""presto-parser/src/main/java/com/facebook/presto/sql/tree/GroupingSets.java"",\n    ""presto-parser/src/main/java/com/facebook/presto/sql/tree/GroupingElement.java"",\n    ""presto-parser/src/main/java/com/facebook/presto/sql/tree/GroupingSets.java"",\n    ""presto-parser/src/main/java/com/facebook/presto/sql/tree/GroupingElement.java"",\n    ""presto-parser/src/main/java/com/facebook/presto/sql/tree/GroupingSets.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/PlanNodeSearcher.java"",\n    ""presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/PlanOptimizer.java"",\n    ""presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/PlanSanityChecker.java"",\n    ""presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/TypeValidator.java"",\n    ""presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/ValidateDependenciesChecker.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""presto-spi/src/main/java/com/facebook/presto/spi/connector/classloader/ClassLoaderSafeConnectorSplitManager.java"",\n    ""presto-spi/src/main/java/com/facebook/presto/spi/connector/classloader/ClassLoaderSafeNodePartitioningProvider.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""presto-main/src/main/java/com/facebook/presto/operator/HashAggregationOperator.java"",\n    ""presto-main/src/main/java/com/facebook/presto/operator/MultiChannelGroupByHash.java"",\n    ""presto-main/src/main/java/com/facebook/presto/operator/GroupByHash.java"",\n    ""presto-main/src/main/java/com/facebook/presto/operator/GroupByIdBlock.java"",\n    ""presto-main/src/main/java/com/facebook/presto/sql/planner/optimizations/PlanNodeSearcher.java""\n  ]\n}\n```']",5,11835.863828659058
191,prestodb/presto/6208/6196,prestodb,presto,https://github.com/prestodb/presto/issues/6196,https://github.com/prestodb/presto/pull/6208,https://github.com/prestodb/presto/pull/6208,1,fixes,Deadlock in task info fetching,"Hit this one in production. Suddenly all queries get queued and all clients start timing out. [Here](https://gist.githubusercontent.com/nezihyigitbasi/108b844625d69de66bd8d74e427ea876/raw/c22dc663517fa991b87c162de2b387c0e8af0d69/presto-stack) is the full stack trace.

```
Found one Java-level deadlock:
=============================
""http-worker-2010473"":
  waiting to lock monitor 0x00007f8fed4a6fb8 (object 0x00007f9615a7e020, a com.facebook.presto.execution.resourceGroups.ResourceGroup$RootResourceGroup),
  which is held by ""ResourceGroupManager""
""ResourceGroupManager"":
  waiting to lock monitor 0x00007f91f0cc3598 (object 0x00007f9a9f000a48, a com.facebook.presto.execution.SqlStageExecution),
  which is held by ""HttpRemoteTask-20160926_222904_08073_w6q27.1.105-2010288""
""HttpRemoteTask-20160926_222904_08073_w6q27.1.105-2010288"":
  waiting to lock monitor 0x00007f90ed8c3ee8 (object 0x00007f9a9f000870, a com.facebook.presto.server.remotetask.ContinuousTaskStatusFetcher),
  which is held by ""ContinuousTaskStatusFetcher-20160926_222904_08073_w6q27.1.105-2009564""
""ContinuousTaskStatusFetcher-20160926_222904_08073_w6q27.1.105-2009564"":
  waiting to lock monitor 0x00007f910c0b5948 (object 0x00007f9a9f0008e0, a com.facebook.presto.server.remotetask.HttpRemoteTask),
  which is held by ""HttpRemoteTask-20160926_222904_08073_w6q27.1.105-2010288""

Java stack information for the threads listed above:
===================================================
""http-worker-2010473"":
    at com.facebook.presto.execution.resourceGroups.ResourceGroup.run(ResourceGroup.java:322)
    - waiting to lock <0x00007f9615a7e020> (a com.facebook.presto.execution.resourceGroups.ResourceGroup$RootResourceGroup)
    at com.facebook.presto.execution.resourceGroups.ResourceGroupManager.submit(ResourceGroupManager.java:89)
    at com.facebook.presto.execution.SqlQueryManager.createQuery(SqlQueryManager.java:348)
    at com.facebook.presto.server.StatementResource$Query.<init>(StatementResource.java:308)
    at com.facebook.presto.server.StatementResource.createQuery(StatementResource.java:171)
    at sun.reflect.GeneratedMethodAccessor1181.invoke(Unknown Source)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke(Method.java:498)
    at org.glassfish.jersey.server.model.internal.ResourceMethodInvocationHandlerFactory$1.invoke(ResourceMethodInvocationHandlerFactory.java:81)
    at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher$1.run(AbstractJavaResourceMethodDispatcher.java:144)
    at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.invoke(AbstractJavaResourceMethodDispatcher.java:161)
    at org.glassfish.jersey.server.model.internal.JavaResourceMethodDispatcherProvider$ResponseOutInvoker.doDispatch(JavaResourceMethodDispatcherProvider.java:160)
    at org.glassfish.jersey.server.model.internal.AbstractJavaResourceMethodDispatcher.dispatch(AbstractJavaResourceMethodDispatcher.java:99)
    at org.glassfish.jersey.server.model.ResourceMethodInvoker.invoke(ResourceMethodInvoker.java:389)
    at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:347)
    at org.glassfish.jersey.server.model.ResourceMethodInvoker.apply(ResourceMethodInvoker.java:102)
    at org.glassfish.jersey.server.ServerRuntime$2.run(ServerRuntime.java:326)
    at org.glassfish.jersey.internal.Errors$1.call(Errors.java:271)
    at org.glassfish.jersey.internal.Errors$1.call(Errors.java:267)
    at org.glassfish.jersey.internal.Errors.process(Errors.java:315)
    at org.glassfish.jersey.internal.Errors.process(Errors.java:297)
    at org.glassfish.jersey.internal.Errors.process(Errors.java:267)
    at org.glassfish.jersey.process.internal.RequestScope.runInScope(RequestScope.java:317)
    at org.glassfish.jersey.server.ServerRuntime.process(ServerRuntime.java:305)
    at org.glassfish.jersey.server.ApplicationHandler.handle(ApplicationHandler.java:1154)
    at org.glassfish.jersey.servlet.WebComponent.serviceImpl(WebComponent.java:473)
    at org.glassfish.jersey.servlet.WebComponent.service(WebComponent.java:427)
    at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:388)
    at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:341)
    at org.glassfish.jersey.servlet.ServletContainer.service(ServletContainer.java:228)
    at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:845)
    at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1689)
    at io.airlift.http.server.TraceTokenFilter.doFilter(TraceTokenFilter.java:63)
    at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1676)
    at io.airlift.http.server.TimingFilter.doFilter(TimingFilter.java:52)
    at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1676)
    at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:581)
    at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
    at org.eclipse.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:396)
    at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1176)
    at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:511)
    at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1106)
    at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
    at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
    at org.eclipse.jetty.server.handler.StatisticsHandler.handle(StatisticsHandler.java:169)
    at org.eclipse.jetty.server.handler.HandlerList.handle(HandlerList.java:52)
    at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
    at org.eclipse.jetty.server.Server.handle(Server.java:518)
    at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:314)
    at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:253)
    at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:273)
    at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:95)
    at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
    at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:654)
    at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:572)
    at java.lang.Thread.run(Thread.java:745)
""ResourceGroupManager"":
    at com.facebook.presto.execution.SqlStageExecution.getMemoryReservation(SqlStageExecution.java:184)
    - waiting to lock <0x00007f9a9f000a48> (a com.facebook.presto.execution.SqlStageExecution)
    at com.facebook.presto.execution.scheduler.SqlQueryScheduler$$Lambda$792/605126606.applyAsLong(Unknown Source)
    at java.util.stream.ReferencePipeline$5$1.accept(ReferencePipeline.java:227)
    at java.util.Iterator.forEachRemaining(Iterator.java:116)
    at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
    at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481)
    at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471)
    at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708)
    at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)
    at java.util.stream.LongPipeline.reduce(LongPipeline.java:438)
    at java.util.stream.LongPipeline.sum(LongPipeline.java:396)
    at com.facebook.presto.execution.scheduler.SqlQueryScheduler.getTotalMemoryReservation(SqlQueryScheduler.java:310)
    at com.facebook.presto.execution.SqlQueryExecution.getTotalMemoryReservation(SqlQueryExecution.java:188)
    at com.facebook.presto.execution.resourceGroups.ResourceGroup.internalRefreshStats(ResourceGroup.java:438)
    - locked <0x00007f9615a7e020> (a com.facebook.presto.execution.resourceGroups.ResourceGroup$RootResourceGroup)
    at com.facebook.presto.execution.resourceGroups.ResourceGroup.internalRefreshStats(ResourceGroup.java:445)
    - locked <0x00007f9615a7e020> (a com.facebook.presto.execution.resourceGroups.ResourceGroup$RootResourceGroup)
    at com.facebook.presto.execution.resourceGroups.ResourceGroup$RootResourceGroup.processQueuedQueries(ResourceGroup.java:580)
    - locked <0x00007f9615a7e020> (a com.facebook.presto.execution.resourceGroups.ResourceGroup$RootResourceGroup)
    at com.facebook.presto.execution.resourceGroups.ResourceGroupManager.refreshAndStartQueries(ResourceGroupManager.java:110)
    at com.facebook.presto.execution.resourceGroups.ResourceGroupManager$$Lambda$140/724736957.run(Unknown Source)
    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
    at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
    at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
    at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
    at java.lang.Thread.run(Thread.java:745)
""HttpRemoteTask-20160926_222904_08073_w6q27.1.105-2010288"":
    at com.facebook.presto.server.remotetask.ContinuousTaskStatusFetcher.updateTaskStatus(ContinuousTaskStatusFetcher.java:214)
    - waiting to lock <0x00007f9a9f000870> (a com.facebook.presto.server.remotetask.ContinuousTaskStatusFetcher)
    at com.facebook.presto.server.remotetask.HttpRemoteTask.abort(HttpRemoteTask.java:560)
    - locked <0x00007f9a9f0008e0> (a com.facebook.presto.server.remotetask.HttpRemoteTask)
    at com.facebook.presto.server.remotetask.HttpRemoteTask.abort(HttpRemoteTask.java:552)
    - locked <0x00007f9a9f0008e0> (a com.facebook.presto.server.remotetask.HttpRemoteTask)
    at com.facebook.presto.execution.SqlStageExecution$$Lambda$1037/616866428.accept(Unknown Source)
    at java.lang.Iterable.forEach(Iterable.java:75)
    at com.facebook.presto.execution.SqlStageExecution.abort(SqlStageExecution.java:179)
    - locked <0x00007f9a9f000a48> (a com.facebook.presto.execution.SqlStageExecution)
    at com.facebook.presto.execution.scheduler.SqlQueryScheduler$$Lambda$1035/234080167.accept(Unknown Source)
    at java.util.Iterator.forEachRemaining(Iterator.java:116)
    at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801)
    at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580)
    at com.facebook.presto.execution.scheduler.SqlQueryScheduler.abort(SqlQueryScheduler.java:412)
    at com.facebook.presto.execution.SqlQueryExecution.lambda$new$0(SqlQueryExecution.java:154)
    at com.facebook.presto.execution.SqlQueryExecution$$Lambda$440/1153217709.stateChanged(Unknown Source)
    at com.facebook.presto.execution.StateMachine.lambda$fireStateChanged$0(StateMachine.java:225)
    at com.facebook.presto.execution.StateMachine$$Lambda$413/743619379.run(Unknown Source)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
    at java.lang.Thread.run(Thread.java:745)
""ContinuousTaskStatusFetcher-20160926_222904_08073_w6q27.1.105-2009564"":
    at com.facebook.presto.server.remotetask.HttpRemoteTask.abort(HttpRemoteTask.java:557)
    - waiting to lock <0x00007f9a9f0008e0> (a com.facebook.presto.server.remotetask.HttpRemoteTask)
    at com.facebook.presto.server.remotetask.HttpRemoteTask.failTask(HttpRemoteTask.java:621)
    at com.facebook.presto.server.remotetask.HttpRemoteTask$$Lambda$817/1647878013.accept(Unknown Source)
    at com.facebook.presto.server.remotetask.ContinuousTaskStatusFetcher.updateTaskStatus(ContinuousTaskStatusFetcher.java:234)
    - locked <0x00007f9a9f000870> (a com.facebook.presto.server.remotetask.ContinuousTaskStatusFetcher)
    at com.facebook.presto.server.remotetask.ContinuousTaskStatusFetcher.success(ContinuousTaskStatusFetcher.java:168)
    at com.facebook.presto.server.remotetask.ContinuousTaskStatusFetcher.success(ContinuousTaskStatusFetcher.java:52)
    at com.facebook.presto.server.remotetask.SimpleHttpResponseHandler.onSuccess(SimpleHttpResponseHandler.java:49)
    at com.facebook.presto.server.remotetask.SimpleHttpResponseHandler.onSuccess(SimpleHttpResponseHandler.java:27)
    at com.google.common.util.concurrent.Futures$6.run(Futures.java:1319)
    at io.airlift.concurrent.BoundedExecutor.drainQueue(BoundedExecutor.java:77)
    at io.airlift.concurrent.BoundedExecutor$$Lambda$437/311179219.run(Unknown Source)
    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
    at java.lang.Thread.run(Thread.java:745)

Found 1 deadlock.
```
",e5dbe7ca1cb519f50a7b13fc1a775e5ba966ab89,72d65cdc4485c788e13647cf2fbca9ff867fd731,https://github.com/prestodb/presto/compare/e5dbe7ca1cb519f50a7b13fc1a775e5ba966ab89...72d65cdc4485c788e13647cf2fbca9ff867fd731,"diff --git a/presto-main/src/main/java/com/facebook/presto/server/remotetask/ContinuousTaskStatusFetcher.java b/presto-main/src/main/java/com/facebook/presto/server/remotetask/ContinuousTaskStatusFetcher.java
index 77d8dacfeb..12bedf066c 100644
--- a/presto-main/src/main/java/com/facebook/presto/server/remotetask/ContinuousTaskStatusFetcher.java
+++ b/presto-main/src/main/java/com/facebook/presto/server/remotetask/ContinuousTaskStatusFetcher.java
@@ -208,7 +208,7 @@ class ContinuousTaskStatusFetcher
         }
     }
 
-    synchronized void updateTaskStatus(TaskStatus newValue)
+    void updateTaskStatus(TaskStatus newValue)
     {
         // change to new value if old value is not changed and new value has a newer version
         AtomicBoolean taskMismatch = new AtomicBoolean();",['presto-main/src/main/java/com/facebook/presto/server/remotetask/ContinuousTaskStatusFetcher.java'],{'.java': 1},1,1,0,0,1,12693049,2519379,352796,2569,108,19,2,1,13128,403,3208,152,1,1,2016-09-27 21:57:38,14935,Java,"{'Java': 53409077, 'C++': 959227, 'JavaScript': 286856, 'Shell': 61154, 'Roff': 52281, 'Python': 39357, 'ANTLR': 33548, 'CMake': 33259, 'HTML': 29601, 'CSS': 28319, 'Mustache': 17803, 'Makefile': 17213, 'Thrift': 14675, 'NASL': 13553, 'Dockerfile': 8372, 'Batchfile': 795, 'PLSQL': 85}",Apache License 2.0,"['presto-spi/src/main/java/com/facebook/presto/spi/ConnectorSplit.java', 'presto-spi/src/main/java/com/facebook/presto/spi/ConnectorSplitSource.java', 'presto-server/src/main/java/com/facebook/presto/server/remotetask/ContinuousTaskStatusFetcher.java', 'presto-spi/src/main/java/com/facebook/presto/spi/memory/MemoryPoolInfo.java', 'presto-spi/src/main/java/com/facebook/presto/spi/ConnectorMetadata.java', 'presto-server/src/main/java/com/facebook/presto/server/remotetask/HttpRemoteTask.java', 'presto-main/src/main/java/com/facebook/presto/server/remotetask/ResourceGroupManager.java', 'presto-spi/src/main/java/com/facebook/presto/spi/resourceGroups/ResourceGroupConfigurationManagerContext.java', 'presto-spi/src/main/java/com/facebook/presto/spi/memory/MemoryPoolId.java', 'presto-main/src/main/java/com/facebook/presto/execution/SqlStageExecution.java', 'presto-spi/src/main/java/com/facebook/presto/spi/resourceGroups/ResourceGroup.java', 'presto-main/src/main/java/com/facebook/presto/server/remotetask/HttpRemoteTask.java', 'presto-spi/src/main/java/com/facebook/presto/spi/ConnectorSession.java', 'presto-spi/src/main/java/com/facebook/presto/spi/resourceGroups/ResourceGroupSelector.java', 'presto-teradata-functions/src/main/java/com/facebook/presto/teradata/functions/dateformat/DateFormatParser.java', 'presto-spi/src/main/java/com/facebook/presto/spi/resourceGroups/ResourceGroupConfigurationManagerFactory.java', 'presto-execution/src/main/java/com/facebook/presto/execution/SqlStageExecution.java', 'presto-main/src/main/java/com/facebook/presto/execution/resourceGroups/ResourceGroup.java', 'presto-main/src/main/java/com/facebook/presto/server/remotetask/ContinuousTaskStatusFetcher.java', 'presto-spi/src/main/java/com/facebook/presto/spi/resourceGroups/ResourceGroupConfigurationManager.java', 'presto-spi/src/main/java/com/facebook/presto/spi/memory/ClusterMemoryPoolManager.java', 'presto-spi/src/main/java/com/facebook/presto/spi/ConnectorSplitManager.java', 'presto-main/src/main/java/com/facebook/presto/execution/scheduler/SqlQueryScheduler.java', 'presto-main/src/main/java/com/facebook/presto/execution/resourceGroups/ResourceGroupManager.java']","['presto-spi/src/main/java/com/facebook/presto/spi/resourceGroups/ResourceGroup.java', 'presto-spi/src/main/java/com/facebook/presto/spi/resourceGroups/ResourceGroupConfigurationManager.java', 'presto-main/src/main/java/com/facebook/presto/server/remotetask/HttpRemoteTask.java', 'presto-spi/src/main/java/com/facebook/presto/spi/ConnectorSession.java', 'presto-main/src/main/java/com/facebook/presto/execution/SqlStageExecution.java']","['```json\n{\n  ""files"": [\n    ""presto-main/src/main/java/com/facebook/presto/execution/resourceGroups/ResourceGroup.java"",\n    ""presto-main/src/main/java/com/facebook/presto/execution/resourceGroups/ResourceGroupManager.java"",\n    ""presto-server/src/main/java/com/facebook/presto/server/remotetask/ContinuousTaskStatusFetcher.java"",\n    ""presto-server/src/main/java/com/facebook/presto/server/remotetask/HttpRemoteTask.java"",\n    ""presto-execution/src/main/java/com/facebook/presto/execution/SqlStageExecution.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""presto-main/src/main/java/com/facebook/presto/execution/resourceGroups/ResourceGroup.java"",\n    ""presto-main/src/main/java/com/facebook/presto/execution/resourceGroups/ResourceGroupManager.java"",\n    ""presto-main/src/main/java/com/facebook/presto/server/remotetask/ContinuousTaskStatusFetcher.java"",\n    ""presto-main/src/main/java/com/facebook/presto/server/remotetask/HttpRemoteTask.java"",\n    ""presto-main/src/main/java/com/facebook/presto/execution/scheduler/SqlQueryScheduler.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""presto-main/src/main/java/com/facebook/presto/execution/resourceGroups/ResourceGroup.java"",\n    ""presto-main/src/main/java/com/facebook/presto/execution/resourceGroups/ResourceGroupManager.java"",\n    ""presto-main/src/main/java/com/facebook/presto/server/remotetask/ContinuousTaskStatusFetcher.java"",\n    ""presto-main/src/main/java/com/facebook/presto/server/remotetask/HttpRemoteTask.java"",\n    ""presto-main/src/main/java/com/facebook/presto/execution/scheduler/SqlQueryScheduler.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""presto-spi/src/main/java/com/facebook/presto/spi/ConnectorSplitManager.java"",\n    ""presto-spi/src/main/java/com/facebook/presto/spi/ConnectorSplitSource.java"",\n    ""presto-spi/src/main/java/com/facebook/presto/spi/ConnectorSplit.java"",\n    ""presto-spi/src/main/java/com/facebook/presto/spi/ConnectorSession.java"",\n    ""presto-spi/src/main/java/com/facebook/presto/spi/ConnectorMetadata.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""presto-main/src/main/java/com/facebook/presto/execution/resourceGroups/ResourceGroup.java"",\n    ""presto-main/src/main/java/com/facebook/presto/execution/resourceGroups/ResourceGroupManager.java"",\n    ""presto-main/src/main/java/com/facebook/presto/server/remotetask/ContinuousTaskStatusFetcher.java"",\n    ""presto-main/src/main/java/com/facebook/presto/server/remotetask/HttpRemoteTask.java"",\n    ""presto-main/src/main/java/com/facebook/presto/execution/scheduler/SqlQueryScheduler.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""presto-main/src/main/java/com/facebook/presto/server/remotetask/ContinuousTaskStatusFetcher.java"",\n    ""presto-main/src/main/java/com/facebook/presto/server/remotetask/HttpRemoteTask.java"",\n    ""presto-main/src/main/java/com/facebook/presto/server/remotetask/ResourceGroupManager.java"",\n    ""presto-main/src/main/java/com/facebook/presto/execution/resourceGroups/ResourceGroup.java"",\n    ""presto-main/src/main/java/com/facebook/presto/execution/SqlStageExecution.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""presto-spi/src/main/java/com/facebook/presto/spi/memory/ClusterMemoryPoolManager.java"",\n    ""presto-spi/src/main/java/com/facebook/presto/spi/memory/MemoryPoolId.java"",\n    ""presto-spi/src/main/java/com/facebook/presto/spi/memory/MemoryPoolInfo.java"",\n    ""presto-spi/src/main/java/com/facebook/presto/spi/memory/MemoryPoolInfo.java"",\n    ""presto-spi/src/main/java/com/facebook/presto/spi/memory/MemoryPoolInfo.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""presto-spi/src/main/java/com/facebook/presto/spi/resourceGroups/ResourceGroup.java"",\n    ""presto-spi/src/main/java/com/facebook/presto/spi/resourceGroups/ResourceGroupConfigurationManager.java"",\n    ""presto-spi/src/main/java/com/facebook/presto/spi/resourceGroups/ResourceGroupConfigurationManagerContext.java"",\n    ""presto-spi/src/main/java/com/facebook/presto/spi/resourceGroups/ResourceGroupConfigurationManagerFactory.java"",\n    ""presto-spi/src/main/java/com/facebook/presto/spi/resourceGroups/ResourceGroupSelector.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""presto-teradata-functions/src/main/java/com/facebook/presto/teradata/functions/dateformat/DateFormatParser.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""presto-spi/src/main/java/com/facebook/presto/spi/resourceGroups/ResourceGroup.java"",\n    ""presto-spi/src/main/java/com/facebook/presto/spi/resourceGroups/ResourceGroupConfigurationManager.java"",\n    ""presto-main/src/main/java/com/facebook/presto/server/remotetask/HttpRemoteTask.java"",\n    ""presto-spi/src/main/java/com/facebook/presto/spi/ConnectorSession.java"",\n    ""presto-main/src/main/java/com/facebook/presto/execution/SqlStageExecution.java""\n  ]\n}\n```']",9,21964.95270729065
9739,deeplearning4j/deeplearning4j/4664/4635,deeplearning4j,deeplearning4j,https://github.com/deeplearning4j/deeplearning4j/issues/4635,https://github.com/deeplearning4j/deeplearning4j/pull/4664,https://github.com/deeplearning4j/deeplearning4j/pull/4664,1,fix,Error using TransferLearningHelper with TinyYOLO,"Hi

By calling the following code:

TinyYOLO model = new TinyYOLO(nClasses, seed);
ComputationGraph computationGraph = (ComputationGraph) model.initPretrained();
TransferLearningHelper transferLearningHelper = new TransferLearningHelper(computationGraph, ""conv2d_9"");

We get the following exception stacktrace:

Exception in thread ""main"" org.nd4j.linalg.exception.ND4JIllegalStateException: Invalid shape: Requested INDArray shape [1, 0] contains dimension size values < 1 (all dimensions must be 1 or more)
	at org.nd4j.linalg.factory.Nd4j.checkShapeValues(Nd4j.java:5122)
	at org.nd4j.linalg.factory.Nd4j.create(Nd4j.java:5112)
	at org.nd4j.linalg.factory.Nd4j.create(Nd4j.java:5065)
	at org.nd4j.linalg.factory.Nd4j.create(Nd4j.java:4170)
	at org.deeplearning4j.nn.graph.ComputationGraph.init(ComputationGraph.java:452)
	at org.deeplearning4j.nn.graph.ComputationGraph.init(ComputationGraph.java:377)
	at org.deeplearning4j.nn.transferlearning.TransferLearning$GraphBuilder.build(TransferLearning.java:755)
	at org.deeplearning4j.nn.transferlearning.TransferLearningHelper.initHelperGraph(TransferLearningHelper.java:252)
	at org.deeplearning4j.nn.transferlearning.TransferLearningHelper.<init>(TransferLearningHelper.java:56)
	at nlb.ai.deeplearning.dl4j.image.objectdetection.PersonsDetection.main(PersonsDetection.java:39)

It works perfectly well with VGG16.

* Deeplearning4j version 0.9.2-SANPSHOT
* windows 10
* neither CUDA nor NVIDIA are used

",6edd2e893be21e465790af47c8410851a8094c57,3e36a29d08219be90dfaa13ebd865a2e05b64ee1,https://github.com/deeplearning4j/deeplearning4j/compare/6edd2e893be21e465790af47c8410851a8094c57...3e36a29d08219be90dfaa13ebd865a2e05b64ee1,"diff --git a/deeplearning4j-core/src/test/java/org/deeplearning4j/nn/graph/TestComputationGraphNetwork.java b/deeplearning4j-core/src/test/java/org/deeplearning4j/nn/graph/TestComputationGraphNetwork.java
index 76098e52ca..8c776ce99c 100644
--- a/deeplearning4j-core/src/test/java/org/deeplearning4j/nn/graph/TestComputationGraphNetwork.java
+++ b/deeplearning4j-core/src/test/java/org/deeplearning4j/nn/graph/TestComputationGraphNetwork.java
@@ -6,8 +6,10 @@ import org.datavec.api.records.reader.RecordReader;
 import org.datavec.api.records.reader.impl.csv.CSVRecordReader;
 import org.datavec.api.split.FileSplit;
 import org.deeplearning4j.BaseDL4JTest;
+import org.deeplearning4j.TestUtils;
 import org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator;
 import org.deeplearning4j.datasets.iterator.impl.IrisDataSetIterator;
+import org.deeplearning4j.datasets.iterator.impl.MnistDataSetIterator;
 import org.deeplearning4j.eval.Evaluation;
 import org.deeplearning4j.exception.DL4JException;
 import org.deeplearning4j.nn.api.OptimizationAlgorithm;
@@ -1340,4 +1342,32 @@ public class TestComputationGraphNetwork extends BaseDL4JTest {
         assertEquals(13, net.layerSize(""3""));
     }
 
+    @Test
+    public void testZeroParamNet() throws Exception {
+
+        ComputationGraphConfiguration conf = new NeuralNetConfiguration.Builder()
+                .graphBuilder()
+                .addInputs(""in"")
+                .layer(""0"", new SubsamplingLayer.Builder().kernelSize(2,2).stride(2,2).build(), ""in"")
+                .layer(""1"", new LossLayer.Builder().activation(Activation.SIGMOID).lossFunction(LossFunctions.LossFunction.MSE).build(), ""0"")
+                .setOutputs(""1"")
+                .setInputTypes(InputType.convolutionalFlat(28,28,1))
+                .build();
+
+        ComputationGraph net = new ComputationGraph(conf);
+        net.init();
+
+        DataSet ds = new MnistDataSetIterator(16, true, 12345).next();
+
+        INDArray out = net.outputSingle(ds.getFeatures());
+
+        INDArray labelTemp = Nd4j.create(out.shape());
+        ds.setLabels(labelTemp);
+
+        net.fit(ds);
+
+        ComputationGraph net2 = TestUtils.testModelSerialization(net);
+        INDArray out2 = net2.outputSingle(ds.getFeatures());
+        assertEquals(out, out2);
+    }
 }
diff --git a/deeplearning4j-core/src/test/java/org/deeplearning4j/nn/multilayer/MultiLayerTest.java b/deeplearning4j-core/src/test/java/org/deeplearning4j/nn/multilayer/MultiLayerTest.java
index 6b3b87d013..af21fb6c08 100644
--- a/deeplearning4j-core/src/test/java/org/deeplearning4j/nn/multilayer/MultiLayerTest.java
+++ b/deeplearning4j-core/src/test/java/org/deeplearning4j/nn/multilayer/MultiLayerTest.java
@@ -1245,4 +1245,32 @@ public class MultiLayerTest extends BaseDL4JTest {
         assertEquals(30, net.layerSize(2));
         assertEquals(13, net.layerSize(3));
     }
+
+
+    @Test
+    public void testZeroParamNet() throws Exception {
+
+        MultiLayerConfiguration conf = new NeuralNetConfiguration.Builder()
+                .list()
+                .layer(new SubsamplingLayer.Builder().kernelSize(2,2).stride(2,2).build())
+                .layer(new LossLayer.Builder().activation(Activation.SIGMOID).lossFunction(LossFunctions.LossFunction.MSE).build())
+                .setInputType(InputType.convolutionalFlat(28,28,1))
+                .build();
+
+        MultiLayerNetwork net = new MultiLayerNetwork(conf);
+        net.init();
+
+        DataSet ds = new MnistDataSetIterator(16, true, 12345).next();
+
+        INDArray out = net.output(ds.getFeatures());
+
+        INDArray labelTemp = Nd4j.create(out.shape());
+        ds.setLabels(labelTemp);
+
+        net.fit(ds);
+
+        MultiLayerNetwork net2 = TestUtils.testModelSerialization(net);
+        INDArray out2 = net2.output(ds.getFeatures());
+        assertEquals(out, out2);
+    }
 }
diff --git a/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/gradient/DefaultGradient.java b/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/gradient/DefaultGradient.java
index d09015682b..dea4e3e4d3 100644
--- a/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/gradient/DefaultGradient.java
+++ b/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/gradient/DefaultGradient.java
@@ -93,7 +93,7 @@ public class DefaultGradient implements Gradient {
                 }
             }
             flattenedGradient = Nd4j.toFlattened(DEFAULT_FLATTENING_ORDER, toFlatten);
-        } else {
+        } else if( !gradients.values().isEmpty() ){ //Edge case: can be empty for nets with 0 params
             //Standard case: flatten all to f order
             flattenedGradient = Nd4j.toFlattened(DEFAULT_FLATTENING_ORDER, gradients.values());
         }
diff --git a/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/graph/ComputationGraph.java b/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/graph/ComputationGraph.java
index 59399df257..db983b45b1 100755
--- a/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/graph/ComputationGraph.java
+++ b/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/graph/ComputationGraph.java
@@ -449,9 +449,12 @@ public class ComputationGraph implements Serializable, Model, NeuralNetwork {
                 flattenedParams = parameters;
 
             initializeParams = false;
-        } else {
+        } else if(numParams > 0){
             flattenedParams = Nd4j.create(1, numParams);
             initializeParams = true;
+        } else {
+            flattenedParams = null;
+            initializeParams = false;
         }
 
         //Set RNG seed, for repeatability between initializations when set
@@ -632,7 +635,10 @@ public class ComputationGraph implements Serializable, Model, NeuralNetwork {
                 numParams += numParamsForVertex[i];
                 i++;
             }
-            flattenedGradients = Nd4j.create(1, numParams);
+
+            if(numParams > 0) {
+                flattenedGradients = Nd4j.create(1, numParams);
+            }
 
             //Given the topological ordering: work out the subset of the gradient array used for each layer, and set it
             int paramOffsetSoFar = 0;
@@ -1138,6 +1144,10 @@ public class ComputationGraph implements Serializable, Model, NeuralNetwork {
      * @param labelMaskArrays   Mas arrays for the labels/outputs. Typically used for RNN training. May be null.
      */
     public void fit(INDArray[] inputs, INDArray[] labels, INDArray[] featureMaskArrays, INDArray[] labelMaskArrays) {
+        if (numParams() == 0) {
+            return; //Edge case: net with no params: fitting is a no-op
+        }
+
         if (flattenedGradients == null) {
             initGradientsView();
         }
diff --git a/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/multilayer/MultiLayerNetwork.java b/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/multilayer/MultiLayerNetwork.java
index b220483e91..ce19832f2a 100755
--- a/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/multilayer/MultiLayerNetwork.java
+++ b/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/multilayer/MultiLayerNetwork.java
@@ -604,9 +604,13 @@ public class MultiLayerNetwork implements Serializable, Classifier, Layer, Neura
                     flattenedParams = parameters;
 
                 initializeParams = false;
-            } else {
+            } else if(paramLength > 0){
                 flattenedParams = Nd4j.create(1, paramLength);
                 initializeParams = true;
+            } else {
+                //Edge case: 0 params in network
+                flattenedParams = null;
+                initializeParams = false;
             }
 
             //Set RNG seed, for repeatability between initializations when set
@@ -693,7 +697,9 @@ public class MultiLayerNetwork implements Serializable, Classifier, Layer, Neura
                 paramLength += nParamsPerLayer[i];
             }
 
-            flattenedGradients = Nd4j.zeros(new int[] {1, paramLength}, 'f'); //No need to initialize, as each layer will do it each iteration anyway
+            if(paramLength > 0) {
+                flattenedGradients = Nd4j.zeros(new int[]{1, paramLength}, 'f'); //No need to initialize, as each layer will do it each iteration anyway
+            }
 
             int backpropParamsSoFar = 0;
             for (int i = 0; i < layers.length; i++) {
@@ -1861,6 +1867,10 @@ public class MultiLayerNetwork implements Serializable, Classifier, Layer, Neura
      * @param labelsMask The mask array for the labels (used for variable length time series, etc). May be null.
      */
     public void fit(INDArray features, INDArray labels, INDArray featuresMask, INDArray labelsMask) {
+        if(numParams() == 0){
+            //No op: can't fit a network with 0 parameters
+            return;
+        }
 
         setInput(features);
         setLabels(labels);
diff --git a/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/updater/BaseMultiLayerUpdater.java b/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/updater/BaseMultiLayerUpdater.java
index ba08beb97f..da46b30e77 100644
--- a/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/updater/BaseMultiLayerUpdater.java
+++ b/deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/updater/BaseMultiLayerUpdater.java
@@ -299,7 +299,11 @@ public abstract class BaseMultiLayerUpdater<T extends Model> implements Updater
                 gradient.gradient().divi(batchSize);
             } else {
                 //Standard case
-                getFlattenedGradientsView().divi(batchSize);
+                INDArray grad = getFlattenedGradientsView();
+                if(grad != null) {
+                    //May be null for nets with no parameters
+                    grad.divi(batchSize);
+                }
             }
         }
     }
diff --git a/deeplearning4j-nn/src/main/java/org/deeplearning4j/util/ModelSerializer.java b/deeplearning4j-nn/src/main/java/org/deeplearning4j/util/ModelSerializer.java
index e0644a9f1b..70694cc547 100644
--- a/deeplearning4j-nn/src/main/java/org/deeplearning4j/util/ModelSerializer.java
+++ b/deeplearning4j-nn/src/main/java/org/deeplearning4j/util/ModelSerializer.java
@@ -125,12 +125,18 @@ public class ModelSerializer {
         ZipEntry coefficients = new ZipEntry(""coefficients.bin"");
         zipfile.putNextEntry(coefficients);
         DataOutputStream dos = new DataOutputStream(new BufferedOutputStream(zipfile));
-        try {
-            Nd4j.write(model.params(), dos);
-        } finally {
-            dos.flush();
-            if (!saveUpdater)
-                dos.close();
+        INDArray params = model.params();
+        if(params != null) {
+            try {
+                Nd4j.write(model.params(), dos);
+            } finally {
+                dos.flush();
+                if (!saveUpdater)
+                    dos.close();
+            }
+        } else {
+            ZipEntry noParamsMarker = new ZipEntry(""noParams.marker"");
+            zipfile.putNextEntry(noParamsMarker);
         }
 
         if (saveUpdater) {
@@ -225,13 +231,18 @@ public class ModelSerializer {
 
 
         ZipEntry coefficients = zipFile.getEntry(""coefficients.bin"");
-        if (coefficients != null) {
-            InputStream stream = zipFile.getInputStream(coefficients);
-            DataInputStream dis = new DataInputStream(new BufferedInputStream(stream));
-            params = Nd4j.read(dis);
+        if (coefficients != null ) {
+            if(coefficients.getSize() > 0) {
+                InputStream stream = zipFile.getInputStream(coefficients);
+                DataInputStream dis = new DataInputStream(new BufferedInputStream(stream));
+                params = Nd4j.read(dis);
 
-            dis.close();
-            gotCoefficients = true;
+                dis.close();
+                gotCoefficients = true;
+            } else {
+                ZipEntry noParamsMarker = zipFile.getEntry(""noParams.marker"");
+                gotCoefficients = (noParamsMarker != null);
+            }
         }
 
         if (loadUpdater) {
@@ -470,12 +481,17 @@ public class ModelSerializer {
 
         ZipEntry coefficients = zipFile.getEntry(""coefficients.bin"");
         if (coefficients != null) {
-            InputStream stream = zipFile.getInputStream(coefficients);
-            DataInputStream dis = new DataInputStream(new BufferedInputStream(stream));
-            params = Nd4j.read(dis);
+            if(coefficients.getSize() > 0) {
+                InputStream stream = zipFile.getInputStream(coefficients);
+                DataInputStream dis = new DataInputStream(new BufferedInputStream(stream));
+                params = Nd4j.read(dis);
 
-            dis.close();
-            gotCoefficients = true;
+                dis.close();
+                gotCoefficients = true;
+            } else {
+                ZipEntry noParamsMarker = zipFile.getEntry(""noParams.marker"");
+                gotCoefficients = (noParamsMarker != null);
+            }
         }
 
 
diff --git a/deeplearning4j-zoo/src/test/java/org/deeplearning4j/zoo/TestInstantiation.java b/deeplearning4j-zoo/src/test/java/org/deeplearning4j/zoo/TestInstantiation.java
index 66d0b54f95..10232887cd 100644
--- a/deeplearning4j-zoo/src/test/java/org/deeplearning4j/zoo/TestInstantiation.java
+++ b/deeplearning4j-zoo/src/test/java/org/deeplearning4j/zoo/TestInstantiation.java
@@ -5,6 +5,7 @@ import org.deeplearning4j.datasets.iterator.impl.BenchmarkDataSetIterator;
 import org.deeplearning4j.nn.api.Model;
 import org.deeplearning4j.nn.graph.ComputationGraph;
 import org.deeplearning4j.nn.multilayer.MultiLayerNetwork;
+import org.deeplearning4j.nn.transferlearning.TransferLearningHelper;
 import org.deeplearning4j.zoo.model.Darknet19;
 import org.deeplearning4j.zoo.model.GoogLeNet;
 import org.deeplearning4j.zoo.model.ResNet50;
@@ -139,4 +140,16 @@ public class TestInstantiation {
         assertArrayEquals(result[0].shape(), new int[] {1, 125, 13, 13});
     }
 
+
+    @Test
+    public void testYolo4635() throws Exception {
+        //https://github.com/deeplearning4j/deeplearning4j/issues/4635
+
+        int nClasses = 10;
+        int seed = 12345;
+        TinyYOLO model = new TinyYOLO(nClasses, seed);
+        ComputationGraph computationGraph = (ComputationGraph) model.initPretrained();
+        TransferLearningHelper transferLearningHelper = new TransferLearningHelper(computationGraph, ""conv2d_9"");
+    }
+
 }","['deeplearning4j-core/src/test/java/org/deeplearning4j/nn/multilayer/MultiLayerTest.java', 'deeplearning4j-zoo/src/test/java/org/deeplearning4j/zoo/TestInstantiation.java', 'deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/graph/ComputationGraph.java', 'deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/gradient/DefaultGradient.java', 'deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/multilayer/MultiLayerNetwork.java', 'deeplearning4j-core/src/test/java/org/deeplearning4j/nn/graph/TestComputationGraphNetwork.java', 'deeplearning4j-nn/src/main/java/org/deeplearning4j/util/ModelSerializer.java', 'deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/updater/BaseMultiLayerUpdater.java']",{'.java': 8},8,8,0,0,8,7878422,1707448,215784,1363,3741,728,86,5,1486,94,389,29,0,0,2018-02-16 06:54:32,13099,Java,"{'Java': 42895752, 'C++': 17237193, 'Cuda': 2203734, 'Kotlin': 2030453, 'JavaScript': 296767, 'C': 172853, 'CMake': 126415, 'Shell': 96643, 'TypeScript': 81217, 'Python': 77566, 'FreeMarker': 77257, 'HTML': 18609, 'CSS': 12974, 'PureBasic': 12254, 'Cython': 12094, 'Ruby': 4558, 'Batchfile': 1458, 'Scala': 1026, 'Smarty': 975, 'Starlark': 931}",Apache License 2.0,"['deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/transferlearning/TransferLearning.java', 'org/deeplearning4j/nn/conf/layers/ZeroPaddingLayer.java', 'deeplearning4j-nlp-parent/deeplearning4j-nlp/src/main/java/org/deeplearning4j/models/embeddings/learning/impl/elements/RandomUtils.java', 'deeplearning4j-nlp-parent/deeplearning4j-nlp/src/main/java/org/deeplearning4j/models/embeddings/learning/impl/elements/SkipGram.java', 'deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/graph/ComputationGraph.java', 'deeplearning4j-nlp-parent/deeplearning4j-nlp/src/main/java/org/deeplearning4j/models/embeddings/learning/impl/elements/GloVe.java', 'deeplearning4j-nlp-parent/deeplearning4j-nlp/src/main/java/org/deeplearning4j/models/embeddings/learning/impl/elements/CBOW.java', 'deeplearning4j-scaleout/spark/dl4j-spark-nlp/src/main/java/org/deeplearning4j/spark/models/embeddings/glove/cooccurrences/CoOccurrenceCounts.java', 'deeplearning4j-nlp-parent/deeplearning4j-nlp/src/main/java/org/deeplearning4j/models/embeddings/learning/impl/sequence/DBOW.java', 'org/deeplearning4j/nn/graph/ComputationGraph.java', 'org/deeplearning4j/nn/conf/layers/ConvolutionLayer.java', 'deeplearning4j-scaleout/spark/dl4j-spark-nlp-java8/src/main/java/org/deeplearning4j/spark/models/sequencevectors/learning/sequence/SparkDM.java', 'org/deeplearning4j/nn/transferlearning/TransferLearningHelper.java', 'deeplearning4j-scaleout/spark/dl4j-spark-nlp/src/main/java/org/deeplearning4j/spark/models/embeddings/glove/cooccurrences/CoOccurrenceCalculator.java', 'deeplearning4j-zoo/src/main/java/org/deeplearning4j/zoo/model/TinyYOLO.java', 'org/deeplearning4j/nn/transferlearning/TransferLearning.java', 'deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/transferlearning/TransferLearningHelper.java']","['deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/graph/ComputationGraph.java', 'deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/transferlearning/TransferLearning.java', 'deeplearning4j-zoo/src/main/java/org/deeplearning4j/zoo/model/TinyYOLO.java', 'deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/transferlearning/TransferLearningHelper.java']","['```json\n{\n  ""files"": [\n    ""deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/transferlearning/TransferLearningHelper.java"",\n    ""deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/transferlearning/TransferLearning.java"",\n    ""deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/graph/ComputationGraph.java"",\n    ""deeplearning4j-zoo/src/main/java/org/deeplearning4j/zoo/model/TinyYOLO.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""org/deeplearning4j/nn/transferlearning/TransferLearningHelper.java"",\n    ""org/deeplearning4j/nn/transferlearning/TransferLearning.java"",\n    ""org/deeplearning4j/nn/graph/ComputationGraph.java"",\n    ""org/deeplearning4j/nn/conf/layers/ZeroPaddingLayer.java"",\n    ""org/deeplearning4j/nn/conf/layers/ConvolutionLayer.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/transferlearning/TransferLearning.java"",\n    ""deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/transferlearning/TransferLearningHelper.java"",\n    ""deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/graph/ComputationGraph.java"",\n    ""deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/graph/ComputationGraph.java"",\n    ""deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/graph/ComputationGraph.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""deeplearning4j-nlp-parent/deeplearning4j-nlp/src/main/java/org/deeplearning4j/models/embeddings/learning/impl/elements/CBOW.java"",\n    ""deeplearning4j-nlp-parent/deeplearning4j-nlp/src/main/java/org/deeplearning4j/models/embeddings/learning/impl/elements/GloVe.java"",\n    ""deeplearning4j-nlp-parent/deeplearning4j-nlp/src/main/java/org/deeplearning4j/models/embeddings/learning/impl/elements/RandomUtils.java"",\n    ""deeplearning4j-nlp-parent/deeplearning4j-nlp/src/main/java/org/deeplearning4j/models/embeddings/learning/impl/elements/SkipGram.java"",\n    ""deeplearning4j-nlp-parent/deeplearning4j-nlp/src/main/java/org/deeplearning4j/models/embeddings/learning/impl/sequence/DBOW.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""deeplearning4j-scaleout/spark/dl4j-spark-nlp/src/main/java/org/deeplearning4j/spark/models/embeddings/glove/cooccurrences/CoOccurrenceCalculator.java"",\n    ""deeplearning4j-scaleout/spark/dl4j-spark-nlp/src/main/java/org/deeplearning4j/spark/models/embeddings/glove/cooccurrences/CoOccurrenceCounts.java"",\n    ""deeplearning4j-scaleout/spark/dl4j-spark-nlp-java8/src/main/java/org/deeplearning4j/spark/models/sequencevectors/learning/sequence/SparkDM.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/transferlearning/TransferLearningHelper.java"",\n    ""deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/transferlearning/TransferLearning.java"",\n    ""deeplearning4j-zoo/src/main/java/org/deeplearning4j/zoo/model/TinyYOLO.java"",\n    ""deeplearning4j-nn/src/main/java/org/deeplearning4j/nn/graph/ComputationGraph.java""\n  ]\n}\n```']",5,14159.470319747925
1206,pinpoint-apm/pinpoint/2078/2077,pinpoint-apm,pinpoint,https://github.com/pinpoint-apm/pinpoint/issues/2077,https://github.com/pinpoint-apm/pinpoint/pull/2078,https://github.com/pinpoint-apm/pinpoint/pull/2078,1,fixes,Tomcat plugin fails to trace when profiler.tomcat.excludeurl is empty,"Tomcat plugin fails to inject interceptor to `StandardHostValve.invoke(...)` when _pinpoint.config_'s `profiler.tomcat.excludeurl` option is empty.
",0f94b21205ca84f01d18283b381615f5e88f3f55,6f90e3cbcd4d1f34dbe87ef28f84e2759966d6d2,https://github.com/pinpoint-apm/pinpoint/compare/0f94b21205ca84f01d18283b381615f5e88f3f55...6f90e3cbcd4d1f34dbe87ef28f84e2759966d6d2,"diff --git a/plugins/tomcat/src/main/java/com/navercorp/pinpoint/plugin/tomcat/TomcatConfiguration.java b/plugins/tomcat/src/main/java/com/navercorp/pinpoint/plugin/tomcat/TomcatConfiguration.java
index 0c0ba3bfcf..3f7e8089f6 100644
--- a/plugins/tomcat/src/main/java/com/navercorp/pinpoint/plugin/tomcat/TomcatConfiguration.java
+++ b/plugins/tomcat/src/main/java/com/navercorp/pinpoint/plugin/tomcat/TomcatConfiguration.java
@@ -14,9 +14,9 @@
  */
 package com.navercorp.pinpoint.plugin.tomcat;
 
-import com.navercorp.pinpoint.bootstrap.config.ExcludePathFilter;
 import com.navercorp.pinpoint.bootstrap.config.Filter;
 import com.navercorp.pinpoint.bootstrap.config.ProfilerConfig;
+import com.navercorp.pinpoint.bootstrap.config.SkipFilter;
 
 /**
  * @author Jongho Moon
@@ -24,14 +24,14 @@ import com.navercorp.pinpoint.bootstrap.config.ProfilerConfig;
  */
 public class TomcatConfiguration {
     private final boolean tomcatHidePinpointHeader;
-    private Filter<String> tomcatExcludeUrlFilter;
+    private final Filter<String> tomcatExcludeUrlFilter;
 
     public TomcatConfiguration(ProfilerConfig config) {
         this.tomcatHidePinpointHeader = config.readBoolean(""profiler.tomcat.hidepinpointheader"", true);
-        final String tomcatExcludeURL = config.readString(""profiler.tomcat.excludeurl"", """");
-        
-        if (!tomcatExcludeURL.isEmpty()) {
-            this.tomcatExcludeUrlFilter = new ExcludePathFilter(tomcatExcludeURL);
+        if (config.getTomcatExcludeProfileMethodFilter() == null) {
+            this.tomcatExcludeUrlFilter = new SkipFilter<String>();
+        } else {
+            this.tomcatExcludeUrlFilter = config.getTomcatExcludeUrlFilter();
         }
     }
 ",['plugins/tomcat/src/main/java/com/navercorp/pinpoint/plugin/tomcat/TomcatConfiguration.java'],{'.java': 1},1,1,0,0,1,11648680,2582423,338149,2482,703,146,12,1,148,14,35,2,0,0,2016-09-08 09:16:21,12879,Java,"{'Java': 20427181, 'TypeScript': 1739527, 'CSS': 222853, 'HTML': 216928, 'Thrift': 15920, 'Shell': 6420, 'JavaScript': 6310, 'Groovy': 1431, 'Kotlin': 1329, 'TSQL': 978, 'Batchfile': 200}",Apache License 2.0,"['profiler/src/main/java/com/navercorp/pinpoint/profiler/plugin/PluginConfig.java', 'web/src/main/java/com/navercorp/pinpoint/web/filter/FilterChain.java', '    ""profiler/src/main/java/com/navercorp/pinpoint/profiler/plugin/xml/transformer/ClassRecipe.java"",', 'profiler-optional/profiler-optional-jdk7/src/main/java/com/navercorp/pinpoint/profiler/monitor/codahale/cpu/metric/ibm/DefaultCpuLoadMetricSet.java', 'profiler/src/main/java/com/navercorp/pinpoint/profiler/instrument/interceptor/InterceptorType.java', 'profiler/src/main/java/com/navercorp/pinpoint/profiler/instrument/aspect/AspectWeaverClass.java', '  ""files"": [', '    ""plugins/tomcat/src/main/java/com/navercorp/pinpoint/plugin/tomcat/interceptor/StandardHostValveInvokeInterceptor.java"",', 'web/src/main/java/com/navercorp/pinpoint/web/filter/FilterDescriptor.java', 'profiler/src/main/java/com/navercorp/pinpoint/profiler/plugin/DefaultProfilerPluginContext.java', 'web/src/main/java/com/navercorp/pinpoint/web/filter/FilterBuilder.java', '```json', '    ""profiler/src/main/java/com/navercorp/pinpoint/profiler/plugin/xml/transformer/ClassFileTransformerBuilder.java"",', 'profiler/src/main/java/com/navercorp/pinpoint/profiler/plugin/ClassNameFilter.java', 'plugins/tomcat/src/main/java/com/navercorp/pinpoint/plugin/tomcat/TomcatConfiguration.java', 'web/src/main/java/com/navercorp/pinpoint/web/filter/Filter.java', 'profiler/src/main/java/com/navercorp/pinpoint/profiler/plugin/ProfilerPluginLoader.java', 'profiler/src/main/java/com/navercorp/pinpoint/profiler/plugin/ProfilerPlugin.java', '    ""profiler/src/main/java/com/navercorp/pinpoint/profiler/plugin', '{', 'profiler/src/main/java/com/navercorp/pinpoint/profiler/instrument/transformer/DefaultTransformerRegistry.java', '    ""profiler/src/main/java/com/navercorp/pinpoint/profiler/plugin/xml/transformer/ClassWeaver.java"",', 'profiler/src/main/java/com/navercorp/pinpoint/profiler/instrument/interceptor/InterceptorDefinitionFactory.java', 'web/src/main/java/com/navercorp/pinpoint/web/filter/URLPatternFilter.java', 'profiler-optional/profiler-optional-jdk7/src/main/java/com/navercorp/pinpoint/profiler/monitor/codahale/cpu/metric/oracle/DefaultCpuLoadMetricSet.java']","['profiler/src/main/java/com/navercorp/pinpoint/profiler/plugin/DefaultProfilerPluginContext.java', 'plugins/tomcat/src/main/java/com/navercorp/pinpoint/plugin/tomcat/TomcatConfiguration.java', 'profiler/src/main/java/com/navercorp/pinpoint/profiler/plugin/ProfilerPluginLoader.java']","['```json\n{\n  ""files"": [\n    ""profiler/src/main/java/com/navercorp/pinpoint/profiler/plugin/DefaultProfilerPluginContext.java"",\n    ""profiler/src/main/java/com/navercorp/pinpoint/profiler/plugin/PluginConfig.java"",\n    ""profiler/src/main/java/com/navercorp/pinpoint/profiler/plugin/ProfilerPluginLoader.java"",\n    ""profiler/src/main/java/com/navercorp/pinpoint/profiler/plugin/ProfilerPlugin.java"",\n    ""profiler/src/main/java/com/navercorp/pinpoint/profiler/plugin/ClassNameFilter.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""web/src/main/java/com/navercorp/pinpoint/web/filter/URLPatternFilter.java"",\n    ""web/src/main/java/com/navercorp/pinpoint/web/filter/FilterBuilder.java"",\n    ""web/src/main/java/com/navercorp/pinpoint/web/filter/FilterDescriptor.java"",\n    ""web/src/main/java/com/navercorp/pinpoint/web/filter/Filter.java"",\n    ""web/src/main/java/com/navercorp/pinpoint/web/filter/FilterChain.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""plugins/tomcat/src/main/java/com/navercorp/pinpoint/plugin/tomcat/TomcatConfiguration.java"",\n    ""profiler/src/main/java/com/navercorp/pinpoint/profiler/instrument/aspect/AspectWeaverClass.java"",\n    ""profiler/src/main/java/com/navercorp/pinpoint/profiler/instrument/interceptor/InterceptorDefinitionFactory.java"",\n    ""profiler/src/main/java/com/navercorp/pinpoint/profiler/instrument/interceptor/InterceptorType.java"",\n    ""profiler/src/main/java/com/navercorp/pinpoint/profiler/instrument/transformer/DefaultTransformerRegistry.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""plugins/tomcat/src/main/java/com/navercorp/pinpoint/plugin/tomcat/interceptor/StandardHostValveInvokeInterceptor.java"",\n    ""profiler/src/main/java/com/navercorp/pinpoint/profiler/plugin/xml/transformer/ClassRecipe.java"",\n    ""profiler/src/main/java/com/navercorp/pinpoint/profiler/plugin/xml/transformer/ClassWeaver.java"",\n    ""profiler/src/main/java/com/navercorp/pinpoint/profiler/plugin/xml/transformer/ClassFileTransformerBuilder.java"",\n    ""profiler/src/main/java/com/navercorp/pinpoint/profiler/plugin', '```json\n{\n  ""files"": [\n    ""profiler-optional/profiler-optional-jdk7/src/main/java/com/navercorp/pinpoint/profiler/monitor/codahale/cpu/metric/oracle/DefaultCpuLoadMetricSet.java"",\n    ""profiler-optional/profiler-optional-jdk7/src/main/java/com/navercorp/pinpoint/profiler/monitor/codahale/cpu/metric/ibm/DefaultCpuLoadMetricSet.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""plugins/tomcat/src/main/java/com/navercorp/pinpoint/plugin/tomcat/TomcatConfiguration.java"",\n    ""profiler/src/main/java/com/navercorp/pinpoint/profiler/plugin/DefaultProfilerPluginContext.java"",\n    ""profiler/src/main/java/com/navercorp/pinpoint/profiler/plugin/ProfilerPluginLoader.java""\n  ]\n}\n```']",5,13298.546314239502
2180,quarkusio/quarkus/33586/33305,quarkusio,quarkus,https://github.com/quarkusio/quarkus/issues/33305,https://github.com/quarkusio/quarkus/pull/33586,https://github.com/quarkusio/quarkus/pull/33586,1,fix,OutputTargetBuildItem.getOutputDirectory() returning a strange value when running a test in the Platform,"### Describe the bug

I see `OutputTargetBuildItem.getOutputDirectory()` returning a very strange value 

```
/home/ppalaga/orgs/quarkus/quarkus-platform/generated-platform-project/quarkus-cxf/integration-tests/quarkus-cxf-integration-test-server/..
```
when running a generarated test project on the Platform.

I'd expect something like 

```
/home/ppalaga/orgs/quarkus/quarkus-platform/generated-platform-project/quarkus-cxf/integration-tests/quarkus-cxf-integration-test-server/target
```

Is this a bug or some peculiarity of the Platform test config @aloubyansky ?
",8101c3ec85fed92ecfff556a40c68243e93b0c73,47fa50fa5e6b5203c14af80e1c68a0e3cb1de089,https://github.com/quarkusio/quarkus/compare/8101c3ec85fed92ecfff556a40c68243e93b0c73...47fa50fa5e6b5203c14af80e1c68a0e3cb1de089,"diff --git a/independent-projects/bootstrap/core/src/main/java/io/quarkus/bootstrap/BootstrapAppModelFactory.java b/independent-projects/bootstrap/core/src/main/java/io/quarkus/bootstrap/BootstrapAppModelFactory.java
index 6c068b88029..e7b1c5a1e4c 100644
--- a/independent-projects/bootstrap/core/src/main/java/io/quarkus/bootstrap/BootstrapAppModelFactory.java
+++ b/independent-projects/bootstrap/core/src/main/java/io/quarkus/bootstrap/BootstrapAppModelFactory.java
@@ -205,7 +205,7 @@ public CurationResult resolveAppModel() throws BootstrapException {
         if (serializedModel != null) {
             final Path p = Paths.get(serializedModel);
             if (Files.exists(p)) {
-                try (InputStream existing = Files.newInputStream(Paths.get(serializedModel))) {
+                try (InputStream existing = Files.newInputStream(p)) {
                     final ApplicationModel appModel = (ApplicationModel) new ObjectInputStream(existing).readObject();
                     return new CurationResult(appModel);
                 } catch (IOException | ClassNotFoundException e) {
diff --git a/test-framework/common/src/main/java/io/quarkus/test/common/PathTestHelper.java b/test-framework/common/src/main/java/io/quarkus/test/common/PathTestHelper.java
index 079f0d7a32d..05fda9bc7c6 100644
--- a/test-framework/common/src/main/java/io/quarkus/test/common/PathTestHelper.java
+++ b/test-framework/common/src/main/java/io/quarkus/test/common/PathTestHelper.java
@@ -292,14 +292,10 @@ private static Path toPath(URL resource) {
      * @return project build dir
      */
     public static Path getProjectBuildDir(Path projectRoot, Path testClassLocation) {
-        Path outputDir;
-        try {
-            // this should work for both maven and gradle
-            outputDir = projectRoot.resolve(projectRoot.relativize(testClassLocation).getName(0));
-        } catch (Exception e) {
-            // this shouldn't happen since testClassLocation is usually found under the project dir
-            outputDir = projectRoot;
+        if (!testClassLocation.startsWith(projectRoot)) {
+            // this typically happens in the platform testsuite where test classes are loaded from jars
+            return projectRoot.resolve(""target"");
         }
-        return outputDir;
+        return projectRoot.resolve(projectRoot.relativize(testClassLocation).getName(0));
     }
 }","['test-framework/common/src/main/java/io/quarkus/test/common/PathTestHelper.java', 'independent-projects/bootstrap/core/src/main/java/io/quarkus/bootstrap/BootstrapAppModelFactory.java']",{'.java': 2},2,2,0,0,2,26579575,5242481,675870,6244,168,29,2,1,586,45,140,17,0,2,2023-05-24 19:12:05,12047,Java,"{'Java': 45174846, 'HTML': 1260641, 'Kotlin': 726044, 'JavaScript': 519044, 'Shell': 51146, 'Groovy': 25140, 'ANTLR': 23342, 'Batchfile': 13971, 'Mustache': 13199, 'Scala': 9778, 'FreeMarker': 8106, 'CSS': 5346, 'Dockerfile': 660, 'PLpgSQL': 109}",Apache License 2.0,"['devtools/cli/src/main/java/io/quarkus/cli/build/MavenRunner.java', 'devtools/cli/src/main/java/io/quarkus/cli/build/ExecuteUtil.java', 'extensions/vertx-http/runtime/src/main/java/io/quarkus/vertx/http/runtime/VertxConfigBuilder.java', 'extensions/resteasy-reactive/quarkus-resteasy-reactive/runtime/src/main/java/io/quarkus/resteasy/reactive/server/EndpointDisabled.java', 'extensions/hibernate-orm/deployment/src/main/java/io/quarkus/hibernate/orm/deployment/HibernateOrmEnabled.java', 'extensions/redis-client/runtime/src/main/java/io/quarkus/redis/runtime/client/VertxRedisClientFactory.java', 'extensions/opentelemetry/deployment/src/main/java/io/quarkus/opentelemetry/deployment/tracing/TracerProcessor.java', 'extensions/redis-client/runtime/src/main/java/io/quarkus/redis/runtime/client/RedisDataLoader.java', 'extensions/hibernate-orm/deployment/src/main/java/io/quarkus/hibernate/orm/deployment/dev/HibernateOrmDevUIProcessor.java', 'devtools/cli/src/main/java/io/quarkus/cli/build/GradleRunner.java', 'extensions/smallrye-reactive-messaging-rabbitmq/runtime/src/main/java/io/quarkus/smallrye/reactivemessaging/rabbitmq/runtime/devconsole/DevRabbitMqHttpPortSupplier.java', 'independent-projects/tools/devtools-common/src/main/java/io/quarkus/devtools/commands/CreateExtension.java', 'extensions/redis-client/runtime/src/main/java/io/quarkus/redis/runtime/client/ReactiveRedisClientImpl.java', 'extensions/vertx/deployment/src/main/java/io/quarkus/vertx/deployment/MessageCodecBuildItem.java', 'extensions/devservices/deployment/src/main/java/io/quarkus/devservices/deployment/DevServicesCommand.java', 'extensions/redis-client/runtime/src/main/java/io/quarkus/redis/runtime/client/RedisClientRecorder.java', 'extensions/container-image/container-image-docker/deployment/src/main/java/io/quarkus/container/image/docker/deployment/DockerProcessor.java', 'extensions/cxf/integration-tests/quarkus-cxf-integration-test-server/src/test/java/io/quarkus/cxf/integration/test/QuarkusCxfIntegrationTestServerTest.java', 'extensions/hibernate-orm/deployment/src/main/java/io/quarkus/hibernate/orm/deployment/HibernateOrmConfig.java', 'core/deployment/src/main/java/io/quarkus/deployment/pkg/builditem/OutputTargetBuildItem.java', 'extensions/vertx-http/runtime/src/main/java/io/quarkus/vertx/http/runtime/HttpConfiguration.java', 'extensions/smallrye-reactive-messaging-rabbitmq/runtime/src/main/java/io/quarkus/smallrye/reactivemessaging/rabbitmq/runtime/devconsole/RabbitHttpPortFinder.java', 'extensions/hibernate-orm/runtime/src/main/java/io/quarkus/hibernate/orm/runtime/dev/HibernateOrmDevInfo.java', 'extensions/panache/hibernate-orm-rest-data-panache/runtime/src/main/java/io/quarkus/hibernate/orm/rest/data/panache/runtime/jta/TransactionalUpdateExecutor.java', 'extensions/vertx/deployment/src/main/java/io/quarkus/vertx/deployment/EventConsumerBusinessMethodItem.java', 'extensions/hibernate-orm/runtime/src/main/java/io/quarkus/hibernate/orm/runtime/dev/HibernateOrmDevController.java', 'extensions/container-image/container-image-docker/deployment/src/main/java/io/quarkus/container/image/docker/deployment/RedHatOpenJDKRuntimeBaseProvider.java', 'extensions/hibernate-orm/deployment/src/main/java/io/quarkus/hibernate/orm/deployment/dev/HibernateOrmDevServicesProcessor.java', 'core/deployment/src/main/java/io/quarkus/deployment/builditem/OutputTargetBuildItem.java', 'extensions/hibernate-reactive/deployment/src/main/java/io/quarkus/hibernate/reactive/deployment/HibernateReactiveProcessor.java', 'extensions/vertx-http/runtime/src/main/java/io/quarkus/vertx/http/runtime/HttpBuildTimeConfig.java', 'extensions/jdbc/jdbc-mysql/runtime/src/main/java/io/quarkus/jdbc/mysql/runtime/graal/com/mysql/cj/jdbc/MySQLJDBCSubstitutions.java', 'extensions/container-image/container-image-docker/deployment/src/main/java/io/quarkus/container/image/docker/deployment/DockerFileBaseInformationProvider.java', 'extensions/smallrye-reactive-messaging-rabbitmq/runtime/src/main/java/io/quarkus/smallrye/reactivemessaging/rabbitmq/runtime/devconsole/RabbitMqJsonRpcService.java', 'extensions/vertx/deployment/src/main/java/io/quarkus/vertx/deployment/EventBusConsumer.java', 'independent-projects/tools/devtools-common/src/main/java/io/quarkus/devtools/commands/CreateProjectHelper.java', 'extensions/redis-client/runtime/src/main/java/io/quarkus/redis/runtime/client/RedisClientImpl.java', 'independent-projects/tools/devtools-common/src/main/java/io/quarkus/devtools/commands/CreateJBangProject.java', 'extensions/vertx-http/runtime/src/main/java/io/quarkus/vertx/http/runtime/VertxHttpRecorder.java', 'extensions/vertx/deployment/src/main/java/io/quarkus/vertx/deployment/CopyVertxContextDataBuildItem.java', 'extensions/jdbc/jdbc-mssql/runtime/src/main/java/io/quarkus/jdbc/mssql/runtime/graal/com/microsoft/sqlserver/jdbc/SQLServerJDBCSubstitutions.java', 'extensions/devservices/deployment/src/main/java/io/quarkus/devservices/deployment/DevServicesProcessor.java', 'extensions/container-image/container-image-docker/deployment/src/main/java/io/quarkus/container/image/docker/deployment/DockerConfig.java', 'devtools/cli/src/main/java/io/quarkus/cli/build/BuildSystemRunner.java', 'extensions/opentelemetry/runtime/src/main/java/io/quarkus/opentelemetry/runtime/tracing/TracerUtil.java', 'extensions/hibernate-orm/deployment/src/main/java/io/quarkus/hibernate/orm/deployment/dev/HibernateOrmDevConsoleProcessor.java', 'extensions/devservices/deployment/src/main/java/io/quarkus/devservices/deployment/DevServicesLogsCommand.java', 'extensions/hibernate-orm/deployment/src/main/java/io/quarkus/hibernate/orm/deployment/HibernateEntityEnhancer.java', 'extensions/smallrye-reactive-messaging-rabbitmq/runtime/src/main/java/io/quarkus/smallrye/reactivemessaging/rabbitmq/runtime/devconsole/DevRabbitMqHttpPort.java', 'extensions/hibernate-orm/deployment/src/main/java/io/quarkus/hibernate/orm/deployment/HibernateOrmProcessor.java', 'extensions/opentelemetry/runtime/src/main/java/io/quarkus/opentelemetry/runtime/tracing/TracerRecorder.java', 'extensions/devservices/deployment/src/main/java/io/quarkus/devservices/deployment/DevServicesListCommand.java', 'extensions/vertx-http/runtime/src/main/java/io/quarkus/vertx/http/runtime/VertxCoreRecorder.java', 'devtools/cli/src/main/java/io/quarkus/cli/build/BaseBuildCommand.java', 'independent-projects/tools/devtools-common/src/main/java/io/quarkus/devtools/commands/CreateProject.java', 'extensions/container-image/container-image-docker/deployment/src/main/java/io/quarkus/container/image/docker/deployment/DockerBuild.java', 'extensions/vertx/deployment/src/main/java/io/quarkus/vertx/deployment/EventBusCodecProcessor.java', 'extensions/devservices/deployment/src/main/java/io/quarkus/devservices/deployment/ContainerLogForwarder.java']",['core/deployment/src/main/java/io/quarkus/deployment/pkg/builditem/OutputTargetBuildItem.java'],"['```json\n{\n  ""files"": [\n    ""core/deployment/src/main/java/io/quarkus/deployment/builditem/OutputTargetBuildItem.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""devtools/cli/src/main/java/io/quarkus/cli/build/BaseBuildCommand.java"",\n    ""devtools/cli/src/main/java/io/quarkus/cli/build/BuildSystemRunner.java"",\n    ""devtools/cli/src/main/java/io/quarkus/cli/build/ExecuteUtil.java"",\n    ""devtools/cli/src/main/java/io/quarkus/cli/build/GradleRunner.java"",\n    ""devtools/cli/src/main/java/io/quarkus/cli/build/MavenRunner.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""core/deployment/src/main/java/io/quarkus/deployment/pkg/builditem/OutputTargetBuildItem.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""extensions/devservices/deployment/src/main/java/io/quarkus/devservices/deployment/ContainerLogForwarder.java"",\n    ""extensions/devservices/deployment/src/main/java/io/quarkus/devservices/deployment/DevServicesCommand.java"",\n    ""extensions/devservices/deployment/src/main/java/io/quarkus/devservices/deployment/DevServicesListCommand.java"",\n    ""extensions/devservices/deployment/src/main/java/io/quarkus/devservices/deployment/DevServicesLogsCommand.java"",\n    ""extensions/devservices/deployment/src/main/java/io/quarkus/devservices/deployment/DevServicesProcessor.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""extensions/vertx/deployment/src/main/java/io/quarkus/vertx/deployment/EventBusCodecProcessor.java"",\n    ""extensions/vertx/deployment/src/main/java/io/quarkus/vertx/deployment/EventBusConsumer.java"",\n    ""extensions/vertx/deployment/src/main/java/io/quarkus/vertx/deployment/EventConsumerBusinessMethodItem.java"",\n    ""extensions/vertx/deployment/src/main/java/io/quarkus/vertx/deployment/CopyVertxContextDataBuildItem.java"",\n    ""extensions/vertx/deployment/src/main/java/io/quarkus/vertx/deployment/MessageCodecBuildItem.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""independent-projects/tools/devtools-common/src/main/java/io/quarkus/devtools/commands/CreateProject.java"",\n    ""independent-projects/tools/devtools-common/src/main/java/io/quarkus/devtools/commands/CreateJBangProject.java"",\n    ""independent-projects/tools/devtools-common/src/main/java/io/quarkus/devtools/commands/CreateExtension.java"",\n    ""independent-projects/tools/devtools-common/src/main/java/io/quarkus/devtools/commands/CreateProjectHelper.java"",\n    ""independent-projects/tools/devtools-common/src/main/java/io/quarkus/devtools/commands/CreateJBangProject.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""extensions/hibernate-reactive/deployment/src/main/java/io/quarkus/hibernate/reactive/deployment/HibernateReactiveProcessor.java"",\n    ""extensions/hibernate-orm/deployment/src/main/java/io/quarkus/hibernate/orm/deployment/HibernateOrmProcessor.java"",\n    ""extensions/hibernate-orm/deployment/src/main/java/io/quarkus/hibernate/orm/deployment/HibernateOrmConfig.java"",\n    ""extensions/hibernate-orm/deployment/src/main/java/io/quarkus/hibernate/orm/deployment/HibernateEntityEnhancer.java"",\n    ""extensions/hibernate-orm/deployment/src/main/java/io/quarkus/hibernate/orm/deployment/HibernateOrmEnabled.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""extensions/opentelemetry/deployment/src/main/java/io/quarkus/opentelemetry/deployment/tracing/TracerProcessor.java"",\n    ""extensions/opentelemetry/runtime/src/main/java/io/quarkus/opentelemetry/runtime/tracing/TracerRecorder.java"",\n    ""extensions/opentelemetry/runtime/src/main/java/io/quarkus/opentelemetry/runtime/tracing/TracerUtil.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""extensions/redis-client/runtime/src/main/java/io/quarkus/redis/runtime/client/RedisClientRecorder.java"",\n    ""extensions/redis-client/runtime/src/main/java/io/quarkus/redis/runtime/client/ReactiveRedisClientImpl.java"",\n    ""extensions/redis-client/runtime/src/main/java/io/quarkus/redis/runtime/client/RedisClientImpl.java"",\n    ""extensions/redis-client/runtime/src/main/java/io/quarkus/redis/runtime/client/VertxRedisClientFactory.java"",\n    ""extensions/redis-client/runtime/src/main/java/io/quarkus/redis/runtime/client/RedisDataLoader.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""extensions/vertx-http/runtime/src/main/java/io/quarkus/vertx/http/runtime/VertxHttpRecorder.java"",\n    ""extensions/vertx-http/runtime/src/main/java/io/quarkus/vertx/http/runtime/HttpConfiguration.java"",\n    ""extensions/vertx-http/runtime/src/main/java/io/quarkus/vertx/http/runtime/VertxConfigBuilder.java"",\n    ""extensions/vertx-http/runtime/src/main/java/io/quarkus/vertx/http/runtime/HttpBuildTimeConfig.java"",\n    ""extensions/vertx-http/runtime/src/main/java/io/quarkus/vertx/http/runtime/VertxCoreRecorder.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""extensions/hibernate-orm/deployment/src/main/java/io/quarkus/hibernate/orm/deployment/dev/HibernateOrmDevConsoleProcessor.java"",\n    ""extensions/hibernate-orm/deployment/src/main/java/io/quarkus/hibernate/orm/deployment/dev/HibernateOrmDevServicesProcessor.java"",\n    ""extensions/hibernate-orm/deployment/src/main/java/io/quarkus/hibernate/orm/deployment/dev/HibernateOrmDevUIProcessor.java"",\n    ""extensions/hibernate-orm/runtime/src/main/java/io/quarkus/hibernate/orm/runtime/dev/HibernateOrmDevController.java"",\n    ""extensions/hibernate-orm/runtime/src/main/java/io/quarkus/hibernate/orm/runtime/dev/HibernateOrmDevInfo.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""extensions/resteasy-reactive/quarkus-resteasy-reactive/runtime/src/main/java/io/quarkus/resteasy/reactive/server/EndpointDisabled.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""extensions/container-image/container-image-docker/deployment/src/main/java/io/quarkus/container/image/docker/deployment/DockerBuild.java"",\n    ""extensions/container-image/container-image-docker/deployment/src/main/java/io/quarkus/container/image/docker/deployment/DockerConfig.java"",\n    ""extensions/container-image/container-image-docker/deployment/src/main/java/io/quarkus/container/image/docker/deployment/DockerFileBaseInformationProvider.java"",\n    ""extensions/container-image/container-image-docker/deployment/src/main/java/io/quarkus/container/image/docker/deployment/DockerProcessor.java"",\n    ""extensions/container-image/container-image-docker/deployment/src/main/java/io/quarkus/container/image/docker/deployment/RedHatOpenJDKRuntimeBaseProvider.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""extensions/smallrye-reactive-messaging-rabbitmq/runtime/src/main/java/io/quarkus/smallrye/reactivemessaging/rabbitmq/runtime/devconsole/DevRabbitMqHttpPort.java"",\n    ""extensions/smallrye-reactive-messaging-rabbitmq/runtime/src/main/java/io/quarkus/smallrye/reactivemessaging/rabbitmq/runtime/devconsole/DevRabbitMqHttpPortSupplier.java"",\n    ""extensions/smallrye-reactive-messaging-rabbitmq/runtime/src/main/java/io/quarkus/smallrye/reactivemessaging/rabbitmq/runtime/devconsole/RabbitHttpPortFinder.java"",\n    ""extensions/smallrye-reactive-messaging-rabbitmq/runtime/src/main/java/io/quarkus/smallrye/reactivemessaging/rabbitmq/runtime/devconsole/RabbitMqJsonRpcService.java"",\n    ""extensions/smallrye-reactive-messaging-rabbitmq/runtime/src/main/java/io/quarkus/smallrye/reactivemessaging/rabbitmq/runtime/devconsole/RabbitMqJsonRpcService.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""extensions/cxf/integration-tests/quarkus-cxf-integration-test-server/src/test/java/io/quarkus/cxf/integration/test/QuarkusCxfIntegrationTestServerTest.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""extensions/panache/hibernate-orm-rest-data-panache/runtime/src/main/java/io/quarkus/hibernate/orm/rest/data/panache/runtime/jta/TransactionalUpdateExecutor.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""extensions/jdbc/jdbc-mssql/runtime/src/main/java/io/quarkus/jdbc/mssql/runtime/graal/com/microsoft/sqlserver/jdbc/SQLServerJDBCSubstitutions.java"",\n    ""extensions/jdbc/jdbc-mysql/runtime/src/main/java/io/quarkus/jdbc/mysql/runtime/graal/com/mysql/cj/jdbc/MySQLJDBCSubstitutions.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""core/deployment/src/main/java/io/quarkus/deployment/pkg/builditem/OutputTargetBuildItem.java""\n  ]\n}\n```']",17,36467.99111366272
531,codecentric/spring-boot-admin/1589/1586,codecentric,spring-boot-admin,https://github.com/codecentric/spring-boot-admin/issues/1586,https://github.com/codecentric/spring-boot-admin/pull/1589,https://github.com/codecentric/spring-boot-admin/pull/1589#issuecomment-765189411,1,closes,Unable to override spring.security.user.name and spring.security.user.password credentials in spring-boot-admin-sample-servlet sample,"I was unable to override `spring.security.user.name` and `spring.security.user.password` credentials in spring-boot-admin-sample-servlet sample when I migrate from 2.1.6 to 2.3.1.

I think the problem may be related to this code [here](https://github.com/codecentric/spring-boot-admin/blob/10022c67a0fcbd6d6dadaf969a423824cc68ce5b/spring-boot-admin-samples/spring-boot-admin-sample-servlet/src/main/java/de/codecentric/boot/admin/SecuritySecureConfig.java#L71). It forces fixed credentials.

I look forward to your answer.",8beb98664de476546c8f2df4627051764610a3e1,dac53444fbc6eaa29225292486fea43e5e9d6ed5,https://github.com/codecentric/spring-boot-admin/compare/8beb98664de476546c8f2df4627051764610a3e1...dac53444fbc6eaa29225292486fea43e5e9d6ed5,"diff --git a/spring-boot-admin-samples/spring-boot-admin-sample-servlet/src/main/java/de/codecentric/boot/admin/SecuritySecureConfig.java b/spring-boot-admin-samples/spring-boot-admin-sample-servlet/src/main/java/de/codecentric/boot/admin/SecuritySecureConfig.java
index 314539e7..794cc43c 100644
--- a/spring-boot-admin-samples/spring-boot-admin-sample-servlet/src/main/java/de/codecentric/boot/admin/SecuritySecureConfig.java
+++ b/spring-boot-admin-samples/spring-boot-admin-sample-servlet/src/main/java/de/codecentric/boot/admin/SecuritySecureConfig.java
@@ -18,6 +18,7 @@ package de.codecentric.boot.admin;
 
 import java.util.UUID;
 
+import org.springframework.boot.autoconfigure.security.SecurityProperties;
 import org.springframework.context.annotation.Configuration;
 import org.springframework.context.annotation.Profile;
 import org.springframework.http.HttpMethod;
@@ -38,8 +39,11 @@ public class SecuritySecureConfig extends WebSecurityConfigurerAdapter {
 
 	private final AdminServerProperties adminServer;
 
-	public SecuritySecureConfig(AdminServerProperties adminServer) {
+	private final SecurityProperties security;
+
+	public SecuritySecureConfig(AdminServerProperties adminServer, SecurityProperties security) {
 		this.adminServer = adminServer;
+		this.security = security;
 	}
 
 	@Override
@@ -70,7 +74,8 @@ public class SecuritySecureConfig extends WebSecurityConfigurerAdapter {
 	// Required to provide UserDetailsService for ""remember functionality""
 	@Override
 	protected void configure(AuthenticationManagerBuilder auth) throws Exception {
-		auth.inMemoryAuthentication().withUser(""user"").password(""{noop}password"").roles(""USER"");
+		auth.inMemoryAuthentication().withUser(security.getUser().getName())
+				.password(""{noop}"" + security.getUser().getPassword()).roles(""USER"");
 	}
 
 }",['spring-boot-admin-samples/spring-boot-admin-sample-servlet/src/main/java/de/codecentric/boot/admin/SecuritySecureConfig.java'],{'.java': 1},1,1,0,0,1,545695,113488,15941,196,553,101,9,1,526,40,136,5,1,0,2021-01-14 16:29:26,11832,Java,"{'Java': 1222285, 'Vue': 485886, 'TypeScript': 421999, 'JavaScript': 28953, 'HTML': 9736, 'CSS': 7226, 'SCSS': 4803, 'MDX': 582, 'Dockerfile': 159}",Apache License 2.0,['spring-boot-admin-samples/spring-boot-admin-sample-servlet/src/main/java/de/codecentric/boot/admin/SecuritySecureConfig.java'],['spring-boot-admin-samples/spring-boot-admin-sample-servlet/src/main/java/de/codecentric/boot/admin/SecuritySecureConfig.java'],"['```json\n{\n  ""files"": [\n    ""spring-boot-admin-samples/spring-boot-admin-sample-servlet/src/main/java/de/codecentric/boot/admin/SecuritySecureConfig.java""\n  ]\n}\n```']",1,1186.7380142211914
612,zaproxy/zaproxy/7494/7484,zaproxy,zaproxy,https://github.com/zaproxy/zaproxy/issues/7484,https://github.com/zaproxy/zaproxy/pull/7494,https://github.com/zaproxy/zaproxy/pull/7494,1,fix,Using the Active Scan for GET targets sends a 'Content-Length' header,"When using the Active Scan for a GET target Zap sends the header 'Content-Length: 0' in the requests.

This should not happen and can prevent scanning some servers which do reject the 'Content-Length: 0' header in GET requests.

Reproduction:
Install Python
Start Python http server: `python -m http.server 7777`
Start Zap GUI, proxy at 8080, turn off HUD
Make a request using curl: `curl --proxy http://localhost:8080 http://localhost:7777`
See the request in Zap history
Right click the request in Zap history, select ""Open/Resend in request editor""
See that no ""content-length"" header is present
Right click the request again, select ""Attack->Active Scan""
Check the requests in the Active Scan tab
See that all the request have the header `Content-Length: 0`

The requests in the attack should not have the ""Content-Length"" header as some systems reject GET requests with it.

Zap version used: 2.11.1",680d0024afbef18339c7acfe3b64b9861e73de51,3ba3cc92f6a127349eecf54f4e8928a3bf9efbc4,https://github.com/zaproxy/zaproxy/compare/680d0024afbef18339c7acfe3b64b9861e73de51...3ba3cc92f6a127349eecf54f4e8928a3bf9efbc4,"diff --git a/zap/src/main/java/org/parosproxy/paros/core/scanner/AbstractPlugin.java b/zap/src/main/java/org/parosproxy/paros/core/scanner/AbstractPlugin.java
index 963f38c27..57e306581 100644
--- a/zap/src/main/java/org/parosproxy/paros/core/scanner/AbstractPlugin.java
+++ b/zap/src/main/java/org/parosproxy/paros/core/scanner/AbstractPlugin.java
@@ -74,6 +74,7 @@
 // ZAP: 2022/06/05 Remove usage of HttpException.
 // ZAP: 2022/08/03 Keep enabled state when setting default alert threshold (Issue 7400).
 // ZAP: 2022/09/08 Use format specifiers instead of concatenation when logging.
+// ZAP: 2022/09/28 Do not set the Content-Length header when the method does not require one.
 package org.parosproxy.paros.core.scanner;
 
 import java.io.IOException;
@@ -95,6 +96,7 @@ import org.parosproxy.paros.core.scanner.Alert.Source;
 import org.parosproxy.paros.model.HistoryReference;
 import org.parosproxy.paros.network.HttpHeader;
 import org.parosproxy.paros.network.HttpMessage;
+import org.parosproxy.paros.network.HttpRequestHeader;
 import org.parosproxy.paros.network.HttpStatusCode;
 import org.zaproxy.zap.control.AddOn;
 import org.zaproxy.zap.extension.anticsrf.ExtensionAntiCSRF;
@@ -297,7 +299,8 @@ public abstract class AbstractPlugin implements Plugin, Comparable<Object> {
         // always get the fresh copy
         message.getRequestHeader().setHeader(HttpHeader.IF_MODIFIED_SINCE, null);
         message.getRequestHeader().setHeader(HttpHeader.IF_NONE_MATCH, null);
-        message.getRequestHeader().setContentLength(message.getRequestBody().length());
+
+        updateRequestContentLength(message);
 
         if (this.getDelayInMs() > 0) {
             try {
@@ -323,6 +326,30 @@ public abstract class AbstractPlugin implements Plugin, Comparable<Object> {
         parent.performScannerHookAfterScan(message, this);
     }
 
+    /**
+     * Updates the Content-Length header of the request.
+     *
+     * <p>For methods with absent or unanticipated enclosed content, the header is removed otherwise
+     * in all other cases the header is updated to match the length of the content.
+     *
+     * @param message the message to update.
+     * @since 2.12.0
+     */
+    protected void updateRequestContentLength(HttpMessage message) {
+        int bodyLength = message.getRequestBody().length();
+        String method = message.getRequestHeader().getMethod();
+        if (bodyLength == 0
+                && (HttpRequestHeader.GET.equalsIgnoreCase(method)
+                        || HttpRequestHeader.CONNECT.equalsIgnoreCase(method)
+                        || HttpRequestHeader.DELETE.equalsIgnoreCase(method)
+                        || HttpRequestHeader.HEAD.equalsIgnoreCase(method)
+                        || HttpRequestHeader.TRACE.equalsIgnoreCase(method))) {
+            message.getRequestHeader().setHeader(HttpHeader.CONTENT_LENGTH, null);
+            return;
+        }
+        message.getRequestHeader().setContentLength(bodyLength);
+    }
+
     @Override
     public void run() {
         // ZAP : set skipped to false otherwise the plugin should stop continuously
diff --git a/zap/src/test/java/org/parosproxy/paros/core/scanner/AbstractPluginUnitTest.java b/zap/src/test/java/org/parosproxy/paros/core/scanner/AbstractPluginUnitTest.java
index c5b3a6fa2..c108385c0 100644
--- a/zap/src/test/java/org/parosproxy/paros/core/scanner/AbstractPluginUnitTest.java
+++ b/zap/src/test/java/org/parosproxy/paros/core/scanner/AbstractPluginUnitTest.java
@@ -36,6 +36,8 @@ import static org.mockito.Mockito.when;
 
 import java.io.IOException;
 import java.security.InvalidParameterException;
+import java.util.Arrays;
+import java.util.List;
 import java.util.stream.Stream;
 import org.apache.commons.configuration.Configuration;
 import org.apache.commons.httpclient.URI;
@@ -50,6 +52,7 @@ import org.mockito.ArgumentCaptor;
 import org.parosproxy.paros.Constant;
 import org.parosproxy.paros.core.scanner.Plugin.AlertThreshold;
 import org.parosproxy.paros.network.HttpHeader;
+import org.parosproxy.paros.network.HttpMalformedHeaderException;
 import org.parosproxy.paros.network.HttpMessage;
 import org.parosproxy.paros.network.HttpRequestHeader;
 import org.parosproxy.paros.network.HttpSender;
@@ -63,6 +66,19 @@ import org.zaproxy.zap.utils.ZapXmlConfiguration;
 /** Unit test for {@link AbstractPlugin}. */
 class AbstractPluginUnitTest extends PluginTestUtils {
 
+    private static final List<String> METHODS_NO_ENCLOSED_CONTENT =
+            Arrays.asList(
+                    HttpRequestHeader.CONNECT,
+                    ""connect"",
+                    HttpRequestHeader.DELETE,
+                    ""delete"",
+                    HttpRequestHeader.GET,
+                    ""get"",
+                    HttpRequestHeader.HEAD,
+                    ""head"",
+                    HttpRequestHeader.TRACE,
+                    ""trace"");
+
     HostProcess parent;
     HttpMessage message;
     Analyser analyser;
@@ -2073,6 +2089,95 @@ class AbstractPluginUnitTest extends PluginTestUtils {
         assertThat(message.getRequestHeader().getHeader(HttpHeader.X_ZAP_SCAN_ID), is(nullValue()));
     }
 
+    @ParameterizedTest
+    @MethodSource(""methodsNoEnclosedContent"")
+    void shouldNotAddContentLenthHeaderWhenNotExpected(String method) {
+        // Given
+        HttpMessage message = messageWithMethod(method);
+        // When
+        plugin.updateRequestContentLength(message);
+        // Then
+        assertContentLength(message.getRequestHeader(), null);
+    }
+
+    @ParameterizedTest
+    @MethodSource(""methodsNoEnclosedContent"")
+    void shouldRemoveExistingContentLengthHeaderWhenNotExpectedNorNeeded(String method) {
+        // Given
+        HttpMessage message = messageWithMethod(method);
+        message.getRequestHeader().setContentLength(1234);
+        // When
+        plugin.updateRequestContentLength(message);
+        // Then
+        assertContentLength(message.getRequestHeader(), null);
+    }
+
+    @ParameterizedTest
+    @MethodSource(""allMethods"")
+    void shouldAddContentLengthHeaderWhenNeeded(String method) {
+        // Given
+        HttpMessage message = messageWithMethod(method);
+        message.setRequestBody(""1234"");
+        // When
+        plugin.updateRequestContentLength(message);
+        // Then
+        assertContentLength(message.getRequestHeader(), ""4"");
+    }
+
+    @ParameterizedTest
+    @MethodSource(""allMethodsExceptNoEnclosedContent"")
+    void shouldAddZeroContentLengthHeaderWhenNeeded(String method) {
+        // Given
+        HttpMessage message = messageWithMethod(method);
+        // When
+        plugin.updateRequestContentLength(message);
+        // Then
+        assertContentLength(message.getRequestHeader(), ""0"");
+    }
+
+    @ParameterizedTest
+    @MethodSource(""allMethods"")
+    void shouldUpdateExistingContentLengthHeaderWhenNeeded(String method) {
+        // Given
+        HttpMessage message = messageWithMethod(method);
+        message.setRequestBody(""1234"");
+        message.getRequestHeader().setContentLength(42);
+        // When
+        plugin.updateRequestContentLength(message);
+        // Then
+        assertContentLength(message.getRequestHeader(), ""4"");
+    }
+
+    private static void assertContentLength(HttpHeader header, String value) {
+        assertThat(header.getHeader(HttpHeader.CONTENT_LENGTH), is(equalTo(value)));
+    }
+
+    private static HttpMessage messageWithMethod(String method) {
+        try {
+            String header =
+                    method
+                            + (HttpRequestHeader.CONNECT.equalsIgnoreCase(method)
+                                    ? "" example.com ""
+                                    : "" / "")
+                            + ""HTTP/1.1"";
+            return new HttpMessage(new HttpRequestHeader(header));
+        } catch (HttpMalformedHeaderException e) {
+            throw new RuntimeException(e);
+        }
+    }
+
+    private static Stream<String> allMethods() {
+        return Stream.of(HttpRequestHeader.METHODS);
+    }
+
+    private static Stream<String> methodsNoEnclosedContent() {
+        return METHODS_NO_ENCLOSED_CONTENT.stream();
+    }
+
+    private static Stream<String> allMethodsExceptNoEnclosedContent() {
+        return allMethods().filter(e -> !METHODS_NO_ENCLOSED_CONTENT.contains(e));
+    }
+
     private static HttpMessage createAlertMessage() {
         return createAlertMessage(null);
     }","['zap/src/test/java/org/parosproxy/paros/core/scanner/AbstractPluginUnitTest.java', 'zap/src/main/java/org/parosproxy/paros/core/scanner/AbstractPlugin.java']",{'.java': 2},2,2,0,0,2,9989471,1993309,272919,1169,1432,256,29,1,922,141,216,19,2,0,2022-09-28 20:39:04,11102,Java,"{'Java': 12002133, 'HTML': 3977629, 'Python': 158050, 'Kotlin': 54286, 'JavaScript': 9640, 'Shell': 8430, 'Lex': 5179, 'Perl': 3832, 'XSLT': 3054}",Apache License 2.0,"['zap/src/main/java/org/zaproxy/zap/extension/ascan/ActiveScanPanel.java', 'zap/src/main/java/org/zaproxy/zap/network/HttpSender.java', 'zap/src/main/java/org/zaproxy/zap/network/HttpSenderImpl.java', 'zap/src/main/java/org/zaproxy/zap/network/HttpSenderListener.java', 'zap/src/main/java/org/zaproxy/zap/network/HttpRequestHeader.java', 'zap/src/main/java/org/zaproxy/zap/network/ZapHttpParser.java', 'zap/src/main/java/org/zaproxy/zap/extension/ascan/ActiveScan.java', 'zap/src/main/java/org/zaproxy/zap/extension/ascan/ActiveScanAPI.java', 'zap/src/main/java/org/zaproxy/zap/extension/ascan/ActiveScanController.java', 'zap/src/main/java/org/zaproxy/zap/extension/httppanel/view/syntaxhighlight/components/split/response/HttpResponseHeaderPanelSyntaxHighlightTextView.java', 'zap/src/main/java/org/zaproxy/zap/extension/ascan/ActiveScanEventPublisher.java']","['zap/src/main/java/org/zaproxy/zap/network/HttpSenderImpl.java', 'zap/src/main/java/org/zaproxy/zap/network/HttpSenderListener.java', 'zap/src/main/java/org/zaproxy/zap/extension/ascan/ActiveScanAPI.java', 'zap/src/main/java/org/zaproxy/zap/extension/ascan/ActiveScan.java', 'zap/src/main/java/org/zaproxy/zap/extension/ascan/ActiveScanController.java']","['```json\n{\n  ""files"": [\n    ""zap/src/main/java/org/zaproxy/zap/network/ZapHttpParser.java"",\n    ""zap/src/main/java/org/zaproxy/zap/network/HttpRequestHeader.java"",\n    ""zap/src/main/java/org/zaproxy/zap/network/HttpSender.java"",\n    ""zap/src/main/java/org/zaproxy/zap/network/HttpSenderImpl.java"",\n    ""zap/src/main/java/org/zaproxy/zap/network/HttpSenderListener.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""zap/src/main/java/org/zaproxy/zap/extension/ascan/ActiveScan.java"",\n    ""zap/src/main/java/org/zaproxy/zap/extension/ascan/ActiveScanAPI.java"",\n    ""zap/src/main/java/org/zaproxy/zap/extension/ascan/ActiveScanController.java"",\n    ""zap/src/main/java/org/zaproxy/zap/extension/ascan/ActiveScanEventPublisher.java"",\n    ""zap/src/main/java/org/zaproxy/zap/extension/ascan/ActiveScanPanel.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""zap/src/main/java/org/zaproxy/zap/extension/httppanel/view/syntaxhighlight/components/split/response/HttpResponseHeaderPanelSyntaxHighlightTextView.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""zap/src/main/java/org/zaproxy/zap/network/HttpSenderImpl.java"",\n    ""zap/src/main/java/org/zaproxy/zap/network/HttpSenderListener.java"",\n    ""zap/src/main/java/org/zaproxy/zap/extension/ascan/ActiveScan.java"",\n    ""zap/src/main/java/org/zaproxy/zap/extension/ascan/ActiveScanAPI.java"",\n    ""zap/src/main/java/org/zaproxy/zap/extension/ascan/ActiveScanController.java""\n  ]\n}\n```']",3,6908.541917800903
8857,apache/dolphinscheduler/3957/3956,apache,dolphinscheduler,https://github.com/apache/dolphinscheduler/issues/3956,https://github.com/apache/dolphinscheduler/pull/3957,https://github.com/apache/dolphinscheduler/pull/3957,1,close,"[Bug][Master] When running a task, the resource file is lost, which results in an error","When running a shell task, the resource file is lost, which results in an error

TaskParams 
Taskparams does not have a resourcelist. When converting, the content of resourcelist will be lost

Not only shell tasks, param parameters in other task types may be overridden

The code is as follows: 
VarPoolUtils#setTaskNodeLocalParams
```
/**
     * setTaskNodeLocalParams
     * @param taskNode taskNode
     * @param prop LocalParamName
     * @param value LocalParamValue
     */
    public static void setTaskNodeLocalParams(TaskNode taskNode, String prop, Object value) {
        String taskParamsJson = taskNode.getParams();
        TaskParams taskParams = JSONUtils.parseObject(taskParamsJson, TaskParams.class);
        if (taskParams == null) {
            return;
        }
        taskParams.setLocalParamValue(prop, value);
        taskNode.setParams(JSONUtils.toJsonString(taskParams));
    }

```
",44259688bab684923776b70e04c09f535d01848b,7dd717af16f374c217f956b7c55d19161580dbd3,https://github.com/apache/dolphinscheduler/compare/44259688bab684923776b70e04c09f535d01848b...7dd717af16f374c217f956b7c55d19161580dbd3,"diff --git a/dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/task/TaskParams.java b/dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/task/TaskParams.java
deleted file mode 100644
index abea2d95b..000000000
--- a/dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/task/TaskParams.java
+++ /dev/null
@@ -1,78 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the ""License""); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an ""AS IS"" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.dolphinscheduler.common.task;
-
-import java.util.Map;
-
-public class TaskParams {
-
-    private String rawScript;
-    private Map<String, String>[] localParams;
-
-    public void setRawScript(String rawScript) {
-        this.rawScript = rawScript;
-    }
-
-    public void setLocalParams(Map<String, String>[] localParams) {
-        this.localParams = localParams;
-    }
-
-    public String getRawScript() {
-        return rawScript;
-    }
-
-    public void setLocalParamValue(String prop, Object value) {
-        if (localParams == null || value == null) {
-            return;
-        }
-        for (int i = 0; i < localParams.length; i++) {
-            if (localParams[i].get(""prop"").equals(prop)) {
-                localParams[i].put(""value"", (String)value);
-            }
-        }
-    }
-
-    public void setLocalParamValue(Map<String, Object> propToValue) {
-        if (localParams == null || propToValue == null) {
-            return;
-        }
-        for (int i = 0; i < localParams.length; i++) {
-            String prop = localParams[i].get(""prop"");
-            if (propToValue.containsKey(prop)) {
-                localParams[i].put(""value"",(String)propToValue.get(prop));
-            }
-        }
-    }
-
-    public String getLocalParamValue(String prop) {
-        if (localParams == null) {
-            return null;
-        }
-        for (int i = 0; i < localParams.length; i++) {
-            String tmpProp = localParams[i].get(""prop"");
-            if (tmpProp.equals(prop)) {
-                return localParams[i].get(""value"");
-            }
-        }
-        return null;
-    }
-    
-    public Map<String, String>[] getLocalParams() {
-        return localParams;
-    }
-} 
\\ No newline at end of file
diff --git a/dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/VarPoolUtils.java b/dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/VarPoolUtils.java
index 837e96f55..89a8605a9 100644
--- a/dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/VarPoolUtils.java
+++ b/dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/VarPoolUtils.java
@@ -18,42 +18,19 @@
 package org.apache.dolphinscheduler.common.utils;
 
 import org.apache.dolphinscheduler.common.model.TaskNode;
-import org.apache.dolphinscheduler.common.task.TaskParams;
 
 import java.text.ParseException;
+import java.util.ArrayList;
+import java.util.HashMap;
 import java.util.Map;
 
 public class VarPoolUtils {
-    /**
-     * getTaskNodeLocalParam
-     * @param taskNode taskNode
-     * @param prop prop
-     * @return localParamForProp
-     */
-    public static Object getTaskNodeLocalParam(TaskNode taskNode, String prop) {
-        String taskParamsJson = taskNode.getParams();
-        TaskParams taskParams = JSONUtils.parseObject(taskParamsJson, TaskParams.class);
-        if (taskParams == null) {
-            return null;
-        }
-        return taskParams.getLocalParamValue(prop);
-    }
-    
-    /**
-     * setTaskNodeLocalParams
-     * @param taskNode taskNode
-     * @param prop LocalParamName
-     * @param value LocalParamValue
-     */
-    public static void setTaskNodeLocalParams(TaskNode taskNode, String prop, Object value) {
-        String taskParamsJson = taskNode.getParams();
-        TaskParams taskParams = JSONUtils.parseObject(taskParamsJson, TaskParams.class);
-        if (taskParams == null) {
-            return;
-        }
-        taskParams.setLocalParamValue(prop, value);
-        taskNode.setParams(JSONUtils.toJsonString(taskParams));
-    }
+
+    private static final  String LOCALPARAMS = ""localParams"";
+
+    private static final  String PROP = ""prop"";
+
+    private static final  String VALUE = ""value"";
 
     /**
      * setTaskNodeLocalParams
@@ -62,11 +39,20 @@ public class VarPoolUtils {
      */
     public static void setTaskNodeLocalParams(TaskNode taskNode, Map<String, Object> propToValue) {
         String taskParamsJson = taskNode.getParams();
-        TaskParams taskParams = JSONUtils.parseObject(taskParamsJson, TaskParams.class);
-        if (taskParams == null) {
-            return;
+        Map<String,Object> taskParams = JSONUtils.parseObject(taskParamsJson, HashMap.class);
+
+        Object localParamsObject = taskParams.get(LOCALPARAMS);
+        if (null != localParamsObject && null != propToValue && propToValue.size() > 0) {
+            ArrayList<Object> localParams = (ArrayList)localParamsObject;
+            for (int i = 0; i < localParams.size(); i++) {
+                Map<String,String> map = (Map)localParams.get(i);
+                String prop = map.get(PROP);
+                if (StringUtils.isNotEmpty(prop) && propToValue.containsKey(prop)) {
+                    map.put(VALUE,(String)propToValue.get(prop));
+                }
+            }
+            taskParams.put(LOCALPARAMS,localParams);
         }
-        taskParams.setLocalParamValue(propToValue);
         taskNode.setParams(JSONUtils.toJsonString(taskParams));
     }
 
diff --git a/dolphinscheduler-common/src/test/java/org/apache/dolphinscheduler/common/utils/VarPoolUtilsTest.java b/dolphinscheduler-common/src/test/java/org/apache/dolphinscheduler/common/utils/VarPoolUtilsTest.java
index e47203c22..6713b221b 100644
--- a/dolphinscheduler-common/src/test/java/org/apache/dolphinscheduler/common/utils/VarPoolUtilsTest.java
+++ b/dolphinscheduler-common/src/test/java/org/apache/dolphinscheduler/common/utils/VarPoolUtilsTest.java
@@ -19,6 +19,8 @@ package org.apache.dolphinscheduler.common.utils;
 
 import org.apache.dolphinscheduler.common.model.TaskNode;
 
+import java.util.HashMap;
+import java.util.Map;
 import java.util.concurrent.ConcurrentHashMap;
 
 import org.junit.Assert;
@@ -29,28 +31,7 @@ import org.slf4j.LoggerFactory;
 public class VarPoolUtilsTest {
     
     private static final Logger logger = LoggerFactory.getLogger(VarPoolUtilsTest.class);
-    
-    @Test
-    public void testSetTaskNodeLocalParams() {
-        String taskJson = ""{\\""conditionResult\\"":\\""{\\\\\\""successNode\\\\\\"":[\\\\\\""\\\\\\""],\\\\\\""failedNode\\\\\\"":[\\\\\\""\\\\\\""]}\\"",""
-            + ""\\""conditionsTask\\"":false,\\""depList\\"":[],\\""dependence\\"":\\""{}\\"",\\""forbidden\\"":false,\\""id\\"":\\""tasks-75298\\"",\\""maxRetryTimes\\"":0,\\""name\\"":\\""a1\\"",""
-            + ""\\""params\\"":\\""{\\\\\\""rawScript\\\\\\"":\\\\\\""print(\\\\\\\\\\\\\\""this is python task \\\\\\\\\\\\\\"",${p0})\\\\\\"",""
-            + ""\\\\\\""localParams\\\\\\"":[{\\\\\\""prop\\\\\\"":\\\\\\""p1\\\\\\"",\\\\\\""direct\\\\\\"":\\\\\\""IN\\\\\\"",\\\\\\""type\\\\\\"":\\\\\\""VARCHAR\\\\\\"",\\\\\\""value\\\\\\"":\\\\\\""1\\\\\\""}],""
-            + ""\\\\\\""resourceList\\\\\\"":[]}\\"",\\""preTasks\\"":\\""[]\\"",\\""retryInterval\\"":1,\\""runFlag\\"":\\""NORMAL\\"",\\""taskInstancePriority\\"":\\""MEDIUM\\"",""
-            + ""\\""taskTimeoutParameter\\"":{\\""enable\\"":false,\\""interval\\"":0},\\""timeout\\"":\\""{\\\\\\""enable\\\\\\"":false,\\\\\\""strategy\\\\\\"":\\\\\\""\\\\\\""}\\"",""
-            + ""\\""type\\"":\\""PYTHON\\"",\\""workerGroup\\"":\\""default\\""}"";
-        TaskNode taskNode = JSONUtils.parseObject(taskJson, TaskNode.class);
-        
-        VarPoolUtils.setTaskNodeLocalParams(taskNode, ""p1"", ""test1"");
-        Assert.assertEquals(VarPoolUtils.getTaskNodeLocalParam(taskNode, ""p1""), ""test1"");
-        
-        ConcurrentHashMap<String, Object> propToValue = new ConcurrentHashMap<String, Object>();
-        propToValue.put(""p1"", ""test2"");
-        
-        VarPoolUtils.setTaskNodeLocalParams(taskNode, propToValue);
-        Assert.assertEquals(VarPoolUtils.getTaskNodeLocalParam(taskNode, ""p1""), ""test2"");
-    }
-    
+
     @Test
     public void testConvertVarPoolToMap() throws Exception {
         String varPool = ""p1,66$VarPool$p2,69$VarPool$"";
@@ -70,4 +51,40 @@ public class VarPoolUtilsTest {
             + ""print(\\""${{setValue({},{})}}\\"".format(\\""p2\\"",4));"");
         logger.info(rawScript);
     }
+
+    @Test
+    public void testSetTaskNodeLocalParams() throws Exception {
+        String taskJson = ""{\\""id\\"":\\""tasks-66199\\"",\\""name\\"":\\""file-shell\\"",\\""desc\\"":null,\\""type\\"":\\""SHELL\\"",""
+                        + ""\\""runFlag\\"":\\""NORMAL\\"",\\""loc\\"":null,\\""maxRetryTimes\\"":0,\\""retryInterval\\"":1,\\""""
+                        +  ""params\\"":{\\""rawScript\\"":\\""sh n-1/n-1-1/run.sh\\"",\\""""
+                        + ""localParams\\"":[{\\""prop\\"":\\""k1\\"",\\""direct\\"":\\""IN\\"",\\""type\\"":\\""VARCHAR\\"",\\""value\\"":\\""v1\\""},{\\""prop\\"":\\""k2\\"",\\""direct\\"":\\""IN\\"",\\""type\\"":\\""VARCHAR\\"",\\""value\\"":\\""v2\\""},""
+                        + ""{\\""prop\\"":\\""k3\\"",\\""direct\\"":\\""IN\\"",\\""type\\"":\\""VARCHAR\\"",\\""value\\"":\\""v3\\""}],\\""""
+                        + ""resourceList\\"":[{\\""id\\"":\\""dolphinschedule-code\\"",\\""res\\"":\\""n-1/n-1-1/dolphinscheduler-api-server.log\\""},""
+                        + ""{\\""id\\"":\\""mr-code\\"",\\""res\\"":\\""n-1/n-1-1/hadoop-mapreduce-examples-2.7.4.jar\\""},""
+                        + ""{\\""id\\"":\\""run\\"",\\""res\\"":\\""n-1/n-1-1/run.sh\\""}]},\\""preTasks\\"":[],\\""extras\\"":null,\\""depList\\"":[],\\""""
+                        + ""dependence\\"":{},\\""conditionResult\\"":{\\""successNode\\"":[\\""\\""],\\""failedNode\\"":[\\""\\""]},\\""taskInstancePriority\\"":\\""MEDIUM\\"",\\""""
+                        + ""workerGroup\\"":\\""default\\"",\\""workerGroupId\\"":null,\\""timeout\\"":{\\""strategy\\"":\\""\\"",\\""interval\\"":null,\\""enable\\"":false},\\""delayTime\\"":0}"";
+        String changeTaskJson = ""{\\""id\\"":\\""tasks-66199\\"",\\""name\\"":\\""file-shell\\"",\\""desc\\"":null,\\""type\\"":\\""SHELL\\"",""
+                        + ""\\""runFlag\\"":\\""NORMAL\\"",\\""loc\\"":null,\\""maxRetryTimes\\"":0,\\""retryInterval\\"":1,\\""""
+                        +  ""params\\"":{\\""rawScript\\"":\\""sh n-1/n-1-1/run.sh\\"",\\""""
+                        + ""localParams\\"":[{\\""prop\\"":\\""k1\\"",\\""direct\\"":\\""IN\\"",\\""type\\"":\\""VARCHAR\\"",\\""value\\"":\\""k1-value-change\\""},""
+                        + ""{\\""prop\\"":\\""k2\\"",\\""direct\\"":\\""IN\\"",\\""type\\"":\\""VARCHAR\\"",\\""value\\"":\\""k2-value-change\\""},""
+                        + ""{\\""prop\\"":\\""k3\\"",\\""direct\\"":\\""IN\\"",\\""type\\"":\\""VARCHAR\\"",\\""value\\"":\\""v3\\""}],\\""""
+                        + ""resourceList\\"":[{\\""id\\"":\\""dolphinschedule-code\\"",\\""res\\"":\\""n-1/n-1-1/dolphinscheduler-api-server.log\\""},""
+                        + ""{\\""id\\"":\\""mr-code\\"",\\""res\\"":\\""n-1/n-1-1/hadoop-mapreduce-examples-2.7.4.jar\\""},""
+                        + ""{\\""id\\"":\\""run\\"",\\""res\\"":\\""n-1/n-1-1/run.sh\\""}]},\\""preTasks\\"":[],\\""extras\\"":null,\\""depList\\"":[],\\""""
+                        + ""dependence\\"":{},\\""conditionResult\\"":{\\""successNode\\"":[\\""\\""],\\""failedNode\\"":[\\""\\""]},\\""taskInstancePriority\\"":\\""MEDIUM\\"",\\""""
+                        + ""workerGroup\\"":\\""default\\"",\\""workerGroupId\\"":null,\\""timeout\\"":{\\""strategy\\"":\\""\\"",\\""interval\\"":null,\\""enable\\"":false},\\""delayTime\\"":0}"";
+        Map<String, Object> propToValue = new HashMap<String, Object>();
+        propToValue.put(""k1"",""k1-value-change"");
+        propToValue.put(""k2"",""k2-value-change"");
+
+        TaskNode taskNode = JSONUtils.parseObject(taskJson,TaskNode.class);
+
+        VarPoolUtils.setTaskNodeLocalParams(taskNode,propToValue);
+
+        Assert.assertEquals(changeTaskJson,JSONUtils.toJsonString(taskNode));
+
+    }
+
 }","['dolphinscheduler-common/src/test/java/org/apache/dolphinscheduler/common/utils/VarPoolUtilsTest.java', 'dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/VarPoolUtils.java', 'dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/task/TaskParams.java']",{'.java': 3},3,3,0,0,3,2839790,576131,82878,522,4892,1057,134,2,935,98,209,28,0,1,2020-10-20 11:27:54,10886,Java,"{'Java': 10141828, 'TypeScript': 2049856, 'Vue': 1360734, 'PLpgSQL': 62410, 'HCL': 54673, 'SCSS': 52091, 'Shell': 42925, 'Python': 19071, 'Smarty': 13851, 'Dockerfile': 6454, 'Batchfile': 1677, 'Makefile': 1496}",Apache License 2.0,"['dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/task/AbstractParameters.java', 'dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/task/conditions/ConditionsParameters.java', 'dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/placeholder/PropertyPlaceholderHelper.java', 'dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/worker/task/shell/ShellTask.java', 'dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/placeholder/PlaceholderUtils.java']","['dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/task/AbstractParameters.java', 'dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/task/conditions/ConditionsParameters.java', 'dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/placeholder/PropertyPlaceholderHelper.java', 'dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/worker/task/shell/ShellTask.java', 'dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/placeholder/PlaceholderUtils.java']","['```json\n{\n  ""files"": [\n    ""dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/worker/task/shell/ShellTask.java"",\n    ""dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/task/AbstractParameters.java"",\n    ""dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/task/conditions/ConditionsParameters.java"",\n    ""dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/placeholder/PlaceholderUtils.java"",\n    ""dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/placeholder/PropertyPlaceholderHelper.java""\n  ]\n}\n```']",1,2206.7863941192627
1415,grpc/grpc-java/667/583,grpc,grpc-java,https://github.com/grpc/grpc-java/issues/583,https://github.com/grpc/grpc-java/pull/667,https://github.com/grpc/grpc-java/pull/667,1,fixes,OkHttp's cancellation is not properly synchronized,"[`OkHttpClientStream.sendCancel()` calls `finishStream()`](https://github.com/grpc/grpc-java/blob/master/okhttp/src/main/java/io/grpc/transport/okhttp/OkHttpClientStream.java#L213) from an application thread. But `finishStream()` [calls transportReportStatus() without any lock held](https://github.com/grpc/grpc-java/blob/master/okhttp/src/main/java/io/grpc/transport/okhttp/OkHttpClientTransport.java#L463). That is not synchronized correctly, as `transportReportStatus()` may only be called from the transport thread (i.e., while `lock` is held).

It seems that all usages of `streams` is done while `lock` is held except for within `finishStream()` and [data()](https://github.com/grpc/grpc-java/blob/master/okhttp/src/main/java/io/grpc/transport/okhttp/OkHttpClientTransport.java#L570). `data()` can actually race with `finishStream()` and end up sending DATA frames after the RST_STREAM. It seems it would be best to just have `stream` protected by `lock`, because it having its own synchronization isn't providing much benefit and isn't leading to correct code.
",1ac64bd09ddcec60829d5291c4db4147aeb2328a,750f6265e21ffb83a0ee46d2120af92b30785b30,https://github.com/grpc/grpc-java/compare/1ac64bd09ddcec60829d5291c4db4147aeb2328a...750f6265e21ffb83a0ee46d2120af92b30785b30,"diff --git a/okhttp/src/main/java/io/grpc/transport/okhttp/AsyncFrameWriter.java b/okhttp/src/main/java/io/grpc/transport/okhttp/AsyncFrameWriter.java
index bbc6e79ca..8615e489b 100644
--- a/okhttp/src/main/java/io/grpc/transport/okhttp/AsyncFrameWriter.java
+++ b/okhttp/src/main/java/io/grpc/transport/okhttp/AsyncFrameWriter.java
@@ -32,7 +32,6 @@
 package io.grpc.transport.okhttp;
 
 import com.google.common.base.Preconditions;
-import com.google.common.util.concurrent.SettableFuture;
 
 import com.squareup.okhttp.internal.spdy.ErrorCode;
 import com.squareup.okhttp.internal.spdy.FrameWriter;
@@ -44,11 +43,15 @@ import io.grpc.SerializingExecutor;
 import okio.Buffer;
 
 import java.io.IOException;
+import java.net.Socket;
 import java.util.List;
-import java.util.concurrent.ExecutionException;
+import java.util.logging.Level;
+import java.util.logging.Logger;
 
 class AsyncFrameWriter implements FrameWriter {
+  private static final Logger log = Logger.getLogger(OkHttpClientTransport.class.getName());
   private FrameWriter frameWriter;
+  private Socket socket;
   // Although writes are thread-safe, we serialize them to prevent consuming many Threads that are
   // just waiting on each other.
   private final SerializingExecutor executor;
@@ -60,12 +63,16 @@ class AsyncFrameWriter implements FrameWriter {
   }
 
   /**
-   * Set the real frameWriter, should only be called by thread of executor.
+   * Set the real frameWriter and the corresponding underlying socket, the socket is needed for
+   * closing.
+   *
+   * <p>should only be called by thread of executor.
    */
-  void setFrameWriter(FrameWriter frameWriter) {
+  void becomeConnected(FrameWriter frameWriter, Socket socket) {
     Preconditions.checkState(this.frameWriter == null,
         ""AsyncFrameWriter's setFrameWriter() should only be called once."");
-    this.frameWriter = frameWriter;
+    this.frameWriter = Preconditions.checkNotNull(frameWriter);
+    this.socket = Preconditions.checkNotNull(socket);
   }
 
   @Override
@@ -207,30 +214,19 @@ class AsyncFrameWriter implements FrameWriter {
 
   @Override
   public void close() {
-    // Wait for the frameWriter to close.
-    final SettableFuture<?> closeFuture = SettableFuture.create();
     executor.execute(new Runnable() {
       @Override
       public void run() {
-        try {
-          if (frameWriter != null) {
+        if (frameWriter != null) {
+          try {
             frameWriter.close();
+            socket.close();
+          } catch (IOException e) {
+            log.log(Level.WARNING, ""Failed closing connection"", e);
           }
-        } catch (IOException e) {
-          closeFuture.setException(e);
-        } finally {
-          closeFuture.set(null);
         }
       }
     });
-    try {
-      closeFuture.get();
-    } catch (InterruptedException e) {
-      Thread.currentThread().interrupt();
-      throw new RuntimeException(e);
-    } catch (ExecutionException e) {
-      throw new RuntimeException(e);
-    }
   }
 
   private abstract class WriteRunnable implements Runnable {
diff --git a/okhttp/src/main/java/io/grpc/transport/okhttp/OkHttpClientStream.java b/okhttp/src/main/java/io/grpc/transport/okhttp/OkHttpClientStream.java
index 0f92bad3c..fa042944d 100644
--- a/okhttp/src/main/java/io/grpc/transport/okhttp/OkHttpClientStream.java
+++ b/okhttp/src/main/java/io/grpc/transport/okhttp/OkHttpClientStream.java
@@ -37,7 +37,6 @@ import static com.google.common.base.Preconditions.checkState;
 import com.squareup.okhttp.internal.spdy.ErrorCode;
 import com.squareup.okhttp.internal.spdy.Header;
 
-import io.grpc.Metadata;
 import io.grpc.MethodDescriptor.MethodType;
 import io.grpc.Status;
 import io.grpc.transport.ClientStreamListener;
@@ -69,8 +68,8 @@ class OkHttpClientStream extends Http2ClientStream {
                                       AsyncFrameWriter frameWriter,
                                       OkHttpClientTransport transport,
                                       OutboundFlowController outboundFlow,
-                                      MethodType type) {
-    return new OkHttpClientStream(listener, frameWriter, transport, outboundFlow, type);
+                                      MethodType type, Object lock) {
+    return new OkHttpClientStream(listener, frameWriter, transport, outboundFlow, type, lock);
   }
 
   @GuardedBy(""lock"")
@@ -80,7 +79,7 @@ class OkHttpClientStream extends Http2ClientStream {
   private final AsyncFrameWriter frameWriter;
   private final OutboundFlowController outboundFlow;
   private final OkHttpClientTransport transport;
-  private final Object lock = new Object();
+  private final Object lock;
   private Object outboundFlowState;
   private volatile Integer id;
 
@@ -88,12 +87,14 @@ class OkHttpClientStream extends Http2ClientStream {
                              AsyncFrameWriter frameWriter,
                              OkHttpClientTransport transport,
                              OutboundFlowController outboundFlow,
-                             MethodType type) {
+                             MethodType type,
+                             Object lock) {
     super(new OkHttpWritableBufferAllocator(), listener);
     this.frameWriter = frameWriter;
     this.transport = transport;
     this.outboundFlow = outboundFlow;
     this.type = type;
+    this.lock = lock;
   }
 
   /**
@@ -139,33 +140,30 @@ class OkHttpClientStream extends Http2ClientStream {
     onSentBytes(numBytes);
   }
 
+  /**
+   * Must be called with holding the transport lock.
+   */
   public void transportHeadersReceived(List<Header> headers, boolean endOfStream) {
-    synchronized (lock) {
-      if (endOfStream) {
-        transportTrailersReceived(Utils.convertTrailers(headers));
-      } else {
-        transportHeadersReceived(Utils.convertHeaders(headers));
-      }
+    if (endOfStream) {
+      transportTrailersReceived(Utils.convertTrailers(headers));
+    } else {
+      transportHeadersReceived(Utils.convertHeaders(headers));
     }
   }
 
   /**
-   * We synchronized on ""lock"" for delivering frames and updating window size, because
-   * the {@link #request(int)} call can be called in other thread for delivering frames.
+   * Must be called with holding the transport lock.
    */
   public void transportDataReceived(okio.Buffer frame, boolean endOfStream) {
-    synchronized (lock) {
-      long length = frame.size();
-      window -= length;
-      if (window < 0) {
-        frameWriter.rstStream(id(), ErrorCode.FLOW_CONTROL_ERROR);
-        Status status = Status.INTERNAL.withDescription(
-            ""Received data size exceeded our receiving window size"");
-        transport.finishStream(id(), status, null);
-        return;
-      }
-      super.transportDataReceived(new OkHttpReadableBuffer(frame), endOfStream);
+    long length = frame.size();
+    window -= length;
+    if (window < 0) {
+      frameWriter.rstStream(id(), ErrorCode.FLOW_CONTROL_ERROR);
+      transport.finishStream(id(), Status.INTERNAL.withDescription(
+          ""Received data size exceeded our receiving window size""), null);
+      return;
     }
+    super.transportDataReceived(new OkHttpReadableBuffer(frame), endOfStream);
   }
 
   @Override
@@ -199,14 +197,6 @@ class OkHttpClientStream extends Http2ClientStream {
     }
   }
 
-  @Override
-  public void transportReportStatus(Status newStatus, boolean stopDelivery,
-      Metadata.Trailers trailers) {
-    synchronized (lock) {
-      super.transportReportStatus(newStatus, stopDelivery, trailers);
-    }
-  }
-
   @Override
   protected void sendCancel(Status reason) {
     transport.finishStream(id(), reason, ErrorCode.CANCEL);
diff --git a/okhttp/src/main/java/io/grpc/transport/okhttp/OkHttpClientTransport.java b/okhttp/src/main/java/io/grpc/transport/okhttp/OkHttpClientTransport.java
index c62927156..c4ed67932 100644
--- a/okhttp/src/main/java/io/grpc/transport/okhttp/OkHttpClientTransport.java
+++ b/okhttp/src/main/java/io/grpc/transport/okhttp/OkHttpClientTransport.java
@@ -70,7 +70,6 @@ import okio.Okio;
 
 import java.io.IOException;
 import java.net.Socket;
-import java.util.ArrayList;
 import java.util.Collections;
 import java.util.HashMap;
 import java.util.Iterator;
@@ -93,6 +92,7 @@ import javax.net.ssl.SSLSocketFactory;
 class OkHttpClientTransport implements ClientTransport {
   private static final Map<ErrorCode, Status> ERROR_CODE_TO_STATUS;
   private static final Logger log = Logger.getLogger(OkHttpClientTransport.class.getName());
+  private static final OkHttpClientStream[] EMPTY_STREAM_ARRAY = new OkHttpClientStream[0];
 
   static {
     Map<ErrorCode, Status> errorToStatus = new HashMap<ErrorCode, Status>();
@@ -138,8 +138,9 @@ class OkHttpClientTransport implements ClientTransport {
   private final Object lock = new Object();
   @GuardedBy(""lock"")
   private int nextStreamId;
+  @GuardedBy(""lock"")
   private final Map<Integer, OkHttpClientStream> streams =
-      Collections.synchronizedMap(new HashMap<Integer, OkHttpClientStream>());
+      new HashMap<Integer, OkHttpClientStream>();
   private final Executor executor;
   // Wrap on executor, to guarantee some operations be executed serially.
   private final SerializingExecutor serializingExecutor;
@@ -245,8 +246,8 @@ class OkHttpClientTransport implements ClientTransport {
     Preconditions.checkNotNull(headers, ""headers"");
     Preconditions.checkNotNull(listener, ""listener"");
 
-    OkHttpClientStream clientStream =
-        OkHttpClientStream.newStream(listener, frameWriter, this, outboundFlow, method.getType());
+    OkHttpClientStream clientStream = OkHttpClientStream.newStream(
+            listener, frameWriter, this, outboundFlow, method.getType(), lock);
 
     String defaultPath = ""/"" + method.getFullMethodName();
     List<Header> requestHeaders =
@@ -332,7 +333,7 @@ class OkHttpClientTransport implements ClientTransport {
           clientFrameHandler = new ClientFrameHandler(testFrameReader);
           executor.execute(clientFrameHandler);
           connectedCallback.run();
-          frameWriter.setFrameWriter(testFrameWriter);
+          frameWriter.becomeConnected(testFrameWriter, socket);
           return;
         }
         BufferedSource source;
@@ -369,7 +370,7 @@ class OkHttpClientTransport implements ClientTransport {
 
         Variant variant = new Http2();
         rawFrameWriter = variant.newWriter(sink, true);
-        frameWriter.setFrameWriter(rawFrameWriter);
+        frameWriter.becomeConnected(rawFrameWriter, socket);
 
         try {
           // Do these with the raw FrameWriter, so that they will be done in this thread,
@@ -390,25 +391,35 @@ class OkHttpClientTransport implements ClientTransport {
 
   @Override
   public void shutdown() {
-    boolean normalClose;
     synchronized (lock) {
-      normalClose = !goAway;
+      if (goAway) {
+        return;
+      }
     }
-    if (normalClose) {
-      // Send GOAWAY with lastGoodStreamId of 0, since we don't expect any server-initiated streams.
-      // The GOAWAY is part of graceful shutdown.
-      frameWriter.goAway(0, ErrorCode.NO_ERROR, new byte[0]);
 
-      onGoAway(Integer.MAX_VALUE, Status.UNAVAILABLE.withDescription(""Transport stopped""));
+    // Send GOAWAY with lastGoodStreamId of 0, since we don't expect any server-initiated streams.
+    // The GOAWAY is part of graceful shutdown.
+    frameWriter.goAway(0, ErrorCode.NO_ERROR, new byte[0]);
+
+    onGoAway(Integer.MAX_VALUE, Status.UNAVAILABLE.withDescription(""Transport stopped""));
+  }
+
+  /**
+   * Gets all active streams as an array.
+   */
+  OkHttpClientStream[] getActiveStreams() {
+    synchronized (lock) {
+      return streams.values().toArray(EMPTY_STREAM_ARRAY);
     }
-    stopIfNecessary();
   }
 
+
   @VisibleForTesting
   ClientFrameHandler getHandler() {
     return clientFrameHandler;
   }
 
+  @VisibleForTesting
   Map<Integer, OkHttpClientStream> getStreams() {
     return streams;
   }
@@ -438,37 +449,32 @@ class OkHttpClientTransport implements ClientTransport {
 
   private void onGoAway(int lastKnownStreamId, Status status) {
     boolean notifyShutdown;
-    ArrayList<OkHttpClientStream> goAwayStreams = new ArrayList<OkHttpClientStream>();
-    List<PendingStream> pendingStreamsCopy;
     synchronized (lock) {
       notifyShutdown = !goAway;
       goAway = true;
       goAwayStatus = status;
-      synchronized (streams) {
-        Iterator<Map.Entry<Integer, OkHttpClientStream>> it = streams.entrySet().iterator();
-        while (it.hasNext()) {
-          Map.Entry<Integer, OkHttpClientStream> entry = it.next();
-          if (entry.getKey() > lastKnownStreamId) {
-            goAwayStreams.add(entry.getValue());
-            it.remove();
-          }
+      Iterator<Map.Entry<Integer, OkHttpClientStream>> it = streams.entrySet().iterator();
+      while (it.hasNext()) {
+        Map.Entry<Integer, OkHttpClientStream> entry = it.next();
+        if (entry.getKey() > lastKnownStreamId) {
+          it.remove();
+          entry.getValue().transportReportStatus(status, false, new Metadata.Trailers());
         }
       }
-      pendingStreamsCopy = pendingStreams;
-      pendingStreams = new LinkedList<PendingStream>();
+
+      for (PendingStream stream : pendingStreams) {
+        stream.clientStream.transportReportStatus(status, true, new Metadata.Trailers());
+        stream.createdFuture.set(null);
+      }
+      pendingStreams.clear();
     }
 
     if (notifyShutdown) {
+      // TODO(madongfly): Another thread may called stopIfNecessary() and closed the socket, so that
+      // the reading thread calls listener.transportTerminated() and race with this call.
       listener.transportShutdown();
     }
-    for (OkHttpClientStream stream : goAwayStreams) {
-      stream.transportReportStatus(status, false, new Metadata.Trailers());
-    }
-    for (PendingStream stream : pendingStreamsCopy) {
-      stream.clientStream.transportReportStatus(
-          status, true, new Metadata.Trailers());
-      stream.createdFuture.set(null);
-    }
+
     stopIfNecessary();
   }
 
@@ -486,19 +492,20 @@ class OkHttpClientTransport implements ClientTransport {
    * @param errorCode reset the stream with this ErrorCode if not null.
    */
   void finishStream(int streamId, @Nullable Status status, @Nullable ErrorCode errorCode) {
-    OkHttpClientStream stream;
-    stream = streams.remove(streamId);
-    if (stream != null) {
-      if (errorCode != null) {
-        frameWriter.rstStream(streamId, ErrorCode.CANCEL);
-      }
-      if (status != null) {
-        boolean isCancelled = (status.getCode() == Code.CANCELLED
-            || status.getCode() == Code.DEADLINE_EXCEEDED);
-        stream.transportReportStatus(status, isCancelled, new Metadata.Trailers());
-      }
-      if (!startPendingStreams()) {
-        stopIfNecessary();
+    synchronized (lock) {
+      OkHttpClientStream stream = streams.remove(streamId);
+      if (stream != null) {
+        if (errorCode != null) {
+          frameWriter.rstStream(streamId, ErrorCode.CANCEL);
+        }
+        if (status != null) {
+          boolean isCancelled = (status.getCode() == Code.CANCELLED
+              || status.getCode() == Code.DEADLINE_EXCEEDED);
+          stream.transportReportStatus(status, isCancelled, new Metadata.Trailers());
+        }
+        if (!startPendingStreams()) {
+          stopIfNecessary();
+        }
       }
     }
   }
@@ -507,39 +514,21 @@ class OkHttpClientTransport implements ClientTransport {
    * When the transport is in goAway states, we should stop it once all active streams finish.
    */
   void stopIfNecessary() {
-    boolean shouldStop;
-    Http2Ping outstandingPing = null;
-    boolean socketConnected;
     synchronized (lock) {
-      shouldStop = (goAway && streams.size() == 0);
-      if (shouldStop) {
-        if (stopped) {
-          // We've already stopped, don't stop again.
-          shouldStop = false;
-        } else {
+      if (goAway && streams.size() == 0) {
+        if (!stopped) {
           stopped = true;
-          outstandingPing = ping;
-          ping = null;
-        }
-      }
-      socketConnected = socket != null;
-    }
-    if (shouldStop) {
-      // Wait for the frame writer to close.
-      frameWriter.close();
-      if (socketConnected) {
-        // Close the socket to break out the reader thread, which will close the
-        // frameReader and notify the listener.
-        try {
-          socket.close();
-        } catch (IOException e) {
-          log.log(Level.WARNING, ""Failed closing socket"", e);
+          // We will close the underlying socket in the writing thread to break out the reader
+          // thread, which will close the frameReader and notify the listener.
+          frameWriter.close();
+
+          if (ping != null) {
+            ping.failed(getPingFailure());
+            ping = null;
+          }
         }
       }
     }
-    if (outstandingPing != null) {
-      outstandingPing.failed(getPingFailure());
-    }
   }
 
   private Throwable getPingFailure() {
@@ -558,6 +547,12 @@ class OkHttpClientTransport implements ClientTransport {
     }
   }
 
+  OkHttpClientStream getStream(int streamId) {
+    synchronized (lock) {
+      return streams.get(streamId);
+    }
+  }
+
   /**
    * Returns a Grpc status corresponding to the given ErrorCode.
    */
@@ -607,8 +602,7 @@ class OkHttpClientTransport implements ClientTransport {
     @Override
     public void data(boolean inFinished, int streamId, BufferedSource in, int length)
         throws IOException {
-      final OkHttpClientStream stream;
-      stream = streams.get(streamId);
+      OkHttpClientStream stream = getStream(streamId);
       if (stream == null) {
         if (mayHaveCreatedStream(streamId)) {
           frameWriter.rstStream(streamId, ErrorCode.INVALID_STREAM);
@@ -622,7 +616,9 @@ class OkHttpClientTransport implements ClientTransport {
 
         Buffer buf = new Buffer();
         buf.write(in.buffer(), length);
-        stream.transportDataReceived(buf, inFinished);
+        synchronized (lock) {
+          stream.transportDataReceived(buf, inFinished);
+        }
       }
 
       // connection window update
@@ -643,18 +639,23 @@ class OkHttpClientTransport implements ClientTransport {
         int associatedStreamId,
         List<Header> headerBlock,
         HeadersMode headersMode) {
-      OkHttpClientStream stream;
-      stream = streams.get(streamId);
-      if (stream == null) {
-        if (mayHaveCreatedStream(streamId)) {
-          frameWriter.rstStream(streamId, ErrorCode.INVALID_STREAM);
+      boolean unknownStream = false;
+      synchronized (lock) {
+        OkHttpClientStream stream = streams.get(streamId);
+        if (stream == null) {
+          if (mayHaveCreatedStream(streamId)) {
+            frameWriter.rstStream(streamId, ErrorCode.INVALID_STREAM);
+          } else {
+            unknownStream = true;
+          }
         } else {
-          // We don't expect any server-initiated streams.
-          onError(ErrorCode.PROTOCOL_ERROR, ""Received header for unknown stream: "" + streamId);
+          stream.transportHeadersReceived(headerBlock, inFinished);
         }
-        return;
       }
-      stream.transportHeadersReceived(headerBlock, inFinished);
+      if (unknownStream) {
+        // We don't expect any server-initiated streams.
+        onError(ErrorCode.PROTOCOL_ERROR, ""Received header for unknown stream: "" + streamId);
+      }
     }
 
     @Override
@@ -748,7 +749,7 @@ class OkHttpClientTransport implements ClientTransport {
         return;
       }
 
-      OkHttpClientStream stream = streams.get(streamId);
+      OkHttpClientStream stream = getStream(streamId);
       if (stream != null) {
         outboundFlow.windowUpdate(stream, (int) delta);
       } else if (!mayHaveCreatedStream(streamId)) {
diff --git a/okhttp/src/main/java/io/grpc/transport/okhttp/OutboundFlowController.java b/okhttp/src/main/java/io/grpc/transport/okhttp/OutboundFlowController.java
index ebe062be0..3112c5635 100644
--- a/okhttp/src/main/java/io/grpc/transport/okhttp/OutboundFlowController.java
+++ b/okhttp/src/main/java/io/grpc/transport/okhttp/OutboundFlowController.java
@@ -54,7 +54,6 @@ import javax.annotation.Nullable;
  * streams.
  */
 class OutboundFlowController {
-  private static final OkHttpClientStream[] EMPTY_STREAM_ARRAY = new OkHttpClientStream[0];
   private final OkHttpClientTransport transport;
   private final FrameWriter frameWriter;
   private int initialWindowSize = DEFAULT_WINDOW_SIZE;
@@ -72,7 +71,7 @@ class OutboundFlowController {
 
     int delta = newWindowSize - initialWindowSize;
     initialWindowSize = newWindowSize;
-    for (OkHttpClientStream stream : getActiveStreams()) {
+    for (OkHttpClientStream stream : transport.getActiveStreams()) {
       OutboundFlowState state = (OutboundFlowState) stream.getOutboundFlowState();
       if (state == null) {
         // Create the OutboundFlowState with the new window size.
@@ -116,7 +115,7 @@ class OutboundFlowController {
       throw new IllegalArgumentException(""Invalid streamId: "" + streamId);
     }
 
-    OkHttpClientStream stream = transport.getStreams().get(streamId);
+    OkHttpClientStream stream = transport.getStream(streamId);
     if (stream == null) {
       // This is possible for a stream that has received end-of-stream from server (but hasn't sent
       // end-of-stream), and was removed from the transport stream map.
@@ -173,18 +172,11 @@ class OutboundFlowController {
     return state;
   }
 
-  /**
-   * Gets all active streams as an array.
-   */
-  private OkHttpClientStream[] getActiveStreams() {
-    return transport.getStreams().values().toArray(EMPTY_STREAM_ARRAY);
-  }
-
   /**
    * Writes as much data for all the streams as possible given the current flow control windows.
    */
   private void writeStreams() {
-    OkHttpClientStream[] streams = getActiveStreams();
+    OkHttpClientStream[] streams = transport.getActiveStreams();
     int connectionWindow = connectionState.window();
     for (int numStreams = streams.length; numStreams > 0 && connectionWindow > 0;) {
       int nextNumStreams = 0;
@@ -210,7 +202,7 @@ class OutboundFlowController {
 
     // Now take one last pass through all of the streams and write any allocated bytes.
     WriteStatus writeStatus = new WriteStatus();
-    for (OkHttpClientStream stream : getActiveStreams()) {
+    for (OkHttpClientStream stream : transport.getActiveStreams()) {
       OutboundFlowState state = state(stream);
       state.writeBytes(state.allocatedBytes(), writeStatus);
       state.clearAllocatedBytes();
diff --git a/okhttp/src/test/java/io/grpc/transport/okhttp/OkHttpClientTransportTest.java b/okhttp/src/test/java/io/grpc/transport/okhttp/OkHttpClientTransportTest.java
index cec61987d..58a8b41d3 100644
--- a/okhttp/src/test/java/io/grpc/transport/okhttp/OkHttpClientTransportTest.java
+++ b/okhttp/src/test/java/io/grpc/transport/okhttp/OkHttpClientTransportTest.java
@@ -195,7 +195,7 @@ public class OkHttpClientTransportTest {
     assertEquals(""Protocol error\\n"" + NETWORK_ISSUE_MESSAGE, listener1.status.getDescription());
     assertEquals(Status.INTERNAL.getCode(), listener2.status.getCode());
     assertEquals(""Protocol error\\n"" + NETWORK_ISSUE_MESSAGE, listener2.status.getDescription());
-    verify(transportListener).transportShutdown();
+    verify(transportListener, timeout(TIME_OUT_MS)).transportShutdown();
     verify(transportListener, timeout(TIME_OUT_MS)).transportTerminated();
   }
 ","['okhttp/src/main/java/io/grpc/transport/okhttp/OutboundFlowController.java', 'okhttp/src/main/java/io/grpc/transport/okhttp/AsyncFrameWriter.java', 'okhttp/src/main/java/io/grpc/transport/okhttp/OkHttpClientStream.java', 'okhttp/src/main/java/io/grpc/transport/okhttp/OkHttpClientTransport.java', 'okhttp/src/test/java/io/grpc/transport/okhttp/OkHttpClientTransportTest.java']",{'.java': 5},5,5,0,0,5,1687079,354616,48934,211,12204,2434,285,4,1069,98,247,4,3,0,2015-07-24 18:17:02,10705,Java,"{'Java': 11734252, 'Shell': 64137, 'C++': 50003, 'Starlark': 45373, 'Batchfile': 6230, 'Dockerfile': 3878, 'Python': 1961}",Apache License 2.0,"['okhttp/src/main/java/io/grpc/transport/okhttp/OkHttpClientTransport.java', 'okhttp/src/main/java/io/grpc/transport/okhttp/OkHttpClientStream.java']","['okhttp/src/main/java/io/grpc/transport/okhttp/OkHttpClientTransport.java', 'okhttp/src/main/java/io/grpc/transport/okhttp/OkHttpClientStream.java']","['```json\n{\n  ""files"": [\n    ""okhttp/src/main/java/io/grpc/transport/okhttp/OkHttpClientStream.java"",\n    ""okhttp/src/main/java/io/grpc/transport/okhttp/OkHttpClientTransport.java""\n  ]\n}\n```']",1,1149.2972373962402
44,tootallnate/java-websocket/570/564,tootallnate,java-websocket,https://github.com/TooTallNate/Java-WebSocket/issues/564,https://github.com/TooTallNate/Java-WebSocket/pull/570,https://github.com/TooTallNate/Java-WebSocket/pull/570,2,fix,Continuous binary getting swallowed?,"My WS JS hosted in Chrome seems to be sending the following frames:
BINARY, isFin = false
CONTINUOUS, isFin = true

Java-WebSocket seems to drop the CONTINUOUS frame on the floor and the application never gets it:

```java
// org/java_websocket/drafts/Draft_6455.java:542
} else if( frame.isFin() ) {
	if( current_continuous_frame == null )
		throw new InvalidDataException( CloseFrame.PROTOCOL_ERROR, ""Continuous frame sequence was not started."" );
	//Check if the whole payload is valid utf8, when the opcode indicates a text
	if( current_continuous_frame.getOpcode() == Framedata.Opcode.TEXT ) {
		//Checking a bit more from the frame before this one just to make sure all the code points are correct
		int off = Math.max( current_continuous_frame.getPayloadData().limit() - 64, 0 );
		current_continuous_frame.append( frame );
		if( !Charsetfunctions.isValidUTF8( current_continuous_frame.getPayloadData(), off ) ) {
			throw new InvalidDataException( CloseFrame.NO_UTF8 );
		}
	}
	// **** What about if the current_continuous_frame.getOpcode() == Framedata.Opcode.BINARY ****//
	current_continuous_frame = null;
```

Is this expected? Is Chrome breaking the spec? Is this something Java-WebSocket should handle differently?",f33422e9951369ffd948d473c026ef0e6da6b8e4,32c1ce01c9064d68c8adcfa3b1b577d30bed8cb2,https://github.com/tootallnate/java-websocket/compare/f33422e9951369ffd948d473c026ef0e6da6b8e4...32c1ce01c9064d68c8adcfa3b1b577d30bed8cb2,"diff --git a/src/main/java/org/java_websocket/WebSocketImpl.java b/src/main/java/org/java_websocket/WebSocketImpl.java
index 74aca19..f794591 100644
--- a/src/main/java/org/java_websocket/WebSocketImpl.java
+++ b/src/main/java/org/java_websocket/WebSocketImpl.java
@@ -605,7 +605,7 @@ public class WebSocketImpl implements WebSocket {
 		if( !isOpen() ) {
 			throw new WebsocketNotConnectedException();
 		}
-		if( frames == null || frames.isEmpty() ) {
+		if( frames == null) {
 			throw new IllegalArgumentException();
 		}
 		ArrayList<ByteBuffer> outgoingFrames = new ArrayList<ByteBuffer>();
diff --git a/src/main/java/org/java_websocket/WebSocketListener.java b/src/main/java/org/java_websocket/WebSocketListener.java
index d865504..fd19883 100644
--- a/src/main/java/org/java_websocket/WebSocketListener.java
+++ b/src/main/java/org/java_websocket/WebSocketListener.java
@@ -59,7 +59,7 @@ public interface WebSocketListener {
 	 * @throws InvalidDataException
 	 *             Throwing this exception will cause this handshake to be rejected
 	 */
-	public ServerHandshakeBuilder onWebsocketHandshakeReceivedAsServer( WebSocket conn, Draft draft, ClientHandshake request ) throws InvalidDataException;
+	ServerHandshakeBuilder onWebsocketHandshakeReceivedAsServer( WebSocket conn, Draft draft, ClientHandshake request ) throws InvalidDataException;
 
 	/**
 	 * Called on the client side when the socket connection is first established, and the WebSocketImpl
@@ -74,7 +74,7 @@ public interface WebSocketListener {
 	 * @throws InvalidDataException
 	 *             Allows the client to reject the connection with the server in respect of its handshake response.
 	 */
-	public void onWebsocketHandshakeReceivedAsClient( WebSocket conn, ClientHandshake request, ServerHandshake response ) throws InvalidDataException;
+	void onWebsocketHandshakeReceivedAsClient( WebSocket conn, ClientHandshake request, ServerHandshake response ) throws InvalidDataException;
 
 	/**
 	 * Called on the client side when the socket connection is first established, and the WebSocketImpl
@@ -87,7 +87,7 @@ public interface WebSocketListener {
 	 * @throws InvalidDataException
 	 *             Allows the client to stop the connection from progressing
 	 */
-	public void onWebsocketHandshakeSentAsClient( WebSocket conn, ClientHandshake request ) throws InvalidDataException;
+	void onWebsocketHandshakeSentAsClient( WebSocket conn, ClientHandshake request ) throws InvalidDataException;
 
 	/**
 	 * Called when an entire text frame has been received. Do whatever you want
@@ -98,7 +98,7 @@ public interface WebSocketListener {
 	 * @param message
 	 *            The UTF-8 decoded message that was received.
 	 */
-	public void onWebsocketMessage( WebSocket conn, String message );
+	void onWebsocketMessage( WebSocket conn, String message );
 
 	/**
 	 * Called when an entire binary frame has been received. Do whatever you want
@@ -109,16 +109,18 @@ public interface WebSocketListener {
 	 * @param blob
 	 *            The binary message that was received.
 	 */
-	public void onWebsocketMessage( WebSocket conn, ByteBuffer blob );
+	void onWebsocketMessage( WebSocket conn, ByteBuffer blob );
 
 	/**
 	 * Called when a frame fragment has been recieved
 	 *
+	 * This method will be removed in a future version since the lib will also call the respective onWebsocketMessage method
 	 * @param conn
 	 *            The <tt>WebSocket</tt> instance this event is occurring on.
 	 * @param frame The fragmented frame
 	 */
-	public void onWebsocketMessageFragment( WebSocket conn, Framedata frame );
+	@Deprecated
+	void onWebsocketMessageFragment( WebSocket conn, Framedata frame );
 
 	/**
 	 * Called after <var>onHandshakeReceived</var> returns <var>true</var>.
@@ -128,7 +130,7 @@ public interface WebSocketListener {
 	 * @param conn The <tt>WebSocket</tt> instance this event is occuring on.
 	 * @param d The handshake of the websocket instance
 	 */
-	public void onWebsocketOpen( WebSocket conn, Handshakedata d );
+	void onWebsocketOpen( WebSocket conn, Handshakedata d );
 
 	/**
 	 * Called after <tt>WebSocket#close</tt> is explicity called, or when the
@@ -139,7 +141,7 @@ public interface WebSocketListener {
 	 * @param reason Additional information string
 	 * @param remote Returns whether or not the closing of the connection was initiated by the remote host.
 	 */
-	public void onWebsocketClose( WebSocket ws, int code, String reason, boolean remote );
+	void onWebsocketClose( WebSocket ws, int code, String reason, boolean remote );
 
 	/** Called as soon as no further frames are accepted
 	 *
@@ -148,7 +150,7 @@ public interface WebSocketListener {
 	 * @param reason Additional information string
 	 * @param remote Returns whether or not the closing of the connection was initiated by the remote host.
 	 */
-	public void onWebsocketClosing( WebSocket ws, int code, String reason, boolean remote );
+	void onWebsocketClosing( WebSocket ws, int code, String reason, boolean remote );
 
 	/** send when this peer sends a close handshake
 	 *
@@ -156,7 +158,7 @@ public interface WebSocketListener {
 	 * @param code The codes can be looked up here: {@link CloseFrame}
 	 * @param reason Additional information string
 	 */
-	public void onWebsocketCloseInitiated( WebSocket ws, int code, String reason );
+	void onWebsocketCloseInitiated( WebSocket ws, int code, String reason );
 
 	/**
 	 * Called if an exception worth noting occurred.
@@ -167,7 +169,7 @@ public interface WebSocketListener {
 	 *            The exception that occurred. <br>
 	 *            Might be null if the exception is not related to any specific connection. For example if the server port could not be bound.
 	 */
-	public void onWebsocketError( WebSocket conn, Exception ex );
+	void onWebsocketError( WebSocket conn, Exception ex );
 
 	/**
 	 * Called a ping frame has been received.
@@ -176,7 +178,7 @@ public interface WebSocketListener {
 	 * @param conn The <tt>WebSocket</tt> instance this event is occuring on.
 	 * @param f The ping frame. Control frames may contain payload.
 	 */
-	public void onWebsocketPing( WebSocket conn, Framedata f );
+	void onWebsocketPing( WebSocket conn, Framedata f );
 
 	/**
 	 * Called when a pong frame is received.
@@ -184,7 +186,7 @@ public interface WebSocketListener {
 	 * @param conn The <tt>WebSocket</tt> instance this event is occuring on.
 	 * @param f The pong frame. Control frames may contain payload.
 	 **/
-	public void onWebsocketPong( WebSocket conn, Framedata f );
+	void onWebsocketPong( WebSocket conn, Framedata f );
 
 	/**
 	 * @see WebSocketAdapter#getFlashPolicy(WebSocket)
@@ -192,12 +194,13 @@ public interface WebSocketListener {
 	 * @throws InvalidDataException thrown when some data that is required to generate the flash-policy like the websocket local port could not be obtained.
 	 * @return An XML String that comforts to Flash's security policy. You MUST not include the null char at the end, it is appended automatically.
 	 */
-	public String getFlashPolicy( WebSocket conn ) throws InvalidDataException;
+	@Deprecated
+	String getFlashPolicy( WebSocket conn ) throws InvalidDataException;
 
 	/** This method is used to inform the selector thread that there is data queued to be written to the socket.
 	 * @param conn The <tt>WebSocket</tt> instance this event is occuring on.
 	 */
-	public void onWriteDemand( WebSocket conn );
+	void onWriteDemand( WebSocket conn );
 
 	/**
 	 * @see  WebSocket#getLocalSocketAddress()
@@ -205,7 +208,7 @@ public interface WebSocketListener {
 	 * @param conn The <tt>WebSocket</tt> instance this event is occuring on.
 	 * @return Returns the address of the endpoint this socket is bound to.
 	 */
-	public InetSocketAddress getLocalSocketAddress( WebSocket conn );
+	InetSocketAddress getLocalSocketAddress( WebSocket conn );
 
 	/**
 	 * @see  WebSocket#getRemoteSocketAddress()
@@ -213,5 +216,5 @@ public interface WebSocketListener {
 	 * @param conn The <tt>WebSocket</tt> instance this event is occuring on.
 	 * @return Returns the address of the endpoint this socket is connected to, or{@code null} if it is unconnected.
 	 */
-	public InetSocketAddress getRemoteSocketAddress( WebSocket conn );
+	InetSocketAddress getRemoteSocketAddress( WebSocket conn );
 }
diff --git a/src/main/java/org/java_websocket/drafts/Draft_6455.java b/src/main/java/org/java_websocket/drafts/Draft_6455.java
index e44e72f..03bb639 100644
--- a/src/main/java/org/java_websocket/drafts/Draft_6455.java
+++ b/src/main/java/org/java_websocket/drafts/Draft_6455.java
@@ -62,6 +62,11 @@ public class Draft_6455 extends Draft {
 	 */
 	private Framedata current_continuous_frame;
 
+	/**
+	 * Attribute for the payload of the current continuous frame
+	 */
+	private List<ByteBuffer> byteBufferList;
+
 	/**
 	 * Attribute for the current incomplete frame
 	 */
@@ -96,6 +101,7 @@ public class Draft_6455 extends Draft {
 	public Draft_6455( List<IExtension> inputExtensions ) {
 		knownExtensions = new ArrayList<IExtension>();
 		boolean hasDefault = false;
+		byteBufferList = new ArrayList<ByteBuffer>();
 		for( IExtension inputExtension : inputExtensions ) {
 			if( inputExtension.getClass().equals( DefaultExtension.class ) ) {
 				hasDefault = true;
@@ -548,19 +554,30 @@ public class Draft_6455 extends Draft {
 				if( current_continuous_frame != null )
 					throw new InvalidDataException( CloseFrame.PROTOCOL_ERROR, ""Previous continuous frame sequence not completed."" );
 				current_continuous_frame = frame;
+				byteBufferList.add( frame.getPayloadData() );
 			} else if( frame.isFin() ) {
 				if( current_continuous_frame == null )
 					throw new InvalidDataException( CloseFrame.PROTOCOL_ERROR, ""Continuous frame sequence was not started."" );
-				//Check if the whole payload is valid utf8, when the opcode indicates a text
+				byteBufferList.add( frame.getPayloadData() );
 				if( current_continuous_frame.getOpcode() == Framedata.Opcode.TEXT ) {
-					//Checking a bit more from the frame before this one just to make sure all the code points are correct
-					int off = Math.max( current_continuous_frame.getPayloadData().limit() - 64, 0 );
-					current_continuous_frame.append( frame );
-					if( !Charsetfunctions.isValidUTF8( current_continuous_frame.getPayloadData(), off ) ) {
-						throw new InvalidDataException( CloseFrame.NO_UTF8 );
+					((FramedataImpl1) current_continuous_frame).setPayload( getPayloadFromByteBufferList() );
+					((FramedataImpl1) current_continuous_frame ).isValid();
+					try {
+						webSocketImpl.getWebSocketListener().onWebsocketMessage( webSocketImpl, Charsetfunctions.stringUtf8( current_continuous_frame.getPayloadData() ) );
+					} catch ( RuntimeException e ) {
+						webSocketImpl.getWebSocketListener().onWebsocketError( webSocketImpl, e );
+					}
+				} else if( current_continuous_frame.getOpcode() == Framedata.Opcode.BINARY ) {
+					((FramedataImpl1) current_continuous_frame).setPayload( getPayloadFromByteBufferList() );
+					((FramedataImpl1) current_continuous_frame ).isValid();
+					try {
+						webSocketImpl.getWebSocketListener().onWebsocketMessage( webSocketImpl, current_continuous_frame.getPayloadData() );
+					} catch ( RuntimeException e ) {
+						webSocketImpl.getWebSocketListener().onWebsocketError( webSocketImpl, e );
 					}
 				}
 				current_continuous_frame = null;
+				byteBufferList.clear();
 			} else if( current_continuous_frame == null ) {
 				throw new InvalidDataException( CloseFrame.PROTOCOL_ERROR, ""Continuous frame sequence was not started."" );
 			}
@@ -571,18 +588,8 @@ public class Draft_6455 extends Draft {
 				}
 			}
 			//Checking if the current continous frame contains a correct payload with the other frames combined
-			if( curop == Framedata.Opcode.CONTINUOUS && current_continuous_frame != null && current_continuous_frame.getOpcode() == Framedata.Opcode.TEXT ) {
-				//Checking a bit more from the frame before this one just to make sure all the code points are correct
-				int off = Math.max( current_continuous_frame.getPayloadData().limit() - 64, 0 );
-				current_continuous_frame.append( frame );
-				if( !Charsetfunctions.isValidUTF8( current_continuous_frame.getPayloadData(), off ) ) {
-					throw new InvalidDataException( CloseFrame.NO_UTF8 );
-				}
-			}
-			try {
-				webSocketImpl.getWebSocketListener().onWebsocketMessageFragment( webSocketImpl, frame );
-			} catch ( RuntimeException e ) {
-				webSocketImpl.getWebSocketListener().onWebsocketError( webSocketImpl, e );
+			if( curop == Framedata.Opcode.CONTINUOUS && current_continuous_frame != null ) {
+				byteBufferList.add( frame.getPayloadData() );
 			}
 			return;
 		} else if( current_continuous_frame != null ) {
@@ -632,4 +639,25 @@ public class Draft_6455 extends Draft {
 	public int hashCode() {
 		return extension != null ? extension.hashCode() : 0;
 	}
+
+	/**
+	 * Method to generate a full bytebuffer out of all the fragmented frame payload
+	 * @return a bytebuffer containing all the data
+	 * @throws LimitExedeedException will be thrown when the totalSize is bigger then Integer.MAX_VALUE due to not being able to allocate more
+	 */
+	private ByteBuffer getPayloadFromByteBufferList() throws LimitExedeedException {
+		long totalSize = 0;
+		for (ByteBuffer buffer : byteBufferList) {
+			totalSize +=buffer.limit();
+		}
+		if (totalSize > Integer.MAX_VALUE) {
+			throw new LimitExedeedException( ""Payloadsize is to big..."" );
+		}
+		ByteBuffer resultingByteBuffer = ByteBuffer.allocate( (int) totalSize );
+		for (ByteBuffer buffer : byteBufferList) {
+			resultingByteBuffer.put( buffer );
+		}
+		resultingByteBuffer.flip();
+		return resultingByteBuffer;
+	}
 }
diff --git a/src/main/java/org/java_websocket/server/WebSocketServer.java b/src/main/java/org/java_websocket/server/WebSocketServer.java
index 872db60..38c2a6e 100644
--- a/src/main/java/org/java_websocket/server/WebSocketServer.java
+++ b/src/main/java/org/java_websocket/server/WebSocketServer.java
@@ -767,6 +767,7 @@ public abstract class WebSocketServer extends AbstractWebSocket implements Runna
 	 *            The <tt>WebSocket</tt> instance this event is occurring on.
 	 * @param fragment The fragmented frame
 	 */
+	@Deprecated
 	public void onFragment( WebSocket conn, Framedata fragment ) {
 	}
 
diff --git a/src/test/java/org/java_websocket/example/AutobahnServerTest.java b/src/test/java/org/java_websocket/example/AutobahnServerTest.java
index 1cc752d..e8749a4 100644
--- a/src/test/java/org/java_websocket/example/AutobahnServerTest.java
+++ b/src/test/java/org/java_websocket/example/AutobahnServerTest.java
@@ -48,7 +48,6 @@ import java.util.Collections;
 
 public class AutobahnServerTest extends WebSocketServer {
 	private static int counter = 0;
-
 	public AutobahnServerTest( int port, Draft d ) throws UnknownHostException {
 		super( new InetSocketAddress( port ), Collections.singletonList( d ) );
 	}
@@ -83,17 +82,14 @@ public class AutobahnServerTest extends WebSocketServer {
 	public void onMessage( WebSocket conn, String message ) {
 		conn.send( message );
 	}
-
 	@Override
-	public void onMessage( WebSocket conn, ByteBuffer blob ) {
-		conn.send( blob );
+	public void onFragment( WebSocket conn, Framedata fragment ) {
+		System.out.println( ""received fragment: "" + fragment );
 	}
 
 	@Override
-	public void onWebsocketMessageFragment( WebSocket conn, Framedata frame ) {
-		FramedataImpl1 builder = ( FramedataImpl1 ) frame;
-		builder.setTransferemasked( false );
-		conn.sendFrame( frame );
+	public void onMessage( WebSocket conn, ByteBuffer blob ) {
+		conn.send( blob );
 	}
 
 	public static void main( String[] args ) throws UnknownHostException {","['src/main/java/org/java_websocket/WebSocketListener.java', 'src/main/java/org/java_websocket/WebSocketImpl.java', 'src/main/java/org/java_websocket/drafts/Draft_6455.java', 'src/main/java/org/java_websocket/server/WebSocketServer.java', 'src/test/java/org/java_websocket/example/AutobahnServerTest.java']",{'.java': 5},5,5,0,0,5,404340,97292,11329,64,6409,1398,104,4,1252,157,291,25,0,1,2017-10-10 20:30:24,9888,Java,"{'Java': 920046, 'HTML': 673666, 'Gherkin': 1433}",MIT License,['src/main/java/org/java_websocket/drafts/Draft_6455.java'],['src/main/java/org/java_websocket/drafts/Draft_6455.java'],"['```json\n{\n  ""files"": [\n    ""src/main/java/org/java_websocket/drafts/Draft_6455.java""\n  ]\n}\n```']",1,887.4876499176025
46,tootallnate/java-websocket/329/259,tootallnate,java-websocket,https://github.com/TooTallNate/Java-WebSocket/issues/259,https://github.com/TooTallNate/Java-WebSocket/pull/329,https://github.com/TooTallNate/Java-WebSocket/pull/329,2,fixes,WebSocketServer freezes in stop() method,"Hello,

first I would like to thank you for creating a great and useful library.

I'am using it in Android application to communicate with website. 
When I try to stop the server, the application sometimes stops responding.
The main thread is indefinitely waiting in ""WebSocketServer.stop()"" method in ""selectorThread.join()"" line, because the ""selectorThread"" never ends. This happens because ""selectorThread"" is waiting in ""run()"" method in ""selector.select()"" line.

Do you know what could be the cause of this behavior?

Thank you all in advance for any help you can provide.

Regards,
Vito
",ac45d846806ad662de48c206896d1248acbb53ff,e4c248a69f0cb36f87e5b3d3100bd2b46e027289,https://github.com/tootallnate/java-websocket/compare/ac45d846806ad662de48c206896d1248acbb53ff...e4c248a69f0cb36f87e5b3d3100bd2b46e027289,"diff --git a/src/main/java/org/java_websocket/server/WebSocketServer.java b/src/main/java/org/java_websocket/server/WebSocketServer.java
index 5fc6a39..12cea2f 100644
--- a/src/main/java/org/java_websocket/server/WebSocketServer.java
+++ b/src/main/java/org/java_websocket/server/WebSocketServer.java
@@ -216,16 +216,10 @@ public abstract class WebSocketServer extends WebSocketAdapter implements Runnab
 		}
 
 		synchronized ( this ) {
-			if( selectorthread != null ) {
-				if( Thread.currentThread() != selectorthread ) {
-
-				}
-				if( selectorthread != Thread.currentThread() ) {
-					if( socketsToClose.size() > 0 )
-						selectorthread.join( timeout );// isclosed will tell the selectorthread to go down after the last connection was closed
-					selectorthread.interrupt();// in case the selectorthread did not terminate in time we send the interrupt
-					selectorthread.join();
-				}
+			if( selectorthread != null && selectorthread != Thread.currentThread() ) {
+				selector.wakeup();
+				selectorthread.interrupt();
+				selectorthread.join( timeout );
 			}
 		}
 	}",['src/main/java/org/java_websocket/server/WebSocketServer.java'],{'.java': 1},1,1,0,0,1,262584,64741,7715,50,636,147,14,1,595,90,124,15,0,0,2015-08-06 21:13:00,9888,Java,"{'Java': 920046, 'HTML': 673666, 'Gherkin': 1433}",MIT License,['src/main/java/org/java_websocket/server/WebSocketServer.java'],['src/main/java/org/java_websocket/server/WebSocketServer.java'],"['```json\n{\n  ""files"": [\n    ""src/main/java/org/java_websocket/server/WebSocketServer.java""\n  ]\n}\n```']",1,695.8115100860596
8247,trinodb/trino/17804/17803,trinodb,trino,https://github.com/trinodb/trino/issues/17803,https://github.com/trinodb/trino/pull/17804,https://github.com/trinodb/trino/pull/17804,1,fixes,Correctness issue with double slash location on Glue & S3 in Hive connector,"The file is generated correctly under the table location, but it returns an empty result. Delta and Iceberg connectors are fine as far as I confirmed. 
```sql
create table test_slash (c1 int) with (external_location = 's3://bucket/foo//bar');
insert into test_slash values (1);
table test_slash;
 c1
----
(0 rows)
```",eaf893a74737d877aeb4e6cd267a8018203a632d,8cb4bd1b5e81541b96c5faeb725126a698789144,https://github.com/trinodb/trino/compare/eaf893a74737d877aeb4e6cd267a8018203a632d...8cb4bd1b5e81541b96c5faeb725126a698789144,"diff --git a/plugin/trino-delta-lake/src/test/java/io/trino/plugin/deltalake/metastore/glue/TestDeltaLakeConcurrentModificationGlueMetastore.java b/plugin/trino-delta-lake/src/test/java/io/trino/plugin/deltalake/metastore/glue/TestDeltaLakeConcurrentModificationGlueMetastore.java
index f4aaad4880..de99991545 100644
--- a/plugin/trino-delta-lake/src/test/java/io/trino/plugin/deltalake/metastore/glue/TestDeltaLakeConcurrentModificationGlueMetastore.java
+++ b/plugin/trino-delta-lake/src/test/java/io/trino/plugin/deltalake/metastore/glue/TestDeltaLakeConcurrentModificationGlueMetastore.java
@@ -17,6 +17,8 @@ import com.amazonaws.auth.DefaultAWSCredentialsProviderChain;
 import com.amazonaws.services.glue.AWSGlueAsync;
 import com.amazonaws.services.glue.model.ConcurrentModificationException;
 import io.trino.Session;
+import io.trino.filesystem.hdfs.HdfsFileSystemFactory;
+import io.trino.hdfs.TrinoHdfsFileSystemStats;
 import io.trino.plugin.deltalake.TestingDeltaLakePlugin;
 import io.trino.plugin.deltalake.metastore.TestingDeltaLakeMetastoreModule;
 import io.trino.plugin.hive.metastore.glue.DefaultGlueColumnStatisticsProviderFactory;
@@ -92,6 +94,7 @@ public class TestDeltaLakeConcurrentModificationGlueMetastore
         });
 
         metastore = new GlueHiveMetastore(
+                new HdfsFileSystemFactory(HDFS_ENVIRONMENT, new TrinoHdfsFileSystemStats()),
                 HDFS_ENVIRONMENT,
                 glueConfig,
                 directExecutor(),
diff --git a/plugin/trino-hive/src/main/java/io/trino/plugin/hive/BackgroundHiveSplitLoader.java b/plugin/trino-hive/src/main/java/io/trino/plugin/hive/BackgroundHiveSplitLoader.java
index 1da5e9d99c..354fc61f27 100644
--- a/plugin/trino-hive/src/main/java/io/trino/plugin/hive/BackgroundHiveSplitLoader.java
+++ b/plugin/trino-hive/src/main/java/io/trino/plugin/hive/BackgroundHiveSplitLoader.java
@@ -106,6 +106,7 @@ import static com.google.common.util.concurrent.Futures.immediateVoidFuture;
 import static com.google.common.util.concurrent.MoreExecutors.directExecutor;
 import static io.airlift.concurrent.MoreFutures.addExceptionCallback;
 import static io.airlift.concurrent.MoreFutures.toListenableFuture;
+import static io.trino.filesystem.hdfs.HadoopPaths.hadoopPath;
 import static io.trino.hdfs.ConfigurationUtils.toJobConf;
 import static io.trino.plugin.hive.HiveErrorCode.HIVE_BAD_DATA;
 import static io.trino.plugin.hive.HiveErrorCode.HIVE_EXCEEDED_PARTITION_LIMIT;
@@ -429,7 +430,8 @@ public class BackgroundHiveSplitLoader
             return COMPLETED_FUTURE;
         }
 
-        Path path = new Path(getPartitionLocation(table, partition.getPartition()));
+        Location location = Location.of(getPartitionLocation(table, partition.getPartition()));
+        Path path = hadoopPath(location);
         Configuration configuration = hdfsEnvironment.getConfiguration(hdfsContext, path);
         InputFormat<?, ?> inputFormat = getInputFormat(configuration, schema, false);
         FileSystem fs = hdfsEnvironment.getFileSystem(hdfsContext, path);
@@ -548,7 +550,6 @@ public class BackgroundHiveSplitLoader
         }
 
         TrinoFileSystem trinoFileSystem = fileSystemFactory.create(session);
-        Location location = Location.of(path.toString());
         // Bucketed partitions are fully loaded immediately since all files must be loaded to determine the file to bucket mapping
         if (tableBucketInfo.isPresent()) {
             List<TrinoFileStatus> files = listBucketFiles(trinoFileSystem, location, splitFactory.getPartitionName());
diff --git a/plugin/trino-hive/src/main/java/io/trino/plugin/hive/HiveLocationService.java b/plugin/trino-hive/src/main/java/io/trino/plugin/hive/HiveLocationService.java
index 6da35e45ba..e91e99e58d 100644
--- a/plugin/trino-hive/src/main/java/io/trino/plugin/hive/HiveLocationService.java
+++ b/plugin/trino-hive/src/main/java/io/trino/plugin/hive/HiveLocationService.java
@@ -27,6 +27,7 @@ import org.apache.hadoop.fs.Path;
 
 import java.util.Optional;
 
+import static io.trino.filesystem.hdfs.HadoopPaths.hadoopPath;
 import static io.trino.plugin.hive.HiveErrorCode.HIVE_PATH_ALREADY_EXISTS;
 import static io.trino.plugin.hive.LocationHandle.WriteMode.DIRECT_TO_TARGET_EXISTING_DIRECTORY;
 import static io.trino.plugin.hive.LocationHandle.WriteMode.DIRECT_TO_TARGET_NEW_DIRECTORY;
@@ -63,7 +64,7 @@ public class HiveLocationService
         Location targetPath = getTableDefaultLocation(context, metastore, hdfsEnvironment, schemaName, tableName);
 
         // verify the target directory for table
-        if (pathExists(context, hdfsEnvironment, new Path(targetPath.toString()))) {
+        if (pathExists(context, hdfsEnvironment, hadoopPath(targetPath))) {
             throw new TrinoException(HIVE_PATH_ALREADY_EXISTS, format(""Target directory for table '%s.%s' already exists: %s"", schemaName, tableName, targetPath));
         }
         return targetPath;
@@ -76,13 +77,13 @@ public class HiveLocationService
         Location targetPath = externalLocation.orElseGet(() -> getTableDefaultLocation(context, metastore, hdfsEnvironment, schemaName, tableName));
 
         // verify the target directory for the table
-        if (pathExists(context, hdfsEnvironment, new Path(targetPath.toString()))) {
+        if (pathExists(context, hdfsEnvironment, hadoopPath(targetPath))) {
             throw new TrinoException(HIVE_PATH_ALREADY_EXISTS, format(""Target directory for table '%s.%s' already exists: %s"", schemaName, tableName, targetPath));
         }
 
         // TODO detect when existing table's location is a on a different file system than the temporary directory
-        if (shouldUseTemporaryDirectory(context, new Path(targetPath.toString()), externalLocation.isPresent())) {
-            Location writePath = createTemporaryPath(context, hdfsEnvironment, new Path(targetPath.toString()), temporaryStagingDirectoryPath);
+        if (shouldUseTemporaryDirectory(context, hadoopPath(targetPath), externalLocation.isPresent())) {
+            Location writePath = createTemporaryPath(context, hdfsEnvironment, hadoopPath(targetPath), temporaryStagingDirectoryPath);
             return new LocationHandle(targetPath, writePath, STAGE_AND_MOVE_TO_TARGET_DIRECTORY);
         }
         return new LocationHandle(targetPath, targetPath, DIRECT_TO_TARGET_NEW_DIRECTORY);
@@ -94,8 +95,8 @@ public class HiveLocationService
         HdfsContext context = new HdfsContext(session);
         Location targetPath = Location.of(table.getStorage().getLocation());
 
-        if (shouldUseTemporaryDirectory(context, new Path(targetPath.toString()), false) && !isTransactionalTable(table.getParameters())) {
-            Location writePath = createTemporaryPath(context, hdfsEnvironment, new Path(targetPath.toString()), temporaryStagingDirectoryPath);
+        if (shouldUseTemporaryDirectory(context, hadoopPath(targetPath), false) && !isTransactionalTable(table.getParameters())) {
+            Location writePath = createTemporaryPath(context, hdfsEnvironment, hadoopPath(targetPath), temporaryStagingDirectoryPath);
             return new LocationHandle(targetPath, writePath, STAGE_AND_MOVE_TO_TARGET_DIRECTORY);
         }
         return new LocationHandle(targetPath, targetPath, DIRECT_TO_TARGET_EXISTING_DIRECTORY);
diff --git a/plugin/trino-hive/src/main/java/io/trino/plugin/hive/HiveMetadata.java b/plugin/trino-hive/src/main/java/io/trino/plugin/hive/HiveMetadata.java
index 564f128dd2..cd3d0dc742 100644
--- a/plugin/trino-hive/src/main/java/io/trino/plugin/hive/HiveMetadata.java
+++ b/plugin/trino-hive/src/main/java/io/trino/plugin/hive/HiveMetadata.java
@@ -165,6 +165,7 @@ import static com.google.common.collect.ImmutableMap.toImmutableMap;
 import static com.google.common.collect.ImmutableSet.toImmutableSet;
 import static com.google.common.collect.Iterables.concat;
 import static com.google.common.collect.Iterables.getOnlyElement;
+import static io.trino.filesystem.hdfs.HadoopPaths.hadoopPath;
 import static io.trino.hdfs.ConfigurationUtils.toJobConf;
 import static io.trino.plugin.hive.HiveAnalyzeProperties.getColumnNames;
 import static io.trino.plugin.hive.HiveAnalyzeProperties.getPartitionList;
@@ -1734,7 +1735,7 @@ public class HiveMetadata
             partitionUpdates = PartitionUpdate.mergePartitionUpdates(concat(partitionUpdates, partitionUpdatesForMissingBuckets));
             for (PartitionUpdate partitionUpdate : partitionUpdatesForMissingBuckets) {
                 Optional<Partition> partition = table.getPartitionColumns().isEmpty() ? Optional.empty() : Optional.of(buildPartitionObject(session, table, partitionUpdate));
-                createEmptyFiles(session, partitionUpdate.getWritePath(), table, partition, partitionUpdate.getFileNames());
+                createEmptyFiles(session, hadoopPath(partitionUpdate.getWritePath()), table, partition, partitionUpdate.getFileNames());
             }
             if (handle.isTransactional()) {
                 AcidTransaction transaction = handle.getTransaction();
@@ -1765,7 +1766,7 @@ public class HiveMetadata
             tableStatistics = new PartitionStatistics(createEmptyStatistics(), ImmutableMap.of());
         }
 
-        Optional<Path> writePath = Optional.of(new Path(writeInfo.writePath().toString()));
+        Optional<Location> writePath = Optional.of(Location.of(writeInfo.writePath().toString()));
         if (handle.getPartitionedBy().isEmpty()) {
             List<String> fileNames;
             if (partitionUpdates.isEmpty()) {
@@ -1845,7 +1846,7 @@ public class HiveMetadata
     private List<String> computeFileNamesForMissingBuckets(
             ConnectorSession session,
             HiveStorageFormat storageFormat,
-            Path targetPath,
+            Location targetPath,
             int bucketCount,
             boolean transactionalCreateTable,
             PartitionUpdate partitionUpdate)
@@ -1855,7 +1856,7 @@ public class HiveMetadata
             return ImmutableList.of();
         }
         HdfsContext hdfsContext = new HdfsContext(session);
-        JobConf conf = toJobConf(hdfsEnvironment.getConfiguration(hdfsContext, targetPath));
+        JobConf conf = toJobConf(hdfsEnvironment.getConfiguration(hdfsContext, hadoopPath(targetPath)));
         configureCompression(conf, selectCompressionCodec(session, storageFormat));
         String fileExtension = HiveWriterFactory.getFileExtension(conf, fromHiveStorageFormat(storageFormat));
         Set<String> fileNames = ImmutableSet.copyOf(partitionUpdate.getFileNames());
@@ -2141,7 +2142,7 @@ public class HiveMetadata
                             statistics,
                             handle.isRetriesEnabled());
                 }
-                createEmptyFiles(session, partitionUpdate.getWritePath(), table, partition, partitionUpdate.getFileNames());
+                createEmptyFiles(session, hadoopPath(partitionUpdate.getWritePath()), table, partition, partitionUpdate.getFileNames());
             }
         }
 
@@ -2227,10 +2228,10 @@ public class HiveMetadata
                         getColumnStatistics(partitionComputedStatistics, partitionName, partitionValues, partitionTypes));
                 if (partitionUpdate.getUpdateMode() == OVERWRITE) {
                     if (handle.getLocationHandle().getWriteMode() == DIRECT_TO_TARGET_EXISTING_DIRECTORY) {
-                        removeNonCurrentQueryFiles(session, partitionUpdate.getTargetPath());
+                        removeNonCurrentQueryFiles(session, hadoopPath(partitionUpdate.getTargetPath()));
                         if (handle.isRetriesEnabled()) {
                             HdfsContext hdfsContext = new HdfsContext(session);
-                            cleanExtraOutputFiles(hdfsEnvironment, hdfsContext, session.getQueryId(), partitionUpdate.getTargetPath(), ImmutableSet.copyOf(partitionUpdate.getFileNames()));
+                            cleanExtraOutputFiles(hdfsEnvironment, hdfsContext, session.getQueryId(), hadoopPath(partitionUpdate.getTargetPath()), ImmutableSet.copyOf(partitionUpdate.getFileNames()));
                         }
                     }
                     else {
@@ -2555,22 +2556,22 @@ public class HiveMetadata
         }
 
         // path to be deleted
-        Set<Path> scannedPaths = splitSourceInfo.stream()
-                .map(file -> new Path((String) file))
+        Set<Location> scannedPaths = splitSourceInfo.stream()
+                .map(file -> Location.of((String) file))
                 .collect(toImmutableSet());
         // track remaining files to be delted for error reporting
-        Set<Path> remainingFilesToDelete = new HashSet<>(scannedPaths);
+        Set<Location> remainingFilesToDelete = new HashSet<>(scannedPaths);
 
         // delete loop
         boolean someDeleted = false;
-        Optional<Path> firstScannedPath = Optional.empty();
+        Optional<Location> firstScannedPath = Optional.empty();
         try {
-            for (Path scannedPath : scannedPaths) {
+            for (Location scannedPath : scannedPaths) {
                 if (firstScannedPath.isEmpty()) {
                     firstScannedPath = Optional.of(scannedPath);
                 }
                 retry().run(""delete "" + scannedPath, () -> {
-                    checkedDelete(fs, scannedPath, false);
+                    checkedDelete(fs, hadoopPath(scannedPath), false);
                     return null;
                 });
                 someDeleted = true;
@@ -2578,7 +2579,7 @@ public class HiveMetadata
             }
         }
         catch (Exception e) {
-            if (!someDeleted && (firstScannedPath.isEmpty() || exists(fs, firstScannedPath.get()))) {
+            if (!someDeleted && (firstScannedPath.isEmpty() || exists(fs, hadoopPath(firstScannedPath.get())))) {
                 // we are good - we did not delete any source files so we can just throw error and allow rollback to happend
                 // if someDeleted flag is false we do extra checkig if first file we tried to delete is still there. There is a chance that
                 // fs.delete above could throw exception but file was actually deleted.
diff --git a/plugin/trino-hive/src/main/java/io/trino/plugin/hive/HiveWriter.java b/plugin/trino-hive/src/main/java/io/trino/plugin/hive/HiveWriter.java
index 7628b45362..4445ff3556 100644
--- a/plugin/trino-hive/src/main/java/io/trino/plugin/hive/HiveWriter.java
+++ b/plugin/trino-hive/src/main/java/io/trino/plugin/hive/HiveWriter.java
@@ -14,6 +14,7 @@
 package io.trino.plugin.hive;
 
 import com.google.common.collect.ImmutableList;
+import io.trino.filesystem.Location;
 import io.trino.plugin.hive.PartitionUpdate.UpdateMode;
 import io.trino.spi.Page;
 
@@ -114,8 +115,8 @@ public class HiveWriter
         return new PartitionUpdate(
                 partitionName.orElse(""""),
                 updateMode,
-                writePath,
-                targetPath,
+                Location.of(writePath),
+                Location.of(targetPath),
                 ImmutableList.of(fileName),
                 rowCount,
                 inputSizeInBytes,
diff --git a/plugin/trino-hive/src/main/java/io/trino/plugin/hive/PartitionUpdate.java b/plugin/trino-hive/src/main/java/io/trino/plugin/hive/PartitionUpdate.java
index 926d02ae35..e6b26cf332 100644
--- a/plugin/trino-hive/src/main/java/io/trino/plugin/hive/PartitionUpdate.java
+++ b/plugin/trino-hive/src/main/java/io/trino/plugin/hive/PartitionUpdate.java
@@ -17,8 +17,8 @@ import com.fasterxml.jackson.annotation.JsonCreator;
 import com.fasterxml.jackson.annotation.JsonProperty;
 import com.google.common.collect.ImmutableList;
 import com.google.common.collect.Multimaps;
+import io.trino.filesystem.Location;
 import io.trino.spi.TrinoException;
-import org.apache.hadoop.fs.Path;
 
 import java.util.Collection;
 import java.util.List;
@@ -33,8 +33,8 @@ public class PartitionUpdate
 {
     private final String name;
     private final UpdateMode updateMode;
-    private final Path writePath;
-    private final Path targetPath;
+    private final Location writePath;
+    private final Location targetPath;
     private final List<String> fileNames;
     private final long rowCount;
     private final long inMemoryDataSizeInBytes;
@@ -54,8 +54,8 @@ public class PartitionUpdate
         this(
                 name,
                 updateMode,
-                new Path(requireNonNull(writePath, ""writePath is null"")),
-                new Path(requireNonNull(targetPath, ""targetPath is null"")),
+                Location.of(requireNonNull(writePath, ""writePath is null"")),
+                Location.of(requireNonNull(targetPath, ""targetPath is null"")),
                 fileNames,
                 rowCount,
                 inMemoryDataSizeInBytes,
@@ -65,8 +65,8 @@ public class PartitionUpdate
     public PartitionUpdate(
             String name,
             UpdateMode updateMode,
-            Path writePath,
-            Path targetPath,
+            Location writePath,
+            Location targetPath,
             List<String> fileNames,
             long rowCount,
             long inMemoryDataSizeInBytes,
@@ -101,12 +101,12 @@ public class PartitionUpdate
         return updateMode;
     }
 
-    public Path getWritePath()
+    public Location getWritePath()
     {
         return writePath;
     }
 
-    public Path getTargetPath()
+    public Location getTargetPath()
     {
         return targetPath;
     }
diff --git a/plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/SemiTransactionalHiveMetastore.java b/plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/SemiTransactionalHiveMetastore.java
index 3e453c80d7..4aaf7410d6 100644
--- a/plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/SemiTransactionalHiveMetastore.java
+++ b/plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/SemiTransactionalHiveMetastore.java
@@ -98,6 +98,7 @@ import static com.google.common.collect.ImmutableList.toImmutableList;
 import static com.google.common.collect.ImmutableMap.toImmutableMap;
 import static com.google.common.collect.ImmutableSet.toImmutableSet;
 import static io.airlift.concurrent.MoreFutures.getFutureValue;
+import static io.trino.filesystem.hdfs.HadoopPaths.hadoopPath;
 import static io.trino.plugin.hive.HiveErrorCode.HIVE_CORRUPTED_COLUMN_STATISTICS;
 import static io.trino.plugin.hive.HiveErrorCode.HIVE_FILESYSTEM_ERROR;
 import static io.trino.plugin.hive.HiveErrorCode.HIVE_METASTORE_ERROR;
@@ -562,7 +563,7 @@ public class SemiTransactionalHiveMetastore
             ConnectorSession session,
             Table table,
             PrincipalPrivileges principalPrivileges,
-            Optional<Path> currentPath,
+            Optional<Location> currentPath,
             Optional<List<String>> files,
             boolean ignoreExisting,
             PartitionStatistics statistics,
@@ -680,7 +681,7 @@ public class SemiTransactionalHiveMetastore
             ConnectorSession session,
             String databaseName,
             String tableName,
-            Path currentLocation,
+            Location currentLocation,
             List<String> fileNames,
             PartitionStatistics statisticsUpdate,
             boolean cleanExtraOutputFilesOnCommit)
@@ -792,7 +793,7 @@ public class SemiTransactionalHiveMetastore
                             new TableAndMergeResults(
                                     table,
                                     Optional.of(principalPrivileges),
-                                    Optional.of(new Path(currentLocation.toString())),
+                                    Optional.of(currentLocation),
                                     partitionUpdateAndMergeResults,
                                     partitions),
                             hdfsContext,
@@ -968,7 +969,7 @@ public class SemiTransactionalHiveMetastore
             String databaseName,
             String tableName,
             Partition partition,
-            Path currentLocation,
+            Location currentLocation,
             Optional<List<String>> files,
             PartitionStatistics statistics,
             boolean cleanExtraOutputFilesOnCommit)
@@ -1733,16 +1734,16 @@ public class SemiTransactionalHiveMetastore
                 }
             }
 
-            Path currentPath = tableAndMore.getCurrentLocation()
+            Location currentPath = tableAndMore.getCurrentLocation()
                     .orElseThrow(() -> new IllegalArgumentException(""location should be present for alter table""));
-            Path targetPath = new Path(targetLocation);
+            Location targetPath = Location.of(targetLocation);
             if (!targetPath.equals(currentPath)) {
                 renameDirectory(
                         hdfsContext,
                         hdfsEnvironment,
-                        currentPath,
-                        targetPath,
-                        () -> cleanUpTasksForAbort.add(new DirectoryCleanUpTask(hdfsContext, targetPath, true)));
+                        hadoopPath(currentPath),
+                        hadoopPath(targetPath),
+                        () -> cleanUpTasksForAbort.add(new DirectoryCleanUpTask(hdfsContext, hadoopPath(targetPath), true)));
             }
             // Partition alter must happen regardless of whether original and current location is the same
             // because metadata might change: e.g. storage format, column types, etc
@@ -1766,8 +1767,8 @@ public class SemiTransactionalHiveMetastore
                 Optional<String> targetLocation = table.getStorage().getOptionalLocation();
                 if (targetLocation.isPresent()) {
                     checkArgument(!targetLocation.get().isEmpty(), ""target location is empty"");
-                    Optional<Path> currentPath = tableAndMore.getCurrentLocation();
-                    Path targetPath = new Path(targetLocation.get());
+                    Optional<Location> currentPath = tableAndMore.getCurrentLocation();
+                    Location targetPath = Location.of(targetLocation.get());
                     if (table.getPartitionColumns().isEmpty() && currentPath.isPresent()) {
                         // CREATE TABLE AS SELECT unpartitioned table
                         if (targetPath.equals(currentPath.get())) {
@@ -1777,15 +1778,15 @@ public class SemiTransactionalHiveMetastore
                             renameDirectory(
                                     context,
                                     hdfsEnvironment,
-                                    currentPath.get(),
-                                    targetPath,
-                                    () -> cleanUpTasksForAbort.add(new DirectoryCleanUpTask(context, targetPath, true)));
+                                    hadoopPath(currentPath.get()),
+                                    hadoopPath(targetPath),
+                                    () -> cleanUpTasksForAbort.add(new DirectoryCleanUpTask(context, hadoopPath(targetPath), true)));
                         }
                     }
                     else {
                         // CREATE TABLE AS SELECT partitioned table, or
                         // CREATE TABLE partitioned/unpartitioned table (without data)
-                        if (pathExists(context, hdfsEnvironment, targetPath)) {
+                        if (pathExists(context, hdfsEnvironment, hadoopPath(targetPath))) {
                             if (currentPath.isPresent() && currentPath.get().equals(targetPath)) {
                                 // It is okay to skip directory creation when currentPath is equal to targetPath
                                 // because the directory may have been created when creating partition directories.
@@ -1799,8 +1800,8 @@ public class SemiTransactionalHiveMetastore
                             }
                         }
                         else {
-                            cleanUpTasksForAbort.add(new DirectoryCleanUpTask(context, targetPath, true));
-                            createDirectory(context, hdfsEnvironment, targetPath);
+                            cleanUpTasksForAbort.add(new DirectoryCleanUpTask(context, hadoopPath(targetPath), true));
+                            createDirectory(context, hdfsEnvironment, hadoopPath(targetPath));
                         }
                     }
                 }
@@ -1813,10 +1814,10 @@ public class SemiTransactionalHiveMetastore
         {
             deleteOnly = false;
             Table table = tableAndMore.getTable();
-            Path targetPath = new Path(table.getStorage().getLocation());
+            Location targetPath = Location.of(table.getStorage().getLocation());
             tablesToInvalidate.add(table);
-            Path currentPath = tableAndMore.getCurrentLocation().orElseThrow();
-            cleanUpTasksForAbort.add(new DirectoryCleanUpTask(context, targetPath, false));
+            Location currentPath = Location.of(tableAndMore.getCurrentLocation().orElseThrow().toString());
+            cleanUpTasksForAbort.add(new DirectoryCleanUpTask(context, hadoopPath(targetPath), false));
 
             if (!targetPath.equals(currentPath)) {
                 // if staging directory is used we cherry-pick files to be moved
@@ -1846,9 +1847,9 @@ public class SemiTransactionalHiveMetastore
 
             deleteOnly = false;
             Table table = tableAndMore.getTable();
-            Path targetPath = new Path(table.getStorage().getLocation());
-            Path currentPath = tableAndMore.getCurrentLocation().get();
-            cleanUpTasksForAbort.add(new DirectoryCleanUpTask(context, targetPath, false));
+            Location targetPath = Location.of(table.getStorage().getLocation());
+            Location currentPath = Location.of(tableAndMore.getCurrentLocation().get().toString());
+            cleanUpTasksForAbort.add(new DirectoryCleanUpTask(context, hadoopPath(targetPath), false));
             if (!targetPath.equals(currentPath)) {
                 asyncRename(hdfsEnvironment, fileSystemExecutor, fileSystemOperationsCancelled, fileSystemOperationFutures, context, currentPath, targetPath, tableAndMore.getFileNames().get());
             }
@@ -1920,15 +1921,15 @@ public class SemiTransactionalHiveMetastore
                 }
             }
 
-            Path currentPath = partitionAndMore.getCurrentLocation();
-            Path targetPath = new Path(targetLocation);
+            Location currentPath = partitionAndMore.getCurrentLocation();
+            Location targetPath = Location.of(targetLocation);
             if (!targetPath.equals(currentPath)) {
                 renameDirectory(
                         hdfsContext,
                         hdfsEnvironment,
-                        currentPath,
-                        targetPath,
-                        () -> cleanUpTasksForAbort.add(new DirectoryCleanUpTask(hdfsContext, targetPath, true)));
+                        hadoopPath(currentPath),
+                        hadoopPath(targetPath),
+                        () -> cleanUpTasksForAbort.add(new DirectoryCleanUpTask(hdfsContext, hadoopPath(targetPath), true)));
             }
             // Partition alter must happen regardless of whether original and current location is the same
             // because metadata might change: e.g. storage format, column types, etc
@@ -1944,7 +1945,7 @@ public class SemiTransactionalHiveMetastore
             }
             verify(partitionAndMore.hasFileNames(), ""fileNames expected to be set if isCleanExtraOutputFilesOnCommit is true"");
 
-            SemiTransactionalHiveMetastore.cleanExtraOutputFiles(hdfsEnvironment, hdfsContext, queryId, partitionAndMore.getCurrentLocation(), ImmutableSet.copyOf(partitionAndMore.getFileNames()));
+            SemiTransactionalHiveMetastore.cleanExtraOutputFiles(hdfsEnvironment, hdfsContext, queryId, hadoopPath(partitionAndMore.getCurrentLocation()), ImmutableSet.copyOf(partitionAndMore.getFileNames()));
         }
 
         private void cleanExtraOutputFiles(HdfsContext hdfsContext, String queryId, TableAndMore tableAndMore)
@@ -1952,9 +1953,9 @@ public class SemiTransactionalHiveMetastore
             if (!tableAndMore.isCleanExtraOutputFilesOnCommit()) {
                 return;
             }
-            Path tableLocation = tableAndMore.getCurrentLocation().orElseThrow(() -> new IllegalArgumentException(""currentLocation expected to be set if isCleanExtraOutputFilesOnCommit is true""));
+            Location tableLocation = tableAndMore.getCurrentLocation().orElseThrow(() -> new IllegalArgumentException(""currentLocation expected to be set if isCleanExtraOutputFilesOnCommit is true""));
             List<String> files = tableAndMore.getFileNames().orElseThrow(() -> new IllegalArgumentException(""fileNames expected to be set if isCleanExtraOutputFilesOnCommit is true""));
-            SemiTransactionalHiveMetastore.cleanExtraOutputFiles(hdfsEnvironment, hdfsContext, queryId, tableLocation, ImmutableSet.copyOf(files));
+            SemiTransactionalHiveMetastore.cleanExtraOutputFiles(hdfsEnvironment, hdfsContext, queryId, hadoopPath(tableLocation), ImmutableSet.copyOf(files));
         }
 
         private PartitionStatistics getExistingPartitionStatistics(Partition partition, String partitionName)
@@ -1989,8 +1990,8 @@ public class SemiTransactionalHiveMetastore
 
             Partition partition = partitionAndMore.getPartition();
             String targetLocation = partition.getStorage().getLocation();
-            Path currentPath = partitionAndMore.getCurrentLocation();
-            Path targetPath = new Path(targetLocation);
+            Location currentPath = partitionAndMore.getCurrentLocation();
+            Location targetPath = Location.of(targetLocation);
 
             cleanExtraOutputFiles(hdfsContext, queryId, partitionAndMore);
 
@@ -2002,19 +2003,19 @@ public class SemiTransactionalHiveMetastore
                 if (fileSystemOperationsCancelled.get()) {
                     return;
                 }
-                if (pathExists(hdfsContext, hdfsEnvironment, currentPath)) {
+                if (pathExists(hdfsContext, hdfsEnvironment, hadoopPath(currentPath))) {
                     if (!targetPath.equals(currentPath)) {
                         renameDirectory(
                                 hdfsContext,
                                 hdfsEnvironment,
-                                currentPath,
-                                targetPath,
-                                () -> cleanUpTasksForAbort.add(new DirectoryCleanUpTask(hdfsContext, targetPath, true)));
+                                hadoopPath(currentPath),
+                                hadoopPath(targetPath),
+                                () -> cleanUpTasksForAbort.add(new DirectoryCleanUpTask(hdfsContext, hadoopPath(targetPath), true)));
                     }
                 }
                 else {
-                    cleanUpTasksForAbort.add(new DirectoryCleanUpTask(hdfsContext, targetPath, true));
-                    createDirectory(hdfsContext, hdfsEnvironment, targetPath);
+                    cleanUpTasksForAbort.add(new DirectoryCleanUpTask(hdfsContext, hadoopPath(targetPath), true));
+                    createDirectory(hdfsContext, hdfsEnvironment, hadoopPath(targetPath));
                 }
             }, fileSystemExecutor));
 
@@ -2028,9 +2029,9 @@ public class SemiTransactionalHiveMetastore
 
             Partition partition = partitionAndMore.getPartition();
             partitionsToInvalidate.add(partition);
-            Path targetPath = new Path(partition.getStorage().getLocation());
-            Path currentPath = partitionAndMore.getCurrentLocation();
-            cleanUpTasksForAbort.add(new DirectoryCleanUpTask(hdfsContext, targetPath, false));
+            Location targetPath = Location.of(partition.getStorage().getLocation());
+            Location currentPath = partitionAndMore.getCurrentLocation();
+            cleanUpTasksForAbort.add(new DirectoryCleanUpTask(hdfsContext, hadoopPath(targetPath), false));
 
             if (!targetPath.equals(currentPath)) {
                 // if staging directory is used we cherry-pick files to be moved
@@ -2499,21 +2500,21 @@ public class SemiTransactionalHiveMetastore
             AtomicBoolean cancelled,
             List<CompletableFuture<?>> fileRenameFutures,
             HdfsContext context,
-            Path currentPath,
-            Path targetPath,
+            Location currentPath,
+            Location targetPath,
             List<String> fileNames)
     {
         FileSystem fileSystem;
         try {
-            fileSystem = hdfsEnvironment.getFileSystem(context, currentPath);
+            fileSystem = hdfsEnvironment.getFileSystem(context, hadoopPath(currentPath));
         }
         catch (IOException e) {
             throw new TrinoException(HIVE_FILESYSTEM_ERROR, format(""Error moving data files to final location. Error listing directory %s"", currentPath), e);
         }
 
         for (String fileName : fileNames) {
-            Path source = new Path(currentPath, fileName);
-            Path target = new Path(targetPath, fileName);
+            Path source = hadoopPath(currentPath.appendPath(fileName));
+            Path target = hadoopPath(targetPath.appendPath(fileName));
             fileRenameFutures.add(CompletableFuture.runAsync(() -> {
                 if (cancelled.get()) {
                     return;
@@ -2830,7 +2831,7 @@ public class SemiTransactionalHiveMetastore
     {
         private final Table table;
         private final Optional<PrincipalPrivileges> principalPrivileges;
-        private final Optional<Path> currentLocation; // unpartitioned table only
+        private final Optional<Location> currentLocation; // unpartitioned table only
         private final Optional<List<String>> fileNames;
         private final boolean ignoreExisting;
         private final PartitionStatistics statistics;
@@ -2840,7 +2841,7 @@ public class SemiTransactionalHiveMetastore
         public TableAndMore(
                 Table table,
                 Optional<PrincipalPrivileges> principalPrivileges,
-                Optional<Path> currentLocation,
+                Optional<Location> currentLocation,
                 Optional<List<String>> fileNames,
                 boolean ignoreExisting,
                 PartitionStatistics statistics,
@@ -2876,7 +2877,7 @@ public class SemiTransactionalHiveMetastore
             return principalPrivileges.get();
         }
 
-        public Optional<Path> getCurrentLocation()
+        public Optional<Location> getCurrentLocation()
         {
             return currentLocation;
         }
@@ -2923,7 +2924,7 @@ public class SemiTransactionalHiveMetastore
         private final List<PartitionUpdateAndMergeResults> partitionMergeResults;
         private final List<Partition> partitions;
 
-        public TableAndMergeResults(Table table, Optional<PrincipalPrivileges> principalPrivileges, Optional<Path> currentLocation, List<PartitionUpdateAndMergeResults> partitionMergeResults, List<Partition> partitions)
+        public TableAndMergeResults(Table table, Optional<PrincipalPrivileges> principalPrivileges, Optional<Location> currentLocation, List<PartitionUpdateAndMergeResults> partitionMergeResults, List<Partition> partitions)
         {
             super(table, principalPrivileges, currentLocation, Optional.empty(), false, PartitionStatistics.empty(), PartitionStatistics.empty(), false); // retries are not supported for transactional tables
             this.partitionMergeResults = requireNonNull(partitionMergeResults, ""partitionMergeResults is null"");
@@ -2951,13 +2952,13 @@ public class SemiTransactionalHiveMetastore
     private static class PartitionAndMore
     {
         private final Partition partition;
-        private final Path currentLocation;
+        private final Location currentLocation;
         private final Optional<List<String>> fileNames;
         private final PartitionStatistics statistics;
         private final PartitionStatistics statisticsUpdate;
         private final boolean cleanExtraOutputFilesOnCommit;
 
-        public PartitionAndMore(Partition partition, Path currentLocation, Optional<List<String>> fileNames, PartitionStatistics statistics, PartitionStatistics statisticsUpdate, boolean cleanExtraOutputFilesOnCommit)
+        public PartitionAndMore(Partition partition, Location currentLocation, Optional<List<String>> fileNames, PartitionStatistics statistics, PartitionStatistics statisticsUpdate, boolean cleanExtraOutputFilesOnCommit)
         {
             this.partition = requireNonNull(partition, ""partition is null"");
             this.currentLocation = requireNonNull(currentLocation, ""currentLocation is null"");
@@ -2972,7 +2973,7 @@ public class SemiTransactionalHiveMetastore
             return partition;
         }
 
-        public Path getCurrentLocation()
+        public Location getCurrentLocation()
         {
             return currentLocation;
         }
@@ -3704,9 +3705,9 @@ public class SemiTransactionalHiveMetastore
         }
     }
 
-    public record PartitionUpdateInfo(List<String> partitionValues, Path currentLocation, List<String> fileNames, PartitionStatistics statisticsUpdate)
+    public record PartitionUpdateInfo(List<String> partitionValues, Location currentLocation, List<String> fileNames, PartitionStatistics statisticsUpdate)
     {
-        public PartitionUpdateInfo(List<String> partitionValues, Path currentLocation, List<String> fileNames, PartitionStatistics statisticsUpdate)
+        public PartitionUpdateInfo(List<String> partitionValues, Location currentLocation, List<String> fileNames, PartitionStatistics statisticsUpdate)
         {
             this.partitionValues = requireNonNull(partitionValues, ""partitionValues is null"");
             this.currentLocation = requireNonNull(currentLocation, ""currentLocation is null"");
diff --git a/plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/GlueHiveMetastore.java b/plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/GlueHiveMetastore.java
index 41b8cec11b..c6c06608cb 100644
--- a/plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/GlueHiveMetastore.java
+++ b/plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/GlueHiveMetastore.java
@@ -69,12 +69,16 @@ import dev.failsafe.Failsafe;
 import dev.failsafe.RetryPolicy;
 import io.airlift.concurrent.MoreFutures;
 import io.airlift.log.Logger;
+import io.trino.filesystem.Location;
+import io.trino.filesystem.TrinoFileSystemFactory;
+import io.trino.filesystem.hdfs.HdfsFileSystemFactory;
 import io.trino.hdfs.DynamicHdfsConfiguration;
 import io.trino.hdfs.HdfsConfig;
 import io.trino.hdfs.HdfsConfiguration;
 import io.trino.hdfs.HdfsConfigurationInitializer;
 import io.trino.hdfs.HdfsContext;
 import io.trino.hdfs.HdfsEnvironment;
+import io.trino.hdfs.TrinoHdfsFileSystemStats;
 import io.trino.hdfs.authentication.NoHdfsAuthentication;
 import io.trino.plugin.hive.HiveColumnStatisticType;
 import io.trino.plugin.hive.HiveType;
@@ -185,6 +189,7 @@ public class GlueHiveMetastore
             .withMaxRetries(3)
             .build();
 
+    private final TrinoFileSystemFactory fileSystemFactory;
     private final HdfsEnvironment hdfsEnvironment;
     private final HdfsContext hdfsContext;
     private final AWSGlueAsync glueClient;
@@ -198,6 +203,7 @@ public class GlueHiveMetastore
 
     @Inject
     public GlueHiveMetastore(
+            TrinoFileSystemFactory fileSystemFactory,
             HdfsEnvironment hdfsEnvironment,
             GlueHiveMetastoreConfig glueConfig,
             @ForGlueHiveMetastore Executor partitionsReadExecutor,
@@ -206,6 +212,7 @@ public class GlueHiveMetastore
             @ForGlueHiveMetastore GlueMetastoreStats stats,
             @ForGlueHiveMetastore Predicate<com.amazonaws.services.glue.model.Table> tableFilter)
     {
+        this.fileSystemFactory = requireNonNull(fileSystemFactory, ""fileSystemFactory is null"");
         this.hdfsEnvironment = requireNonNull(hdfsEnvironment, ""hdfsEnvironment is null"");
         this.hdfsContext = new HdfsContext(ConnectorIdentity.ofUser(DEFAULT_METASTORE_USER));
         this.glueClient = requireNonNull(glueClient, ""glueClient is null"");
@@ -227,7 +234,9 @@ public class GlueHiveMetastore
         GlueMetastoreStats stats = new GlueMetastoreStats();
         GlueHiveMetastoreConfig glueConfig = new GlueHiveMetastoreConfig()
                 .setDefaultWarehouseDir(defaultWarehouseDir.toUri().toString());
+        TrinoFileSystemFactory fileSystemFactory = new HdfsFileSystemFactory(hdfsEnvironment, new TrinoHdfsFileSystemStats());
         return new GlueHiveMetastore(
+                fileSystemFactory,
                 hdfsEnvironment,
                 glueConfig,
                 directExecutor(),
@@ -555,7 +564,7 @@ public class GlueHiveMetastore
         }
 
         if (deleteData) {
-            location.ifPresent(path -> deleteDir(hdfsContext, hdfsEnvironment, new Path(path), true));
+            location.ifPresent(path -> deleteDir(hdfsContext, path));
         }
     }
 
@@ -621,7 +630,7 @@ public class GlueHiveMetastore
         Optional<String> location = table.getStorage().getOptionalLocation()
                 .filter(not(String::isEmpty));
         if (deleteData && isManagedTable(table) && location.isPresent()) {
-            deleteDir(hdfsContext, hdfsEnvironment, new Path(location.get()), true);
+            deleteDir(hdfsContext, location.get());
         }
     }
 
@@ -630,10 +639,10 @@ public class GlueHiveMetastore
         return table.getTableType().equals(MANAGED_TABLE.name());
     }
 
-    private static void deleteDir(HdfsContext context, HdfsEnvironment hdfsEnvironment, Path path, boolean recursive)
+    private void deleteDir(HdfsContext context, String path)
     {
         try {
-            hdfsEnvironment.getFileSystem(context, path).delete(path, recursive);
+            fileSystemFactory.create(context.getIdentity()).deleteDirectory(Location.of(path));
         }
         catch (Exception e) {
             // don't fail if unable to delete path
@@ -1082,7 +1091,7 @@ public class GlueHiveMetastore
 
         String partLocation = partition.getStorage().getLocation();
         if (deleteData && isManagedTable(table) && !isNullOrEmpty(partLocation)) {
-            deleteDir(hdfsContext, hdfsEnvironment, new Path(partLocation), true);
+            deleteDir(hdfsContext, partLocation);
         }
     }
 
diff --git a/plugin/trino-hive/src/main/java/io/trino/plugin/hive/procedure/RegisterPartitionProcedure.java b/plugin/trino-hive/src/main/java/io/trino/plugin/hive/procedure/RegisterPartitionProcedure.java
index 7f7a737610..4a696a24e9 100644
--- a/plugin/trino-hive/src/main/java/io/trino/plugin/hive/procedure/RegisterPartitionProcedure.java
+++ b/plugin/trino-hive/src/main/java/io/trino/plugin/hive/procedure/RegisterPartitionProcedure.java
@@ -17,6 +17,7 @@ import com.google.common.collect.ImmutableList;
 import com.google.common.collect.ImmutableMap;
 import com.google.inject.Inject;
 import com.google.inject.Provider;
+import io.trino.filesystem.Location;
 import io.trino.hdfs.HdfsContext;
 import io.trino.hdfs.HdfsEnvironment;
 import io.trino.plugin.hive.HiveConfig;
@@ -34,12 +35,12 @@ import io.trino.spi.connector.SchemaTableName;
 import io.trino.spi.connector.TableNotFoundException;
 import io.trino.spi.procedure.Procedure;
 import io.trino.spi.type.ArrayType;
-import org.apache.hadoop.fs.Path;
 
 import java.lang.invoke.MethodHandle;
 import java.util.List;
 import java.util.Optional;
 
+import static io.trino.filesystem.hdfs.HadoopPaths.hadoopPath;
 import static io.trino.plugin.base.util.Procedures.checkProcedureArgument;
 import static io.trino.plugin.hive.HiveMetadata.PRESTO_QUERY_ID_NAME;
 import static io.trino.plugin.hive.procedure.Procedures.checkIsPartitionedTable;
@@ -131,16 +132,16 @@ public class RegisterPartitionProcedure
             throw new TrinoException(ALREADY_EXISTS, format(""Partition [%s] is already registered with location %s"", partitionName, partition.get().getStorage().getLocation()));
         }
 
-        Path partitionLocation;
+        Location partitionLocation;
 
         if (location == null) {
-            partitionLocation = new Path(table.getStorage().getLocation(), makePartName(partitionColumns, partitionValues));
+            partitionLocation = Location.of(table.getStorage().getLocation()).appendPath(makePartName(partitionColumns, partitionValues));
         }
         else {
-            partitionLocation = new Path(location);
+            partitionLocation = Location.of(location);
         }
 
-        if (!HiveWriteUtils.pathExists(hdfsContext, hdfsEnvironment, partitionLocation)) {
+        if (!HiveWriteUtils.pathExists(hdfsContext, hdfsEnvironment, hadoopPath(partitionLocation))) {
             throw new TrinoException(INVALID_PROCEDURE_ARGUMENT, ""Partition location does not exist: "" + partitionLocation);
         }
 
@@ -157,7 +158,7 @@ public class RegisterPartitionProcedure
         metastore.commit();
     }
 
-    private static Partition buildPartitionObject(ConnectorSession session, Table table, List<String> partitionValues, Path location)
+    private static Partition buildPartitionObject(ConnectorSession session, Table table, List<String> partitionValues, Location location)
     {
         return Partition.builder()
                 .setDatabaseName(table.getDatabaseName())
diff --git a/plugin/trino-hive/src/main/java/io/trino/plugin/hive/procedure/SyncPartitionMetadataProcedure.java b/plugin/trino-hive/src/main/java/io/trino/plugin/hive/procedure/SyncPartitionMetadataProcedure.java
index dd0e0983b1..f25b56bd99 100644
--- a/plugin/trino-hive/src/main/java/io/trino/plugin/hive/procedure/SyncPartitionMetadataProcedure.java
+++ b/plugin/trino-hive/src/main/java/io/trino/plugin/hive/procedure/SyncPartitionMetadataProcedure.java
@@ -19,6 +19,7 @@ import com.google.common.collect.Lists;
 import com.google.common.collect.Sets;
 import com.google.inject.Inject;
 import com.google.inject.Provider;
+import io.trino.filesystem.Location;
 import io.trino.hdfs.HdfsContext;
 import io.trino.hdfs.HdfsEnvironment;
 import io.trino.plugin.hive.PartitionStatistics;
@@ -240,7 +241,7 @@ public class SyncPartitionMetadataProcedure
                     table.getDatabaseName(),
                     table.getTableName(),
                     buildPartitionObject(session, table, name),
-                    new Path(table.getStorage().getLocation(), name),
+                    Location.of(table.getStorage().getLocation()).appendPath(name),
                     Optional.empty(), // no need for failed attempts cleanup
                     PartitionStatistics.empty(),
                     false);
diff --git a/plugin/trino-hive/src/test/java/io/trino/plugin/hive/AbstractTestHive.java b/plugin/trino-hive/src/test/java/io/trino/plugin/hive/AbstractTestHive.java
index 06cb66a91c..78bd3c4dd9 100644
--- a/plugin/trino-hive/src/test/java/io/trino/plugin/hive/AbstractTestHive.java
+++ b/plugin/trino-hive/src/test/java/io/trino/plugin/hive/AbstractTestHive.java
@@ -203,6 +203,7 @@ import static io.airlift.testing.Assertions.assertGreaterThanOrEqual;
 import static io.airlift.testing.Assertions.assertInstanceOf;
 import static io.airlift.testing.Assertions.assertLessThanOrEqual;
 import static io.airlift.units.DataSize.Unit.KILOBYTE;
+import static io.trino.filesystem.hdfs.HadoopPaths.hadoopPath;
 import static io.trino.parquet.reader.ParquetReader.PARQUET_CODEC_METRIC_PREFIX;
 import static io.trino.plugin.hive.AbstractTestHive.TransactionDeleteInsertTestTag.COMMIT;
 import static io.trino.plugin.hive.AbstractTestHive.TransactionDeleteInsertTestTag.ROLLBACK_AFTER_APPEND_PAGE;
@@ -6304,8 +6305,8 @@ public abstract class AbstractTestHive
                 throws IOException
         {
             for (PartitionUpdate partitionUpdate : partitionUpdates) {
-                if (""pk2=insert2"".equals(partitionUpdate.getTargetPath().getName())) {
-                    path = new Path(partitionUpdate.getTargetPath(), partitionUpdate.getFileNames().get(0));
+                if (""pk2=insert2"".equals(partitionUpdate.getTargetPath().fileName())) {
+                    path = new Path(hadoopPath(partitionUpdate.getTargetPath()), partitionUpdate.getFileNames().get(0));
                     break;
                 }
             }
diff --git a/plugin/trino-hive/src/test/java/io/trino/plugin/hive/AbstractTestHiveLocal.java b/plugin/trino-hive/src/test/java/io/trino/plugin/hive/AbstractTestHiveLocal.java
index f97a28461b..a3288f846e 100644
--- a/plugin/trino-hive/src/test/java/io/trino/plugin/hive/AbstractTestHiveLocal.java
+++ b/plugin/trino-hive/src/test/java/io/trino/plugin/hive/AbstractTestHiveLocal.java
@@ -18,6 +18,7 @@ import com.google.common.collect.ImmutableMap;
 import com.google.common.io.RecursiveDeleteOption;
 import com.google.common.reflect.ClassPath;
 import io.airlift.log.Logger;
+import io.trino.filesystem.Location;
 import io.trino.plugin.hive.metastore.Column;
 import io.trino.plugin.hive.metastore.Database;
 import io.trino.plugin.hive.metastore.HiveMetastore;
@@ -33,7 +34,6 @@ import io.trino.spi.connector.SchemaTableName;
 import io.trino.spi.predicate.TupleDomain;
 import io.trino.spi.security.PrincipalType;
 import io.trino.testing.MaterializedResult;
-import org.apache.hadoop.fs.Path;
 import org.apache.hadoop.hive.metastore.TableType;
 import org.testng.SkipException;
 import org.testng.annotations.AfterClass;
@@ -44,7 +44,6 @@ import java.io.File;
 import java.io.IOException;
 import java.io.InputStream;
 import java.io.UncheckedIOException;
-import java.net.URI;
 import java.nio.file.Files;
 import java.util.List;
 import java.util.Optional;
@@ -190,7 +189,7 @@ public abstract class AbstractTestHiveLocal
                             BUCKETING_V1,
                             3,
                             ImmutableList.of(new SortingColumn(""name"", SortingColumn.Order.ASCENDING)))),
-                    new Path(URI.create(""file://"" + externalLocation.toString())));
+                    Location.of(""file://"" + externalLocation.toString()));
 
             assertReadFailsWithMessageMatching(ORC, tableName, ""Hive table is corrupt\\\\. File '.*/.*' is for bucket [0-2], but contains a row for bucket [0-2]."");
             markTableAsCreatedBySpark(tableName, ""orc"");
@@ -227,7 +226,7 @@ public abstract class AbstractTestHiveLocal
         }
     }
 
-    private void createExternalTable(SchemaTableName schemaTableName, HiveStorageFormat hiveStorageFormat, List<Column> columns, List<Column> partitionColumns, Optional<HiveBucketProperty> bucketProperty, Path externalLocation)
+    private void createExternalTable(SchemaTableName schemaTableName, HiveStorageFormat hiveStorageFormat, List<Column> columns, List<Column> partitionColumns, Optional<HiveBucketProperty> bucketProperty, Location externalLocation)
     {
         try (Transaction transaction = newTransaction()) {
             ConnectorSession session = newSession();
diff --git a/plugin/trino-hive/src/test/java/io/trino/plugin/hive/TestHiveCreateExternalTable.java b/plugin/trino-hive/src/test/java/io/trino/plugin/hive/TestHiveCreateExternalTable.java
index 6ca1d28257..e897747666 100644
--- a/plugin/trino-hive/src/test/java/io/trino/plugin/hive/TestHiveCreateExternalTable.java
+++ b/plugin/trino-hive/src/test/java/io/trino/plugin/hive/TestHiveCreateExternalTable.java
@@ -51,13 +51,13 @@ public class TestHiveCreateExternalTable
             throws IOException
     {
         Path tempDir = createTempDirectory(null);
-        Path tableLocation = tempDir.resolve(""data"");
+        String tableLocation = tempDir.resolve(""data"").toUri().toASCIIString();
 
         @Language(""SQL"") String createTableSql = format("""" +
                         ""CREATE TABLE test_create_external "" +
                         ""WITH (external_location = '%s') AS "" +
                         ""SELECT * FROM tpch.tiny.nation"",
-                tableLocation.toUri().toASCIIString());
+                tableLocation);
 
         assertUpdate(createTableSql, 25);
 
@@ -67,7 +67,7 @@ public class TestHiveCreateExternalTable
 
         MaterializedResult result = computeActual(""SELECT DISTINCT regexp_replace(\\""$path\\"", '/[^/]*$', '/') FROM test_create_external"");
         String tablePath = (String) result.getOnlyValue();
-        assertThat(tablePath).startsWith(tableLocation.toFile().toURI().toString());
+        assertThat(tablePath).startsWith(tableLocation);
 
         assertUpdate(""DROP TABLE test_create_external"");
         deleteRecursively(tempDir, ALLOW_INSECURE);
diff --git a/plugin/trino-hive/src/test/java/io/trino/plugin/hive/TestHiveS3AndGlueMetastoreTest.java b/plugin/trino-hive/src/test/java/io/trino/plugin/hive/TestHiveS3AndGlueMetastoreTest.java
index e0f2b5d797..78600d318c 100644
--- a/plugin/trino-hive/src/test/java/io/trino/plugin/hive/TestHiveS3AndGlueMetastoreTest.java
+++ b/plugin/trino-hive/src/test/java/io/trino/plugin/hive/TestHiveS3AndGlueMetastoreTest.java
@@ -24,11 +24,9 @@ import org.testng.annotations.Test;
 
 import java.nio.file.Path;
 import java.util.HashSet;
-import java.util.List;
 import java.util.Optional;
 import java.util.Set;
 
-import static com.google.common.collect.ImmutableList.toImmutableList;
 import static io.trino.plugin.hive.metastore.glue.GlueHiveMetastore.createTestingGlueHiveMetastore;
 import static io.trino.spi.security.SelectedRole.Type.ROLE;
 import static io.trino.testing.TestingNames.randomNameSuffix;
@@ -37,6 +35,7 @@ import static java.util.Objects.requireNonNull;
 import static org.assertj.core.api.Assertions.assertThat;
 import static org.assertj.core.api.Assertions.assertThatThrownBy;
 
+// TODO Run this test also with Hive thrift metastore
 public class TestHiveS3AndGlueMetastoreTest
         extends BaseS3AndGlueMetastoreTest
 {
@@ -254,14 +253,55 @@ public class TestHiveS3AndGlueMetastoreTest
                 .hasStackTraceContaining(""Fragment is not allowed in a file system location"");
     }
 
+    @Test
+    public void testCreateTableWithDoubleSlash()
+    {
+        String schemaName = ""test_create_table_with_double_slash_"" + randomNameSuffix();
+        String schemaLocation = ""s3://%s/%s/double_slash//test_schema"".formatted(bucketName, schemaName);
+        String tableName = ""test_create_table_with_double_slash_"" + randomNameSuffix();
+        String schemaTableName = schemaName + ""."" + tableName;
+
+        // Previously, HiveLocationService replaced double slash with single slash
+        assertUpdate(""CREATE SCHEMA "" + schemaName + "" WITH (location = '"" + schemaLocation + ""')"");
+        String existingKey = ""%s/double_slash/test_schema/%s"".formatted(schemaName, tableName);
+        s3.putObject(bucketName, existingKey, ""test content"");
+
+        assertUpdate(""CREATE TABLE "" + schemaTableName + ""(col_int int)"");
+        assertUpdate(""INSERT INTO "" + schemaTableName + "" VALUES 1"", 1);
+        assertQuery(""SELECT * FROM "" + schemaTableName, ""VALUES 1"");
+        assertUpdate(""DROP TABLE "" + schemaTableName);
+        s3.deleteObject(bucketName, existingKey);
+    }
+
+    @Test
+    public void testCtasWithDoubleSlash()
+    {
+        String schemaName = ""test_ctas_with_double_slash_"" + randomNameSuffix();
+        String schemaLocation = ""s3://%s/%s/double_slash//test_schema"".formatted(bucketName, schemaName);
+        String tableName = ""test_create_table_with_double_slash_"" + randomNameSuffix();
+        String schemaTableName = schemaName + ""."" + tableName;
+
+        // Previously, HiveLocationService replaced double slash with single slash
+        assertUpdate(""CREATE SCHEMA "" + schemaName + "" WITH (location = '"" + schemaLocation + ""')"");
+        String existingKey = ""%s/double_slash/test_schema/%s"".formatted(schemaName, tableName);
+        s3.putObject(bucketName, existingKey, ""test content"");
+
+        assertUpdate(""CREATE TABLE "" + schemaTableName + "" AS SELECT 1 AS col_int"", 1);
+        assertQuery(""SELECT * FROM "" + schemaTableName, ""VALUES 1"");
+        assertUpdate(""DROP TABLE "" + schemaTableName);
+        s3.deleteObject(bucketName, existingKey);
+    }
+
     @Test
     public void testCreateSchemaWithIncorrectLocation()
     {
         String schemaName = ""test_create_schema_with_incorrect_location_"" + randomNameSuffix();
-        String schemaLocation = ""s3://%s/%2$s/a#hash/%2$s"".formatted(bucketName, schemaName);
+        String key = ""%1$s/a#hash/%1$s"";
+        String schemaLocation = ""s3://%s/%s"".formatted(bucketName, key);
         String tableName = ""test_basic_operations_table_"" + randomNameSuffix();
         String qualifiedTableName = schemaName + ""."" + tableName;
 
+        // TODO Disallow creating a schema with incorrect location
         assertUpdate(""CREATE SCHEMA "" + schemaName + "" WITH (location = '"" + schemaLocation + ""')"");
         assertThat(getSchemaLocation(schemaName)).isEqualTo(schemaLocation);
 
@@ -272,6 +312,8 @@ public class TestHiveS3AndGlueMetastoreTest
                 .hasMessageContaining(""Fragment is not allowed in a file system location"");
 
         assertUpdate(""DROP SCHEMA "" + schemaName);
+        // Delete S3 directory explicitly because the above DROP SCHEMA failed to delete it due to fragment in the location
+        s3.deleteObject(bucketName, key);
     }
 
     @Test
@@ -286,13 +328,4 @@ public class TestHiveS3AndGlueMetastoreTest
 
         assertUpdate(""DROP SCHEMA \\"""" + schemaName + ""\\"""");
     }
-
-    @Override
-    protected List<String> locationPatterns()
-    {
-        // TODO https://github.com/trinodb/trino/issues/17803 Fix correctness issue with double slash
-        return super.locationPatterns().stream()
-                .filter(location -> !location.contains(""double_slash""))
-                .collect(toImmutableList());
-    }
 }
diff --git a/plugin/trino-hive/src/test/java/io/trino/plugin/hive/TestPartitionUpdate.java b/plugin/trino-hive/src/test/java/io/trino/plugin/hive/TestPartitionUpdate.java
index 69031a976a..52cb3aa1ea 100644
--- a/plugin/trino-hive/src/test/java/io/trino/plugin/hive/TestPartitionUpdate.java
+++ b/plugin/trino-hive/src/test/java/io/trino/plugin/hive/TestPartitionUpdate.java
@@ -15,8 +15,8 @@ package io.trino.plugin.hive;
 
 import com.google.common.collect.ImmutableList;
 import io.airlift.json.JsonCodec;
+import io.trino.filesystem.Location;
 import io.trino.plugin.hive.PartitionUpdate.UpdateMode;
-import org.apache.hadoop.fs.Path;
 import org.testng.annotations.Test;
 
 import static io.airlift.json.JsonCodec.jsonCodec;
@@ -43,8 +43,8 @@ public class TestPartitionUpdate
 
         assertEquals(actual.getName(), ""test"");
         assertEquals(actual.getUpdateMode(), UpdateMode.APPEND);
-        assertEquals(actual.getWritePath(), new Path(""/writePath""));
-        assertEquals(actual.getTargetPath(), new Path(""/targetPath""));
+        assertEquals(actual.getWritePath(), Location.of(""/writePath""));
+        assertEquals(actual.getTargetPath(), Location.of(""/targetPath""));
         assertEquals(actual.getFileNames(), ImmutableList.of(""file1"", ""file3""));
         assertEquals(actual.getRowCount(), 123);
         assertEquals(actual.getInMemoryDataSizeInBytes(), 456);
diff --git a/plugin/trino-hive/src/test/java/io/trino/plugin/hive/metastore/TestSemiTransactionalHiveMetastore.java b/plugin/trino-hive/src/test/java/io/trino/plugin/hive/metastore/TestSemiTransactionalHiveMetastore.java
index df0a3f1b1a..836b011568 100644
--- a/plugin/trino-hive/src/test/java/io/trino/plugin/hive/metastore/TestSemiTransactionalHiveMetastore.java
+++ b/plugin/trino-hive/src/test/java/io/trino/plugin/hive/metastore/TestSemiTransactionalHiveMetastore.java
@@ -15,13 +15,13 @@ package io.trino.plugin.hive.metastore;
 
 import com.google.common.collect.ImmutableList;
 import com.google.common.collect.ImmutableMap;
+import io.trino.filesystem.Location;
 import io.trino.plugin.hive.HiveBucketProperty;
 import io.trino.plugin.hive.HiveMetastoreClosure;
 import io.trino.plugin.hive.HiveType;
 import io.trino.plugin.hive.PartitionStatistics;
 import io.trino.plugin.hive.acid.AcidTransaction;
 import io.trino.plugin.hive.fs.FileSystemDirectoryLister;
-import org.apache.hadoop.fs.Path;
 import org.testng.annotations.Test;
 
 import java.util.List;
@@ -53,7 +53,7 @@ public class TestSemiTransactionalHiveMetastore
             Optional.of(""comment""));
     private static final Storage TABLE_STORAGE = new Storage(
             StorageFormat.create(""serde"", ""input"", ""output""),
-            Optional.of(""location""),
+            Optional.of(""file://location/""),
             Optional.of(new HiveBucketProperty(ImmutableList.of(""column""), BUCKETING_V1, 10, ImmutableList.of(new SortingColumn(""column"", SortingColumn.Order.ASCENDING)))),
             true,
             ImmutableMap.of(""param"", ""value2""));
@@ -109,7 +109,7 @@ public class TestSemiTransactionalHiveMetastore
             IntStream.range(0, tablesToUpdate).forEach(i -> semiTransactionalHiveMetastore.finishChangingExistingTable(INSERT, SESSION,
                     ""database"",
                     ""table_"" + i,
-                    new Path(""location""),
+                    Location.of(""file://location/""),
                     ImmutableList.of(),
                     PartitionStatistics.empty(),
                     false));
diff --git a/plugin/trino-hive/src/test/java/io/trino/plugin/hive/metastore/glue/TestHiveGlueMetastore.java b/plugin/trino-hive/src/test/java/io/trino/plugin/hive/metastore/glue/TestHiveGlueMetastore.java
index 89da152872..c8e2264d22 100644
--- a/plugin/trino-hive/src/test/java/io/trino/plugin/hive/metastore/glue/TestHiveGlueMetastore.java
+++ b/plugin/trino-hive/src/test/java/io/trino/plugin/hive/metastore/glue/TestHiveGlueMetastore.java
@@ -30,6 +30,8 @@ import com.google.common.collect.ImmutableMap;
 import io.airlift.concurrent.BoundedExecutor;
 import io.airlift.log.Logger;
 import io.airlift.slice.Slice;
+import io.trino.filesystem.hdfs.HdfsFileSystemFactory;
+import io.trino.hdfs.TrinoHdfsFileSystemStats;
 import io.trino.plugin.hive.AbstractTestHiveLocal;
 import io.trino.plugin.hive.HiveBasicStatistics;
 import io.trino.plugin.hive.HiveMetastoreClosure;
@@ -232,6 +234,7 @@ public class TestHiveGlueMetastore
         Executor executor = new BoundedExecutor(this.executor, 10);
         GlueMetastoreStats stats = new GlueMetastoreStats();
         return new GlueHiveMetastore(
+                new HdfsFileSystemFactory(HDFS_ENVIRONMENT, new TrinoHdfsFileSystemStats()),
                 HDFS_ENVIRONMENT,
                 glueConfig,
                 executor,","['plugin/trino-hive/src/test/java/io/trino/plugin/hive/metastore/TestSemiTransactionalHiveMetastore.java', 'plugin/trino-hive/src/main/java/io/trino/plugin/hive/HiveMetadata.java', 'plugin/trino-hive/src/test/java/io/trino/plugin/hive/AbstractTestHiveLocal.java', 'plugin/trino-delta-lake/src/test/java/io/trino/plugin/deltalake/metastore/glue/TestDeltaLakeConcurrentModificationGlueMetastore.java', 'plugin/trino-hive/src/main/java/io/trino/plugin/hive/PartitionUpdate.java', 'plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/GlueHiveMetastore.java', 'plugin/trino-hive/src/main/java/io/trino/plugin/hive/procedure/SyncPartitionMetadataProcedure.java', 'plugin/trino-hive/src/main/java/io/trino/plugin/hive/BackgroundHiveSplitLoader.java', 'plugin/trino-hive/src/test/java/io/trino/plugin/hive/TestHiveCreateExternalTable.java', 'plugin/trino-hive/src/test/java/io/trino/plugin/hive/metastore/glue/TestHiveGlueMetastore.java', 'plugin/trino-hive/src/test/java/io/trino/plugin/hive/AbstractTestHive.java', 'plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/SemiTransactionalHiveMetastore.java', 'plugin/trino-hive/src/test/java/io/trino/plugin/hive/TestPartitionUpdate.java', 'plugin/trino-hive/src/main/java/io/trino/plugin/hive/HiveWriter.java', 'plugin/trino-hive/src/main/java/io/trino/plugin/hive/procedure/RegisterPartitionProcedure.java', 'plugin/trino-hive/src/test/java/io/trino/plugin/hive/TestHiveS3AndGlueMetastoreTest.java', 'plugin/trino-hive/src/main/java/io/trino/plugin/hive/HiveLocationService.java']",{'.java': 17},17,17,0,0,17,38138403,7631131,995195,6473,17841,3222,218,9,325,48,82,9,0,1,2023-06-08 09:08:52,8254,Java,"{'Java': 71658946, 'JavaScript': 233768, 'ANTLR': 56491, 'Shell': 49457, 'HTML': 30842, 'CSS': 13515, 'Scala': 10145, 'Python': 7379, 'Smarty': 1938, 'Dockerfile': 1723, 'Groovy': 1702, 'PLSQL': 85}",Apache License 2.0,"['core/trino-main/src/main/java/io/trino/metadata/CatalogProcedures.java', 'plugin/trino-hive/src/main/java/io/trino/plugin/hive/HiveTransactionManager.java', 'plugin/trino-hive/src/main/java/io/trino/plugin/hive/SystemTableHandler.java', 'core/trino-spi/src/main/java/io/trino/spi/function/table/Primitives.java', 'core/trino-spi/src/main/java/io/trino/spi/connector/ColumnHandle.java', 'plugin/trino-hive/src/main/java/io/trino/plugin/hive/util/TempFileReader.java', 'plugin/trino-hive/src/main/java/io/trino/plugin/hive/HiveToTrinoTranslator.java', 'core/trino-main/src/main/java/io/trino/connector/system/jdbc/FilterUtil.java', 'lib/trino-hive-formats/src/main/java/io/trino/hive/formats/line/csv/CsvSerializerFactory.java', 'plugin/trino-delta-lake/src/main/java/io/trino/plugin/deltalake/expression/SparkExpressionTreeVisitor.java', 'plugin/trino-hive/src/main/java/io/trino/plugin/hive/util/HiveUtil.java', 'plugin/trino-hive/src/main/java/io/trino/plugin/hive/util/ValidTxnWriteIdList.java', 'core/trino-spi/src/main/java/io/trino/spi/function/table/TableFunctionDataProcessor.java', 'plugin/trino-raptor-legacy/src/main/java/io/trino/plugin/raptor/legacy/storage/organization/ShardOrganizer.java', 'core/trino-spi/src/main/java/io/trino/spi/function/table/TableFunctionProcessorProvider.java', 'core/trino-main/src/main/java/io/trino/connector/hive/HiveSplitManager.java', 'core/trino/sql/planner/ConnectorExpressions.java', 'core/trino/server/ServerPluginsProvider.java', 'plugin/trino-hive/src/main/java/io/trino/plugin/hive/HiveMetadata.java', 'plugin/trino-raptor-legacy/src/main/java/io/trino/plugin/raptor/legacy/storage/organization/TableOrganizationInfo.java', 'plugin/trino-hive/src/main/java/io/trino/plugin/hive/SystemTableProvider.java', 'lib/trino-filesystem-s3/src/main/java/io/trino/filesystem/s3/S3Input.java', 'core/trino-main/src/main/java/io/trino/connector/hive/HiveSplit.java', 'lib/trino-hive-formats/src/main/java/io/trino/hive/formats/line/csv/CsvDeserializerFactory.java', 'core/trino-main/src/main/java/io/trino/metadata/CatalogInfo.java', 'core/trino-main/src/main/java/io/trino/connector/system/jdbc/TableJdbcTable.java', 'core/trino-main/src/main/java/io/trino/metadata/CatalogManager.java', 'lib/trino-filesystem-s3/src/main/java/io/trino/filesystem/s3/S3InputFile.java', 'core/trino/sql/planner/RelationPlan.java', 'lib/trino-filesystem-s3/src/main/java/io/trino/filesystem/s3/S3OutputFile.java', 'plugin/trino-delta-lake/src/main/java/io/trino/plugin/deltalake/expression/SparkExpressionConverter.java', 'core/trino-main/src/main/java/io/trino/metadata/CatalogMetadata.java', 'core/trino/server/ServerConfig.java', 'core/trino-main/src/main/java/io/trino/connector/hive/HivePageSource.java', 'core/trino-spi/src/main/java/io/trino/spi/connector/CatalogSchemaName.java', 'core/trino-spi/src/main/java/io/trino/spi/function/table/TableFunctionProcessorState.java', 'lib/trino-hive-formats/src/main/java/io/trino/hive/formats/line/json/JsonDeserializer.java', 'plugin/trino-hive/src/main/java/io/trino/plugin/hive/HiveTableProperties.java', 'core/trino/server/ServerPluginsProviderConfig.java', 'core/trino-spi/src/main/java/io/trino/spi/connector/ConnectorTableMetadata.java', 'core/trino/server/ServerMainModule.java', 'core/trino-spi/src/main/java/io/trino/spi/connector/CatalogHandle.java', 'core/trino-main/src/main/java/io/trino/connector/system/jdbc/SchemaJdbcTable.java', 'plugin/trino-delta-lake/src/main/java/io/trino/plugin/deltalake/expression/SparkExpression.java', 'plugin/trino-delta-lake/src/main/java/io/trino/plugin/deltalake/expression/SparkExpressionBuilder.java', 'core/trino-main/src/main/java/io/trino/connector/hive/HiveMetadata.java', 'plugin/trino-delta-lake/src/main/java/io/trino/plugin/deltalake/expression/SparkExpressionParser.java', 'core/trino/sql/planner/RelationPlanner.java', 'plugin/trino-hive/src/main/java/io/trino/plugin/hive/PartitionsSystemTableProvider.java', 'core/trino-main/src/main/java/io/trino/metadata/Catalog.java', 'plugin/trino-raptor-legacy/src/main/java/io/trino/plugin/raptor/legacy/storage/organization/ShardOrganizerDao.java', 'plugin/trino-hive/src/main/java/io/trino/plugin/hive/HiveTransactionHandle.java', 'core/trino-main/src/main/java/io/trino/connector/informationschema/InformationSchemaColumnHandle.java', 'core/trino/sql/planner/ConnectorExpressionTranslator.java', 'lib/trino-hive-formats/src/main/java/io/trino/hive/formats/line/csv/CsvDeserializer.java', 'core/trino-spi/src/main/java/io/trino/spi/function/table/TableFunctionAnalysis.java', 'core/trino/server/ServletSecurityUtils.java', 'plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/GlueToTrinoConverter.java', 'core/trino-main/src/main/java/io/trino/connector/hive/HivePageSink.java', 'core/trino/sql/planner/ResolvedFunctionCallRewriter.java', 'plugin/trino-hive/src/main/java/io/trino/plugin/hive/util/ValidWriteIdList.java', 'plugin/trino-raptor-legacy/src/main/java/io/trino/plugin/raptor/legacy/storage/organization/ShardOrganizerUtil.java', 'plugin/trino-hive/src/main/java/io/trino/plugin/hive/util/Statistics.java', 'plugin/trino-hive/src/main/java/io/trino/plugin/hive/PropertiesSystemTableProvider.java', 'lib/trino-filesystem-s3/src/main/java/io/trino/filesystem/s3/S3Location.java', 'plugin/trino-hive/src/main/java/io/trino/plugin/hive/TableToPartitionMapping.java', 'plugin/trino-kafka/src/main/java/io/trino/plugin/kafka/encoder/json/format/util/TimeConversions.java', 'core/trino-spi/src/main/java/io/trino/spi/connector/CatalogSchemaTableName.java', 'core/trino-spi/src/main/java/io/trino/spi/connector/CatalogSchemaRoutineName.java', 'lib/trino-hive-formats/src/main/java/io/trino/hive/formats/line/csv/CsvSerializer.java', 'plugin/trino-hive/src/main/java/io/trino/plugin/hive/HiveTableHandle.java']","['plugin/trino-hive/src/main/java/io/trino/plugin/hive/HiveTransactionHandle.java', 'plugin/trino-hive/src/main/java/io/trino/plugin/hive/HiveTableProperties.java', 'plugin/trino-hive/src/main/java/io/trino/plugin/hive/HiveTableHandle.java', 'lib/trino-hive-formats/src/main/java/io/trino/hive/formats/line/csv/CsvDeserializer.java', 'plugin/trino-hive/src/main/java/io/trino/plugin/hive/HiveUtil.java']","['```json\n{\n  ""files"": [\n    ""core/trino-main/src/main/java/io/trino/metadata/CatalogMetadata.java"",\n    ""core/trino-main/src/main/java/io/trino/metadata/CatalogManager.java"",\n    ""core/trino-main/src/main/java/io/trino/metadata/CatalogProcedures.java"",\n    ""core/trino-main/src/main/java/io/trino/metadata/CatalogInfo.java"",\n    ""core/trino-main/src/main/java/io/trino/metadata/Catalog.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""core/trino/server/ServletSecurityUtils.java"",\n    ""core/trino/server/ServerConfig.java"",\n    ""core/trino/server/ServerMainModule.java"",\n    ""core/trino/server/ServerPluginsProvider.java"",\n    ""core/trino/server/ServerPluginsProviderConfig.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""core/trino-main/src/main/java/io/trino/connector/informationschema/InformationSchemaColumnHandle.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""core/trino-main/src/main/java/io/trino/connector/hive/HiveMetadata.java"",\n    ""core/trino-main/src/main/java/io/trino/connector/hive/HivePageSink.java"",\n    ""core/trino-main/src/main/java/io/trino/connector/hive/HivePageSource.java"",\n    ""core/trino-main/src/main/java/io/trino/connector/hive/HiveSplit.java"",\n    ""core/trino-main/src/main/java/io/trino/connector/hive/HiveSplitManager.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""core/trino/sql/planner/ConnectorExpressionTranslator.java"",\n    ""core/trino/sql/planner/ConnectorExpressions.java"",\n    ""core/trino/sql/planner/RelationPlanner.java"",\n    ""core/trino/sql/planner/RelationPlan.java"",\n    ""core/trino/sql/planner/ResolvedFunctionCallRewriter.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""core/trino-spi/src/main/java/io/trino/spi/connector/CatalogSchemaTableName.java"",\n    ""core/trino-spi/src/main/java/io/trino/spi/connector/CatalogSchemaRoutineName.java"",\n    ""core/trino-spi/src/main/java/io/trino/spi/connector/CatalogSchemaName.java"",\n    ""core/trino-spi/src/main/java/io/trino/spi/connector/CatalogHandle.java"",\n    ""core/trino-spi/src/main/java/io/trino/spi/connector/ColumnHandle.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""core/trino-spi/src/main/java/io/trino/spi/connector/ConnectorTableMetadata.java"",\n    ""lib/trino-filesystem-s3/src/main/java/io/trino/filesystem/s3/S3Location.java"",\n    ""lib/trino-filesystem-s3/src/main/java/io/trino/filesystem/s3/S3Input.java"",\n    ""lib/trino-filesystem-s3/src/main/java/io/trino/filesystem/s3/S3InputFile.java"",\n    ""lib/trino-filesystem-s3/src/main/java/io/trino/filesystem/s3/S3OutputFile.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""plugin/trino-hive/src/main/java/io/trino/plugin/hive/HiveMetadata.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""plugin/trino-hive/src/main/java/io/trino/plugin/hive/HiveTableHandle.java"",\n    ""plugin/trino-hive/src/main/java/io/trino/plugin/hive/HiveTableProperties.java"",\n    ""plugin/trino-hive/src/main/java/io/trino/plugin/hive/HiveToTrinoTranslator.java"",\n    ""plugin/trino-hive/src/main/java/io/trino/plugin/hive/HiveTransactionHandle.java"",\n    ""plugin/trino-hive/src/main/java/io/trino/plugin/hive/HiveTransactionManager.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""plugin/trino-hive/src/main/java/io/trino/plugin/hive/PropertiesSystemTableProvider.java"",\n    ""plugin/trino-hive/src/main/java/io/trino/plugin/hive/PartitionsSystemTableProvider.java"",\n    ""plugin/trino-hive/src/main/java/io/trino/plugin/hive/SystemTableHandler.java"",\n    ""plugin/trino-hive/src/main/java/io/trino/plugin/hive/SystemTableProvider.java"",\n    ""plugin/trino-hive/src/main/java/io/trino/plugin/hive/TableToPartitionMapping.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""core/trino-main/src/main/java/io/trino/connector/system/jdbc/FilterUtil.java"",\n    ""core/trino-main/src/main/java/io/trino/connector/system/jdbc/TableJdbcTable.java"",\n    ""core/trino-main/src/main/java/io/trino/connector/system/jdbc/SchemaJdbcTable.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""core/trino-spi/src/main/java/io/trino/spi/function/table/TableFunctionProcessorProvider.java"",\n    ""core/trino-spi/src/main/java/io/trino/spi/function/table/TableFunctionProcessorState.java"",\n    ""core/trino-spi/src/main/java/io/trino/spi/function/table/TableFunctionDataProcessor.java"",\n    ""core/trino-spi/src/main/java/io/trino/spi/function/table/TableFunctionAnalysis.java"",\n    ""core/trino-spi/src/main/java/io/trino/spi/function/table/Primitives.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""plugin/trino-delta-lake/src/main/java/io/trino/plugin/deltalake/expression/SparkExpressionParser.java"",\n    ""plugin/trino-delta-lake/src/main/java/io/trino/plugin/deltalake/expression/SparkExpressionConverter.java"",\n    ""plugin/trino-delta-lake/src/main/java/io/trino/plugin/deltalake/expression/SparkExpressionTreeVisitor.java"",\n    ""plugin/trino-delta-lake/src/main/java/io/trino/plugin/deltalake/expression/SparkExpressionBuilder.java"",\n    ""plugin/trino-delta-lake/src/main/java/io/trino/plugin/deltalake/expression/SparkExpression.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""plugin/trino-hive/src/main/java/io/trino/plugin/hive/util/HiveUtil.java"",\n    ""plugin/trino-hive/src/main/java/io/trino/plugin/hive/util/ValidTxnWriteIdList.java"",\n    ""plugin/trino-hive/src/main/java/io/trino/plugin/hive/util/ValidWriteIdList.java"",\n    ""plugin/trino-hive/src/main/java/io/trino/plugin/hive/util/Statistics.java"",\n    ""plugin/trino-hive/src/main/java/io/trino/plugin/hive/util/TempFileReader.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""lib/trino-hive-formats/src/main/java/io/trino/hive/formats/line/csv/CsvDeserializer.java"",\n    ""lib/trino-hive-formats/src/main/java/io/trino/hive/formats/line/csv/CsvDeserializerFactory.java"",\n    ""lib/trino-hive-formats/src/main/java/io/trino/hive/formats/line/csv/CsvSerializer.java"",\n    ""lib/trino-hive-formats/src/main/java/io/trino/hive/formats/line/csv/CsvSerializerFactory.java"",\n    ""lib/trino-hive-formats/src/main/java/io/trino/hive/formats/line/json/JsonDeserializer.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""plugin/trino-hive/src/main/java/io/trino/plugin/hive/metastore/glue/GlueToTrinoConverter.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""plugin/trino-raptor-legacy/src/main/java/io/trino/plugin/raptor/legacy/storage/organization/ShardOrganizerUtil.java"",\n    ""plugin/trino-raptor-legacy/src/main/java/io/trino/plugin/raptor/legacy/storage/organization/ShardOrganizer.java"",\n    ""plugin/trino-raptor-legacy/src/main/java/io/trino/plugin/raptor/legacy/storage/organization/ShardOrganizerDao.java"",\n    ""plugin/trino-raptor-legacy/src/main/java/io/trino/plugin/raptor/legacy/storage/organization/TableOrganizationInfo.java"",\n    ""plugin/trino-kafka/src/main/java/io/trino/plugin/kafka/encoder/json/format/util/TimeConversions.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""plugin/trino-hive/src/main/java/io/trino/plugin/hive/HiveTableHandle.java"",\n    ""plugin/trino-hive/src/main/java/io/trino/plugin/hive/HiveTableProperties.java"",\n    ""plugin/trino-hive/src/main/java/io/trino/plugin/hive/HiveUtil.java"",\n    ""plugin/trino-hive/src/main/java/io/trino/plugin/hive/HiveTransactionHandle.java"",\n    ""lib/trino-hive-formats/src/main/java/io/trino/hive/formats/line/csv/CsvDeserializer.java""\n  ]\n}\n```']",17,34965.693950653076
9635,thundernest/k-9/3219/632,thundernest,k-9,https://github.com/thundernest/k-9/issues/632,https://github.com/thundernest/k-9/pull/3219,https://github.com/thundernest/k-9/pull/3219,1,fixes,Case sensitivity problem in account>folders settings,"I have an IMAP account with two directories, one named ""Spam"", and other named ""spam"".

In K9Mail I go to Account Preferences, Folders, Spam folder, and try to choose the lower case ""spam"".

After that, marking a message as spam, K9Mail will still move it to the ""Spam"" folder, instead of ""spam"".

I suppose the problem is case sensitivity?
",ddc048b56b647c35e066b4255c0982ae80e065f3,95b046bbf6057dcff124be4dfcc0b6281f8e0aa5,https://github.com/thundernest/k-9/compare/ddc048b56b647c35e066b4255c0982ae80e065f3...95b046bbf6057dcff124be4dfcc0b6281f8e0aa5,"diff --git a/k9mail-library/src/main/java/com/fsck/k9/mail/store/imap/ImapFolder.java b/k9mail-library/src/main/java/com/fsck/k9/mail/store/imap/ImapFolder.java
index 14cec2a31..f80e58c05 100644
--- a/k9mail-library/src/main/java/com/fsck/k9/mail/store/imap/ImapFolder.java
+++ b/k9mail-library/src/main/java/com/fsck/k9/mail/store/imap/ImapFolder.java
@@ -41,6 +41,7 @@ import static com.fsck.k9.mail.store.imap.ImapUtility.getLastResponse;
 
 
 class ImapFolder extends Folder<ImapMessage> {
+    static final String INBOX = ""INBOX"";
     private static final ThreadLocal<SimpleDateFormat> RFC3501_DATE = new ThreadLocal<SimpleDateFormat>() {
         @Override
         protected SimpleDateFormat initialValue() {
@@ -78,7 +79,7 @@ class ImapFolder extends Folder<ImapMessage> {
     private String getPrefixedName() throws MessagingException {
         String prefixedName = """";
 
-        if (!store.getStoreConfig().getInboxFolderName().equalsIgnoreCase(name)) {
+        if (!INBOX.equalsIgnoreCase(name)) {
             ImapConnection connection;
             synchronized (this) {
                 if (this.connection == null) {
@@ -391,7 +392,7 @@ class ImapFolder extends Folder<ImapMessage> {
             return;
         }
 
-        if (trashFolderName == null || getName().equalsIgnoreCase(trashFolderName)) {
+        if (trashFolderName == null || getName().equals(trashFolderName)) {
             setFlags(messages, Collections.singleton(Flag.DELETED), true);
         } else {
             ImapFolder remoteTrashFolder = getStore().getFolder(trashFolderName);
@@ -1369,7 +1370,7 @@ class ImapFolder extends Folder<ImapMessage> {
     public boolean equals(Object other) {
         if (other instanceof ImapFolder) {
             ImapFolder otherFolder = (ImapFolder) other;
-            return otherFolder.getName().equalsIgnoreCase(getName());
+            return otherFolder.getName().equals(getName());
         }
 
         return super.equals(other);
diff --git a/k9mail-library/src/main/java/com/fsck/k9/mail/store/imap/ImapStore.java b/k9mail-library/src/main/java/com/fsck/k9/mail/store/imap/ImapStore.java
index 9888dff00..966c8e515 100644
--- a/k9mail-library/src/main/java/com/fsck/k9/mail/store/imap/ImapStore.java
+++ b/k9mail-library/src/main/java/com/fsck/k9/mail/store/imap/ImapStore.java
@@ -197,7 +197,7 @@ public class ImapStore extends RemoteStore {
                 combinedPrefix = null;
             }
 
-            if (folder.equalsIgnoreCase(mStoreConfig.getInboxFolderName())) {
+            if (ImapFolder.INBOX.equalsIgnoreCase(folder)) {
                 continue;
             } else if (folder.equals(mStoreConfig.getOutboxFolderName())) {
                 /*
@@ -216,12 +216,14 @@ public class ImapStore extends RemoteStore {
             }
         }
 
-        folderNames.add(mStoreConfig.getInboxFolderName());
+        folderNames.add(ImapFolder.INBOX);
 
         return folderNames;
     }
 
     void autoconfigureFolders(final ImapConnection connection) throws IOException, MessagingException {
+        mStoreConfig.setInboxFolderName(ImapFolder.INBOX);
+
         if (!connection.hasCapability(Capabilities.SPECIAL_USE)) {
             if (K9MailLib.isDebug()) {
                 Timber.d(""No detected folder auto-configuration methods."");
diff --git a/k9mail-library/src/main/java/com/fsck/k9/mail/store/pop3/Pop3Folder.java b/k9mail-library/src/main/java/com/fsck/k9/mail/store/pop3/Pop3Folder.java
index f7ae94be2..20eb7cebc 100644
--- a/k9mail-library/src/main/java/com/fsck/k9/mail/store/pop3/Pop3Folder.java
+++ b/k9mail-library/src/main/java/com/fsck/k9/mail/store/pop3/Pop3Folder.java
@@ -31,6 +31,9 @@ import static com.fsck.k9.mail.store.pop3.Pop3Commands.*;
  * POP3 only supports one folder, ""Inbox"". So the folder name is the ID here.
  */
 class Pop3Folder extends Folder<Pop3Message> {
+    static final String INBOX = ""INBOX"";
+
+
     private Pop3Store pop3Store;
     private Map<String, Pop3Message> uidToMsgMap = new HashMap<>();
     @SuppressLint(""UseSparseArrays"")
@@ -44,10 +47,6 @@ class Pop3Folder extends Folder<Pop3Message> {
         super();
         this.pop3Store = pop3Store;
         this.name = name;
-
-        if (this.name.equalsIgnoreCase(pop3Store.getConfig().getInboxFolderName())) {
-            this.name = pop3Store.getConfig().getInboxFolderName();
-        }
     }
 
     @Override
@@ -56,7 +55,7 @@ class Pop3Folder extends Folder<Pop3Message> {
             return;
         }
 
-        if (!name.equalsIgnoreCase(pop3Store.getConfig().getInboxFolderName())) {
+        if (!INBOX.equals(name)) {
             throw new MessagingException(""Folder does not exist"");
         }
 
@@ -113,7 +112,7 @@ class Pop3Folder extends Folder<Pop3Message> {
 
     @Override
     public boolean exists() throws MessagingException {
-        return name.equalsIgnoreCase(pop3Store.getConfig().getInboxFolderName());
+        return INBOX.equals(name);
     }
 
     @Override
diff --git a/k9mail-library/src/main/java/com/fsck/k9/mail/store/pop3/Pop3Store.java b/k9mail-library/src/main/java/com/fsck/k9/mail/store/pop3/Pop3Store.java
index 2b3dde34b..ed07707e1 100644
--- a/k9mail-library/src/main/java/com/fsck/k9/mail/store/pop3/Pop3Store.java
+++ b/k9mail-library/src/main/java/com/fsck/k9/mail/store/pop3/Pop3Store.java
@@ -201,13 +201,15 @@ public class Pop3Store extends RemoteStore {
     @Override
     public List<Pop3Folder> getPersonalNamespaces(boolean forceListAll) throws MessagingException {
         List<Pop3Folder> folders = new LinkedList<>();
-        folders.add(getFolder(mStoreConfig.getInboxFolderName()));
+        folders.add(getFolder(Pop3Folder.INBOX));
         return folders;
     }
 
     @Override
     public void checkSettings() throws MessagingException {
-        Pop3Folder folder = new Pop3Folder(this, mStoreConfig.getInboxFolderName());
+        mStoreConfig.setInboxFolderName(Pop3Folder.INBOX);
+
+        Pop3Folder folder = new Pop3Folder(this, Pop3Folder.INBOX);
         try {
             folder.open(Folder.OPEN_MODE_RW);
             folder.requestUidl();
diff --git a/k9mail-library/src/test/java/com/fsck/k9/mail/store/pop3/Pop3FolderTest.java b/k9mail-library/src/test/java/com/fsck/k9/mail/store/pop3/Pop3FolderTest.java
index 56f31b60a..fc00ab566 100644
--- a/k9mail-library/src/test/java/com/fsck/k9/mail/store/pop3/Pop3FolderTest.java
+++ b/k9mail-library/src/test/java/com/fsck/k9/mail/store/pop3/Pop3FolderTest.java
@@ -6,8 +6,6 @@ import java.io.ByteArrayOutputStream;
 import java.io.File;
 import java.io.IOException;
 import java.io.InputStream;
-import java.nio.charset.StandardCharsets;
-import java.util.ArrayList;
 import java.util.List;
 
 import com.fsck.k9.mail.FetchProfile;
@@ -49,10 +47,10 @@ public class Pop3FolderTest {
         mockStoreConfig = mock(StoreConfig.class);
         mockListener = mock(MessageRetrievalListener.class);
         when(mockStore.getConfig()).thenReturn(mockStoreConfig);
-        when(mockStoreConfig.getInboxFolderName()).thenReturn(""Inbox"");
+        when(mockStoreConfig.getInboxFolderName()).thenReturn(Pop3Folder.INBOX);
         when(mockStore.createConnection()).thenReturn(mockConnection);
         when(mockConnection.executeSimpleCommand(Pop3Commands.STAT_COMMAND)).thenReturn(""+OK 10 0"");
-        folder = new Pop3Folder(mockStore, ""Inbox"");
+        folder = new Pop3Folder(mockStore, Pop3Folder.INBOX);
         BinaryTempFileBody.setTempDirectory(new File(System.getProperty(""java.io.tmpdir"")));
     }
 
diff --git a/k9mail-library/src/test/java/com/fsck/k9/mail/store/pop3/Pop3StoreTest.java b/k9mail-library/src/test/java/com/fsck/k9/mail/store/pop3/Pop3StoreTest.java
index 4a9c2601e..f17d739f5 100644
--- a/k9mail-library/src/test/java/com/fsck/k9/mail/store/pop3/Pop3StoreTest.java
+++ b/k9mail-library/src/test/java/com/fsck/k9/mail/store/pop3/Pop3StoreTest.java
@@ -66,7 +66,7 @@ public class Pop3StoreTest {
     public void setUp() throws Exception {
         //Using a SSL socket allows us to mock it
         when(mockStoreConfig.getStoreUri()).thenReturn(""pop3+ssl+://PLAIN:user:password@server:12345"");
-        when(mockStoreConfig.getInboxFolderName()).thenReturn(""Inbox"");
+        when(mockStoreConfig.getInboxFolderName()).thenReturn(Pop3Folder.INBOX);
         when(mockTrustedSocketFactory.createSocket(null, ""server"", 12345, null)).thenReturn(mockSocket);
         when(mockSocket.isConnected()).thenReturn(true);
         when(mockSocket.isClosed()).thenReturn(false);
@@ -187,7 +187,7 @@ public class Pop3StoreTest {
         List<Pop3Folder> folders = store.getPersonalNamespaces(true);
 
         assertEquals(1, folders.size());
-        assertEquals(""Inbox"", folders.get(0).getName());
+        assertEquals(""INBOX"", folders.get(0).getName());
     }
 
     @Test
@@ -247,7 +247,7 @@ public class Pop3StoreTest {
         when(mockSocket.getInputStream()).thenReturn(new ByteArrayInputStream(response.getBytes(""UTF-8"")));
         ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream();
         when(mockSocket.getOutputStream()).thenReturn(byteArrayOutputStream);
-        Pop3Folder folder = store.getFolder(""Inbox"");
+        Pop3Folder folder = store.getFolder(Pop3Folder.INBOX);
 
         folder.open(Folder.OPEN_MODE_RW);
 
@@ -262,7 +262,7 @@ public class Pop3StoreTest {
                 CAPA_RESPONSE +
                 AUTH_PLAIN_FAILED_RESPONSE;
         when(mockSocket.getInputStream()).thenReturn(new ByteArrayInputStream(response.getBytes(""UTF-8"")));
-        Pop3Folder folder = store.getFolder(""Inbox"");
+        Pop3Folder folder = store.getFolder(Pop3Folder.INBOX);
 
         folder.open(Folder.OPEN_MODE_RW);
     }
diff --git a/k9mail/src/main/java/com/fsck/k9/Account.java b/k9mail/src/main/java/com/fsck/k9/Account.java
index ba56293b9..8dd6e8ea9 100644
--- a/k9mail/src/main/java/com/fsck/k9/Account.java
+++ b/k9mail/src/main/java/com/fsck/k9/Account.java
@@ -1075,7 +1075,7 @@ public class Account implements BaseAccount, StoreConfig {
     }
 
     public boolean isSpecialFolder(String folderName) {
-        return (folderName != null && (folderName.equalsIgnoreCase(getInboxFolderName()) ||
+        return (folderName != null && (folderName.equals(getInboxFolderName()) ||
                 folderName.equals(getTrashFolderName()) ||
                 folderName.equals(getDraftsFolderName()) ||
                 folderName.equals(getArchiveFolderName()) ||
@@ -1097,7 +1097,7 @@ public class Account implements BaseAccount, StoreConfig {
      * @return true if account has a drafts folder set.
      */
     public synchronized boolean hasDraftsFolder() {
-        return !K9.FOLDER_NONE.equalsIgnoreCase(draftsFolderName);
+        return !K9.FOLDER_NONE.equals(draftsFolderName);
     }
 
     public synchronized String getSentFolderName() {
@@ -1113,7 +1113,7 @@ public class Account implements BaseAccount, StoreConfig {
      * @return true if account has a sent folder set.
      */
     public synchronized boolean hasSentFolder() {
-        return !K9.FOLDER_NONE.equalsIgnoreCase(sentFolderName);
+        return !K9.FOLDER_NONE.equals(sentFolderName);
     }
 
 
@@ -1130,7 +1130,7 @@ public class Account implements BaseAccount, StoreConfig {
      * @return true if account has a trash folder set.
      */
     public synchronized boolean hasTrashFolder() {
-        return !K9.FOLDER_NONE.equalsIgnoreCase(trashFolderName);
+        return !K9.FOLDER_NONE.equals(trashFolderName);
     }
 
     public synchronized String getArchiveFolderName() {
@@ -1146,7 +1146,7 @@ public class Account implements BaseAccount, StoreConfig {
      * @return true if account has an archive folder set.
      */
     public synchronized boolean hasArchiveFolder() {
-        return !K9.FOLDER_NONE.equalsIgnoreCase(archiveFolderName);
+        return !K9.FOLDER_NONE.equals(archiveFolderName);
     }
 
     public synchronized String getSpamFolderName() {
@@ -1162,7 +1162,7 @@ public class Account implements BaseAccount, StoreConfig {
      * @return true if account has a spam folder set.
      */
     public synchronized boolean hasSpamFolder() {
-        return !K9.FOLDER_NONE.equalsIgnoreCase(spamFolderName);
+        return !K9.FOLDER_NONE.equals(spamFolderName);
     }
 
     public synchronized String getOutboxFolderName() {
diff --git a/k9mail/src/main/java/com/fsck/k9/activity/ActivityListener.java b/k9mail/src/main/java/com/fsck/k9/activity/ActivityListener.java
index 93631085d..2990d731a 100644
--- a/k9mail/src/main/java/com/fsck/k9/activity/ActivityListener.java
+++ b/k9mail/src/main/java/com/fsck/k9/activity/ActivityListener.java
@@ -85,9 +85,9 @@ public class ActivityListener extends SimpleMessagingListener {
             }
 
             if (account != null) {
-                if (displayName.equalsIgnoreCase(account.getInboxFolderName())) {
+                if (displayName.equals(account.getInboxFolderName())) {
                     displayName = context.getString(R.string.special_mailbox_name_inbox);
-                } else if (displayName.equalsIgnoreCase(account.getOutboxFolderName())) {
+                } else if (displayName.equals(account.getOutboxFolderName())) {
                     displayName = context.getString(R.string.special_mailbox_name_outbox);
                 }
             }
diff --git a/k9mail/src/main/java/com/fsck/k9/activity/ChooseFolder.java b/k9mail/src/main/java/com/fsck/k9/activity/ChooseFolder.java
index 1a4082145..efb753400 100644
--- a/k9mail/src/main/java/com/fsck/k9/activity/ChooseFolder.java
+++ b/k9mail/src/main/java/com/fsck/k9/activity/ChooseFolder.java
@@ -279,10 +279,7 @@ public class ChooseFolder extends K9ListActivity {
             for (Folder folder : folders) {
                 String name = folder.getName();
 
-                // Inbox needs to be compared case-insensitively
-                if (mHideCurrentFolder && (name.equals(mFolder) || (
-                        mAccount.getInboxFolderName().equalsIgnoreCase(mFolder) &&
-                        mAccount.getInboxFolderName().equalsIgnoreCase(name)))) {
+                if (mHideCurrentFolder && name.equals(mFolder)) {
                     continue;
                 }
                 Folder.FolderClass fMode = folder.getDisplayClass();
@@ -335,7 +332,7 @@ public class ChooseFolder extends K9ListActivity {
             try {
                 int position = 0;
                 for (String name : localFolders) {
-                    if (mAccount.getInboxFolderName().equalsIgnoreCase(name)) {
+                    if (mAccount.getInboxFolderName().equals(name)) {
                         folderList.add(getString(R.string.special_mailbox_name_inbox));
                         mHeldInbox = name;
                     } else if (!account.getOutboxFolderName().equals(name)) {
@@ -351,9 +348,7 @@ public class ChooseFolder extends K9ListActivity {
                         if (name.equals(mSelectFolder)) {
                             selectedFolder = position;
                         }
-                    } else if (name.equals(mFolder) || (
-                            mAccount.getInboxFolderName().equalsIgnoreCase(mFolder) &&
-                            mAccount.getInboxFolderName().equalsIgnoreCase(name))) {
+                    } else if (name.equals(mFolder)) {
                         selectedFolder = position;
                     }
                     position++;
diff --git a/k9mail/src/main/java/com/fsck/k9/activity/FolderInfoHolder.java b/k9mail/src/main/java/com/fsck/k9/activity/FolderInfoHolder.java
index ef52d8b28..b7c63d434 100644
--- a/k9mail/src/main/java/com/fsck/k9/activity/FolderInfoHolder.java
+++ b/k9mail/src/main/java/com/fsck/k9/activity/FolderInfoHolder.java
@@ -121,8 +121,7 @@ public class FolderInfoHolder implements Comparable<FolderInfoHolder> {
                     context.getString(R.string.special_mailbox_name_drafts_fmt), name);
         } else if (name.equals(account.getOutboxFolderName())) {
             displayName = context.getString(R.string.special_mailbox_name_outbox);
-        // FIXME: We really shouldn't do a case-insensitive comparison here
-        } else if (name.equalsIgnoreCase(account.getInboxFolderName())) {
+        } else if (name.equals(account.getInboxFolderName())) {
             displayName = context.getString(R.string.special_mailbox_name_inbox);
         } else {
             displayName = name;
diff --git a/k9mail/src/main/java/com/fsck/k9/activity/setup/AccountSettings.java b/k9mail/src/main/java/com/fsck/k9/activity/setup/AccountSettings.java
index 84b603124..f5ab99975 100644
--- a/k9mail/src/main/java/com/fsck/k9/activity/setup/AccountSettings.java
+++ b/k9mail/src/main/java/com/fsck/k9/activity/setup/AccountSettings.java
@@ -989,7 +989,7 @@ public class AccountSettings extends K9PreferenceActivity {
     }
 
     private String translateFolder(String in) {
-        if (account.getInboxFolderName().equalsIgnoreCase(in)) {
+        if (account.getInboxFolderName().equals(in)) {
             return getString(R.string.special_mailbox_name_inbox);
         } else {
             return in;
diff --git a/k9mail/src/main/java/com/fsck/k9/mailstore/LocalStore.java b/k9mail/src/main/java/com/fsck/k9/mailstore/LocalStore.java
index 92204244d..d3ac2f170 100644
--- a/k9mail/src/main/java/com/fsck/k9/mailstore/LocalStore.java
+++ b/k9mail/src/main/java/com/fsck/k9/mailstore/LocalStore.java
@@ -917,7 +917,7 @@ public class LocalStore extends Store {
                     if (account.isSpecialFolder(name)) {
                         prefHolder.inTopGroup = true;
                         prefHolder.displayClass = LocalFolder.FolderClass.FIRST_CLASS;
-                        if (name.equalsIgnoreCase(account.getInboxFolderName())) {
+                        if (name.equals(account.getInboxFolderName())) {
                             prefHolder.integrate = true;
                             prefHolder.notifyClass = LocalFolder.FolderClass.FIRST_CLASS;
                             prefHolder.pushClass = LocalFolder.FolderClass.FIRST_CLASS;
@@ -925,8 +925,7 @@ public class LocalStore extends Store {
                             prefHolder.pushClass = LocalFolder.FolderClass.INHERITED;
 
                         }
-                        if (name.equalsIgnoreCase(account.getInboxFolderName()) ||
-                                name.equalsIgnoreCase(account.getDraftsFolderName())) {
+                        if (name.equals(account.getInboxFolderName()) || name.equals(account.getDraftsFolderName())) {
                             prefHolder.syncClass = LocalFolder.FolderClass.FIRST_CLASS;
                         } else {
                             prefHolder.syncClass = LocalFolder.FolderClass.NO_CLASS;
diff --git a/k9mail/src/main/java/com/fsck/k9/notification/NotificationActionService.java b/k9mail/src/main/java/com/fsck/k9/notification/NotificationActionService.java
index ea446b4e7..5def5fc8c 100644
--- a/k9mail/src/main/java/com/fsck/k9/notification/NotificationActionService.java
+++ b/k9mail/src/main/java/com/fsck/k9/notification/NotificationActionService.java
@@ -233,7 +233,7 @@ public class NotificationActionService extends CoreService {
 
     private boolean isMovePossible(MessagingController controller, Account account,
             String destinationFolderName) {
-        boolean isSpecialFolderConfigured = !K9.FOLDER_NONE.equalsIgnoreCase(destinationFolderName);
+        boolean isSpecialFolderConfigured = !K9.FOLDER_NONE.equals(destinationFolderName);
 
         return isSpecialFolderConfigured && controller.isMoveCapable(account);
     }
diff --git a/k9mail/src/main/java/com/fsck/k9/notification/WearNotifications.java b/k9mail/src/main/java/com/fsck/k9/notification/WearNotifications.java
index fe9d9ce55..780ed27c1 100644
--- a/k9mail/src/main/java/com/fsck/k9/notification/WearNotifications.java
+++ b/k9mail/src/main/java/com/fsck/k9/notification/WearNotifications.java
@@ -240,7 +240,7 @@ class WearNotifications extends BaseNotifications {
     }
 
     private boolean isMovePossible(Account account, String destinationFolderName) {
-        if (K9.FOLDER_NONE.equalsIgnoreCase(destinationFolderName)) {
+        if (K9.FOLDER_NONE.equals(destinationFolderName)) {
             return false;
         }
 
diff --git a/k9mail/src/main/java/com/fsck/k9/ui/messageview/MessageViewFragment.java b/k9mail/src/main/java/com/fsck/k9/ui/messageview/MessageViewFragment.java
index da52ab507..8732a1c65 100644
--- a/k9mail/src/main/java/com/fsck/k9/ui/messageview/MessageViewFragment.java
+++ b/k9mail/src/main/java/com/fsck/k9/ui/messageview/MessageViewFragment.java
@@ -301,7 +301,7 @@ public class MessageViewFragment extends Fragment implements ConfirmationDialogF
             return;
         }
 
-        if (K9.FOLDER_NONE.equalsIgnoreCase(dstFolder)) {
+        if (K9.FOLDER_NONE.equals(dstFolder)) {
             return;
         }
 ","['k9mail-library/src/main/java/com/fsck/k9/mail/store/pop3/Pop3Store.java', 'k9mail/src/main/java/com/fsck/k9/activity/ActivityListener.java', 'k9mail-library/src/main/java/com/fsck/k9/mail/store/imap/ImapFolder.java', 'k9mail/src/main/java/com/fsck/k9/activity/ChooseFolder.java', 'k9mail/src/main/java/com/fsck/k9/notification/WearNotifications.java', 'k9mail/src/main/java/com/fsck/k9/Account.java', 'k9mail/src/main/java/com/fsck/k9/notification/NotificationActionService.java', 'k9mail-library/src/test/java/com/fsck/k9/mail/store/pop3/Pop3FolderTest.java', 'k9mail-library/src/main/java/com/fsck/k9/mail/store/imap/ImapStore.java', 'k9mail/src/main/java/com/fsck/k9/activity/setup/AccountSettings.java', 'k9mail/src/main/java/com/fsck/k9/mailstore/LocalStore.java', 'k9mail-library/src/main/java/com/fsck/k9/mail/store/pop3/Pop3Folder.java', 'k9mail/src/main/java/com/fsck/k9/activity/FolderInfoHolder.java', 'k9mail/src/main/java/com/fsck/k9/ui/messageview/MessageViewFragment.java', 'k9mail-library/src/test/java/com/fsck/k9/mail/store/pop3/Pop3StoreTest.java']",{'.java': 15},15,15,0,0,15,3644613,714329,99963,501,4712,945,73,13,341,59,85,8,0,0,2018-02-26 03:51:19,8156,Kotlin,"{'Kotlin': 4058553, 'Java': 2375292, 'Shell': 7553, 'AIDL': 1946}",Apache License 2.0,"['k9mail-library/src/main/java/com/fsck/k9/mail/store/imap/ImapStore.java', 'k9mail/src/main/java/com/fsck/k9/preferences/FolderSettings.java', 'k9mail-library/src/main/java/com/fsck/k9/mail/store/imap/ImapStoreUriCreator.java', 'k9mail-library/src/main/java/com/fsck/k9/mail/store/imap/ImapFolder.java', 'k9mail-library/src/main/java/com/fsck/k9/mail/store/imap/ImapStoreSettings.java']","['k9mail-library/src/main/java/com/fsck/k9/mail/store/imap/ImapStore.java', 'k9mail/src/main/java/com/fsck/k9/preferences/FolderSettings.java', 'k9mail-library/src/main/java/com/fsck/k9/mail/store/imap/ImapStoreUriCreator.java', 'k9mail-library/src/main/java/com/fsck/k9/mail/store/imap/ImapFolder.java', 'k9mail-library/src/main/java/com/fsck/k9/mail/store/imap/ImapStoreSettings.java']","['```json\n{\n  ""files"": [\n    ""k9mail/src/main/java/com/fsck/k9/preferences/FolderSettings.java"",\n    ""k9mail-library/src/main/java/com/fsck/k9/mail/store/imap/ImapFolder.java"",\n    ""k9mail-library/src/main/java/com/fsck/k9/mail/store/imap/ImapStore.java"",\n    ""k9mail-library/src/main/java/com/fsck/k9/mail/store/imap/ImapStoreSettings.java"",\n    ""k9mail-library/src/main/java/com/fsck/k9/mail/store/imap/ImapStoreUriCreator.java""\n  ]\n}\n```']",1,2252.2993087768555
401,gocd/gocd/10676/10036,gocd,gocd,https://github.com/gocd/gocd/issues/10036,https://github.com/gocd/gocd/pull/10676,https://github.com/gocd/gocd/pull/10676,1,fixes,HTTP 500 when using external authorization plugins and GoCD site urls are blank,"##### Issue Type

- Bug Report

##### Summary

When using GoCD GitLab or GitHub authentication plugins, the server site URLs must be set properly in the server configuration, otherwise the GoCD will fail with HTTP 500.

##### Environment

Discovered on 21.2.0, Java 15.
I suppose it is not related to the GoCD or Java version.

###### Basic environment details

* Go Version: 21.2.0 
* JAVA Version: 15.0.2
* OS: Linux 4.19.0-17-amd64

##### Steps to Reproduce

1. Put a GitLab or GitHub plugin JAR into the appropriate folder and restart the server
2. Create a new authorization configuration with the desired plugin
3. Make sure that both server site urls are not set OR at least the second one (Secure site URL) is not set
4. Try to login via plugin

##### Expected Results

Should be redirected to the external IDP properly

##### Actual Results

GoCD throws an HTTP500

##### Possible Fix

Use at least the site url which is set or something default, like http://localhost:8153

##### Log snippets

In the go-server.log you can see following:

```
2022-01-03 10:25:48,470 WARN  [qtp679525351-29] HttpChannel:673 - handleException /go/plugin/cd.go.authorization.gitlab/login java.net.MalformedURLException: no protocol:
```

",4fae75d5c7e6e6dcfcacaea0577eafb193e6f29b,5b7c362731eae1fd8deec665bc025c2e99cba3be,https://github.com/gocd/gocd/compare/4fae75d5c7e6e6dcfcacaea0577eafb193e6f29b...5b7c362731eae1fd8deec665bc025c2e99cba3be,"diff --git a/config/config-api/src/main/java/com/thoughtworks/go/config/ServerConfig.java b/config/config-api/src/main/java/com/thoughtworks/go/config/ServerConfig.java
index 0fef04a87e..51f01b601b 100644
--- a/config/config-api/src/main/java/com/thoughtworks/go/config/ServerConfig.java
+++ b/config/config-api/src/main/java/com/thoughtworks/go/config/ServerConfig.java
@@ -294,15 +294,12 @@ public class ServerConfig implements Validatable {
 
 
     public ServerSiteUrlConfig getSiteUrlPreferablySecured() {
-        SiteUrl siteUrl = getSiteUrl();
-        SecureSiteUrl secureSiteUrlConfig = getSecureSiteUrl();
-        if (secureSiteUrlConfig.hasNonNullUrl()) {
-            return secureSiteUrlConfig;
-        }
-        if (!secureSiteUrlConfig.hasNonNullUrl()) {
-            return siteUrl;
+        SecureSiteUrl secureSiteUrl = getSecureSiteUrl();
+        if (!secureSiteUrl.isBlank()) {
+            return secureSiteUrl;
+        } else {
+            return getSiteUrl();
         }
-        return new SiteUrl();
     }
 
     public ServerSiteUrlConfig getHttpsUrl() {
@@ -311,7 +308,7 @@ public class ServerConfig implements Validatable {
     }
 
     public boolean hasAnyUrlConfigured() {
-        return getSiteUrl().hasNonNullUrl() || getSecureSiteUrl().hasNonNullUrl();
+        return !getSiteUrl().isBlank() || !getSecureSiteUrl().isBlank();
     }
 
     public Double getPurgeStart() {
diff --git a/config/config-api/src/main/java/com/thoughtworks/go/domain/ServerSiteUrlConfig.java b/config/config-api/src/main/java/com/thoughtworks/go/domain/ServerSiteUrlConfig.java
index b350abcc9b..c978d4c873 100644
--- a/config/config-api/src/main/java/com/thoughtworks/go/domain/ServerSiteUrlConfig.java
+++ b/config/config-api/src/main/java/com/thoughtworks/go/domain/ServerSiteUrlConfig.java
@@ -16,6 +16,7 @@
 package com.thoughtworks.go.domain;
 
 import com.thoughtworks.go.config.ConfigValue;
+import org.apache.commons.lang3.StringUtils;
 
 import java.net.URI;
 import java.net.URISyntaxException;
@@ -32,8 +33,8 @@ public abstract class ServerSiteUrlConfig {
         this.url = url;
     }
 
-    public boolean hasNonNullUrl() {
-        return getUrl() != null;
+    public boolean isBlank() {
+        return StringUtils.isBlank(url);
     }
 
     public String getUrl() {
@@ -68,14 +69,22 @@ public abstract class ServerSiteUrlConfig {
     }
 
     public String siteUrlFor(String givenUrl, boolean honorGivenHostName) throws URISyntaxException {
-        if (url == null || isPath(givenUrl)) {
+        if (isBlank() || isPath(givenUrl)) {
             return givenUrl; //it is a path
         }
 
         URI baseUri = new URI(url);
         URI givenUri = new URI(givenUrl);
 
-        return new URI(baseUri.getScheme(), getOrDefault(givenUri, baseUri, URI::getUserInfo), honorGivenHostName ? givenUri.getHost() : baseUri.getHost(), baseUri.getPort(), getOrDefault(givenUri, baseUri, URI::getPath), getOrDefault(givenUri, baseUri, URI::getQuery), getOrDefault(givenUri, baseUri, URI::getFragment)).toString();
+        return new URI(
+            baseUri.getScheme(),
+            getOrDefault(givenUri, baseUri, URI::getUserInfo),
+            honorGivenHostName ? givenUri.getHost() : baseUri.getHost(),
+            baseUri.getPort(),
+            getOrDefault(givenUri, baseUri, URI::getPath),
+            getOrDefault(givenUri, baseUri, URI::getQuery),
+            getOrDefault(givenUri, baseUri, URI::getFragment)
+        ).toString();
     }
 
     private boolean isPath(String givenUrl) {
@@ -88,7 +97,7 @@ public abstract class ServerSiteUrlConfig {
     }
 
     public boolean isAHttpsUrl() {
-        return url != null && url.matches(HTTPS_URL_REGEX);
+        return !isBlank() && url.matches(HTTPS_URL_REGEX);
     }
 
     interface Getter {
@@ -97,7 +106,7 @@ public abstract class ServerSiteUrlConfig {
 
     @Override
     public String toString() {
-        return hasNonNullUrl() ? url : """";
+        return isBlank() ? """" : url;
     }
 }
 
diff --git a/config/config-api/src/test/java/com/thoughtworks/go/config/ServerConfigTest.java b/config/config-api/src/test/java/com/thoughtworks/go/config/ServerConfigTest.java
index ccc451b193..14968fde88 100644
--- a/config/config-api/src/test/java/com/thoughtworks/go/config/ServerConfigTest.java
+++ b/config/config-api/src/test/java/com/thoughtworks/go/config/ServerConfigTest.java
@@ -61,11 +61,11 @@ public class ServerConfigTest {
     public void shouldReturnBlankUrlBothSiteUrlAndSecureSiteUrlIsNotDefined() {
         defaultServerConfig.setSiteUrl(null);
         defaultServerConfig.setSecureSiteUrl(null);
-        assertThat(defaultServerConfig.getSiteUrlPreferablySecured().hasNonNullUrl(), is(false));
+        assertThat(defaultServerConfig.getSiteUrlPreferablySecured().isBlank(), is(true));
     }
 
     @Test
-    public void shouldReturnAnEmptyForSecureSiteUrlIfOnlySiteUrlIsConfigured() throws Exception {
+    public void shouldReturnAnEmptyForSecureSiteUrlIfOnlySiteUrlIsConfigured() {
         ServerConfig serverConfig = new ServerConfig(null, null, new SiteUrl(""http://foo.bar:813""), new SecureSiteUrl());
         assertThat(serverConfig.getHttpsUrl(), is(new SecureSiteUrl()));
     }
diff --git a/config/config-api/src/test/java/com/thoughtworks/go/domain/ServerSiteUrlConfigTest.java b/config/config-api/src/test/java/com/thoughtworks/go/domain/ServerSiteUrlConfigTest.java
index 46826f047d..dfb2286558 100644
--- a/config/config-api/src/test/java/com/thoughtworks/go/domain/ServerSiteUrlConfigTest.java
+++ b/config/config-api/src/test/java/com/thoughtworks/go/domain/ServerSiteUrlConfigTest.java
@@ -16,11 +16,14 @@
 package com.thoughtworks.go.domain;
 
 import org.junit.jupiter.api.Test;
+import org.junit.jupiter.params.ParameterizedTest;
+import org.junit.jupiter.params.provider.NullSource;
+import org.junit.jupiter.params.provider.ValueSource;
 
 import java.net.URISyntaxException;
 
-import static org.hamcrest.Matchers.is;
 import static org.hamcrest.MatcherAssert.assertThat;
+import static org.hamcrest.Matchers.is;
 
 public class ServerSiteUrlConfigTest {
     @Test
@@ -77,9 +80,14 @@ public class ServerSiteUrlConfigTest {
         assertThat(url.toString(), is(""http://someurl.com""));
     }
 
-    @Test
-    public void shouldReturnEmptyStringForToStringWhenTheUrlIsNotSet() throws Exception {
-        ServerSiteUrlConfig url = new SiteUrl();
+    @ParameterizedTest
+    @NullSource
+    @ValueSource(strings = {"""", "" ""})
+    public void shouldHandleBlankUrlsConsistently(String input) throws Exception {
+        ServerSiteUrlConfig url = new SiteUrl(input);
         assertThat(url.toString(), is(""""));
+        assertThat(url.isBlank(), is(true));
+        assertThat(url.isAHttpsUrl(), is(false));
+        assertThat(url.siteUrlFor(""http://test.host/foo/bar?foo=bar#quux""), is(""http://test.host/foo/bar?foo=bar#quux""));
     }
 }
diff --git a/server/src/main/java/com/thoughtworks/go/server/newsecurity/providers/WebBasedPluginAuthenticationProvider.java b/server/src/main/java/com/thoughtworks/go/server/newsecurity/providers/WebBasedPluginAuthenticationProvider.java
index daf9d31e81..ef23185c10 100644
--- a/server/src/main/java/com/thoughtworks/go/server/newsecurity/providers/WebBasedPluginAuthenticationProvider.java
+++ b/server/src/main/java/com/thoughtworks/go/server/newsecurity/providers/WebBasedPluginAuthenticationProvider.java
@@ -88,12 +88,12 @@ public class WebBasedPluginAuthenticationProvider extends AbstractPluginAuthenti
         return new AuthenticationToken<>(userPrinciple, credentials, pluginId, clock.currentTimeMillis(), authConfigId);
     }
 
-    private String getRootUrl(String string) {
+    private String rootUrlFrom(String urlString) {
         try {
-            final URL url = new URL(string);
+            final URL url = new URL(urlString);
             return new URL(url.getProtocol(), url.getHost(), url.getPort(), """").toString();
         } catch (MalformedURLException e) {
-            throw new RuntimeException(e);
+            throw new RuntimeException(String.format(""Configured siteUrl [%s] does not appear to be a valid URL"", urlString), e);
         }
     }
 
@@ -107,11 +107,12 @@ public class WebBasedPluginAuthenticationProvider extends AbstractPluginAuthenti
         return goConfigService.security().securityAuthConfigs().findByPluginId(pluginId);
     }
 
-    public String getAuthorizationServerUrl(String pluginId, String rootURL) {
-        if (goConfigService.serverConfig().hasAnyUrlConfigured()) {
-            rootURL = getRootUrl(goConfigService.serverConfig().getSiteUrlPreferablySecured().getUrl());
-        }
-        return authorizationExtension.getAuthorizationServerUrl(pluginId, getAuthConfigs(pluginId), rootURL);
+    public String getAuthorizationServerUrl(String pluginId, String alternateRootUrl) {
+        String chosenRootUrl =
+            goConfigService.serverConfig().hasAnyUrlConfigured()
+                ? rootUrlFrom(goConfigService.serverConfig().getSiteUrlPreferablySecured().getUrl())
+                : alternateRootUrl;
+        return authorizationExtension.getAuthorizationServerUrl(pluginId, getAuthConfigs(pluginId), chosenRootUrl);
     }
 
 }
diff --git a/server/src/test-fast/java/com/thoughtworks/go/server/newsecurity/providers/WebBasedPluginAuthenticationProviderTest.java b/server/src/test-fast/java/com/thoughtworks/go/server/newsecurity/providers/WebBasedPluginAuthenticationProviderTest.java
index 03988934a9..3c63a1d1b5 100644
--- a/server/src/test-fast/java/com/thoughtworks/go/server/newsecurity/providers/WebBasedPluginAuthenticationProviderTest.java
+++ b/server/src/test-fast/java/com/thoughtworks/go/server/newsecurity/providers/WebBasedPluginAuthenticationProviderTest.java
@@ -41,6 +41,8 @@ import org.junit.jupiter.api.extension.ExtendWith;
 import org.mockito.ArgumentCaptor;
 import org.mockito.InOrder;
 
+import java.net.MalformedURLException;
+
 import static com.thoughtworks.go.server.security.GoAuthority.ROLE_USER;
 import static java.util.Arrays.asList;
 import static java.util.Collections.*;
@@ -322,6 +324,19 @@ class WebBasedPluginAuthenticationProviderTest {
         verify(authorizationExtension).getAuthorizationServerUrl(PLUGIN_ID, singletonList(githubSecurityAuthconfig), ""https://example.com"");
     }
 
+    @Test
+    void shouldThrowUsefulErrorIfAuthorizationServerUrlIsBad() {
+        final ServerConfig serverConfig = mock(ServerConfig.class);
+        when(goConfigService.serverConfig()).thenReturn(serverConfig);
+        when(serverConfig.hasAnyUrlConfigured()).thenReturn(true);
+        when(serverConfig.getSiteUrlPreferablySecured()).thenReturn(new SecureSiteUrl(""https://badurl:3434:""));
+
+        assertThatThrownBy(() -> authenticationProvider.getAuthorizationServerUrl(PLUGIN_ID, ""https://example.com""))
+            .isInstanceOf(RuntimeException.class)
+            .hasMessageContaining(""does not appear to be a valid URL"")
+            .hasCauseInstanceOf(MalformedURLException.class);
+    }
+
     @Test
     void shouldFetchAccessTokenFromPlugin() {
         when(authorizationExtension.fetchAccessToken(PLUGIN_ID, emptyMap(), singletonMap(""code"", ""some-code""), singletonList(githubSecurityAuthconfig))).thenReturn(singletonMap(""access_token"", ""some-access-token""));","['config/config-api/src/main/java/com/thoughtworks/go/domain/ServerSiteUrlConfig.java', 'config/config-api/src/main/java/com/thoughtworks/go/config/ServerConfig.java', 'server/src/main/java/com/thoughtworks/go/server/newsecurity/providers/WebBasedPluginAuthenticationProvider.java', 'config/config-api/src/test/java/com/thoughtworks/go/config/ServerConfigTest.java', 'server/src/test-fast/java/com/thoughtworks/go/server/newsecurity/providers/WebBasedPluginAuthenticationProviderTest.java', 'config/config-api/src/test/java/com/thoughtworks/go/domain/ServerSiteUrlConfigTest.java']",{'.java': 6},6,6,0,0,6,15770573,3155800,372021,3332,3869,815,68,4,1275,188,312,47,1,1,2022-08-07 15:32:32,6872,Java,"{'Java': 20634641, 'TypeScript': 4429797, 'Groovy': 2083065, 'JavaScript': 777429, 'SCSS': 597726, 'Ruby': 404083, 'HTML': 257482, 'XSLT': 206746, 'NSIS': 24216, 'Sass': 21277, 'Shell': 15583, 'FreeMarker': 13166, 'EJS': 1626, 'CSS': 1580, 'PowerShell': 664, 'Batchfile': 474}",Apache License 2.0,"['api/api-internal-agent-v1/src/main/java/com/thoughtworks/go/apiv1/internalagent/representers/AgentInstructionRepresenter.java', 'server/src/main/java/com/thoughtworks/go/config/security/GroupSecurity.java', 'server/src/main/java/com/thoughtworks/go/config/ConfigCipherUpdater.java', 'server/src/main/java/com/thoughtworks/go/server/newsecurity/controllers/AuthenticationController.java', 'server/src/main/java/com/thoughtworks/go/config/GoConfigFileReader.java', 'server/src/main/java/com/thoughtworks/go/server/domain/user/Filters.java', 'server/src/main/java/com/thoughtworks/go/config/GoConfigFileWriter.java', 'server/src/main/java/com/thoughtworks/go/server/service/plugins/processor/serverhealth/ServerHealthRequestProcessor.java', 'server/src/main/java/com/thoughtworks/go/spark/HtmlErrorPage.java', 'api/api-internal-agent-v1/src/main/java/com/thoughtworks/go/apiv1/internalagent/representers/GetCookieRequestRepresenter.java', 'server/src/main/java/com/thoughtworks/go/server/service/plugins/processor/pluginsettings/PluginSettingsRequestProcessor.java', 'server/src/main/java/com/thoughtworks/go/spark/Link.java', 'server/src/main/java/com/thoughtworks/go/server/domain/user/FilterValidator.java', 'server/src/main/java/com/thoughtworks/go/server/service/plugins/processor/serverinfo/ServerInfoRequestProcessor.java', 'api/api-shared-v9/src/main/java/com/thoughtworks/go/apiv9/admin/shared/representers/stages/tasks/TaskRepresenter.java', 'server/src/main/java/com/thoughtworks/go/api/ApiVersion.java', 'server/src/main/java/com/thoughtworks/go/spark/DeprecatedAPI.java', 'server/src/main/java/com/thoughtworks/go/server/domain/user/IncludesFilter.java', 'server/src/main/java/com/thoughtworks/go/server/web/BaseUrlProvider.java', 'server/src/main/java/com/thoughtworks/go/server/newsecurity/filters/helpers/ServerUnavailabilityResponse.java', 'server/src/main/java/com/thoughtworks/go/config/security/PipelineGroupsSecurityHelper.java', 'server/src/main/java/com/thoughtworks/go/config/security/Permissions.java', 'server/src/main/java/com/thoughtworks/go/server/service/plugins/processor/authorization/AuthorizationRequestProcessor.java', 'server/src/main/java/com/thoughtworks/go/server/service/plugins/processor/elasticagent/ElasticAgentRequestProcessor.java', 'server/src/main/java/com/thoughtworks/go/config/security/GoConfigPipelinePermissionsAuthority.java', 'server/src/main/java/com/thoughtworks/go/config/GoConfigDao.java', 'server/src/main/java/com/thoughtworks/go/server/domain/user/ExcludesFilter.java', 'server/src/main/java/com/thoughtworks/go/server/newsecurity/handlers/renderer/ContentTypeNegotiationMessageRenderer.java', 'server/src/main/java/com/thoughtworks/go/server/domain/user/DashboardFilter.java', 'server/src/main/java/com/thoughtworks/go/config/update/SecurityAuthConfigCommand.java', 'api/api-shared-v9/src/main/java/com/thoughtworks/go/apiv9/admin/shared/representers/stages/tasks/PluggableTaskRepresenter.java', 'server/src/main/java/com/thoughtworks/go/config/GoConfigMigrator.java', 'server/src/main/java/com/thoughtworks/go/server/service/ServerConfigService.java']","['server/src/main/java/com/thoughtworks/go/config/GoConfigDao.java', 'server/src/main/java/com/thoughtworks/go/config/update/SecurityAuthConfigCommand.java', 'server/src/main/java/com/thoughtworks/go/config/GoConfigFileReader.java', 'server/src/main/java/com/thoughtworks/go/config/GoConfigFileWriter.java', 'server/src/main/java/com/thoughtworks/go/config/GoConfigMigrator.java']","['```json\n{\n  ""files"": [\n    ""server/src/main/java/com/thoughtworks/go/config/ConfigCipherUpdater.java"",\n    ""server/src/main/java/com/thoughtworks/go/config/GoConfigDao.java"",\n    ""server/src/main/java/com/thoughtworks/go/config/GoConfigFileReader.java"",\n    ""server/src/main/java/com/thoughtworks/go/config/GoConfigFileWriter.java"",\n    ""server/src/main/java/com/thoughtworks/go/config/GoConfigMigrator.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""server/src/main/java/com/thoughtworks/go/config/security/GoConfigPipelinePermissionsAuthority.java"",\n    ""server/src/main/java/com/thoughtworks/go/config/security/GroupSecurity.java"",\n    ""server/src/main/java/com/thoughtworks/go/config/security/Permissions.java"",\n    ""server/src/main/java/com/thoughtworks/go/config/security/PipelineGroupsSecurityHelper.java"",\n    ""server/src/main/java/com/thoughtworks/go/config/update/SecurityAuthConfigCommand.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""server/src/main/java/com/thoughtworks/go/server/service/ServerConfigService.java"",\n    ""server/src/main/java/com/thoughtworks/go/server/web/BaseUrlProvider.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""server/src/main/java/com/thoughtworks/go/spark/Link.java"",\n    ""server/src/main/java/com/thoughtworks/go/spark/DeprecatedAPI.java"",\n    ""server/src/main/java/com/thoughtworks/go/spark/HtmlErrorPage.java"",\n    ""server/src/main/java/com/thoughtworks/go/api/ApiVersion.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""server/src/main/java/com/thoughtworks/go/server/domain/user/FilterValidator.java"",\n    ""server/src/main/java/com/thoughtworks/go/server/domain/user/Filters.java"",\n    ""server/src/main/java/com/thoughtworks/go/server/domain/user/ExcludesFilter.java"",\n    ""server/src/main/java/com/thoughtworks/go/server/domain/user/IncludesFilter.java"",\n    ""server/src/main/java/com/thoughtworks/go/server/domain/user/DashboardFilter.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""server/src/main/java/com/thoughtworks/go/server/newsecurity/controllers/AuthenticationController.java"",\n    ""api/api-internal-agent-v1/src/main/java/com/thoughtworks/go/apiv1/internalagent/representers/AgentInstructionRepresenter.java"",\n    ""api/api-internal-agent-v1/src/main/java/com/thoughtworks/go/apiv1/internalagent/representers/GetCookieRequestRepresenter.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""server/src/main/java/com/thoughtworks/go/server/newsecurity/filters/helpers/ServerUnavailabilityResponse.java"",\n    ""server/src/main/java/com/thoughtworks/go/server/newsecurity/handlers/renderer/ContentTypeNegotiationMessageRenderer.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""server/src/main/java/com/thoughtworks/go/server/service/plugins/processor/authorization/AuthorizationRequestProcessor.java"",\n    ""server/src/main/java/com/thoughtworks/go/server/service/plugins/processor/elasticagent/ElasticAgentRequestProcessor.java"",\n    ""server/src/main/java/com/thoughtworks/go/server/service/plugins/processor/pluginsettings/PluginSettingsRequestProcessor.java"",\n    ""server/src/main/java/com/thoughtworks/go/server/service/plugins/processor/serverhealth/ServerHealthRequestProcessor.java"",\n    ""server/src/main/java/com/thoughtworks/go/server/service/plugins/processor/serverinfo/ServerInfoRequestProcessor.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""api/api-shared-v9/src/main/java/com/thoughtworks/go/apiv9/admin/shared/representers/stages/tasks/PluggableTaskRepresenter.java"",\n    ""api/api-shared-v9/src/main/java/com/thoughtworks/go/apiv9/admin/shared/representers/stages/tasks/TaskRepresenter.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""server/src/main/java/com/thoughtworks/go/config/GoConfigFileReader.java"",\n    ""server/src/main/java/com/thoughtworks/go/config/GoConfigFileWriter.java"",\n    ""server/src/main/java/com/thoughtworks/go/config/GoConfigDao.java"",\n    ""server/src/main/java/com/thoughtworks/go/config/GoConfigMigrator.java"",\n    ""server/src/main/java/com/thoughtworks/go/config/update/SecurityAuthConfigCommand.java""\n  ]\n}\n```']",9,17815.38677215576
114,axonframework/axonframework/2756/2751,axonframework,axonframework,https://github.com/AxonFramework/AxonFramework/issues/2751,https://github.com/AxonFramework/AxonFramework/pull/2756,https://github.com/AxonFramework/AxonFramework/pull/2756,2,resolves,Duplicate initialization of TrackingEventProcessor worker threads,"<!-- Please use markdown (https://guides.github.com/features/mastering-markdown/) semantics throughout the bug description. -->

### Basic information

* Axon Framework version: 4.7.1
* JDK version:  Amazon Coretto 17

### Steps to reproduce

We build our applications using Spring Boot and we recently introduced a spring actuator `HealthIndicator` to monitor the health of all axon event processors. The health indicator starts as a spring component and injects the axon `EventProcessingConfiguration` to access the `.eventProcessors()` method to loop over all event processors checking their status.

After the introduction of our new `HealthIndicator` we started seeing random occurrences of duplicated events in our event processors. We spent the last few days tracking down the error and finally found a race condition in the initialization of the axon event processors. After looking at the axon source code we found that calling the `.eventProcessors()` was not a simple get operation (as we expected) but it actually initialized the event processors. In some rare occasions the `HealthIndicator` will call the `.eventProcessors()` method at the same time as it is being initialized by axon during startup. Since the `EventProcessingModule.initializeProcessors()` is not thread safe this will causes duplicate event processor threads being created for the same event processor and segment.

### Expected behaviour

The `.eventProcessors()` method looks like a simple getter, and should not have side effects. If the initialization side effects are unavoidable it should be thread safe.

### Actual behaviour

Race condition when calling `.eventProcessors()` from multiple locations simultaneously during startup.
",62bae3f17614e66d919afbbda08da4cbd6235346,61efd48c72f49feaaecea2c8c01c120889b5aaf8,https://github.com/axonframework/axonframework/compare/62bae3f17614e66d919afbbda08da4cbd6235346...61efd48c72f49feaaecea2c8c01c120889b5aaf8,"diff --git a/config/src/main/java/org/axonframework/config/EventProcessingModule.java b/config/src/main/java/org/axonframework/config/EventProcessingModule.java
index 092a993e6..535b70ac5 100644
--- a/config/src/main/java/org/axonframework/config/EventProcessingModule.java
+++ b/config/src/main/java/org/axonframework/config/EventProcessingModule.java
@@ -1,5 +1,5 @@
 /*
- * Copyright (c) 2010-2022. Axon Framework
+ * Copyright (c) 2010-2023. Axon Framework
  *
  * Licensed under the Apache License, Version 2.0 (the ""License"");
  * you may not use this file except in compliance with the License.
@@ -65,6 +65,7 @@
 import java.util.Optional;
 import java.util.concurrent.Executors;
 import java.util.concurrent.ScheduledExecutorService;
+import java.util.concurrent.atomic.AtomicBoolean;
 import java.util.function.BiFunction;
 import java.util.function.Consumer;
 import java.util.function.Function;
@@ -129,6 +130,7 @@
     protected final Map<String, PooledStreamingProcessorConfiguration> psepConfigs = new HashMap<>();
     protected final Map<String, DeadLetteringInvokerConfiguration> deadLetteringInvokerConfigs = new HashMap<>();
 
+    private final AtomicBoolean initialized = new AtomicBoolean(false);
     private Configuration configuration;
 
     private final Component<ListenerInvocationErrorHandler> defaultListenerInvocationErrorHandler = new Component<>(
@@ -209,7 +211,15 @@ public void initialize(Configuration configuration) {
      * processors have already been initialized, this method does nothing.
      */
     private void initializeProcessors() {
-        if (eventProcessors.isEmpty()) {
+        if (initialized.get()) {
+            return;
+        }
+
+        synchronized (initialized) {
+            if (initialized.get()) {
+                return;
+            }
+
             instanceSelectors.sort(comparing(InstanceProcessingGroupSelector::getPriority).reversed());
 
             Map<String, List<Function<Configuration, EventHandlerInvoker>>> handlerInvokers = new HashMap<>();
@@ -217,12 +227,14 @@ private void initializeProcessors() {
             registerSagaManagers(handlerInvokers);
 
             handlerInvokers.forEach((processorName, invokers) -> {
-                Component<EventProcessor> eventProcessorComponent =
-                        new Component<>(configuration, processorName, c -> buildEventProcessor(invokers, processorName));
+                Component<EventProcessor> eventProcessorComponent = new Component<>(
+                        configuration, processorName, c -> buildEventProcessor(invokers, processorName)
+                );
                 eventProcessors.put(processorName, eventProcessorComponent);
             });
 
             eventProcessors.values().forEach(Component::get);
+            initialized.set(true);
         }
     }
 ",['config/src/main/java/org/axonframework/config/EventProcessingModule.java'],{'.java': 1},1,1,0,0,1,5365156,1045642,127217,970,878,157,20,1,1741,242,333,21,1,0,2023-06-16 11:23:16,3085,Java,{'Java': 10919624},Apache License 2.0,"['messaging/src/main/java/org/axonframework/config/EventProcessingModule.java', 'eventsourcing/src/main/java/org/axonframework/eventsourcing/eventstore/jdbc/statements/AppendSnapshotStatementBuilder.java', 'axon-server-connector/src/main/java/org/axonframework/axonserver/connector/event/axon/AxonServerEventScheduler.java', 'eventsourcing/src/main/java/org/axonframework/eventsourcing/eventstore/jdbc/statements/JdbcEventStorageEngineStatements.java', 'messaging/src/main/java/org/axonframework/eventhandling/async/AsynchronousEventProcessingStrategy.java', 'eventsourcing/src/main/java/org/axonframework/eventsourcing/eventstore/jdbc/statements/AppendEventsStatementBuilder.java', 'messaging/src/main/java/org/axonframework/config/EventProcessingConfiguration.java', 'messaging/src/main/java/org/axonframework/eventhandling/async/FullConcurrencyPolicy.java', 'axon-server-connector/src/main/java/org/axonframework/axonserver/connector/event/axon/AxonServerEventStore.java']","['eventsourcing/src/main/java/org/axonframework/eventsourcing/eventstore/jdbc/statements/AppendSnapshotStatementBuilder.java', 'axon-server-connector/src/main/java/org/axonframework/axonserver/connector/event/axon/AxonServerEventScheduler.java', 'eventsourcing/src/main/java/org/axonframework/eventsourcing/eventstore/jdbc/statements/JdbcEventStorageEngineStatements.java', 'eventsourcing/src/main/java/org/axonframework/eventsourcing/eventstore/jdbc/statements/AppendEventsStatementBuilder.java', 'axon-server-connector/src/main/java/org/axonframework/axonserver/connector/event/axon/AxonServerEventStore.java']","['```json\n{\n  ""files"": [\n    ""messaging/src/main/java/org/axonframework/config/EventProcessingConfiguration.java"",\n    ""messaging/src/main/java/org/axonframework/config/EventProcessingModule.java"",\n    ""messaging/src/main/java/org/axonframework/eventhandling/async/AsynchronousEventProcessingStrategy.java"",\n    ""messaging/src/main/java/org/axonframework/eventhandling/async/FullConcurrencyPolicy.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""eventsourcing/src/main/java/org/axonframework/eventsourcing/eventstore/jdbc/statements/JdbcEventStorageEngineStatements.java"",\n    ""axon-server-connector/src/main/java/org/axonframework/axonserver/connector/event/axon/AxonServerEventStore.java"",\n    ""axon-server-connector/src/main/java/org/axonframework/axonserver/connector/event/axon/AxonServerEventScheduler.java"",\n    ""eventsourcing/src/main/java/org/axonframework/eventsourcing/eventstore/jdbc/statements/AppendEventsStatementBuilder.java"",\n    ""eventsourcing/src/main/java/org/axonframework/eventsourcing/eventstore/jdbc/statements/AppendSnapshotStatementBuilder.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""eventsourcing/src/main/java/org/axonframework/eventsourcing/eventstore/jdbc/statements/AppendEventsStatementBuilder.java"",\n    ""eventsourcing/src/main/java/org/axonframework/eventsourcing/eventstore/jdbc/statements/AppendSnapshotStatementBuilder.java"",\n    ""eventsourcing/src/main/java/org/axonframework/eventsourcing/eventstore/jdbc/statements/JdbcEventStorageEngineStatements.java"",\n    ""axon-server-connector/src/main/java/org/axonframework/axonserver/connector/event/axon/AxonServerEventStore.java"",\n    ""axon-server-connector/src/main/java/org/axonframework/axonserver/connector/event/axon/AxonServerEventScheduler.java""\n  ]\n}\n```']",2,6450.576066970825
65,webbukkit/dynmap/3990/3982,webbukkit,dynmap,https://github.com/webbukkit/dynmap/issues/3982,https://github.com/webbukkit/dynmap/pull/3990,https://github.com/webbukkit/dynmap/pull/3990#issuecomment-1628628414,1,fixes,Dynmap does not disable properly if using wrong platform,"**Issue Description:** *Dynmap does not disable properly, when on the wrong version of bukkit forks*

* **Dynmap Version:** *3.0<version<3.6*
* **Server Version:** *1.20.1*
* **Steps to Replicate:** *Run dynmap 3.5 or lower for a unsupported platform, and have another plugin with dynmap as a dependency,*

Sorry for ruining your template. Doing this in DynmapPlugin#onEnable should work right? (this is really an issue in 3.6 as well, what I noticed):
```java
       if (helper == null) {
            Log.info(""Dynmap is disabled (unsupported platform)"");
            this.setEnabled(false); // Added this line
            return;
        }
```

 [x] *I have looked at all other issues and this is not a duplicate*  
 [x] *I have been able to replicate this*
",87d8c7394151122bf77163c740d27f270213d62b,2503dbfdbb1fe3cb0f7acd4c2f4ca1ccd6349eb6,https://github.com/webbukkit/dynmap/compare/87d8c7394151122bf77163c740d27f270213d62b...2503dbfdbb1fe3cb0f7acd4c2f4ca1ccd6349eb6,"diff --git a/spigot/src/main/java/org/dynmap/bukkit/DynmapPlugin.java b/spigot/src/main/java/org/dynmap/bukkit/DynmapPlugin.java
index b2ad4e66..d54154fc 100644
--- a/spigot/src/main/java/org/dynmap/bukkit/DynmapPlugin.java
+++ b/spigot/src/main/java/org/dynmap/bukkit/DynmapPlugin.java
@@ -914,6 +914,7 @@ public class DynmapPlugin extends JavaPlugin implements DynmapAPI {
         }
         if (helper == null) {
             Log.info(""Dynmap is disabled (unsupported platform)"");
+            this.setEnabled(false);
             return;
         }
         PluginDescriptionFile pdfFile = this.getDescription();",['spigot/src/main/java/org/dynmap/bukkit/DynmapPlugin.java'],{'.java': 1},1,1,0,0,1,4989818,1134908,141482,805,36,5,1,1,777,110,195,18,0,1,2023-07-10 09:49:22,1882,Java,"{'Java': 4992284, 'JavaScript': 528125, 'PHP': 56381, 'CSS': 34930, 'HTML': 7454, 'ASP.NET': 1292}",Apache License 2.0,"['spigot/src/main/java/org/dynmap/bukkit/permissions/NijikokunPermissions.java', 'NBT.java', 'spigot/src/main/java/org/dynmap/bukkit/permissions/GroupManagerPermissions.java', 'spigot/src/main/java/org/dynmap/bukkit/permissions/BukkitPermissions.java', 'DynmapCore/src/main/java/org/dynmap/common/chunk/GenericChunkCache.java', 'spigot/src/main/java/org/dynmap/bukkit/permissions/LuckPerms5Permissions.java', 'DynmapCore/src/main/java/org/dynmap/common/chunk/GenericChunk.java', 'DynmapCore/src/main/java/org/dynmap/common/chunk/GenericMapChunkCache.java', 'spigot/src/main/java/org/dynmap/bukkit/Helper.java', 'spigot/src/main/java/org/dynmap/bukkit/permissions/LuckPermsPermissions.java', 'spigot/src/main/java/org/dynmap/bukkit/DynmapPlugin.java']",['spigot/src/main/java/org/dynmap/bukkit/DynmapPlugin.java'],"['```json\n{\n  ""files"": [\n    ""spigot/src/main/java/org/dynmap/bukkit/DynmapPlugin.java"",\n    ""spigot/src/main/java/org/dynmap/bukkit/Helper.java"",\n    ""DynmapCore/src/main/java/org/dynmap/common/chunk/GenericChunk.java"",\n    ""DynmapCore/src/main/java/org/dynmap/common/chunk/GenericChunkCache.java"",\n    ""DynmapCore/src/main/java/org/dynmap/common/chunk/GenericMapChunkCache.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""spigot/src/main/java/org/dynmap/bukkit/permissions/BukkitPermissions.java"",\n    ""spigot/src/main/java/org/dynmap/bukkit/permissions/GroupManagerPermissions.java"",\n    ""spigot/src/main/java/org/dynmap/bukkit/permissions/LuckPerms5Permissions.java"",\n    ""spigot/src/main/java/org/dynmap/bukkit/permissions/LuckPermsPermissions.java"",\n    ""spigot/src/main/java/org/dynmap/bukkit/permissions/NijikokunPermissions.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""NBT.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""spigot/src/main/java/org/dynmap/bukkit/DynmapPlugin.java""\n  ]\n}\n```']",3,5112.715005874634
23,jdbi/jdbi/1339/1338,jdbi,jdbi,https://github.com/jdbi/jdbi/issues/1338,https://github.com/jdbi/jdbi/pull/1339,https://github.com/jdbi/jdbi/pull/1339,2,fixes,TransactionIsolationLevel.UNKNOWN cause unexpected failure,"Hello @jdbi Team!

I was implementing some nifty transactions support which uses `Transaction` annotation of JDBI and got exception I have not expected.

Sample code:

```java
@Rule
public JdbiMySqlRule db = new JdbiMySqlRule();

interface SampleDao {

	@SqlQuery(""select count(*) from sample"")
	int select();
}

static class Bubu {

	@Transaction
	public void doSomething() {
	}
}

@Test
public void test_tx() throws NoSuchMethodException, SecurityException {

	final Method method = Bubu.class.getDeclaredMethod(""doSomething"");
	final Transaction tx = method.getAnnotation(Transaction.class);

	db.getHandle().inTransaction(tx.value(), c -> {
		return null; // do nothing
	});
}
```

Stack trace:

```plain
org.jdbi.v3.core.transaction.UnableToManipulateTransactionIsolationLevelException: Unable to set isolation level to -2147483648
	at org.jdbi.v3.core.Handle.setTransactionIsolation(Handle.java:477)
	at org.jdbi.v3.core.Handle.setTransactionIsolation(Handle.java:461)
	at org.jdbi.v3.core.Handle.inTransaction(Handle.java:430)
	at ***
Caused by: org.h2.jdbc.JdbcSQLException: Invalid value ""-2147483648"" for parameter ""level"" [90008-197]
	at org.h2.message.DbException.getJdbcSQLException(DbException.java:357)
	at org.h2.message.DbException.get(DbException.java:179)
	at org.h2.message.DbException.getInvalidValueException(DbException.java:240)
	at org.h2.jdbc.JdbcConnection.setTransactionIsolation(JdbcConnection.java:744)
	at org.jdbi.v3.core.Handle.setTransactionIsolation(Handle.java:475)
	... 32 more
```

I understand why this is happening, but from API point of view this is rather unexpected since  `TransactionIsolationLevel.UNKNOWN`, which is a default `Transaction` value, is a valid enum value. As API user I would expect not to have any errors regardless of `TransactionIsolationLevel` being used.

There is this method in `Handle` class: https://github.com/jdbi/jdbi/blob/master/core/src/main/java/org/jdbi/v3/core/Handle.java#L472-L482

```java
    /**
     * Set the transaction isolation level on the underlying connection.
     *
     * @param level the isolation level to use
     */
    public void setTransactionIsolation(int level) {
        try {
            if (connection.getTransactionIsolation() == level) {
                // already set, noop
                return;
            }
            connection.setTransactionIsolation(level);
        } catch (SQLException e) {
            throw new UnableToManipulateTransactionIsolationLevelException(level, e);
        }
    }
```

Which I think should be changed to:

```java
    /**
     * Set the transaction isolation level on the underlying connection.
     *
     * @param level the isolation level to use
     */
    public void setTransactionIsolation(int level) {
        try {
            boolean isAlreadySet = level == connection.getTransactionIsolation();
            boolean isUnknown = level == TransactionIsolationLevel.UNKNOWN;
            if (isAlreadySet || isUnknown) {
                // already set or unknown, noop
                return;
            }
            connection.setTransactionIsolation(level);
        } catch (SQLException e) {
            throw new UnableToManipulateTransactionIsolationLevelException(level, e);
        }
    }
```

So that `TransactionIsolationLevel.UNKNOWN` is handled as a special case.

I see this already done in [`TransactionDecorator`](https://github.com/jdbi/jdbi/blob/a831d3314db43859c9894aa987d3ee4827edc459/sqlobject/src/main/java/org/jdbi/v3/sqlobject/transaction/internal/TransactionDecorator.java#L58-L62) and I'm wondering - why this is done in abstraction and not on a lower lever, in a `Handle` class. Is there something I am missing? Something which requires `Handle` to fail when transaction isolation level is unknown?

One of the other options is to have `inTransaction()` method modified to detect this case, but this will rather mask the problem, not fix it. IMHO `TransactionIsolationLevel.UNKNOWN` should be handled at the most bottom layer, before it's propagated to `Connection`, but I may be wrong since I'm not as familiar with JDBI internals as you are, guys.

This concludes my issue.",981eea33dc4b0fdb8640144e599680fe77e4fe8c,4fe1e506618993f0dc78c2cda1505d41de147d34,https://github.com/jdbi/jdbi/compare/981eea33dc4b0fdb8640144e599680fe77e4fe8c...4fe1e506618993f0dc78c2cda1505d41de147d34,"diff --git a/core/src/main/java/org/jdbi/v3/core/Handle.java b/core/src/main/java/org/jdbi/v3/core/Handle.java
index 26701def2..755644870 100644
--- a/core/src/main/java/org/jdbi/v3/core/Handle.java
+++ b/core/src/main/java/org/jdbi/v3/core/Handle.java
@@ -458,10 +458,14 @@ public class Handle implements Closeable, Configurable<Handle> {
     /**
      * Set the transaction isolation level on the underlying connection.
      *
+     * @throws UnableToManipulateTransactionIsolationLevelException if isolation level is not supported by the underlying connection or JDBC driver
+     *
      * @param level the isolation level to use
      */
     public void setTransactionIsolation(TransactionIsolationLevel level) {
-        setTransactionIsolation(level.intValue());
+        if (level != TransactionIsolationLevel.UNKNOWN) {
+            setTransactionIsolation(level.intValue());
+        }
     }
 
     /**
@@ -471,11 +475,9 @@ public class Handle implements Closeable, Configurable<Handle> {
      */
     public void setTransactionIsolation(int level) {
         try {
-            if (connection.getTransactionIsolation() == level) {
-                // already set, noop
-                return;
+            if (connection.getTransactionIsolation() != level) {
+                connection.setTransactionIsolation(level);
             }
-            connection.setTransactionIsolation(level);
         } catch (SQLException e) {
             throw new UnableToManipulateTransactionIsolationLevelException(level, e);
         }
diff --git a/core/src/main/java/org/jdbi/v3/core/Jdbi.java b/core/src/main/java/org/jdbi/v3/core/Jdbi.java
index 7b99632f9..a5bbc6539 100644
--- a/core/src/main/java/org/jdbi/v3/core/Jdbi.java
+++ b/core/src/main/java/org/jdbi/v3/core/Jdbi.java
@@ -399,7 +399,7 @@ public class Jdbi implements Configurable<Jdbi> {
      * @throws X any exception thrown by the callback
      */
     public <R, X extends Exception> R inTransaction(final TransactionIsolationLevel level, final HandleCallback<R, X> callback) throws X {
-        return withHandle(handle -> handle.<R, X>inTransaction(level, callback));
+        return withHandle(handle -> handle.inTransaction(level, callback));
     }
 
     /**
diff --git a/core/src/test/java/org/jdbi/v3/core/TestHandle.java b/core/src/test/java/org/jdbi/v3/core/TestHandle.java
index 80d0317e6..711471c2e 100644
--- a/core/src/test/java/org/jdbi/v3/core/TestHandle.java
+++ b/core/src/test/java/org/jdbi/v3/core/TestHandle.java
@@ -14,10 +14,14 @@
 package org.jdbi.v3.core;
 
 import org.jdbi.v3.core.rule.H2DatabaseRule;
+import org.jdbi.v3.core.transaction.TransactionIsolationLevel;
+import org.jdbi.v3.core.transaction.UnableToManipulateTransactionIsolationLevelException;
 import org.junit.Rule;
 import org.junit.Test;
 
 import static org.assertj.core.api.Assertions.assertThat;
+import static org.assertj.core.api.Assertions.assertThatCode;
+import static org.assertj.core.api.Assertions.assertThatThrownBy;
 
 public class TestHandle {
     @Rule
@@ -62,4 +66,15 @@ public class TestHandle {
         final Handle h = dbRule.getSharedHandle();
         h.execute(""CREATE TABLE \\""\\u2603\\"" (pk int primary key)"");
     }
+
+    @Test
+    public void unknownTransactionLevelIsOk() {
+        Handle h = dbRule.openHandle();
+
+        assertThatThrownBy(() -> h.setTransactionIsolation(Integer.MIN_VALUE))
+            .isInstanceOf(UnableToManipulateTransactionIsolationLevelException.class);
+
+        assertThatCode(() -> h.setTransactionIsolation(TransactionIsolationLevel.UNKNOWN))
+            .doesNotThrowAnyException();
+    }
 }
diff --git a/sqlobject/src/main/java/org/jdbi/v3/sqlobject/transaction/internal/TransactionDecorator.java b/sqlobject/src/main/java/org/jdbi/v3/sqlobject/transaction/internal/TransactionDecorator.java
index b7c6ce9d9..ca7c6f663 100644
--- a/sqlobject/src/main/java/org/jdbi/v3/sqlobject/transaction/internal/TransactionDecorator.java
+++ b/sqlobject/src/main/java/org/jdbi/v3/sqlobject/transaction/internal/TransactionDecorator.java
@@ -55,11 +55,7 @@ public class TransactionDecorator implements HandlerDecorator {
             }
 
             try {
-                if (isolation == TransactionIsolationLevel.UNKNOWN) {
-                    return h.inTransaction(callback);
-                } else {
-                    return h.inTransaction(isolation, callback);
-                }
+                return h.inTransaction(isolation, callback);
             } finally {
                 if (flipReadOnly) {
                     h.setReadOnly(!readOnly);","['sqlobject/src/main/java/org/jdbi/v3/sqlobject/transaction/internal/TransactionDecorator.java', 'core/src/test/java/org/jdbi/v3/core/TestHandle.java', 'core/src/main/java/org/jdbi/v3/core/Jdbi.java', 'core/src/main/java/org/jdbi/v3/core/Handle.java']",{'.java': 4},4,4,0,0,4,1185510,248249,32783,438,1102,186,20,3,4260,422,954,105,2,4,2018-12-12 11:03:53,1804,Java,"{'Java': 3750631, 'Kotlin': 121092, 'HTML': 33996, 'FreeMarker': 5773, 'ANTLR': 5398, 'Makefile': 3525, 'PLSQL': 1420, 'Shell': 981}",Apache License 2.0,['core/src/main/java/org/jdbi/v3/core/Handle.java'],['core/src/main/java/org/jdbi/v3/core/Handle.java'],"['```json\n{\n  ""files"": [\n    ""core/src/main/java/org/jdbi/v3/core/Handle.java""\n  ]\n}\n```']",1,1258.415699005127
530,spring-projects/spring-session/450/445,spring-projects,spring-session,https://github.com/spring-projects/spring-session/issues/445,https://github.com/spring-projects/spring-session/pull/450,https://github.com/spring-projects/spring-session/pull/450,2,fixes,JdbcOperationsSessionRepository ignores lastAccessTime,"Session always expires after maxInactiveInterval since creation, because lastAccessTime is not loaded from database column.

Session inactivity is checked using de-serialized object, which is **not** updated using UPDATE_SESSION_LAST_ACCESS_TIME_QUERY executed when there are no changes to session attributes.

Session in deleted by the check session.isExpired() in JdbcOperationsSessionRepository.getSession(String id)
",bd2d84691794b8c23f081cec998289b67c99b037,63006db45d4a5d29534078b04c78640c3181e179,https://github.com/spring-projects/spring-session/compare/bd2d84691794b8c23f081cec998289b67c99b037...63006db45d4a5d29534078b04c78640c3181e179,"diff --git a/spring-session/src/integration-test/java/org/springframework/session/jdbc/JdbcOperationsSessionRepositoryITests.java b/spring-session/src/integration-test/java/org/springframework/session/jdbc/JdbcOperationsSessionRepositoryITests.java
index 0c0b7221..07588690 100644
--- a/spring-session/src/integration-test/java/org/springframework/session/jdbc/JdbcOperationsSessionRepositoryITests.java
+++ b/spring-session/src/integration-test/java/org/springframework/session/jdbc/JdbcOperationsSessionRepositoryITests.java
@@ -37,6 +37,7 @@ import org.springframework.security.core.Authentication;
 import org.springframework.security.core.authority.AuthorityUtils;
 import org.springframework.security.core.context.SecurityContext;
 import org.springframework.security.core.context.SecurityContextHolder;
+import org.springframework.session.ExpiringSession;
 import org.springframework.session.FindByIndexNameSessionRepository;
 import org.springframework.session.MapSession;
 import org.springframework.session.Session;
@@ -135,6 +136,26 @@ public class JdbcOperationsSessionRepositoryITests {
 		this.repository.delete(toSave.getId());
 	}
 
+	@Test
+	public void updateLastAccessedTime() {
+		JdbcOperationsSessionRepository.JdbcSession toSave = this.repository
+				.createSession();
+		toSave.setLastAccessedTime(System.currentTimeMillis()
+				- (MapSession.DEFAULT_MAX_INACTIVE_INTERVAL_SECONDS * 1000 + 1000));
+
+		this.repository.save(toSave);
+
+		long lastAccessedTime = System.currentTimeMillis();
+		toSave.setLastAccessedTime(lastAccessedTime);
+		this.repository.save(toSave);
+
+		ExpiringSession session = this.repository.getSession(toSave.getId());
+
+		assertThat(session).isNotNull();
+		assertThat(session.isExpired()).isFalse();
+		assertThat(session.getLastAccessedTime()).isEqualTo(lastAccessedTime);
+	}
+
 	@Test
 	public void findByPrincipalName() throws Exception {
 		String principalName = ""findByPrincipalName"" + UUID.randomUUID();
diff --git a/spring-session/src/main/java/org/springframework/session/jdbc/JdbcOperationsSessionRepository.java b/spring-session/src/main/java/org/springframework/session/jdbc/JdbcOperationsSessionRepository.java
index cd7b3866..a515cdbf 100644
--- a/spring-session/src/main/java/org/springframework/session/jdbc/JdbcOperationsSessionRepository.java
+++ b/spring-session/src/main/java/org/springframework/session/jdbc/JdbcOperationsSessionRepository.java
@@ -102,7 +102,7 @@ public class JdbcOperationsSessionRepository implements
 
 	private static final String CREATE_SESSION_QUERY = ""INSERT INTO %TABLE_NAME%(SESSION_ID, LAST_ACCESS_TIME, PRINCIPAL_NAME, SESSION_BYTES) VALUES (?, ?, ?, ?)"";
 
-	private static final String GET_SESSION_QUERY = ""SELECT SESSION_BYTES FROM %TABLE_NAME% WHERE SESSION_ID = ?"";
+	private static final String GET_SESSION_QUERY = ""SELECT LAST_ACCESS_TIME, SESSION_BYTES FROM %TABLE_NAME% WHERE SESSION_ID = ?"";
 
 	private static final String UPDATE_SESSION_QUERY = ""UPDATE %TABLE_NAME% SET LAST_ACCESS_TIME = ?, PRINCIPAL_NAME = ?, SESSION_BYTES = ? WHERE SESSION_ID = ?"";
 
@@ -110,7 +110,7 @@ public class JdbcOperationsSessionRepository implements
 
 	private static final String DELETE_SESSION_QUERY = ""DELETE FROM %TABLE_NAME% WHERE SESSION_ID = ?"";
 
-	private static final String LIST_SESSIONS_BY_PRINCIPAL_NAME_QUERY = ""SELECT SESSION_BYTES FROM %TABLE_NAME% WHERE PRINCIPAL_NAME = ?"";
+	private static final String LIST_SESSIONS_BY_PRINCIPAL_NAME_QUERY = ""SELECT LAST_ACCESS_TIME, SESSION_BYTES FROM %TABLE_NAME% WHERE PRINCIPAL_NAME = ?"";
 
 	private static final String DELETE_SESSIONS_BY_LAST_ACCESS_TIME_QUERY = ""DELETE FROM %TABLE_NAME% WHERE LAST_ACCESS_TIME < ?"";
 
@@ -473,12 +473,14 @@ public class JdbcOperationsSessionRepository implements
 	private class ExpiringSessionMapper implements RowMapper<ExpiringSession> {
 
 		public ExpiringSession mapRow(ResultSet rs, int rowNum) throws SQLException {
-			return (ExpiringSession) JdbcOperationsSessionRepository.this.conversionService
-					.convert(
+			ExpiringSession session = (ExpiringSession) JdbcOperationsSessionRepository
+					.this.conversionService.convert(
 							JdbcOperationsSessionRepository.this.lobHandler
 									.getBlobAsBytes(rs, ""SESSION_BYTES""),
 							TypeDescriptor.valueOf(byte[].class),
 							TypeDescriptor.valueOf(ExpiringSession.class));
+			session.setLastAccessedTime(rs.getLong(""LAST_ACCESS_TIME""));
+			return session;
 		}
 
 	}
diff --git a/spring-session/src/test/java/org/springframework/session/jdbc/JdbcOperationsSessionRepositoryTests.java b/spring-session/src/test/java/org/springframework/session/jdbc/JdbcOperationsSessionRepositoryTests.java
index d4714b01..b2e5da1f 100644
--- a/spring-session/src/test/java/org/springframework/session/jdbc/JdbcOperationsSessionRepositoryTests.java
+++ b/spring-session/src/test/java/org/springframework/session/jdbc/JdbcOperationsSessionRepositoryTests.java
@@ -212,7 +212,6 @@ public class JdbcOperationsSessionRepositoryTests {
 	}
 
 	@Test
-	@SuppressWarnings(""unchecked"")
 	public void getSessionNotFound() {
 		String sessionId = ""testSessionId"";
 
@@ -225,10 +224,10 @@ public class JdbcOperationsSessionRepositoryTests {
 	}
 
 	@Test
-	@SuppressWarnings(""unchecked"")
 	public void getSessionExpired() {
 		MapSession expired = new MapSession();
-		expired.setMaxInactiveIntervalInSeconds(0);
+		expired.setLastAccessedTime(System.currentTimeMillis() -
+				(MapSession.DEFAULT_MAX_INACTIVE_INTERVAL_SECONDS * 1000 + 1000));
 		given(this.jdbcOperations.queryForObject(startsWith(""SELECT""),
 				eq(new Object[] { expired.getId() }), isA(RowMapper.class)))
 						.willReturn(expired);
@@ -244,7 +243,6 @@ public class JdbcOperationsSessionRepositoryTests {
 	}
 
 	@Test
-	@SuppressWarnings(""unchecked"")
 	public void getSessionFound() {
 		MapSession saved = new MapSession();
 		saved.setAttribute(""savedName"", ""savedValue"");
@@ -283,7 +281,6 @@ public class JdbcOperationsSessionRepositoryTests {
 	}
 
 	@Test
-	@SuppressWarnings(""unchecked"")
 	public void findByIndexNameAndIndexValuePrincipalIndexNameNotFound() {
 		String principal = ""username"";
 
@@ -298,7 +295,6 @@ public class JdbcOperationsSessionRepositoryTests {
 	}
 
 	@Test
-	@SuppressWarnings(""unchecked"")
 	public void findByIndexNameAndIndexValuePrincipalIndexNameFound() {
 		String principal = ""username"";
 		Authentication authentication = new UsernamePasswordAuthenticationToken(principal,","['spring-session/src/test/java/org/springframework/session/jdbc/JdbcOperationsSessionRepositoryTests.java', 'spring-session/src/integration-test/java/org/springframework/session/jdbc/JdbcOperationsSessionRepositoryITests.java', 'spring-session/src/main/java/org/springframework/session/jdbc/JdbcOperationsSessionRepository.java']",{'.java': 3},3,3,0,0,3,471995,101064,14301,146,839,185,10,1,420,47,75,6,0,0,2016-03-28 15:18:40,1796,Java,"{'Java': 1667930, 'Groovy': 56498, 'HTML': 36763, 'JavaScript': 12662, 'Ruby': 7007, 'Shell': 213}",Apache License 2.0,['spring-session/src/main/java/org/springframework/session/jdbc/JdbcOperationsSessionRepository.java'],['spring-session/src/main/java/org/springframework/session/jdbc/JdbcOperationsSessionRepository.java'],"['```json\n{\n  ""files"": [\n    ""spring-session/src/main/java/org/springframework/session/jdbc/JdbcOperationsSessionRepository.java""\n  ]\n}\n```']",1,965.2140140533447
1365,synthetichealth/synthea/410/395,synthetichealth,synthea,https://github.com/synthetichealth/synthea/issues/395,https://github.com/synthetichealth/synthea/pull/410,https://github.com/synthetichealth/synthea/pull/410,1,fixes,Latitude and Longitude are reversed,"The latitude and longitude of patient coordinates appear to be reversed. It's consistent though as patients are correctly assigned to the geographically closest provider, not some random corner of the state.


From a sample FHIR record for a patient in MA:

```
        ""address"": [
          {
            ""extension"": [
              {
                ""url"": ""http://hl7.org/fhir/StructureDefinition/geolocation"",
                ""extension"": [
                  {
                    ""url"": ""latitude"",
                    ""valueDecimal"": -71.026717
                  },
                  {
                    ""url"": ""longitude"",
                    ""valueDecimal"": 42.021617
                  }
                ]
              }
            ],
```
",87661476ec2da9829584cca394506fef4c4e5ef7,9d9e276ab393003352432576df648a3b297407a7,https://github.com/synthetichealth/synthea/compare/87661476ec2da9829584cca394506fef4c4e5ef7...9d9e276ab393003352432576df648a3b297407a7,"diff --git a/src/main/java/org/mitre/synthea/export/FhirDstu2.java b/src/main/java/org/mitre/synthea/export/FhirDstu2.java
index 036e09c05..37adfd8c1 100644
--- a/src/main/java/org/mitre/synthea/export/FhirDstu2.java
+++ b/src/main/java/org/mitre/synthea/export/FhirDstu2.java
@@ -388,7 +388,7 @@ public class FhirDstu2 {
       addrResource.setCountry(COUNTRY_CODE);
     }
 
-    DirectPosition2D coord = (DirectPosition2D) person.attributes.get(Person.COORDINATE);
+    DirectPosition2D coord = person.getLatLon();
     if (coord != null) {
       ExtensionDt geolocationExtension = new ExtensionDt();
       geolocationExtension.setUrl(""http://hl7.org/fhir/StructureDefinition/geolocation"");
diff --git a/src/main/java/org/mitre/synthea/export/FhirStu3.java b/src/main/java/org/mitre/synthea/export/FhirStu3.java
index a9f844660..c49d64571 100644
--- a/src/main/java/org/mitre/synthea/export/FhirStu3.java
+++ b/src/main/java/org/mitre/synthea/export/FhirStu3.java
@@ -483,7 +483,7 @@ public class FhirStu3 {
           mapCodeToCodeableConcept(maritalStatusCode, ""http://hl7.org/fhir/v3/MaritalStatus""));
     }
 
-    DirectPosition2D coord = (DirectPosition2D) person.attributes.get(Person.COORDINATE);
+    DirectPosition2D coord = person.getLatLon();
     if (coord != null) {
       Extension geolocation = addrResource.addExtension();
       geolocation.setUrl(""http://hl7.org/fhir/StructureDefinition/geolocation"");
diff --git a/src/main/java/org/mitre/synthea/world/agents/Provider.java b/src/main/java/org/mitre/synthea/world/agents/Provider.java
index db27a6194..293c6bbec 100644
--- a/src/main/java/org/mitre/synthea/world/agents/Provider.java
+++ b/src/main/java/org/mitre/synthea/world/agents/Provider.java
@@ -272,7 +272,7 @@ public class Provider implements QuadTreeData {
     }
     double lat = Double.parseDouble(line.remove(""LAT""));
     double lon = Double.parseDouble(line.remove(""LON""));
-    d.coordinates = new DirectPosition2D(lat, lon);
+    d.coordinates = new DirectPosition2D(lon, lat);
     return d;
   }
 
diff --git a/src/main/java/org/mitre/synthea/world/geography/Place.java b/src/main/java/org/mitre/synthea/world/geography/Place.java
index c6afdff1f..e270212bd 100644
--- a/src/main/java/org/mitre/synthea/world/geography/Place.java
+++ b/src/main/java/org/mitre/synthea/world/geography/Place.java
@@ -31,7 +31,7 @@ public class Place implements QuadTreeData {
     this.postalCode = row.get(""ZCTA5"");
     double lat = Double.parseDouble(row.get(""LAT""));
     double lon = Double.parseDouble(row.get(""LON""));
-    this.coordinate = new DirectPosition2D(lat, lon);
+    this.coordinate = new DirectPosition2D(lon, lat);
   }
   
   /**","['src/main/java/org/mitre/synthea/world/agents/Provider.java', 'src/main/java/org/mitre/synthea/world/geography/Place.java', 'src/main/java/org/mitre/synthea/export/FhirStu3.java', 'src/main/java/org/mitre/synthea/export/FhirDstu2.java']",{'.java': 4},4,4,0,0,4,640583,146622,17253,49,494,120,8,4,777,68,140,25,1,1,2018-08-23 17:53:08,1790,Java,"{'Java': 2754203, 'FreeMarker': 46623, 'JavaScript': 7344, 'Batchfile': 653, 'Shell': 573}",Apache License 2.0,"['src/main/java/org/mitre/synthea/world/geography/Location.java', 'src/main/java/org/mitre/synthea/world/agents/Person.java', 'src/main/java/org/mitre/synthea/world/agents/Provider.java']","['src/main/java/org/mitre/synthea/world/geography/Location.java', 'src/main/java/org/mitre/synthea/world/agents/Person.java', 'src/main/java/org/mitre/synthea/world/agents/Provider.java']","['```json\n{\n  ""files"": [\n    ""src/main/java/org/mitre/synthea/world/agents/Person.java"",\n    ""src/main/java/org/mitre/synthea/world/agents/Provider.java"",\n    ""src/main/java/org/mitre/synthea/world/geography/Location.java""\n  ]\n}\n```']",1,948.8918781280518
149,naver/ngrinder/189/184,naver,ngrinder,https://github.com/naver/ngrinder/issues/184,https://github.com/naver/ngrinder/pull/189,https://github.com/naver/ngrinder/pull/189,1,fix,Failed to launch ngrinder 3.4,"I've been tried to use ngrinder on ec2 ubuntu 14.04.
I tried 1) war file standalone deployment and 2) deployment with tomcat 7 and both cases failed with same errors. Also, I tried multiple java/tomcat versions and all failed.
Strangely, when I tried it again in another clean digitalocean machine and my local osx with the same environment, it worked.
I guess that anyone can easily reproduce this error because the same thing happens again even on the newly launched ec2 instance.
Please let me know if i'm missing something here.
## Followings are the stack traces

org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'NGrinderDefaultExtensionFinder' defined in file [/home/ubuntu/.ngrinder/tmp/webapp/WEB-INF/classes/org/ngrinder/infra/plugin/finder/NGrinderDefaultExtensionFinder.class]: Unsatisfied dependency expressed through constructor argument with index 0 of type [ro.fortsoft.pf4j.PluginManager]: Error creating bean with name 'NGrinderDefaultPluginManager': Injection of autowired dependencies failed; nested exception is org.springframework.beans.factory.BeanCreationException: Could not autowire method: public void org.ngrinder.infra.plugin.extension.NGrinderDefaultPluginManager.setExtensionFinder(ro.fortsoft.pf4j.ExtensionFinder); nested exception is org.springframework.beans.factory.BeanCurrentlyInCreationException: Error creating bean with name 'NGrinderDefaultExtensionFinder': Requested bean is currently in creation: Is there an unresolvable circular reference?; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'NGrinderDefaultPluginManager': Injection of autowired dependencies failed; nested exception is org.springframework.beans.factory.BeanCreationException: Could not autowire method: public void org.ngrinder.infra.plugin.extension.NGrinderDefaultPluginManager.setExtensionFinder(ro.fortsoft.pf4j.ExtensionFinder); nested exception is org.springframework.beans.factory.BeanCurrentlyInCreationException: Error creating bean with name 'NGrinderDefaultExtensionFinder': Requested bean is currently in creation: Is there an unresolvable circular reference?
        at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:749)
        at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:185)
        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1143)
        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1046)
        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
        at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
        at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
        at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
        at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
        at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
        at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
        at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
        at org.springframework.web.context.ContextLoader.configureAndRefreshWebApplicationContext(ContextLoader.java:444)
        at org.springframework.web.context.ContextLoader.initWebApplicationContext(ContextLoader.java:326)
        at org.springframework.web.context.ContextLoaderListener.contextInitialized(ContextLoaderListener.java:107)
        at org.eclipse.jetty.server.handler.ContextHandler.callContextInitialized(ContextHandler.java:800)
        at org.eclipse.jetty.servlet.ServletContextHandler.callContextInitialized(ServletContextHandler.java:444)
        at org.eclipse.jetty.server.handler.ContextHandler.startContext(ContextHandler.java:791)
        at org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:294)
        at org.eclipse.jetty.webapp.WebAppContext.startWebapp(WebAppContext.java:1349)
        at org.eclipse.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1342)
        at org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:741)
        at org.eclipse.jetty.webapp.WebAppContext.doStart(WebAppContext.java:505)
        at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
        at org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:132)
        at org.eclipse.jetty.server.Server.start(Server.java:387)
        at org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:114)
        at org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:61)
        at org.eclipse.jetty.server.Server.doStart(Server.java:354)
        at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
        at org.ngrinder.NGrinderControllerStarter.run(NGrinderControllerStarter.java:236)
        at org.ngrinder.NGrinderControllerStarter.main(NGrinderControllerStarter.java:310)
Caused by:
org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'NGrinderDefaultPluginManager': Injection of autowired dependencies failed; nested exception is org.springframework.beans.factory.BeanCreationException: Could not autowire method: public void org.ngrinder.infra.plugin.extension.NGrinderDefaultPluginManager.setExtensionFinder(ro.fortsoft.pf4j.ExtensionFinder); nested exception is org.springframework.beans.factory.BeanCurrentlyInCreationException: Error creating bean with name 'NGrinderDefaultExtensionFinder': Requested bean is currently in creation: Is there an unresolvable circular reference?
        at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:334)
        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1214)
        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:543)
        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
        at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
        at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
        at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
        at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
        at org.springframework.beans.factory.support.DefaultListableBeanFactory.findAutowireCandidates(DefaultListableBeanFactory.java:1192)
        at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1116)
        at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1014)
        at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:813)
        at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:741)
        at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:185)
        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1143)
        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1046)
        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
        at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
        at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
        at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
        at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
        at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
        at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:223)
        at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
        at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
        at org.springframework.beans.factory.support.DefaultListableBeanFactory.findAutowireCandidates(DefaultListableBeanFactory.java:1192)
        at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1116)
        at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1014)
        at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredMethodElement.inject(AutowiredAnnotationBeanPostProcessor.java:618)
        at org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:88)
        at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.postProcessPropertyValues(AutowiredAnnotationBeanPostProcessor.java:331)
        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1214)
        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:543)
        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
        at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
        at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
        at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
        at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
        at org.springframework.beans.factory.support.DefaultListableBeanFactory.findAutowireCandidates(DefaultListableBeanFactory.java:1192)
        at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1116)
        at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1014)
        at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:813)
        at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:741)
        at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:185)
        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1143)
        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1046)
        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:510)
        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482)
        at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306)
        at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)
        at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302)
        at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:197)
        at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:772)
        at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:839)
        at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:538)
        at org.springframework.web.context.ContextLoader.configureAndRefreshWebApplicationContext(ContextLoader.java:444)
        at org.springframework.web.context.ContextLoader.initWebApplicationContext(ContextLoader.java:326)
        at org.springframework.web.context.ContextLoaderListener.contextInitialized(ContextLoaderListener.java:107)
        at org.eclipse.jetty.server.handler.ContextHandler.callContextInitialized(ContextHandler.java:800)
        at org.eclipse.jetty.servlet.ServletContextHandler.callContextInitialized(ServletContextHandler.java:444)
        at org.eclipse.jetty.server.handler.ContextHandler.startContext(ContextHandler.java:791)
        at org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:294)
        at org.eclipse.jetty.webapp.WebAppContext.startWebapp(WebAppContext.java:1349)
        at org.eclipse.jetty.webapp.WebAppContext.startContext(WebAppContext.java:1342)
        at org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:741)
        at org.eclipse.jetty.webapp.WebAppContext.doStart(WebAppContext.java:505)
        at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
        at org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:132)
        at org.eclipse.jetty.server.Server.start(Server.java:387)
        at org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:114)
        at org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:61)
        at org.eclipse.jetty.server.Server.doStart(Server.java:354)
        at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68)
        at org.ngrinder.NGrinderControllerStarter.run(NGrinderControllerStarter.java:236)
        at org.ngrinder.NGrinderControllerStarter.main(NGrinderControllerStarter.java:310)
",c522c91d1f477fd78dea09efb205ff3b1e35f3fa,f820dc6cfd0560a0c0d020192c1d1c5c42497e31,https://github.com/naver/ngrinder/compare/c522c91d1f477fd78dea09efb205ff3b1e35f3fa...f820dc6cfd0560a0c0d020192c1d1c5c42497e31,"diff --git a/ngrinder-controller/src/main/java/org/ngrinder/infra/plugin/PluginManager.java b/ngrinder-controller/src/main/java/org/ngrinder/infra/plugin/PluginManager.java
index 09e97e450..0cce37340 100644
--- a/ngrinder-controller/src/main/java/org/ngrinder/infra/plugin/PluginManager.java
+++ b/ngrinder-controller/src/main/java/org/ngrinder/infra/plugin/PluginManager.java
@@ -1,4 +1,4 @@
-/* 
+/*
  * Licensed under the Apache License, Version 2.0 (the ""License"");
  *  you may not use this file except in compliance with the License.
  *  You may obtain a copy of the License at
@@ -9,21 +9,23 @@
  * distributed under the License is distributed on an ""AS IS"" BASIS,
  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  * See the License for the specific language governing permissions and
- * limitations under the License. 
+ * limitations under the License.
  */
 package org.ngrinder.infra.plugin;
 
-import java.util.ArrayList;
-import java.util.List;
-
-import javax.annotation.PostConstruct;
-
 import org.ngrinder.infra.config.Config;
+import org.ngrinder.infra.plugin.extension.NGrinderDefaultPluginManager;
+import org.ngrinder.infra.plugin.extension.NGrinderSpringExtensionFactory;
+import org.ngrinder.infra.plugin.finder.NGrinderDefaultExtensionFinder;
 import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.context.ApplicationContext;
 import org.springframework.context.annotation.Profile;
 import org.springframework.stereotype.Component;
+import ro.fortsoft.pf4j.spring.SpringExtensionFactory;
 
-import ro.fortsoft.pf4j.DefaultPluginManager;
+import javax.annotation.PostConstruct;
+import java.util.ArrayList;
+import java.util.List;
 
 /**
  * Plugin manager which is responsible to initialize the plugin infra.<br/>
@@ -40,9 +42,10 @@ public class PluginManager {
 	@Autowired
 	private Config config;
 
-	@Autowired
-	private DefaultPluginManager manager;
+	private NGrinderDefaultPluginManager manager;
 
+	@Autowired
+	private ApplicationContext applicationContext;
 	/**
 	 * Initialize plugin component.
 	 */
@@ -58,6 +61,9 @@ public class PluginManager {
 	 * Initialize Plugin Framework.
 	 */
 	public void initPluginFramework() {
+		manager = new NGrinderDefaultPluginManager(config, applicationContext);
+		manager.setExtensionFinder(new NGrinderDefaultExtensionFinder(manager));
+		manager.setSpringExtensionFactory(new NGrinderSpringExtensionFactory(manager, applicationContext));
 		manager.loadPlugins();
 		manager.startPlugins();
 	}
diff --git a/ngrinder-controller/src/main/java/org/ngrinder/infra/plugin/extension/NGrinderDefaultPluginManager.java b/ngrinder-controller/src/main/java/org/ngrinder/infra/plugin/extension/NGrinderDefaultPluginManager.java
index f3af53965..ce2c7b73a 100644
--- a/ngrinder-controller/src/main/java/org/ngrinder/infra/plugin/extension/NGrinderDefaultPluginManager.java
+++ b/ngrinder-controller/src/main/java/org/ngrinder/infra/plugin/extension/NGrinderDefaultPluginManager.java
@@ -1,64 +1,60 @@
-package org.ngrinder.infra.plugin.extension;
-
-import java.net.MalformedURLException;
-
-import org.ngrinder.infra.config.Config;
-import org.ngrinder.infra.plugin.finder.NGrinderPluginClasspath;
-import org.springframework.beans.factory.annotation.Autowired;
-import org.springframework.context.ApplicationContext;
-import org.springframework.stereotype.Component;
-
-import ro.fortsoft.pf4j.DefaultPluginManager;
-import ro.fortsoft.pf4j.DefaultPluginRepository;
-import ro.fortsoft.pf4j.DevelopmentPluginClasspath;
-import ro.fortsoft.pf4j.ExtensionFactory;
-import ro.fortsoft.pf4j.ExtensionFinder;
-import ro.fortsoft.pf4j.PluginClasspath;
-import ro.fortsoft.pf4j.RuntimeMode;
-import ro.fortsoft.pf4j.spring.SpringExtensionFactory;
-import ro.fortsoft.pf4j.util.JarFileFilter;
-
-/**
- * DefaultPluginManager extended class.
- *
- * @author Gisoo Gwon ,GeunWoo Son
- * @see https://github.com/decebals/pf4j
- * @since 3.0
- */
-@Component
-public class NGrinderDefaultPluginManager extends DefaultPluginManager {
-
-	@Autowired
-	public NGrinderDefaultPluginManager(Config config, ApplicationContext applicationContext) throws MalformedURLException {
-		super(config.isClustered() ? config.getExHome().getPluginsCacheDirectory() : config.getHome().getPluginsCacheDirectory());
-		super.pluginRepository = new DefaultPluginRepository(config.getHome().getPluginsDirectory(), new JarFileFilter());
-	}
-
-	@Autowired
-	public void setExtensionFinder(ExtensionFinder extensionFinder) {
-		super.extensionFinder = extensionFinder;
-	}
-
-	@Autowired
-	public void setSpringExtensionFactory(SpringExtensionFactory extensionFactory) {
-		super.extensionFactory = extensionFactory;
-	}
-
-	@Override
-	protected PluginClasspath createPluginClasspath() {
-		return new NGrinderPluginClasspath();
-	}
-
-	@Override
-	protected ExtensionFactory createExtensionFactory() {
-		// Disable the default Factory
-		return null;
-	}
-
-	@Override
-	protected ExtensionFinder createExtensionFinder() {
-		// Disable the default finder
-		return null;
-	}
-
-}
+package org.ngrinder.infra.plugin.extension;
+
+import java.net.MalformedURLException;
+
+import org.ngrinder.infra.config.Config;
+import org.ngrinder.infra.plugin.finder.NGrinderPluginClasspath;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.context.ApplicationContext;
+import org.springframework.stereotype.Component;
+
+import ro.fortsoft.pf4j.DefaultPluginManager;
+import ro.fortsoft.pf4j.DefaultPluginRepository;
+import ro.fortsoft.pf4j.DevelopmentPluginClasspath;
+import ro.fortsoft.pf4j.ExtensionFactory;
+import ro.fortsoft.pf4j.ExtensionFinder;
+import ro.fortsoft.pf4j.PluginClasspath;
+import ro.fortsoft.pf4j.RuntimeMode;
+import ro.fortsoft.pf4j.spring.SpringExtensionFactory;
+import ro.fortsoft.pf4j.util.JarFileFilter;
+
+/**
+ * DefaultPluginManager extended class.
+ *
+ * @author Gisoo Gwon ,GeunWoo Son
+ * @see https://github.com/decebals/pf4j
+ * @since 3.0
+ */
+public class NGrinderDefaultPluginManager extends DefaultPluginManager {
+
+	public void setExtensionFinder(ExtensionFinder extensionFinder) {
+		super.extensionFinder = extensionFinder;
+	}
+
+	public NGrinderDefaultPluginManager(Config config, ApplicationContext applicationContext)  {
+		super(config.isClustered() ? config.getExHome().getPluginsCacheDirectory() : config.getHome().getPluginsCacheDirectory());
+		super.pluginRepository = new DefaultPluginRepository(config.getHome().getPluginsDirectory(), new JarFileFilter());
+	}
+
+	public void setSpringExtensionFactory(SpringExtensionFactory extensionFactory) {
+		super.extensionFactory = extensionFactory;
+	}
+
+	@Override
+	protected PluginClasspath createPluginClasspath() {
+		return new NGrinderPluginClasspath();
+	}
+
+	@Override
+	protected ExtensionFactory createExtensionFactory() {
+		// Disable the default Factory
+		return null;
+	}
+
+	@Override
+	protected ExtensionFinder createExtensionFinder() {
+		// Disable the default finder
+		return null;
+	}
+
+}
diff --git a/ngrinder-controller/src/main/java/org/ngrinder/infra/plugin/extension/NGrinderSpringExtensionFactory.java b/ngrinder-controller/src/main/java/org/ngrinder/infra/plugin/extension/NGrinderSpringExtensionFactory.java
index 8ddbfd0d7..d15c0c470 100644
--- a/ngrinder-controller/src/main/java/org/ngrinder/infra/plugin/extension/NGrinderSpringExtensionFactory.java
+++ b/ngrinder-controller/src/main/java/org/ngrinder/infra/plugin/extension/NGrinderSpringExtensionFactory.java
@@ -1,51 +1,45 @@
-package org.ngrinder.infra.plugin.extension;
-
-import org.springframework.beans.factory.annotation.Autowired;
-import org.springframework.context.ApplicationContext;
-import org.springframework.stereotype.Component;
-
-import ro.fortsoft.pf4j.Plugin;
-import ro.fortsoft.pf4j.PluginManager;
-import ro.fortsoft.pf4j.PluginWrapper;
-import ro.fortsoft.pf4j.spring.SpringExtensionFactory;
-import ro.fortsoft.pf4j.spring.SpringPlugin;
-
-/**
- * SpringExtensionFactory extended class.
- * The springframework ApplicationContext injection.
- *
- * @author Gisoo Gwon ,GeunWoo Son
- * @see https://github.com/decebals/pf4j-spring
- * @since 3.0
- */
-@Component
-public class NGrinderSpringExtensionFactory extends SpringExtensionFactory {
-
-	private final PluginManager pluginManager;
-
-	@Autowired
-	private ApplicationContext applicationContext;
-
-	@Autowired
-	public NGrinderSpringExtensionFactory(PluginManager pluginManager) {
-		super(pluginManager);
-		this.pluginManager = pluginManager;
-	}
-
-	protected void setApplicationContext(ApplicationContext applicationContext) {
-		this.applicationContext = applicationContext;
-	}
-
-	@Override
-	public Object create(Class<?> extensionClass) {
-		Object extension = createWithoutSpring(extensionClass);
-		if (extension != null) {
-			PluginWrapper pluginWrapper = pluginManager.whichPlugin(extensionClass);
-			if (pluginWrapper != null) {
-				applicationContext.getAutowireCapableBeanFactory().autowireBean(extension);
-			}
-		}
-		return extension;
-	}
-
-}
+package org.ngrinder.infra.plugin.extension;
+
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.context.ApplicationContext;
+import org.springframework.stereotype.Component;
+
+import ro.fortsoft.pf4j.Plugin;
+import ro.fortsoft.pf4j.PluginManager;
+import ro.fortsoft.pf4j.PluginWrapper;
+import ro.fortsoft.pf4j.spring.SpringExtensionFactory;
+import ro.fortsoft.pf4j.spring.SpringPlugin;
+
+/**
+ * SpringExtensionFactory extended class.
+ * The springframework ApplicationContext injection.
+ *
+ * @author Gisoo Gwon ,GeunWoo Son
+ * @see https://github.com/decebals/pf4j-spring
+ * @since 3.0
+ */
+public class NGrinderSpringExtensionFactory extends SpringExtensionFactory {
+
+	private final PluginManager pluginManager;
+
+	private ApplicationContext applicationContext;
+
+	public NGrinderSpringExtensionFactory(PluginManager pluginManager, ApplicationContext applicationContext) {
+		super(pluginManager);
+		this.pluginManager = pluginManager;
+		this.applicationContext = applicationContext;
+	}
+
+	@Override
+	public Object create(Class<?> extensionClass) {
+		Object extension = createWithoutSpring(extensionClass);
+		if (extension != null) {
+			PluginWrapper pluginWrapper = pluginManager.whichPlugin(extensionClass);
+			if (pluginWrapper != null) {
+				applicationContext.getAutowireCapableBeanFactory().autowireBean(extension);
+			}
+		}
+		return extension;
+	}
+
+}
diff --git a/ngrinder-controller/src/main/java/org/ngrinder/infra/plugin/finder/NGrinderDefaultExtensionFinder.java b/ngrinder-controller/src/main/java/org/ngrinder/infra/plugin/finder/NGrinderDefaultExtensionFinder.java
index 0bf22021c..8e1e14d30 100644
--- a/ngrinder-controller/src/main/java/org/ngrinder/infra/plugin/finder/NGrinderDefaultExtensionFinder.java
+++ b/ngrinder-controller/src/main/java/org/ngrinder/infra/plugin/finder/NGrinderDefaultExtensionFinder.java
@@ -1,31 +1,40 @@
-package org.ngrinder.infra.plugin.finder;
-
-import org.springframework.beans.factory.annotation.Autowired;
-import org.springframework.stereotype.Component;
-
-import ro.fortsoft.pf4j.DefaultExtensionFinder;
-import ro.fortsoft.pf4j.PluginManager;
-
-/**
- * DefaultExtensionFinder extended class.
- * Connect with Finder.
- *
- * @author Gisoo Gwon ,GeunWoo Son
- * @see https://github.com/decebals/pf4j-spring
- * @since 3.0
- */
-@Component
-public class NGrinderDefaultExtensionFinder extends DefaultExtensionFinder{
-
-	@Autowired
-	public NGrinderDefaultExtensionFinder(PluginManager pluginManager) {
-		super(pluginManager);
-		finders.add(new NGrinderServiceProviderExtensionFinder(pluginManager));
-	}
-
-	@Override
-	protected void addDefaults(PluginManager pluginManager) {
-		// Disable the default ProviderExtensionFinder
-	}
-
-}
+package org.ngrinder.infra.plugin.finder;
+
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.stereotype.Component;
+
+import ro.fortsoft.pf4j.DefaultExtensionFinder;
+import ro.fortsoft.pf4j.ExtensionFinder;
+import ro.fortsoft.pf4j.ExtensionWrapper;
+import ro.fortsoft.pf4j.PluginManager;
+
+import java.util.List;
+import java.util.Set;
+
+/**
+ * DefaultExtensionFinder extended class.
+ * Connect with Finder.
+ *
+ * @author Gisoo Gwon ,GeunWoo Son
+ * @see https://github.com/decebals/pf4j-spring
+ * @since 3.0
+ */
+public class NGrinderDefaultExtensionFinder implements ExtensionFinder {
+
+	private NGrinderServiceProviderExtensionFinder finder;
+
+	public NGrinderDefaultExtensionFinder(PluginManager pluginManager) {
+		finder = new NGrinderServiceProviderExtensionFinder(pluginManager);
+	}
+
+
+	@Override
+	public <T> List<ExtensionWrapper<T>> find(Class<T> type) {
+		return finder.find(type);
+	}
+
+	@Override
+	public Set<String> findClassNames(String pluginId) {
+		return finder.findClassNames(pluginId);
+	}
+}","['ngrinder-controller/src/main/java/org/ngrinder/infra/plugin/extension/NGrinderSpringExtensionFactory.java', 'ngrinder-controller/src/main/java/org/ngrinder/infra/plugin/finder/NGrinderDefaultExtensionFinder.java', 'ngrinder-controller/src/main/java/org/ngrinder/infra/plugin/extension/NGrinderDefaultPluginManager.java', 'ngrinder-controller/src/main/java/org/ngrinder/infra/plugin/PluginManager.java']",{'.java': 4},4,4,0,0,4,1206177,276817,40085,357,10112,2242,317,4,15848,477,2962,120,0,0,2016-07-01 15:12:55,1758,Java,"{'Java': 2131561, 'Vue': 441893, 'JavaScript': 33073, 'FreeMarker': 9845, 'Groovy': 7693, 'Python': 4818, 'CSS': 4721, 'HTML': 2433, 'Shell': 2240, 'Dockerfile': 2017, 'Batchfile': 1004}",Apache License 2.0,"['ngrinder-core/src/main/java/org/ngrinder/infra/plugin/finder/NGrinderServiceProviderExtensionFinder.java', 'ngrinder-core/src/main/java/org/ngrinder/infra/plugin/finder/NGrinderDefaultExtensionFinder.java', 'ngrinder-core/src/main/java/org/ngrinder/infra/plugin/finder/NGrinderPluginClasspath.java', 'ngrinder-core/src/main/java/org/ngrinder/infra/plugin/extension/NGrinderDefaultPluginManager.java']",[],"['```json\n{\n  ""files"": [\n    ""ngrinder-core/src/main/java/org/ngrinder/infra/plugin/extension/NGrinderDefaultPluginManager.java"",\n    ""ngrinder-core/src/main/java/org/ngrinder/infra/plugin/finder/NGrinderDefaultExtensionFinder.java"",\n    ""ngrinder-core/src/main/java/org/ngrinder/infra/plugin/finder/NGrinderServiceProviderExtensionFinder.java"",\n    ""ngrinder-core/src/main/java/org/ngrinder/infra/plugin/finder/NGrinderPluginClasspath.java"",\n    ""ngrinder-core/src/main/java/org/ngrinder/infra/plugin/finder/NGrinderDefaultExtensionFinder.java""\n  ]\n}\n```']",1,1970.7937240600586
913,gchq/gaffer/2884/2881,gchq,gaffer,https://github.com/gchq/Gaffer/issues/2881,https://github.com/gchq/Gaffer/pull/2884,https://github.com/gchq/Gaffer/pull/2884,1,resolve,Problems with getOriginalSchema in Federated and Proxy Stores,"Problems have been reported fetching schemas with Federated and Proxy Stores. The current implementation of these stores contain overridden methods for `getSchema` but not `getOriginalSchema`. It's likely that with certain combinations of graphs and stores, the `originalSchema` field could remain `null` or be outdated. This could cause problems with the getSchema operation when used directly on the store (not wrapped) and differences between using a `Store` directly and using it through a `Graph`.

Investigate and fix any problems with Federated and Proxy Store use of `getSchema`/`getOriginalSchema`. This might be as simple as adding overridden methods for `getOriginalSchema`.

**Additional context**
See #2791 for background.
",5f22ae68b1bef77c398919b19a17c4b9f9e3c34f,9ef3e70589b023d3d1b56e079091059d8ca7f44b,https://github.com/gchq/gaffer/compare/5f22ae68b1bef77c398919b19a17c4b9f9e3c34f...9ef3e70589b023d3d1b56e079091059d8ca7f44b,"diff --git a/store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/FederatedGraphStorage.java b/store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/FederatedGraphStorage.java
index 033b3b7c55..1b6aa96e16 100644
--- a/store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/FederatedGraphStorage.java
+++ b/store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/FederatedGraphStorage.java
@@ -27,17 +27,10 @@ import uk.gov.gchq.gaffer.cache.exception.CacheOperationException;
 import uk.gov.gchq.gaffer.commonutil.JsonUtil;
 import uk.gov.gchq.gaffer.commonutil.exception.OverwritingException;
 import uk.gov.gchq.gaffer.commonutil.pair.Pair;
-import uk.gov.gchq.gaffer.core.exception.GafferRuntimeException;
-import uk.gov.gchq.gaffer.data.elementdefinition.exception.SchemaException;
 import uk.gov.gchq.gaffer.federatedstore.exception.StorageException;
-import uk.gov.gchq.gaffer.federatedstore.operation.FederatedOperation;
 import uk.gov.gchq.gaffer.graph.GraphConfig;
 import uk.gov.gchq.gaffer.graph.GraphSerialisable;
-import uk.gov.gchq.gaffer.store.Context;
 import uk.gov.gchq.gaffer.store.library.GraphLibrary;
-import uk.gov.gchq.gaffer.store.operation.GetSchema;
-import uk.gov.gchq.gaffer.store.schema.Schema;
-import uk.gov.gchq.gaffer.store.schema.Schema.Builder;
 import uk.gov.gchq.gaffer.user.User;
 
 import java.util.ArrayList;
@@ -234,35 +227,6 @@ public class FederatedGraphStorage {
         return Collections.unmodifiableList(rtn);
     }
 
-    @Deprecated
-    public Schema getSchema(final FederatedOperation<Void, Object> operation, final Context context) {
-        if (null == context || null == context.getUser()) {
-            // no user then return an empty schema
-            return new Schema();
-        }
-        final List<String> graphIds = isNull(operation) ? null : operation.getGraphIds();
-
-        final Stream<GraphSerialisable> graphs = getStream(context.getUser(), graphIds);
-        final Builder schemaBuilder = new Builder();
-        try {
-            if (nonNull(operation) && operation.hasPayloadOperation() && operation.payloadInstanceOf(GetSchema.class) && ((GetSchema) operation.getPayloadOperation()).isCompact()) {
-                graphs.forEach(gs -> {
-                    try {
-                        schemaBuilder.merge(gs.getGraph().execute((GetSchema) operation.getPayloadOperation(), context));
-                    } catch (final Exception e) {
-                        throw new GafferRuntimeException(""Unable to fetch schema from graph "" + gs.getGraphId(), e);
-                    }
-                });
-            } else {
-                graphs.forEach(g -> schemaBuilder.merge(g.getSchema(graphLibrary)));
-            }
-        } catch (final SchemaException e) {
-            final List<String> resultGraphIds = getStream(context.getUser(), graphIds).map(GraphSerialisable::getGraphId).collect(Collectors.toList());
-            throw new SchemaException(""Unable to merge the schemas for all of your federated graphs: "" + resultGraphIds + "". You can limit which graphs to query for using the FederatedOperation.graphIds option."", e);
-        }
-        return schemaBuilder.build();
-    }
-
     private void validateAllGivenGraphIdsAreVisibleForUser(final User user, final Collection<String> graphIds, final String adminAuth) {
         if (null != graphIds) {
             final Collection<String> visibleIds = getAllIds(user, adminAuth);
diff --git a/store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/FederatedStore.java b/store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/FederatedStore.java
index c880c5ad4c..70aa2e2d13 100644
--- a/store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/FederatedStore.java
+++ b/store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/FederatedStore.java
@@ -58,6 +58,7 @@ import uk.gov.gchq.gaffer.federatedstore.util.ApplyViewToElementsFunction;
 import uk.gov.gchq.gaffer.federatedstore.util.MergeSchema;
 import uk.gov.gchq.gaffer.graph.GraphSerialisable;
 import uk.gov.gchq.gaffer.operation.Operation;
+import uk.gov.gchq.gaffer.operation.OperationException;
 import uk.gov.gchq.gaffer.operation.impl.Validate;
 import uk.gov.gchq.gaffer.operation.impl.add.AddElements;
 import uk.gov.gchq.gaffer.operation.impl.function.Aggregate;
@@ -108,7 +109,6 @@ import static uk.gov.gchq.gaffer.federatedstore.FederatedStoreProperties.IS_PUBL
 import static uk.gov.gchq.gaffer.federatedstore.FederatedStoreProperties.STORE_CONFIGURED_GRAPHIDS;
 import static uk.gov.gchq.gaffer.federatedstore.FederatedStoreProperties.STORE_CONFIGURED_MERGE_FUNCTIONS;
 import static uk.gov.gchq.gaffer.federatedstore.util.FederatedStoreUtil.getCleanStrings;
-import static uk.gov.gchq.gaffer.federatedstore.util.FederatedStoreUtil.getFederatedWrappedSchema;
 import static uk.gov.gchq.gaffer.federatedstore.util.FederatedStoreUtil.loadStoreConfiguredGraphIdsListFrom;
 import static uk.gov.gchq.gaffer.federatedstore.util.FederatedStoreUtil.loadStoreConfiguredMergeFunctionMapFrom;
 
@@ -324,34 +324,50 @@ public class FederatedStore extends Store {
     }
 
     /**
-     * Get {@link Schema} for this FederatedStore
+     * This method exists for compatibility only. It will
+     * always return a blank {@link Schema}. Either use the
+     * {@link FederatedStore#getSchema} method and supply a
+     * {@link Context}, or ideally use the {@link GetSchema}
+     * operation instead.
      *
-     * @return schema
+     * @return {@link Schema} blank schema
      */
     @Override
     public Schema getSchema() {
-        return getSchema((Context) null);
+        return getSchema(new Context(), true);
     }
 
     /**
-     * Get {@link Schema} for this FederatedStore
+     * This method exists for compatibility only. It will
+     * always return a blank {@link Schema}. Either use the
+     * {@link FederatedStore#getSchema} method and supply a
+     * {@link Context}, or ideally use the {@link GetSchema}
+     * operation instead.
      *
-     * @param context context with User.
-     * @return schema
+     * @return {@link Schema} blank schema
      */
-    public Schema getSchema(final Context context) {
-        return getSchema(getFederatedWrappedSchema(), context);
+    @Override
+    public Schema getOriginalSchema() {
+        return getSchema(new Context(), false);
     }
 
     /**
-     * Get {@link Schema} for this FederatedStore
+     * Get {@link Schema} for this FederatedStore.
+     * <p>
+     * This will return a merged schema of the original schemas
+     * or the optimised compact schemas of the stores inside
+     * this FederatedStore.
      *
-     * @param operation operation with graphIds.
-     * @param context   context with User.
+     * @param context context with valid User
+     * @param getCompactSchema if true, gets the optimised compact schemas
      * @return schema
      */
-    public Schema getSchema(final FederatedOperation operation, final Context context) {
-        return graphStorage.getSchema(operation, context);
+    public Schema getSchema(final Context context, final boolean getCompactSchema) {
+        try {
+            return execute(new GetSchema.Builder().compact(getCompactSchema).build(), context);
+        } catch (final OperationException e) {
+            throw new GafferRuntimeException(""Unable to execute GetSchema Operation"", e);
+        }
     }
 
     /**
@@ -589,8 +605,8 @@ public class FederatedStore extends Store {
 
             final List<String> graphIds = new ArrayList<>(storeConfiguredGraphIds);
             final List<String> federatedStoreSystemUser = getAllGraphIds(new User.Builder()
-                    .userId(FEDERATED_STORE_SYSTEM_USER)
-                    .opAuths(this.getProperties().getAdminAuth()).build(),
+                            .userId(FEDERATED_STORE_SYSTEM_USER)
+                            .opAuths(this.getProperties().getAdminAuth()).build(),
                     true);
             graphIds.retainAll(federatedStoreSystemUser);
 
diff --git a/store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/operation/FederatedOperationChainValidator.java b/store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/operation/FederatedOperationChainValidator.java
index d7f8b9c851..c1bc7dfb5b 100644
--- a/store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/operation/FederatedOperationChainValidator.java
+++ b/store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/operation/FederatedOperationChainValidator.java
@@ -1,5 +1,5 @@
 /*
- * Copyright 2016-2022 Crown Copyright
+ * Copyright 2016-2023 Crown Copyright
  *
  * Licensed under the Apache License, Version 2.0 (the ""License"");
  * you may not use this file except in compliance with the License.
@@ -16,13 +16,16 @@
 
 package uk.gov.gchq.gaffer.federatedstore.operation;
 
+import uk.gov.gchq.gaffer.core.exception.GafferRuntimeException;
 import uk.gov.gchq.gaffer.data.elementdefinition.view.View;
 import uk.gov.gchq.gaffer.federatedstore.FederatedStore;
 import uk.gov.gchq.gaffer.graph.GraphSerialisable;
 import uk.gov.gchq.gaffer.operation.Operation;
+import uk.gov.gchq.gaffer.operation.OperationException;
 import uk.gov.gchq.gaffer.store.Context;
 import uk.gov.gchq.gaffer.store.Store;
 import uk.gov.gchq.gaffer.store.StoreTrait;
+import uk.gov.gchq.gaffer.store.operation.GetSchema;
 import uk.gov.gchq.gaffer.store.operation.OperationChainValidator;
 import uk.gov.gchq.gaffer.store.schema.Schema;
 import uk.gov.gchq.gaffer.store.schema.ViewValidator;
@@ -35,7 +38,6 @@ import java.util.List;
 import java.util.stream.Collectors;
 
 import static java.util.Objects.nonNull;
-import static uk.gov.gchq.gaffer.federatedstore.util.FederatedStoreUtil.getFederatedWrappedSchema;
 import static uk.gov.gchq.gaffer.federatedstore.util.FederatedStoreUtil.shallowCloneWithDeepOptions;
 
 /**
@@ -51,9 +53,13 @@ public class FederatedOperationChainValidator extends OperationChainValidator {
 
     @Override
     protected Schema getSchema(final Operation op, final User user, final Store store) {
-        return (op instanceof FederatedOperation)
-                ? ((FederatedStore) store).getSchema(getFederatedWrappedSchema().graphIds(((FederatedOperation) op).getGraphIds()), new Context(user))
-                : ((FederatedStore) store).getSchema(getFederatedWrappedSchema(), new Context(user));
+        try {
+            return (op instanceof FederatedOperation)
+                    ? store.execute(new FederatedOperation.Builder().<Void, Schema>op(new GetSchema()).graphIds(((FederatedOperation<?, ?>) op).getGraphIds()).build(), new Context(user))
+                    : store.execute(new GetSchema(), new Context(user));
+        } catch (final OperationException e) {
+            throw new GafferRuntimeException(""Unable to execute GetSchema Operation"", e);
+        }
     }
 
     @Override
diff --git a/store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/operation/handler/FederatedDelegateToHandler.java b/store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/operation/handler/FederatedDelegateToHandler.java
index 7df3243ad5..fc55f365b3 100644
--- a/store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/operation/handler/FederatedDelegateToHandler.java
+++ b/store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/operation/handler/FederatedDelegateToHandler.java
@@ -1,5 +1,5 @@
 /*
- * Copyright 2022 Crown Copyright
+ * Copyright 2022-2023 Crown Copyright
  *
  * Licensed under the Apache License, Version 2.0 (the ""License"");
  * you may not use this file except in compliance with the License.
@@ -44,7 +44,7 @@ public class FederatedDelegateToHandler implements OutputOperationHandler<InputO
                 || ValidateHandler.class.isAssignableFrom(handler.getClass())
                 || AggregateHandler.class.isAssignableFrom(handler.getClass())) {
             // Use the doOperation which requires a schema.
-            return (Iterable<? extends Element>) ((OperationWithSchemaHandler) handler).doOperation(operation, ((FederatedStore) store).getSchema(context));
+            return (Iterable<? extends Element>) ((OperationWithSchemaHandler) handler).doOperation(operation, ((FederatedStore) store).getSchema(context, true));
         } else {
             return handler.doOperation(operation, context, store);
         }
diff --git a/store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/util/FederatedStoreUtil.java b/store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/util/FederatedStoreUtil.java
index 5732b983b8..b36bb9101d 100644
--- a/store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/util/FederatedStoreUtil.java
+++ b/store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/util/FederatedStoreUtil.java
@@ -280,11 +280,6 @@ public final class FederatedStoreUtil {
         return deprecatedGraphIds;
     }
 
-    @Deprecated
-    public static FederatedOperation<Void, Iterable<Schema>> getFederatedWrappedSchema() {
-        return new FederatedOperation.Builder().<Void, Iterable<Schema>>op(new GetSchema()).build();
-    }
-
     /**
      * Return a clone of the given operations with a deep clone of options.
      * <p>
diff --git a/store-implementation/federated-store/src/test/java/uk/gov/gchq/gaffer/federatedstore/FederatedGraphStorageTest.java b/store-implementation/federated-store/src/test/java/uk/gov/gchq/gaffer/federatedstore/FederatedGraphStorageTest.java
index af1054900d..e4499db2ab 100644
--- a/store-implementation/federated-store/src/test/java/uk/gov/gchq/gaffer/federatedstore/FederatedGraphStorageTest.java
+++ b/store-implementation/federated-store/src/test/java/uk/gov/gchq/gaffer/federatedstore/FederatedGraphStorageTest.java
@@ -1,5 +1,5 @@
 /*
- * Copyright 2017-2022 Crown Copyright
+ * Copyright 2017-2023 Crown Copyright
  *
  * Licensed under the Apache License, Version 2.0 (the ""License"");
  * you may not use this file except in compliance with the License.
@@ -50,7 +50,6 @@ import static org.assertj.core.api.Assertions.assertThatExceptionOfType;
 import static org.assertj.core.api.Assertions.assertThatIllegalArgumentException;
 import static org.junit.jupiter.api.Assertions.assertEquals;
 import static org.junit.jupiter.api.Assertions.assertFalse;
-import static org.junit.jupiter.api.Assertions.assertNotEquals;
 import static org.junit.jupiter.api.Assertions.assertTrue;
 import static org.mockito.Mockito.mock;
 import static uk.gov.gchq.gaffer.federatedstore.FederatedGraphStorage.GRAPH_IDS_NOT_VISIBLE;
@@ -60,9 +59,6 @@ import static uk.gov.gchq.gaffer.federatedstore.FederatedStoreTestUtil.EDGES;
 import static uk.gov.gchq.gaffer.federatedstore.FederatedStoreTestUtil.ENTITIES;
 import static uk.gov.gchq.gaffer.federatedstore.FederatedStoreTestUtil.GRAPH_ID_ACCUMULO;
 import static uk.gov.gchq.gaffer.federatedstore.FederatedStoreTestUtil.STRING;
-import static uk.gov.gchq.gaffer.federatedstore.FederatedStoreTestUtil.contextAuthUser;
-import static uk.gov.gchq.gaffer.federatedstore.FederatedStoreTestUtil.contextBlankUser;
-import static uk.gov.gchq.gaffer.federatedstore.FederatedStoreTestUtil.contextTestUser;
 import static uk.gov.gchq.gaffer.federatedstore.FederatedStoreTestUtil.loadAccumuloStoreProperties;
 import static uk.gov.gchq.gaffer.federatedstore.FederatedStoreTestUtil.resetForFederatedTests;
 import static uk.gov.gchq.gaffer.store.TestTypes.DIRECTED_EITHER;
@@ -295,82 +291,6 @@ public class FederatedGraphStorageTest {
                 .withMessage(String.format(GRAPH_IDS_NOT_VISIBLE, singleton(X)));
     }
 
-    @Test
-    @Deprecated // TODO FS move to FedSchema Tests, when getSchema is deleted
-    public void shouldChangeSchemaWhenAddingGraphB() throws Exception {
-        //given
-        graphStorage.put(graphSerialisableA, auth1Access);
-        final Schema schemaA = graphStorage.getSchema(null, contextTestUser());
-        assertEquals(1, schemaA.getTypes().size());
-        assertEquals(String.class, schemaA.getType(STRING + 1).getClazz());
-        assertEquals(getEntityDefinition(1), schemaA.getElement(ENTITIES + 1));
-        graphStorage.put(graphSerialisableB, auth1Access);
-        final Schema schemaAB = graphStorage.getSchema(null, contextTestUser());
-        assertNotEquals(schemaA, schemaAB);
-        assertEquals(2, schemaAB.getTypes().size());
-        assertEquals(String.class, schemaAB.getType(STRING + 1).getClazz());
-        assertEquals(String.class, schemaAB.getType(STRING + 2).getClazz());
-        assertEquals(getEntityDefinition(1), schemaAB.getElement(ENTITIES + 1));
-        assertEquals(getEntityDefinition(2), schemaAB.getElement(ENTITIES + 2));
-    }
-
-
-    @Test
-    @Deprecated // TODO FS move to FedSchema Tests, when getSchema is deleted
-    public void shouldGetSchemaForOwningUser() throws Exception {
-        graphStorage.put(graphSerialisableA, auth1Access);
-        graphStorage.put(graphSerialisableB, new FederatedAccess(singleton(X), X));
-        final Schema schema = graphStorage.getSchema(null, contextTestUser());
-        assertNotEquals(2, schema.getTypes().size(), ""Revealing hidden schema"");
-        assertEquals(1, schema.getTypes().size());
-        assertEquals(String.class, schema.getType(STRING + 1).getClazz());
-        assertEquals(getEntityDefinition(1), schema.getElement(ENTITIES + 1));
-    }
-
-    @Test
-    @Deprecated // TODO FS move to FedSchema Tests, when getSchema is deleted
-    public void shouldNotGetSchemaForOwningUserWhenBlockingReadAccessPredicateConfigured() throws Exception {
-        graphStorage.put(graphSerialisableA, blockingReadAccess);
-        graphStorage.put(graphSerialisableB, new FederatedAccess(singleton(X), X));
-        final Schema schema = graphStorage.getSchema(null, contextTestUser());
-        assertNotEquals(2, schema.getTypes().size(), ""Revealing hidden schema"");
-        assertEquals(0, schema.getTypes().size(), ""Revealing hidden schema"");
-    }
-
-    @Test
-    @Deprecated // TODO FS move to FedSchema Tests, when getSchema is deleted
-    public void shouldGetSchemaForAuthUser() throws Exception {
-        graphStorage.put(graphSerialisableA, auth1Access);
-        graphStorage.put(graphSerialisableB, new FederatedAccess(singleton(X), X));
-        final Schema schema = graphStorage.getSchema(null, contextAuthUser());
-        assertNotEquals(2, schema.getTypes().size(), ""Revealing hidden schema"");
-        assertEquals(1, schema.getTypes().size());
-        assertEquals(String.class, schema.getType(STRING + 1).getClazz());
-        assertEquals(getEntityDefinition(1), schema.getElement(ENTITIES + 1));
-    }
-
-    @Test
-    @Deprecated // TODO FS move to FedSchema Tests, when getSchema is deleted
-    public void shouldNotGetSchemaForBlankUser() throws Exception {
-        graphStorage.put(graphSerialisableA, auth1Access);
-        graphStorage.put(graphSerialisableB, new FederatedAccess(singleton(X), X));
-        final Schema schema = graphStorage.getSchema(null, contextBlankUser());
-        assertNotEquals(2, schema.getTypes().size(), ""Revealing hidden schema"");
-        assertEquals(0, schema.getTypes().size(), ""Revealing hidden schema"");
-    }
-
-    @Test
-    @Deprecated // TODO FS move to FedSchema Tests, when getSchema is deleted
-    public void shouldGetSchemaForBlankUserWhenPermissiveReadAccessPredicateConfigured() throws Exception {
-        graphStorage.put(graphSerialisableA, permissiveReadAccess);
-        graphStorage.put(graphSerialisableB, new FederatedAccess(singleton(X), X));
-        final Schema schema = graphStorage.getSchema(null, contextBlankUser());
-        assertNotEquals(2, schema.getTypes().size(), ""Revealing hidden schema"");
-        assertEquals(1, schema.getTypes().size());
-        assertEquals(String.class, schema.getType(STRING + 1).getClazz());
-        assertEquals(getEntityDefinition(1), schema.getElement(ENTITIES + 1));
-    }
-
     @Test
     public void shouldRemoveForOwningUser() throws Exception {
         //given
diff --git a/store-implementation/federated-store/src/test/java/uk/gov/gchq/gaffer/federatedstore/FederatedStoreSchemaTest.java b/store-implementation/federated-store/src/test/java/uk/gov/gchq/gaffer/federatedstore/FederatedStoreSchemaTest.java
index 6eb7904ed9..38957ba4c4 100644
--- a/store-implementation/federated-store/src/test/java/uk/gov/gchq/gaffer/federatedstore/FederatedStoreSchemaTest.java
+++ b/store-implementation/federated-store/src/test/java/uk/gov/gchq/gaffer/federatedstore/FederatedStoreSchemaTest.java
@@ -1,5 +1,5 @@
 /*
- * Copyright 2017-2022 Crown Copyright
+ * Copyright 2017-2023 Crown Copyright
  *
  * Licensed under the Apache License, Version 2.0 (the ""License"");
  * you may not use this file except in compliance with the License.
@@ -19,6 +19,9 @@ package uk.gov.gchq.gaffer.federatedstore;
 import org.junit.jupiter.api.BeforeEach;
 import org.junit.jupiter.api.Test;
 
+import uk.gov.gchq.gaffer.access.predicate.AccessPredicate;
+import uk.gov.gchq.gaffer.access.predicate.NoAccessPredicate;
+import uk.gov.gchq.gaffer.access.predicate.UnrestrictedAccessPredicate;
 import uk.gov.gchq.gaffer.accumulostore.AccumuloProperties;
 import uk.gov.gchq.gaffer.data.element.Edge;
 import uk.gov.gchq.gaffer.data.element.Element;
@@ -47,8 +50,10 @@ import uk.gov.gchq.koryphe.impl.predicate.IsEqual;
 import java.util.Arrays;
 import java.util.Collection;
 import java.util.HashSet;
+import java.util.Set;
 import java.util.stream.Collectors;
 
+import static java.util.Collections.singleton;
 import static org.assertj.core.api.Assertions.assertThat;
 import static org.assertj.core.api.Assertions.assertThatExceptionOfType;
 import static uk.gov.gchq.gaffer.federatedstore.FederatedStoreTestUtil.ACCUMULO_STORE_SINGLE_USE_PROPERTIES;
@@ -71,6 +76,9 @@ import static uk.gov.gchq.gaffer.federatedstore.FederatedStoreTestUtil.resetForF
 import static uk.gov.gchq.gaffer.federatedstore.util.FederatedStoreUtil.getDefaultMergeFunction;
 import static uk.gov.gchq.gaffer.federatedstore.util.FederatedStoreUtil.getFederatedOperation;
 import static uk.gov.gchq.gaffer.store.TestTypes.DIRECTED_EITHER;
+import static uk.gov.gchq.gaffer.user.StoreUser.AUTH_1;
+import static uk.gov.gchq.gaffer.user.StoreUser.authUser;
+import static uk.gov.gchq.gaffer.user.StoreUser.blankUser;
 import static uk.gov.gchq.gaffer.user.StoreUser.testUser;
 
 public class FederatedStoreSchemaTest {
@@ -263,6 +271,133 @@ public class FederatedStoreSchemaTest {
                 .isTrue();
     }
 
+    @Test
+    public void shouldGetSchemaWithOperationAndMethodWithContext() throws OperationException {
+        // Given
+        addGraphWith(GRAPH_ID_A, STRING_TYPE, PROPERTY_1);
+
+        // When
+        final Schema schemaFromOperation = federatedStore.execute(new GetSchema.Builder().build(), testContext);
+        final Schema schemaFromStore = federatedStore.getSchema(testContext, false);
+
+        // Then
+        assertThat(schemaFromOperation).isEqualTo(schemaFromStore);
+    }
+
+    @Test
+    public void shouldGetBlankSchemaWhenUsingDefaultMethod() throws OperationException {
+        // Given
+        addGraphWith(GRAPH_ID_A, STRING_TYPE, PROPERTY_1);
+
+        // When
+        final Schema schemaFromStoreMethod = federatedStore.getOriginalSchema(); // No Context, results in blank schema returned
+
+        // Then
+        assertThat(schemaFromStoreMethod).isEqualTo(new Schema());
+    }
+
+    @Test
+    public void shouldGetSchemaWhenUsingDefaultMethodWhenPermissiveReadAccessPredicateConfigured() throws OperationException {
+        // Given
+        addGraphWithContextAndAccess(GRAPH_ID_A, STRING_TYPE, GROUP_BASIC_EDGE, testContext, new UnrestrictedAccessPredicate(), PROPERTY_1);
+
+        // When
+        final Schema schemaFromStoreMethod = federatedStore.getOriginalSchema();
+
+        // Then
+        assertThat(schemaFromStoreMethod.getEdge(GROUP_BASIC_EDGE).getProperties()).contains(PROPERTY_1);
+    }
+
+    @Test
+    public void shouldChangeSchemaWhenAddingGraphB() throws OperationException {
+        // Given
+        addGraphWith(GRAPH_ID_A, STRING_TYPE, PROPERTY_1);
+
+        // When
+        final Schema schemaA = federatedStore.getSchema(testContext, false);
+
+        // Then
+        assertThat(schemaA.getTypes().size()).isEqualTo(2);
+        assertThat(schemaA.getType(STRING).getClazz()).isEqualTo(String.class);
+        assertThat(schemaA.getEdge(GROUP_BASIC_EDGE).getProperties().size()).isEqualTo(1);
+
+        // Given
+        addGraphWith(GRAPH_ID_B, STRING_REQUIRED_TYPE, PROPERTY_2);
+
+        // When
+        final Schema schemaAB = federatedStore.getSchema(testContext, false);
+
+        // Then
+        assertThat(schemaAB).isNotEqualTo(schemaA);
+        assertThat(schemaAB.getEdge(GROUP_BASIC_EDGE).getProperties()).contains(PROPERTY_2);
+    }
+
+    @Test
+    public void shouldGetSchemaForOwningUser() throws OperationException {
+        // Given
+        addGraphWith(GRAPH_ID_A, STRING_REQUIRED_TYPE, PROPERTY_1);
+        addGraphWithContextAndAuths(GRAPH_ID_B, STRING_TYPE, ""hidden"" + GROUP_BASIC_EDGE, singleton(AUTH_1), new Context(authUser()), PROPERTY_2);
+
+        // When
+        final Schema schemaFromOwningUser = federatedStore.getSchema(testContext, false);
+
+        // Then
+        assertThat(schemaFromOwningUser.getEdge(""hidden"" + GROUP_BASIC_EDGE)).withFailMessage(""Revealing hidden schema"").isNull();
+        assertThat(schemaFromOwningUser.getEdge(GROUP_BASIC_EDGE).getProperties()).contains(PROPERTY_1);
+    }
+
+    @Test
+    public void shouldNotGetSchemaForOwningUserWhenBlockingReadAccessPredicateConfigured() throws OperationException {
+        // Given
+        addGraphWithContextAndAccess(GRAPH_ID_A, STRING_TYPE, GROUP_BASIC_EDGE, testContext, new NoAccessPredicate(), PROPERTY_1);
+
+        // When
+        final Schema schemaFromOwningUser = federatedStore.getSchema(testContext, false);
+
+        // Then
+        assertThat(schemaFromOwningUser).withFailMessage(""Revealing blocked schema, should be empty"").isEqualTo(new Schema());
+    }
+
+    @Test
+    public void shouldGetSchemaForAuthUser() throws OperationException {
+        // Given
+        final User authUser = new User.Builder().userId(""authUser2"").opAuths(AUTH_1).build();
+        addGraphWithContextAndAuths(GRAPH_ID_B, STRING_TYPE, GROUP_BASIC_EDGE, singleton(AUTH_1), new Context(authUser()), PROPERTY_1);
+
+        // When
+        final Schema schemaFromAuthUser = federatedStore.getSchema(new Context(authUser), false);
+        final Schema schemaFromTestUser = federatedStore.getSchema(testContext, false);
+
+        // Then
+        assertThat(schemaFromTestUser.getEdge(""hidden"" + GROUP_BASIC_EDGE)).withFailMessage(""Revealing hidden schema"").isNull();
+        assertThat(schemaFromTestUser).withFailMessage(""Revealing hidden schema, should be empty"").isEqualTo(new Schema());
+        assertThat(schemaFromAuthUser.getEdge(GROUP_BASIC_EDGE).getProperties()).contains(PROPERTY_1);
+    }
+
+    @Test
+    public void shouldNotGetSchemaForBlankUser() throws OperationException {
+        // Given
+        addGraphWith(GRAPH_ID_A, STRING_REQUIRED_TYPE, PROPERTY_1);
+
+        // When
+        final Schema schemaFromBlankUser = federatedStore.getSchema(new Context(blankUser()), false);
+
+        // Then
+        assertThat(schemaFromBlankUser).withFailMessage(""Revealing schema to blank user, should be empty"").isEqualTo(new Schema());
+    }
+
+    @Test
+    public void shouldGetSchemaForBlankUserWhenPermissiveReadAccessPredicateConfigured() throws OperationException {
+        // Given
+        addGraphWithContextAndAccess(GRAPH_ID_A, STRING_TYPE, GROUP_BASIC_EDGE, testContext, new UnrestrictedAccessPredicate(), PROPERTY_1);
+
+        // When
+        final Schema schemaFromBlankUser = federatedStore.getSchema(new Context(blankUser()), false);
+
+        // Then
+        assertThat(schemaFromBlankUser.getEdge(GROUP_BASIC_EDGE).getProperties()).contains(PROPERTY_1);
+    }
+
     @Test
     public void shouldValidateCorrectlyWithOverlappingSchemasUsingDefaultMergeFunction() throws OperationException {
         // Given
@@ -788,11 +923,11 @@ public class FederatedStoreSchemaTest {
         addGraphWith(GRAPH_ID_B, stringSchema, PROPERTY_1, PROPERTY_2);
     }
 
-    private void addGraphWith(final String graphId, final Schema stringType, final String... property) throws OperationException {
-        federatedStore.execute(new AddGraph.Builder()
+    private AddGraph.Builder getAddGraphBuilder(final String graphId, final Schema stringType, final String edgeGroup, final String... property) {
+        return new AddGraph.Builder()
                 .graphId(graphId)
                 .schema(new Schema.Builder()
-                        .edge(GROUP_BASIC_EDGE, new SchemaEdgeDefinition.Builder()
+                        .edge(edgeGroup, new SchemaEdgeDefinition.Builder()
                                 .source(STRING)
                                 .destination(STRING)
                                 .directed(DIRECTED_EITHER)
@@ -801,10 +936,28 @@ public class FederatedStoreSchemaTest {
                         .type(DIRECTED_EITHER, Boolean.class)
                         .merge(stringType)
                         .build())
-                .storeProperties(STORE_PROPERTIES.clone())
+                .storeProperties(STORE_PROPERTIES.clone());
+    }
+
+    private void addGraphWith(final String graphId, final Schema stringType, final String... property) throws OperationException {
+        federatedStore.execute(getAddGraphBuilder(graphId, stringType, GROUP_BASIC_EDGE, property)
                 .build(), testContext);
     }
 
+    private void addGraphWithContextAndAuths(final String graphId, final Schema stringType, final String edgeGroup, Set<String> graphAuths,
+                                             Context context, final String... property) throws OperationException {
+        federatedStore.execute(getAddGraphBuilder(graphId, stringType, edgeGroup, property)
+                .graphAuths(graphAuths.toArray(new String[0]))
+                .build(), context);
+    }
+
+    private void addGraphWithContextAndAccess(final String graphId, final Schema stringType, final String edgeGroup, Context context,
+                                              AccessPredicate read, final String... property) throws OperationException {
+        federatedStore.execute(getAddGraphBuilder(graphId, stringType, edgeGroup, property)
+                .readAccessPredicate(read)
+                .build(), context);
+    }
+
     private void addEdgeBasicWith(final String destination, final Integer... propertyValues) throws OperationException {
         federatedStore.execute(new AddElements.Builder()
                 .input(edgeBasicWith(destination, propertyValues))
diff --git a/store-implementation/federated-store/src/test/java/uk/gov/gchq/gaffer/federatedstore/FederatedStoreTest.java b/store-implementation/federated-store/src/test/java/uk/gov/gchq/gaffer/federatedstore/FederatedStoreTest.java
index 5da3e90a41..5873d7d286 100644
--- a/store-implementation/federated-store/src/test/java/uk/gov/gchq/gaffer/federatedstore/FederatedStoreTest.java
+++ b/store-implementation/federated-store/src/test/java/uk/gov/gchq/gaffer/federatedstore/FederatedStoreTest.java
@@ -1,5 +1,5 @@
 /*
- * Copyright 2017-2022 Crown Copyright
+ * Copyright 2017-2023 Crown Copyright
  *
  * Licensed under the Apache License, Version 2.0 (the ""License"");
  * you may not use this file except in compliance with the License.
@@ -323,9 +323,9 @@ public class FederatedStoreTest {
     public void shouldUpdateSchemaWhenNewGraphIsAdded() throws Exception {
         // Given
         addGraphWithPaths(ACC_ID_1, propertiesAlt, blankUserContext, SCHEMA_ENTITY_BASIC_JSON);
-        final Schema before = store.getSchema(new Context(blankUser));
+        final Schema before = store.getSchema(new Context(blankUser), true);
         addGraphWithPaths(ACC_ID_2, propertiesAlt, blankUserContext, SCHEMA_EDGE_BASIC_JSON);
-        final Schema after = store.getSchema(new Context(blankUser));
+        final Schema after = store.getSchema(new Context(blankUser), true);
         // Then
         assertThat(before).isNotEqualTo(after);
     }
@@ -335,15 +335,15 @@ public class FederatedStoreTest {
     public void shouldUpdateSchemaWhenNewGraphIsRemoved() throws Exception {
         // Given
         addGraphWithPaths(ACC_ID_1, propertiesAlt, blankUserContext, SCHEMA_ENTITY_BASIC_JSON);
-        final Schema was = store.getSchema(new Context(blankUser));
+        final Schema was = store.getSchema(new Context(blankUser), true);
         addGraphWithPaths(ACC_ID_2, propertiesAlt, blankUserContext, SCHEMA_EDGE_BASIC_JSON);
 
-        final Schema before = store.getSchema(new Context(blankUser));
+        final Schema before = store.getSchema(new Context(blankUser), true);
 
         // When
         store.remove(ACC_ID_2, blankUser);
 
-        final Schema after = store.getSchema(new Context(blankUser));
+        final Schema after = store.getSchema(new Context(blankUser), true);
         assertThat(before).isNotEqualTo(after);
         assertThat(was).isEqualTo(after);
     }
@@ -1160,8 +1160,8 @@ public class FederatedStoreTest {
         final Iterable<? extends Element> elements = store
                 .execute(new GetAllElements.Builder()
                         .view(new View.Builder()
-                                .edges(store.getSchema(context).getEdgeGroups()) //here
-                                .entities(store.getSchema(context).getEntityGroups()) //here 59 -> 58
+                                .edges(store.getSchema(context, true).getEdgeGroups()) //here
+                                .entities(store.getSchema(context, true).getEntityGroups()) //here 59 -> 58
                                 .build())
                         .build(), context);
 
diff --git a/store-implementation/federated-store/src/test/java/uk/gov/gchq/gaffer/federatedstore/operation/FederatedOperationChainValidatorTest.java b/store-implementation/federated-store/src/test/java/uk/gov/gchq/gaffer/federatedstore/operation/FederatedOperationChainValidatorTest.java
index 13117e8053..fb5aa9793b 100644
--- a/store-implementation/federated-store/src/test/java/uk/gov/gchq/gaffer/federatedstore/operation/FederatedOperationChainValidatorTest.java
+++ b/store-implementation/federated-store/src/test/java/uk/gov/gchq/gaffer/federatedstore/operation/FederatedOperationChainValidatorTest.java
@@ -1,5 +1,5 @@
 /*
- * Copyright 2017-2022 Crown Copyright
+ * Copyright 2017-2023 Crown Copyright
  *
  * Licensed under the Apache License, Version 2.0 (the ""License"");
  * you may not use this file except in compliance with the License.
@@ -29,6 +29,7 @@ import uk.gov.gchq.gaffer.operation.Operation;
 import uk.gov.gchq.gaffer.operation.OperationException;
 import uk.gov.gchq.gaffer.operation.impl.get.GetAllElements;
 import uk.gov.gchq.gaffer.store.Context;
+import uk.gov.gchq.gaffer.store.operation.GetSchema;
 import uk.gov.gchq.gaffer.store.schema.Schema;
 import uk.gov.gchq.gaffer.store.schema.ViewValidator;
 import uk.gov.gchq.gaffer.user.User;
@@ -37,16 +38,14 @@ import static java.util.Collections.singletonList;
 import static org.assertj.core.api.Assertions.assertThatExceptionOfType;
 import static org.junit.jupiter.api.Assertions.assertEquals;
 import static org.mockito.ArgumentMatchers.any;
-import static org.mockito.ArgumentMatchers.eq;
 import static org.mockito.BDDMockito.given;
 import static org.mockito.Mockito.mock;
 import static org.mockito.Mockito.verify;
 import static uk.gov.gchq.gaffer.federatedstore.util.FederatedStoreUtil.getFederatedOperation;
-import static uk.gov.gchq.gaffer.federatedstore.util.FederatedStoreUtil.getFederatedWrappedSchema;
 
 public class FederatedOperationChainValidatorTest {
     @Test
-    public void shouldGetFederatedSchema() {
+    public void shouldGetFederatedSchema() throws OperationException {
         // Given
         final ViewValidator viewValidator = mock(FederatedViewValidator.class);
         final FederatedOperationChainValidator validator = new FederatedOperationChainValidator(viewValidator);
@@ -54,18 +53,18 @@ public class FederatedOperationChainValidatorTest {
         final User user = mock(User.class);
         final Operation op = mock(Operation.class);
         final Schema schema = mock(Schema.class);
-        given(store.getSchema(eq(getFederatedWrappedSchema()), any(Context.class))).willReturn(schema);
+        given(store.execute(any(GetSchema.class), any(Context.class))).willReturn(schema);
 
         // When
         final Schema actualSchema = validator.getSchema(op, user, store);
 
-        verify(store).getSchema(eq(getFederatedWrappedSchema()), any(Context.class));
+        verify(store).execute(any(GetSchema.class), any(Context.class));
         // Then
         assertEquals(schema, actualSchema);
     }
 
     @Test
-    public void shouldNotErrorWithInvalidViewFromMissingGraph() throws OperationException {
+    public void shouldNotErrorWithInvalidViewFromMissingGraph() {
         //given
         String missingGraph = ""missingGraph"";
         final Graph graph = new Graph.Builder()
diff --git a/store-implementation/federated-store/src/test/java/uk/gov/gchq/gaffer/federatedstore/operation/handler/impl/FederatedDelegateToAggregateHandlerTest.java b/store-implementation/federated-store/src/test/java/uk/gov/gchq/gaffer/federatedstore/operation/handler/impl/FederatedDelegateToAggregateHandlerTest.java
index 598d672355..41e38f1181 100644
--- a/store-implementation/federated-store/src/test/java/uk/gov/gchq/gaffer/federatedstore/operation/handler/impl/FederatedDelegateToAggregateHandlerTest.java
+++ b/store-implementation/federated-store/src/test/java/uk/gov/gchq/gaffer/federatedstore/operation/handler/impl/FederatedDelegateToAggregateHandlerTest.java
@@ -1,5 +1,5 @@
 /*
- * Copyright 2016-2022 Crown Copyright
+ * Copyright 2016-2023 Crown Copyright
  *
  * Licensed under the Apache License, Version 2.0 (the ""License"");
  * you may not use this file except in compliance with the License.
@@ -74,7 +74,7 @@ public class FederatedDelegateToAggregateHandlerTest {
                                         @Mock final Schema schema)
             throws OperationException {
         // Given
-        given(store.getSchema(context)).willReturn(schema);
+        given(store.getSchema(context, true)).willReturn(schema);
         given(handler.doOperation(op, schema)).willReturn((Iterable) expectedResult);
 
         final FederatedDelegateToHandler federatedHandler = new FederatedDelegateToHandler(handler);
diff --git a/store-implementation/federated-store/src/test/java/uk/gov/gchq/gaffer/federatedstore/operation/handler/impl/FederatedDelegateToFilterHandlerTest.java b/store-implementation/federated-store/src/test/java/uk/gov/gchq/gaffer/federatedstore/operation/handler/impl/FederatedDelegateToFilterHandlerTest.java
index f456176e8a..41a50f0d6a 100644
--- a/store-implementation/federated-store/src/test/java/uk/gov/gchq/gaffer/federatedstore/operation/handler/impl/FederatedDelegateToFilterHandlerTest.java
+++ b/store-implementation/federated-store/src/test/java/uk/gov/gchq/gaffer/federatedstore/operation/handler/impl/FederatedDelegateToFilterHandlerTest.java
@@ -1,5 +1,5 @@
 /*
- * Copyright 2016-2022 Crown Copyright
+ * Copyright 2016-2023 Crown Copyright
  *
  * Licensed under the Apache License, Version 2.0 (the ""License"");
  * you may not use this file except in compliance with the License.
@@ -42,7 +42,7 @@ public class FederatedDelegateToFilterHandlerTest {
         final Iterable expectedResult = mock(Iterable.class);
         final Schema schema = mock(Schema.class);
 
-        given(store.getSchema(context)).willReturn(schema);
+        given(store.getSchema(context, true)).willReturn(schema);
         given(handler.doOperation(op, schema)).willReturn(expectedResult);
 
         final FederatedDelegateToHandler federatedHandler = new FederatedDelegateToHandler(handler);
@@ -53,6 +53,6 @@ public class FederatedDelegateToFilterHandlerTest {
         // Then
         assertSame(expectedResult, result);
         verify(handler).doOperation(op, schema);
-        verify(store).getSchema(context);
+        verify(store).getSchema(context, true);
     }
 }
diff --git a/store-implementation/federated-store/src/test/java/uk/gov/gchq/gaffer/federatedstore/operation/handler/impl/FederatedDelegateToTransHandlerTest.java b/store-implementation/federated-store/src/test/java/uk/gov/gchq/gaffer/federatedstore/operation/handler/impl/FederatedDelegateToTransHandlerTest.java
index a9a5eaf3f0..3f8e2a2b07 100644
--- a/store-implementation/federated-store/src/test/java/uk/gov/gchq/gaffer/federatedstore/operation/handler/impl/FederatedDelegateToTransHandlerTest.java
+++ b/store-implementation/federated-store/src/test/java/uk/gov/gchq/gaffer/federatedstore/operation/handler/impl/FederatedDelegateToTransHandlerTest.java
@@ -1,5 +1,5 @@
 /*
- * Copyright 2016-2022 Crown Copyright
+ * Copyright 2016-2023 Crown Copyright
  *
  * Licensed under the Apache License, Version 2.0 (the ""License"");
  * you may not use this file except in compliance with the License.
@@ -42,7 +42,7 @@ public class FederatedDelegateToTransHandlerTest {
         final Iterable expectedResult = mock(Iterable.class);
         final Schema schema = mock(Schema.class);
 
-        given(store.getSchema(context)).willReturn(schema);
+        given(store.getSchema(context, true)).willReturn(schema);
         given(handler.doOperation(op, schema)).willReturn(expectedResult);
 
         final FederatedDelegateToHandler federatedHandler = new FederatedDelegateToHandler(handler);
@@ -53,6 +53,6 @@ public class FederatedDelegateToTransHandlerTest {
         // Then
         assertSame(expectedResult, result);
         verify(handler).doOperation(op, schema);
-        verify(store).getSchema(context);
+        verify(store).getSchema(context, true);
     }
 }
diff --git a/store-implementation/federated-store/src/test/java/uk/gov/gchq/gaffer/federatedstore/operation/handler/impl/FederatedDelegateToValidateHandlerTest.java b/store-implementation/federated-store/src/test/java/uk/gov/gchq/gaffer/federatedstore/operation/handler/impl/FederatedDelegateToValidateHandlerTest.java
index 22657ab93b..0cc2425353 100644
--- a/store-implementation/federated-store/src/test/java/uk/gov/gchq/gaffer/federatedstore/operation/handler/impl/FederatedDelegateToValidateHandlerTest.java
+++ b/store-implementation/federated-store/src/test/java/uk/gov/gchq/gaffer/federatedstore/operation/handler/impl/FederatedDelegateToValidateHandlerTest.java
@@ -1,5 +1,5 @@
 /*
- * Copyright 2016-2022 Crown Copyright
+ * Copyright 2016-2023 Crown Copyright
  *
  * Licensed under the Apache License, Version 2.0 (the ""License"");
  * you may not use this file except in compliance with the License.
@@ -42,7 +42,7 @@ public class FederatedDelegateToValidateHandlerTest {
         final Iterable expectedResult = mock(Iterable.class);
         final Schema schema = mock(Schema.class);
 
-        given(store.getSchema(context)).willReturn(schema);
+        given(store.getSchema(context, true)).willReturn(schema);
         given(handler.doOperation(op, schema)).willReturn(expectedResult);
 
         final FederatedDelegateToHandler federatedHandler = new FederatedDelegateToHandler(handler);
diff --git a/store-implementation/proxy-store/src/main/java/uk/gov/gchq/gaffer/proxystore/ProxyStore.java b/store-implementation/proxy-store/src/main/java/uk/gov/gchq/gaffer/proxystore/ProxyStore.java
index 81d27b2b2c..61026697b9 100644
--- a/store-implementation/proxy-store/src/main/java/uk/gov/gchq/gaffer/proxystore/ProxyStore.java
+++ b/store-implementation/proxy-store/src/main/java/uk/gov/gchq/gaffer/proxystore/ProxyStore.java
@@ -54,6 +54,7 @@ import uk.gov.gchq.gaffer.store.StoreException;
 import uk.gov.gchq.gaffer.store.StoreProperties;
 import uk.gov.gchq.gaffer.store.StoreTrait;
 import uk.gov.gchq.gaffer.store.TypeReferenceStoreImpl;
+import uk.gov.gchq.gaffer.store.operation.GetSchema;
 import uk.gov.gchq.gaffer.store.operation.GetTraits;
 import uk.gov.gchq.gaffer.store.operation.handler.GetTraitsHandler;
 import uk.gov.gchq.gaffer.store.operation.handler.OperationHandler;
@@ -86,8 +87,8 @@ import static java.util.Objects.nonNull;
  */
 public class ProxyStore extends Store {
     private static final Logger LOGGER = LoggerFactory.getLogger(ProxyStore.class);
+    public static final String ERROR_FETCHING_SCHEMA_FROM_REMOTE_STORE = ""Error fetching schema from remote store."";
     private Client client;
-    private Schema schema;
 
     public ProxyStore() {
         super(false);
@@ -99,9 +100,8 @@ public class ProxyStore extends Store {
             throws StoreException {
         setProperties(properties);
         client = createClient();
-        schema = fetchSchema();
 
-        super.initialise(graphId, schema, getProperties());
+        super.initialise(graphId, new Schema(), getProperties());
         checkDelegateStoreStatus();
     }
 
@@ -158,10 +158,38 @@ public class ProxyStore extends Store {
         return newTraits;
     }
 
-    protected Schema fetchSchema() throws StoreException {
-        final URL url = getProperties().getGafferUrl(""graph/config/schema"");
-        final ResponseDeserialiser<Schema> responseDeserialiser = getResponseDeserialiserFor(new TypeReferenceStoreImpl.Schema());
-        return doGet(url, responseDeserialiser, null);
+    protected Schema fetchSchema(final boolean getCompactSchema) throws OperationException {
+        final GetSchema.Builder getSchema = new GetSchema.Builder();
+        getSchema.compact(getCompactSchema);
+        return executeOpChainViaUrl(new OperationChain<>(getSchema.build()), new Context());
+    }
+
+    /**
+     * Get original {@link Schema} from the remote Store.
+     *
+     * @return original {@link Schema}
+     */
+    @Override
+    public Schema getOriginalSchema() {
+        try {
+            return fetchSchema(false);
+        } catch (final OperationException e) {
+            throw new GafferRuntimeException(ERROR_FETCHING_SCHEMA_FROM_REMOTE_STORE, e);
+        }
+    }
+
+    /**
+     * Get {@link Schema} from the remote Store.
+     *
+     * @return optimised compact {@link Schema}
+     */
+    @Override
+    public Schema getSchema() {
+        try {
+            return fetchSchema(true);
+        } catch (final OperationException e) {
+            throw new GafferRuntimeException(ERROR_FETCHING_SCHEMA_FROM_REMOTE_STORE, e);
+        }
     }
 
     @Override
diff --git a/store-implementation/proxy-store/src/test/java/uk/gov/gchq/gaffer/proxystore/integration/ProxyStoreBasicIT.java b/store-implementation/proxy-store/src/test/java/uk/gov/gchq/gaffer/proxystore/integration/ProxyStoreBasicIT.java
index 65eeb756cc..8f0455825f 100644
--- a/store-implementation/proxy-store/src/test/java/uk/gov/gchq/gaffer/proxystore/integration/ProxyStoreBasicIT.java
+++ b/store-implementation/proxy-store/src/test/java/uk/gov/gchq/gaffer/proxystore/integration/ProxyStoreBasicIT.java
@@ -50,7 +50,11 @@ import uk.gov.gchq.gaffer.proxystore.ProxyStore;
 import uk.gov.gchq.gaffer.proxystore.SingleUseMapProxyStore;
 import uk.gov.gchq.gaffer.rest.RestApiTestClient;
 import uk.gov.gchq.gaffer.rest.service.v2.RestApiV2TestClient;
+import uk.gov.gchq.gaffer.store.Store;
 import uk.gov.gchq.gaffer.store.StoreTrait;
+import uk.gov.gchq.gaffer.store.operation.GetSchema;
+import uk.gov.gchq.gaffer.store.schema.Schema;
+import uk.gov.gchq.gaffer.store.schema.SchemaOptimiser;
 import uk.gov.gchq.gaffer.user.User;
 
 import java.io.File;
@@ -98,6 +102,7 @@ public class ProxyStoreBasicIT {
                     .build()
     };
 
+    private Store store;
     private Graph graph;
 
     @BeforeAll
@@ -116,13 +121,14 @@ public class ProxyStoreBasicIT {
         CLIENT.reinitialiseGraph(testFolder, StreamUtil.SCHEMA, ""map-store.properties"");
 
         // setup ProxyStore
+        store = new ProxyStore.Builder()
+                .graphId(""graph1"")
+                .host(""localhost"")
+                .port(8080)
+                .contextRoot(""rest/v2"")
+                .build();
         graph = new Graph.Builder()
-                .store(new ProxyStore.Builder()
-                        .graphId(""graph1"")
-                        .host(""localhost"")
-                        .port(8080)
-                        .contextRoot(""rest/v2"")
-                        .build())
+                .store(store)
                 .build();
     }
 
@@ -237,4 +243,36 @@ public class ProxyStoreBasicIT {
                 .build();
         graph.execute(add, USER);
     }
+
+    @Test
+    public void shouldGetOriginalSchemaUsingMethodsAndOperation() throws OperationException {
+        // Given
+        Schema storeSchema = Schema.fromJson(StreamUtil.openStream(this.getClass(), StreamUtil.SCHEMA));
+
+        // When - Get
+        final Schema returnedSchemaFromGraphMethod = graph.getSchema(); // Indirectly runs getOriginalSchema
+        final Schema returnedSchemaFromStoreMethod = store.getOriginalSchema();
+        final Schema returnedSchemaFromOperation = graph.execute(new GetSchema(), USER);
+
+        // Then
+        assertThat(returnedSchemaFromGraphMethod).isEqualTo(storeSchema);
+        assertThat(returnedSchemaFromStoreMethod).isEqualTo(storeSchema);
+        assertThat(returnedSchemaFromOperation).isEqualTo(storeSchema);
+    }
+
+    @Test
+    public void shouldGetInternalOptimisedSchemaUsingMethodAndOperation() throws OperationException {
+        // Given
+        Schema storeSchema = Schema.fromJson(StreamUtil.openStream(this.getClass(), StreamUtil.SCHEMA));
+        Schema optimisedStoreSchema = new SchemaOptimiser().optimise(storeSchema, true);
+
+        // When - Get
+        final Schema returnedSchemaFromMethod = store.getSchema();
+        GetSchema getCompactSchema = new GetSchema.Builder().compact(true).build();
+        final Schema returnedSchemaFromOperation = graph.execute(getCompactSchema, USER);
+
+        // Then
+        assertThat(returnedSchemaFromMethod).isEqualTo(optimisedStoreSchema);
+        assertThat(returnedSchemaFromOperation).isEqualTo(optimisedStoreSchema);
+    }
 }","['store-implementation/federated-store/src/test/java/uk/gov/gchq/gaffer/federatedstore/operation/handler/impl/FederatedDelegateToAggregateHandlerTest.java', 'store-implementation/federated-store/src/test/java/uk/gov/gchq/gaffer/federatedstore/operation/handler/impl/FederatedDelegateToValidateHandlerTest.java', 'store-implementation/proxy-store/src/test/java/uk/gov/gchq/gaffer/proxystore/integration/ProxyStoreBasicIT.java', 'store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/FederatedGraphStorage.java', 'store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/operation/FederatedOperationChainValidator.java', 'store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/FederatedStore.java', 'store-implementation/federated-store/src/test/java/uk/gov/gchq/gaffer/federatedstore/FederatedStoreSchemaTest.java', 'store-implementation/federated-store/src/test/java/uk/gov/gchq/gaffer/federatedstore/FederatedStoreTest.java', 'store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/operation/handler/FederatedDelegateToHandler.java', 'store-implementation/federated-store/src/test/java/uk/gov/gchq/gaffer/federatedstore/operation/handler/impl/FederatedDelegateToFilterHandlerTest.java', 'store-implementation/proxy-store/src/main/java/uk/gov/gchq/gaffer/proxystore/ProxyStore.java', 'store-implementation/federated-store/src/test/java/uk/gov/gchq/gaffer/federatedstore/FederatedGraphStorageTest.java', 'store-implementation/federated-store/src/test/java/uk/gov/gchq/gaffer/federatedstore/operation/handler/impl/FederatedDelegateToTransHandlerTest.java', 'store-implementation/federated-store/src/test/java/uk/gov/gchq/gaffer/federatedstore/operation/FederatedOperationChainValidatorTest.java', 'store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/util/FederatedStoreUtil.java']",{'.java': 15},15,15,0,0,15,4037751,833176,107678,1103,8218,1690,151,6,742,103,150,7,0,0,2023-02-08 17:32:11,1711,Java,"{'Java': 9333788, 'JavaScript': 2752310, 'Shell': 15069, 'HTML': 3332, 'CSS': 505}",Apache License 2.0,"['store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/operation/FederatedOperation.java', 'store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/FederatedStore.java', 'store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/operation/handler/impl/FederatedAddGraphWithHooksHandler.java', 'store-implementation/proxy-store/src/main/java/uk/gov/gchq/gaffer/proxystore/operation/GetProxyUrl.java', 'store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/FederatedStoreProperties.java', 'store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/operation/handler/FederatedDelegateToHandler.java', 'store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/FederatedGraphStorage.java', 'store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/access/predicate/user/FederatedGraphReadUserPredicate.java', 'store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/operation/FederatedOperationChainValidator.java', 'library/spark/spark-library/src/main/java/uk/gov/gchq/gaffer/spark/operation/dataframe/converter/property/impl/datasketches/theta/UnionConverter.java', 'library/spark/spark-library/src/main/java/uk/gov/gchq/gaffer/spark/serialisation/kryo/impl/datasketches/sampling/ReservoirLongsUnionKryoSerializer.java', 'store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/FederatedStoreCacheTransient.java', 'store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/access/predicate/user/FederatedGraphWriteUserPredicate.java', 'store-implementation/proxy-store/src/main/java/uk/gov/gchq/gaffer/proxystore/exception/ProxyStoreException.java', 'store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/access/predicate/FederatedGraphReadAccessPredicate.java', 'store-implementation/proxy-store/src/main/java/uk/gov/gchq/gaffer/proxystore/operation/GetProxyProperties.java', 'store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/access/predicate/FederatedGraphWriteAccessPredicate.java', 'library/spark/spark-library/src/main/java/uk/gov/gchq/gaffer/spark/operation/dataframe/converter/property/impl/datasketches/theta/package-info.java', 'store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/operation/handler/impl/FederatedAddGraphHandler.java', 'store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/operation/handler/FederatedAddGraphHandlerParent.java', 'store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/FederatedStoreCache.java', 'store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/operation/handler/impl/FederatedChangeGraphAccessHandler.java', 'store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/access/predicate/FederatedGraphAccessPredicate.java']","['store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/operation/FederatedOperation.java', 'store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/FederatedStore.java', 'store-implementation/proxy-store/src/main/java/uk/gov/gchq/gaffer/proxystore/operation/GetProxyUrl.java', 'store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/operation/FederatedOperationChainValidator.java', 'store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/FederatedStoreProperties.java']","['```json\n{\n  ""files"": [\n    ""store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/FederatedGraphStorage.java"",\n    ""store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/FederatedStore.java"",\n    ""store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/FederatedStoreCache.java"",\n    ""store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/FederatedStoreCacheTransient.java"",\n    ""store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/FederatedStoreProperties.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/operation/FederatedOperation.java"",\n    ""store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/operation/FederatedOperationChainValidator.java"",\n    ""store-implementation/proxy-store/src/main/java/uk/gov/gchq/gaffer/proxystore/operation/GetProxyProperties.java"",\n    ""store-implementation/proxy-store/src/main/java/uk/gov/gchq/gaffer/proxystore/operation/GetProxyUrl.java"",\n    ""store-implementation/proxy-store/src/main/java/uk/gov/gchq/gaffer/proxystore/exception/ProxyStoreException.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/access/predicate/FederatedGraphAccessPredicate.java"",\n    ""store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/access/predicate/FederatedGraphReadAccessPredicate.java"",\n    ""store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/access/predicate/FederatedGraphWriteAccessPredicate.java"",\n    ""store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/operation/handler/FederatedAddGraphHandlerParent.java"",\n    ""store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/operation/handler/FederatedDelegateToHandler.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/access/predicate/user/FederatedGraphReadUserPredicate.java"",\n    ""store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/access/predicate/user/FederatedGraphWriteUserPredicate.java"",\n    ""store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/operation/handler/impl/FederatedAddGraphHandler.java"",\n    ""store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/operation/handler/impl/FederatedAddGraphWithHooksHandler.java"",\n    ""store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/operation/handler/impl/FederatedChangeGraphAccessHandler.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""library/spark/spark-library/src/main/java/uk/gov/gchq/gaffer/spark/operation/dataframe/converter/property/impl/datasketches/theta/UnionConverter.java"",\n    ""library/spark/spark-library/src/main/java/uk/gov/gchq/gaffer/spark/operation/dataframe/converter/property/impl/datasketches/theta/package-info.java"",\n    ""library/spark/spark-library/src/main/java/uk/gov/gchq/gaffer/spark/serialisation/kryo/impl/datasketches/sampling/ReservoirLongsUnionKryoSerializer.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/FederatedStore.java"",\n    ""store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/FederatedStoreProperties.java"",\n    ""store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/operation/FederatedOperation.java"",\n    ""store-implementation/federated-store/src/main/java/uk/gov/gchq/gaffer/federatedstore/operation/FederatedOperationChainValidator.java"",\n    ""store-implementation/proxy-store/src/main/java/uk/gov/gchq/gaffer/proxystore/operation/GetProxyUrl.java""\n  ]\n}\n```']",5,14538.174867630005
551,embulk/embulk/1054/1031,embulk,embulk,https://github.com/embulk/embulk/issues/1031,https://github.com/embulk/embulk/pull/1054,https://github.com/embulk/embulk/pull/1054,1,fix,"""embulk new"" command not work in windows ","I have executed command in windows 10 x64

> E:\\work> embulk new java-file-output onefile

```
2018-07-18 10:41:05.724 +0900: Embulk v0.9.7
Creating embulk-output-onefile/
java.lang.UnsupportedOperationException
        at sun.nio.fs.WindowsFileSystemProvider.readAttributes(Unknown Source)
        at java.nio.file.Files.readAttributes(Unknown Source)
        at java.nio.file.Files.getPosixFilePermissions(Unknown Source)
        at org.embulk.cli.EmbulkNew.setExecutable(EmbulkNew.java:390)
        at org.embulk.cli.EmbulkNew.newPlugin(EmbulkNew.java:169)
        at org.embulk.cli.EmbulkRun.runSubcommand(EmbulkRun.java:338)
        at org.embulk.cli.EmbulkRun.run(EmbulkRun.java:91)
        at org.embulk.cli.Main.main(Main.java:26)
Failed. Removing the directory created.
```

I have executed same command in cent os6, then success. but not work in windows PC.
JDK version is 1.8.0_171.

",4b8250d88792cd4e9024903e133b76758ef6a02e,ea83f92ecd0b595cd6f04bdad865bbec31e810ab,https://github.com/embulk/embulk/compare/4b8250d88792cd4e9024903e133b76758ef6a02e...ea83f92ecd0b595cd6f04bdad865bbec31e810ab,"diff --git a/embulk-core/src/main/java/org/embulk/cli/EmbulkMigrate.java b/embulk-core/src/main/java/org/embulk/cli/EmbulkMigrate.java
index 8064276d..8a5c152b 100644
--- a/embulk-core/src/main/java/org/embulk/cli/EmbulkMigrate.java
+++ b/embulk-core/src/main/java/org/embulk/cli/EmbulkMigrate.java
@@ -4,6 +4,7 @@ import com.google.common.base.Joiner;
 import com.google.common.collect.ImmutableList;
 import java.io.IOException;
 import java.nio.charset.StandardCharsets;
+import java.nio.file.FileSystem;
 import java.nio.file.FileSystems;
 import java.nio.file.FileVisitResult;
 import java.nio.file.Files;
@@ -87,7 +88,7 @@ public class EmbulkMigrate {
         if (migrator.match(""gradle/wrapper/gradle-wrapper.properties"", GRADLE_VERSION_IN_WRAPPER)) {
             // gradle < 4.1
             migrator.copy(""org/embulk/plugin/template/java/gradlew"", ""gradlew"");
-            migrator.setExecutable(""gradlew"");
+            migrator.setExecutableIfAvailable(""gradlew"");
             migrator.copy(""org/embulk/plugin/template/java/gradle/wrapper/gradle-wrapper.properties"",
                           ""gradle/wrapper/gradle-wrapper.properties"");
             migrator.copy(""org/embulk/plugin/template/java/gradle/wrapper/gradle-wrapper.jar"",
@@ -381,14 +382,18 @@ public class EmbulkMigrate {
             }
         }
 
-        private void setExecutable(String targetFileName) throws IOException {
+        private void setExecutableIfAvailable(final String targetFileName) throws IOException {
             final Path targetPath = this.basePath.resolve(targetFileName);
-            final Set<PosixFilePermission> permissions =
-                    new HashSet<PosixFilePermission>(Files.getPosixFilePermissions(targetPath));
-            permissions.add(PosixFilePermission.OWNER_EXECUTE);
-            permissions.add(PosixFilePermission.GROUP_EXECUTE);
-            permissions.add(PosixFilePermission.OTHERS_EXECUTE);
-            Files.setPosixFilePermissions(targetPath, permissions);
+            final FileSystem fileSystem = targetPath.getFileSystem();
+            if (fileSystem.supportedFileAttributeViews().contains(""posix"")) {
+                // NTFS does not support PosixFilePermissions, for example.
+                final Set<PosixFilePermission> permissions =
+                        new HashSet<PosixFilePermission>(Files.getPosixFilePermissions(targetPath));
+                permissions.add(PosixFilePermission.OWNER_EXECUTE);
+                permissions.add(PosixFilePermission.GROUP_EXECUTE);
+                permissions.add(PosixFilePermission.OTHERS_EXECUTE);
+                Files.setPosixFilePermissions(targetPath, permissions);
+            }
         }
 
         private final Path basePath;
diff --git a/embulk-core/src/main/java/org/embulk/cli/EmbulkNew.java b/embulk-core/src/main/java/org/embulk/cli/EmbulkNew.java
index 4317cf1c..82b0cbbf 100644
--- a/embulk-core/src/main/java/org/embulk/cli/EmbulkNew.java
+++ b/embulk-core/src/main/java/org/embulk/cli/EmbulkNew.java
@@ -7,6 +7,7 @@ import java.io.BufferedWriter;
 import java.io.IOException;
 import java.io.InputStreamReader;
 import java.nio.charset.StandardCharsets;
+import java.nio.file.FileSystem;
 import java.nio.file.FileVisitResult;
 import java.nio.file.Files;
 import java.nio.file.Path;
@@ -166,7 +167,7 @@ public class EmbulkNew {
                     copy(""org/embulk/plugin/template/java/gradle/wrapper/gradle-wrapper.properties"", ""gradle/wrapper/gradle-wrapper.properties"");
                     copy(""org/embulk/plugin/template/java/gradlew.bat"", ""gradlew.bat"");
                     copy(""org/embulk/plugin/template/java/gradlew"", ""gradlew"");
-                    setExecutable(""gradlew"");
+                    setExecutableIfAvailable(""gradlew"");
                     copy(""org/embulk/plugin/template/java/config/checkstyle/checkstyle.xml"", ""config/checkstyle/checkstyle.xml"");
                     copy(""org/embulk/plugin/template/java/config/checkstyle/default.xml"", ""config/checkstyle/default.xml"");
                     copyTemplated(""org/embulk/plugin/template/java/build.gradle.vm"",
@@ -384,14 +385,18 @@ public class EmbulkNew {
         }
     }
 
-    private void setExecutable(String targetFileName) throws IOException {
+    private void setExecutableIfAvailable(final String targetFileName) throws IOException {
         final Path targetPath = this.pluginBasePath.resolve(targetFileName);
-        final Set<PosixFilePermission> permissions =
-                new HashSet<PosixFilePermission>(Files.getPosixFilePermissions(targetPath));
-        permissions.add(PosixFilePermission.OWNER_EXECUTE);
-        permissions.add(PosixFilePermission.GROUP_EXECUTE);
-        permissions.add(PosixFilePermission.OTHERS_EXECUTE);
-        Files.setPosixFilePermissions(targetPath, permissions);
+        final FileSystem fileSystem = targetPath.getFileSystem();
+        if (fileSystem.supportedFileAttributeViews().contains(""posix"")) {
+            // NTFS does not support PosixFilePermissions, for example.
+            final Set<PosixFilePermission> permissions =
+                    new HashSet<PosixFilePermission>(Files.getPosixFilePermissions(targetPath));
+            permissions.add(PosixFilePermission.OWNER_EXECUTE);
+            permissions.add(PosixFilePermission.GROUP_EXECUTE);
+            permissions.add(PosixFilePermission.OTHERS_EXECUTE);
+            Files.setPosixFilePermissions(targetPath, permissions);
+        }
     }
 
     private final Path basePath;
diff --git a/embulk-core/src/main/java/org/embulk/cli/EmbulkSelfUpdate.java b/embulk-core/src/main/java/org/embulk/cli/EmbulkSelfUpdate.java
index 537cb834..58c5c49d 100644
--- a/embulk-core/src/main/java/org/embulk/cli/EmbulkSelfUpdate.java
+++ b/embulk-core/src/main/java/org/embulk/cli/EmbulkSelfUpdate.java
@@ -7,6 +7,7 @@ import java.io.InputStream;
 import java.net.HttpURLConnection;
 import java.net.URISyntaxException;
 import java.net.URL;
+import java.nio.file.FileSystem;
 import java.nio.file.Files;
 import java.nio.file.Path;
 import java.nio.file.Paths;
@@ -88,7 +89,10 @@ public class EmbulkSelfUpdate {
                 InputStream input = connection.getInputStream();
                 // TODO(dmikurube): Confirm if it is okay to replace a temp file created by Files.createTempFile.
                 Files.copy(input, jarPathTemp, StandardCopyOption.REPLACE_EXISTING);
-                Files.setPosixFilePermissions(jarPathTemp, Files.getPosixFilePermissions(jarPathJava));
+                final FileSystem fileSystem = jarPathTemp.getFileSystem();
+                if (fileSystem.supportedFileAttributeViews().contains(""posix"")) {
+                    Files.setPosixFilePermissions(jarPathTemp, Files.getPosixFilePermissions(jarPathJava));
+                }
             } finally {
                 connection.disconnect();
             }","['embulk-core/src/main/java/org/embulk/cli/EmbulkMigrate.java', 'embulk-core/src/main/java/org/embulk/cli/EmbulkNew.java', 'embulk-core/src/main/java/org/embulk/cli/EmbulkSelfUpdate.java']",{'.java': 3},3,3,0,0,3,992870,189754,26097,242,3201,572,48,3,917,68,245,23,0,1,2018-10-29 05:12:21,1692,Java,"{'Java': 1206535, 'Ruby': 102994, 'Batchfile': 4257, 'Shell': 3118, 'HTML': 538}",Apache License 2.0,"['embulk-core/src/main/java/org/embulk/cli/EmbulkRun.java', 'embulk-core/src/main/java/org/embulk/cli/Main.java', 'embulk-core/src/main/java/org/embulk/cli/EmbulkNew.java']","['embulk-core/src/main/java/org/embulk/cli/EmbulkRun.java', 'embulk-core/src/main/java/org/embulk/cli/Main.java', 'embulk-core/src/main/java/org/embulk/cli/EmbulkNew.java']","['```json\n{\n  ""files"": [\n    ""embulk-core/src/main/java/org/embulk/cli/EmbulkNew.java"",\n    ""embulk-core/src/main/java/org/embulk/cli/EmbulkRun.java"",\n    ""embulk-core/src/main/java/org/embulk/cli/Main.java""\n  ]\n}\n```']",1,1396.122932434082
1338,jooby-project/jooby/2220/2210,jooby-project,jooby,https://github.com/jooby-project/jooby/issues/2210,https://github.com/jooby-project/jooby/pull/2220,https://github.com/jooby-project/jooby/pull/2220,1,fixes,Websockets onClose not working,"Hi!

For some weird reason, the onClose event is not called on my WebSockets when setting a handler using the configurator.

Regards
Dominik",f7bd9284d48b589086e30339c9f174e15f662ba5,e105611c98986f6e9f9eaaa72e0efc43a1bfc247,https://github.com/jooby-project/jooby/compare/f7bd9284d48b589086e30339c9f174e15f662ba5...e105611c98986f6e9f9eaaa72e0efc43a1bfc247,"diff --git a/jooby/src/main/java/io/jooby/Server.java b/jooby/src/main/java/io/jooby/Server.java
index e0197145c..8868970aa 100644
--- a/jooby/src/main/java/io/jooby/Server.java
+++ b/jooby/src/main/java/io/jooby/Server.java
@@ -139,8 +139,10 @@ public interface Server {
       String message = cause.getMessage();
       if (message != null) {
         String msg = message.toLowerCase();
-        return msg.contains(""reset by peer"") || msg.contains(""broken pipe"") || msg
-            .contains(""forcibly closed"");
+        return msg.contains(""reset by peer"")
+            || msg.contains(""broken pipe"")
+            || msg.contains(""forcibly closed"")
+            || msg.contains(""connection reset"");
       }
     }
     return (cause instanceof ClosedChannelException) || (cause instanceof EOFException);
diff --git a/modules/jooby-netty/src/main/java/io/jooby/internal/netty/NettyWebSocket.java b/modules/jooby-netty/src/main/java/io/jooby/internal/netty/NettyWebSocket.java
index fe1d2dfda..434461504 100644
--- a/modules/jooby-netty/src/main/java/io/jooby/internal/netty/NettyWebSocket.java
+++ b/modules/jooby-netty/src/main/java/io/jooby/internal/netty/NettyWebSocket.java
@@ -5,6 +5,17 @@
  */
 package io.jooby.internal.netty;
 
+import java.nio.charset.StandardCharsets;
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.List;
+import java.util.concurrent.ConcurrentHashMap;
+import java.util.concurrent.ConcurrentMap;
+import java.util.concurrent.CopyOnWriteArrayList;
+import java.util.concurrent.CountDownLatch;
+
+import javax.annotation.Nonnull;
+
 import io.jooby.Context;
 import io.jooby.Router;
 import io.jooby.Server;
@@ -24,16 +35,6 @@ import io.netty.handler.codec.http.websocketx.TextWebSocketFrame;
 import io.netty.handler.codec.http.websocketx.WebSocketFrame;
 import io.netty.util.AttributeKey;
 
-import javax.annotation.Nonnull;
-import java.nio.charset.StandardCharsets;
-import java.util.ArrayList;
-import java.util.Collections;
-import java.util.List;
-import java.util.concurrent.ConcurrentHashMap;
-import java.util.concurrent.ConcurrentMap;
-import java.util.concurrent.CopyOnWriteArrayList;
-import java.util.concurrent.CountDownLatch;
-
 public class NettyWebSocket implements WebSocketConfigurer, WebSocket, ChannelFutureListener {
   /** All connected websocket. */
   private static final ConcurrentMap<String, List<NettyWebSocket>> all = new ConcurrentHashMap<>();
@@ -155,20 +156,22 @@ public class NettyWebSocket implements WebSocketConfigurer, WebSocket, ChannelFu
 
   private void handleMessage(WebSocketFrame frame) {
     try {
-      if (frame.isFinalFragment()) {
-        ByteBuf content;
-        if (buffer != null) {
-          buffer.writeBytes(frame.content());
-          content = buffer;
-          buffer = null;
+      if (messageCallback != null) {
+        if (frame.isFinalFragment()) {
+          ByteBuf content;
+          if (buffer != null) {
+            buffer.writeBytes(frame.content());
+            content = buffer;
+            buffer = null;
+          } else {
+            content = frame.content();
+          }
+          WebSocketMessage message = WebSocketMessage.create(getContext(), array(content));
+
+          fireCallback(webSocketTask(() -> messageCallback.onMessage(this, message), false));
         } else {
-          content = frame.content();
+          buffer = Unpooled.copiedBuffer(frame.content());
         }
-        WebSocketMessage message = WebSocketMessage.create(getContext(), array(content));
-
-        fireCallback(webSocketTask(() -> messageCallback.onMessage(this, message), false));
-      } else {
-        buffer = Unpooled.copiedBuffer(frame.content());
       }
     } finally {
       frame.release();
diff --git a/modules/jooby-utow/src/main/java/io/jooby/internal/utow/UtowWebSocket.java b/modules/jooby-utow/src/main/java/io/jooby/internal/utow/UtowWebSocket.java
index db5f5c60d..85d3aec73 100644
--- a/modules/jooby-utow/src/main/java/io/jooby/internal/utow/UtowWebSocket.java
+++ b/modules/jooby-utow/src/main/java/io/jooby/internal/utow/UtowWebSocket.java
@@ -198,12 +198,19 @@ public class UtowWebSocket extends AbstractReceiveListener
   @Override protected void onError(WebSocketChannel channel, Throwable x) {
     // should close?
     if (Server.connectionLost(x) || SneakyThrows.isFatal(x)) {
-      handleClose(WebSocketCloseStatus.SERVER_ERROR);
+      if (channel.isOpen()) {
+        handleClose(WebSocketCloseStatus.SERVER_ERROR);
+      }
     }
 
     if (onErrorCallback == null) {
-      ctx.getRouter().getLog()
-          .error(""Websocket resulted in exception: {}"", ctx.getRequestPath(), x);
+      if (Server.connectionLost(x)) {
+        ctx.getRouter().getLog()
+            .debug(""Websocket connection lost: {}"", ctx.getRequestPath(), x);
+      } else {
+        ctx.getRouter().getLog()
+            .error(""Websocket resulted in exception: {}"", ctx.getRequestPath(), x);
+      }
     } else {
       onErrorCallback.onError(this, x);
     }
@@ -215,8 +222,10 @@ public class UtowWebSocket extends AbstractReceiveListener
 
   @Override protected void onCloseMessage(CloseMessage cm,
       WebSocketChannel channel) {
-    handleClose(WebSocketCloseStatus.valueOf(cm.getCode())
-        .orElseGet(() -> new WebSocketCloseStatus(cm.getCode(), cm.getReason())));
+    if (channel.isOpen()) {
+      handleClose(WebSocketCloseStatus.valueOf(cm.getCode())
+          .orElseGet(() -> new WebSocketCloseStatus(cm.getCode(), cm.getReason())));
+    }
   }
 
   private void handleClose(WebSocketCloseStatus closeStatus) {","['modules/jooby-utow/src/main/java/io/jooby/internal/utow/UtowWebSocket.java', 'jooby/src/main/java/io/jooby/Server.java', 'modules/jooby-netty/src/main/java/io/jooby/internal/netty/NettyWebSocket.java']",{'.java': 3},3,3,0,0,3,1905746,440530,64015,475,2972,557,72,3,145,23,32,6,0,0,2021-01-03 22:44:22,1585,Java,"{'Java': 3206985, 'Kotlin': 53463, 'PHP': 16878, 'Handlebars': 13400, 'HTML': 6645, 'Shell': 1325, 'Groovy': 943, 'Dockerfile': 424, 'FreeMarker': 108}",Apache License 2.0,"['jooby/src/main/java/io/jooby/WebSocket.java', 'jooby/src/main/java/io/jooby/internal/handler/WebSocketHandler.java']","['jooby/src/main/java/io/jooby/WebSocket.java', 'jooby/src/main/java/io/jooby/internal/handler/WebSocketHandler.java']","['```json\n{\n  ""files"": [\n    ""jooby/src/main/java/io/jooby/WebSocket.java"",\n    ""jooby/src/main/java/io/jooby/internal/handler/WebSocketHandler.java""\n  ]\n}\n```']",1,1247.680425643921
299,j-easy/easy-random/240/237,j-easy,easy-random,https://github.com/j-easy/easy-random/issues/237,https://github.com/j-easy/easy-random/pull/240,https://github.com/j-easy/easy-random/pull/240,1,fixes,Fundamental issue in random-beans-validation,"I found fundamental problem in `random-beans-validation` implementation. Currently every randomizer created by the package will generate same value every time (or almost every time, see below).

Let's for example look into [`SizeAnnotationHandler`](https://github.com/benas/random-beans/blob/master/random-beans-validation/src/main/java/io/github/benas/randombeans/validation/SizeAnnotationHandler.java).

Every time randomizer is looked up for field annotated with `@Size` it will create [new instance](https://github.com/benas/random-beans/blob/master/random-beans-validation/src/main/java/io/github/benas/randombeans/validation/SizeAnnotationHandler.java#L56) of `CharacterRandomizer` providing it with **same** seed and therefore randomizer will generate **same** value every time. Or almost every time, because randomizer for string length is [not using](https://github.com/benas/random-beans/blob/master/random-beans-validation/src/main/java/io/github/benas/randombeans/validation/SizeAnnotationHandler.java#L54) seed (but it should). Other annotation handlers have same issue, except those generating constant values (for obvious reasons).

Ideal solution would be to somehow cache randomizers created for the field from annotation. But I'm not good with Java, so not sure how feasible/doable it is. ",d4a47dd6e62fe589f2fcaa8d1668cc8b0c168ee4,bb16b8a1c2736fa12f20af37385317dac3f56d58,https://github.com/j-easy/easy-random/compare/d4a47dd6e62fe589f2fcaa8d1668cc8b0c168ee4...bb16b8a1c2736fa12f20af37385317dac3f56d58,"diff --git a/random-beans-validation/src/main/java/io/github/benas/randombeans/validation/DecimaMinMaxAnnotationHandler.java b/random-beans-validation/src/main/java/io/github/benas/randombeans/validation/DecimaMinMaxAnnotationHandler.java
index f23d2e86..155bb7f8 100644
--- a/random-beans-validation/src/main/java/io/github/benas/randombeans/validation/DecimaMinMaxAnnotationHandler.java
+++ b/random-beans-validation/src/main/java/io/github/benas/randombeans/validation/DecimaMinMaxAnnotationHandler.java
@@ -32,13 +32,14 @@ import javax.validation.constraints.DecimalMin;
 import java.lang.reflect.Field;
 import java.math.BigDecimal;
 import java.math.BigInteger;
+import java.util.Random;
 
 class DecimaMinMaxAnnotationHandler implements BeanValidationAnnotationHandler {
 
-    private long seed;
+    private final Random random;
 
     public DecimaMinMaxAnnotationHandler(long seed) {
-        this.seed = seed;
+        random = new Random(seed);
     }
 
     public Randomizer<?> getRandomizer(Field field) {
@@ -62,49 +63,49 @@ class DecimaMinMaxAnnotationHandler implements BeanValidationAnnotationHandler {
                 return new ByteRangeRandomizer(
                         minValue == null ? null : minValue.byteValue(),
                         maxValue == null ? null : maxValue.byteValue(),
-                        seed
+                        random.nextLong()
                 );
             }
             if (fieldType.equals(Short.TYPE) || fieldType.equals(Short.class)) {
                 return new ShortRangeRandomizer(
                         minValue == null ? null : minValue.shortValue(),
                         maxValue == null ? null : maxValue.shortValue(),
-                        seed
+                        random.nextLong()
                 );
             }
             if (fieldType.equals(Integer.TYPE) || fieldType.equals(Integer.class)) {
                 return new IntegerRangeRandomizer(
                         minValue == null ? null : minValue.intValue(),
                         maxValue == null ? null : maxValue.intValue(),
-                        seed
+                        random.nextLong()
                 );
             }
             if (fieldType.equals(Long.TYPE) || fieldType.equals(Long.class)) {
                 return new LongRangeRandomizer(
                         minValue == null ? null : minValue.longValue(),
                         maxValue == null ? null : maxValue.longValue(),
-                        seed
+                        random.nextLong()
                 );
             }
             if (fieldType.equals(BigInteger.class)) {
                 return new BigIntegerRangeRandomizer(
                         minValue == null ? null : minValue.intValue(),
                         maxValue == null ? null : maxValue.intValue(),
-                        seed
+                        random.nextLong()
                 );
             }
             if (fieldType.equals(BigDecimal.class)) {
                 return new BigDecimalRangeRandomizer(
                         minValue == null ? null : minValue.longValue(),
                         maxValue == null ? null : maxValue.longValue(),
-                        seed
+                        random.nextLong()
                 );
             }
             if (fieldType.equals(String.class)) {
                 BigDecimalRangeRandomizer delegate = new BigDecimalRangeRandomizer(
                         minValue == null ? null : minValue.longValue(),
                         maxValue == null ? null : maxValue.longValue(),
-                        seed
+                        random.nextLong()
                 );
                 return new StringDelegatingRandomizer(delegate);
             }
diff --git a/random-beans-validation/src/main/java/io/github/benas/randombeans/validation/FutureAnnotationHandler.java b/random-beans-validation/src/main/java/io/github/benas/randombeans/validation/FutureAnnotationHandler.java
index dc1f4b19..a7a6bddc 100644
--- a/random-beans-validation/src/main/java/io/github/benas/randombeans/validation/FutureAnnotationHandler.java
+++ b/random-beans-validation/src/main/java/io/github/benas/randombeans/validation/FutureAnnotationHandler.java
@@ -30,18 +30,19 @@ import io.github.benas.randombeans.util.Constants;
 import java.lang.reflect.Field;
 import java.util.Calendar;
 import java.util.Date;
+import java.util.Random;
 
 class FutureAnnotationHandler implements BeanValidationAnnotationHandler {
 
-    private long seed;
+    private final Random random;
 
     public FutureAnnotationHandler(long seed) {
-        this.seed = seed;
+        random = new Random(seed);
     }
 
     public Randomizer<?> getRandomizer(Field field) {
         Calendar calendar = Calendar.getInstance();
         calendar.add(Calendar.YEAR, Constants.DEFAULT_DATE_RANGE);
-        return new DateRangeRandomizer(new Date(), calendar.getTime(), seed);
+        return new DateRangeRandomizer(new Date(), calendar.getTime(), random.nextLong());
     }
 }
diff --git a/random-beans-validation/src/main/java/io/github/benas/randombeans/validation/MinMaxAnnotationHandler.java b/random-beans-validation/src/main/java/io/github/benas/randombeans/validation/MinMaxAnnotationHandler.java
index c2792117..cbc21348 100644
--- a/random-beans-validation/src/main/java/io/github/benas/randombeans/validation/MinMaxAnnotationHandler.java
+++ b/random-beans-validation/src/main/java/io/github/benas/randombeans/validation/MinMaxAnnotationHandler.java
@@ -31,13 +31,14 @@ import javax.validation.constraints.Min;
 import java.lang.reflect.Field;
 import java.math.BigDecimal;
 import java.math.BigInteger;
+import java.util.Random;
 
 class MinMaxAnnotationHandler implements BeanValidationAnnotationHandler {
 
-    private long seed;
+    private final Random random;
 
     public MinMaxAnnotationHandler(long seed) {
-        this.seed = seed;
+        random = new Random(seed);
     }
 
     public Randomizer<?> getRandomizer(Field field) {
@@ -61,42 +62,42 @@ class MinMaxAnnotationHandler implements BeanValidationAnnotationHandler {
                 return new ByteRangeRandomizer(
                         minValue == null ? null : minValue.byteValue(),
                         maxValue == null ? null : maxValue.byteValue(),
-                        seed
+                        random.nextLong()
                 );
             }
             if (fieldType.equals(Short.TYPE) || fieldType.equals(Short.class)) {
                 return new ShortRangeRandomizer(
                         minValue == null ? null : minValue.shortValue(),
                         maxValue == null ? null : maxValue.shortValue(),
-                        seed
+                        random.nextLong()
                 );
             }
             if (fieldType.equals(Integer.TYPE) || fieldType.equals(Integer.class)) {
                 return new IntegerRangeRandomizer(
                         minValue == null ? null : minValue.intValue(),
                         maxValue == null ? null : maxValue.intValue(),
-                        seed
+                        random.nextLong()
                 );
             }
             if (fieldType.equals(Long.TYPE) || fieldType.equals(Long.class)) {
                 return new LongRangeRandomizer(
                         minValue == null ? null : minValue,
                         maxValue == null ? null : maxValue,
-                        seed
+                        random.nextLong()
                 );
             }
             if (fieldType.equals(BigInteger.class)) {
                 return new BigIntegerRangeRandomizer(
                         minValue == null ? null : minValue.intValue(),
                         maxValue == null ? null : maxValue.intValue(),
-                        seed
+                        random.nextLong()
                 );
             }
             if (fieldType.equals(BigDecimal.class)) {
                 return new BigDecimalRangeRandomizer(
                         minValue == null ? null : minValue,
                         maxValue == null ? null : maxValue,
-                        seed
+                        random.nextLong()
                 );
             }
         }
diff --git a/random-beans-validation/src/main/java/io/github/benas/randombeans/validation/PastAnnotationHandler.java b/random-beans-validation/src/main/java/io/github/benas/randombeans/validation/PastAnnotationHandler.java
index 16255216..b488272a 100644
--- a/random-beans-validation/src/main/java/io/github/benas/randombeans/validation/PastAnnotationHandler.java
+++ b/random-beans-validation/src/main/java/io/github/benas/randombeans/validation/PastAnnotationHandler.java
@@ -30,18 +30,19 @@ import io.github.benas.randombeans.util.Constants;
 import java.lang.reflect.Field;
 import java.util.Calendar;
 import java.util.Date;
+import java.util.Random;
 
 class PastAnnotationHandler implements BeanValidationAnnotationHandler {
 
-    private long seed;
+    private final Random random;
 
     public PastAnnotationHandler(long seed) {
-        this.seed = seed;
+        random = new Random(seed);
     }
 
     public Randomizer<?> getRandomizer(Field field) {
         Calendar calendar = Calendar.getInstance();
         calendar.add(Calendar.YEAR, -Constants.DEFAULT_DATE_RANGE);
-        return new DateRangeRandomizer(calendar.getTime(), new Date(), seed);
+        return new DateRangeRandomizer(calendar.getTime(), new Date(), random.nextLong());
     }
 }
diff --git a/random-beans-validation/src/main/java/io/github/benas/randombeans/validation/PatternAnnotationHandler.java b/random-beans-validation/src/main/java/io/github/benas/randombeans/validation/PatternAnnotationHandler.java
index 4ae738e8..70810868 100644
--- a/random-beans-validation/src/main/java/io/github/benas/randombeans/validation/PatternAnnotationHandler.java
+++ b/random-beans-validation/src/main/java/io/github/benas/randombeans/validation/PatternAnnotationHandler.java
@@ -28,13 +28,14 @@ import io.github.benas.randombeans.randomizers.RegularExpressionRandomizer;
 
 import javax.validation.constraints.Pattern;
 import java.lang.reflect.Field;
+import java.util.Random;
 
 class PatternAnnotationHandler implements BeanValidationAnnotationHandler {
 
-    private long seed;
+    private final Random random;
 
     public PatternAnnotationHandler(long seed) {
-        this.seed = seed;
+        random = new Random(seed);
     }
 
     public Randomizer<?> getRandomizer(Field field) {
@@ -43,7 +44,7 @@ class PatternAnnotationHandler implements BeanValidationAnnotationHandler {
 
         final String regex = patternAnnotation.regexp();
         if (fieldType.equals(String.class)) {
-            return new RegularExpressionRandomizer(regex, seed);
+            return new RegularExpressionRandomizer(regex, random.nextLong());
         }
         return null;
     }
diff --git a/random-beans-validation/src/main/java/io/github/benas/randombeans/validation/SizeAnnotationHandler.java b/random-beans-validation/src/main/java/io/github/benas/randombeans/validation/SizeAnnotationHandler.java
index d963ea6b..009bd5c1 100644
--- a/random-beans-validation/src/main/java/io/github/benas/randombeans/validation/SizeAnnotationHandler.java
+++ b/random-beans-validation/src/main/java/io/github/benas/randombeans/validation/SizeAnnotationHandler.java
@@ -24,23 +24,21 @@
 package io.github.benas.randombeans.validation;
 
 import io.github.benas.randombeans.api.Randomizer;
-import io.github.benas.randombeans.randomizers.text.CharacterRandomizer;
+import io.github.benas.randombeans.randomizers.text.StringRandomizer;
 
 import javax.validation.constraints.Size;
 import java.lang.reflect.Field;
 import java.nio.charset.Charset;
-
-import static io.github.benas.randombeans.randomizers.range.IntegerRangeRandomizer.aNewIntegerRangeRandomizer;
-import static io.github.benas.randombeans.randomizers.text.CharacterRandomizer.aNewCharacterRandomizer;
+import java.util.Random;
 
 class SizeAnnotationHandler implements BeanValidationAnnotationHandler {
 
-    private long seed;
+    private final Random random;
 
     private Charset charset;
 
     public SizeAnnotationHandler(long seed, Charset charset) {
-        this.seed = seed;
+        random = new Random(seed);
         this.charset = charset;
     }
 
@@ -51,19 +49,7 @@ class SizeAnnotationHandler implements BeanValidationAnnotationHandler {
         final int min = sizeAnnotation.min();
         final int max = sizeAnnotation.max();
         if (fieldType.equals(String.class)) {
-            final int randomLength = aNewIntegerRangeRandomizer(min, max).getRandomValue();
-            return new Randomizer<String>() {
-                private final CharacterRandomizer characterRandomizer = aNewCharacterRandomizer(charset, seed);
-
-                @Override
-                public String getRandomValue() {
-                    StringBuilder stringBuilder = new StringBuilder();
-                    for (int i = 0; i < randomLength; i++) {
-                        stringBuilder.append(characterRandomizer.getRandomValue());
-                    }
-                    return stringBuilder.toString();
-                }
-            };
+            return new StringRandomizer(charset, min, max, random.nextLong());
         }
         return null;
     }
diff --git a/random-beans-validation/src/test/java/io/github/benas/randombeans/validation/BeanValidationTest.java b/random-beans-validation/src/test/java/io/github/benas/randombeans/validation/BeanValidationTest.java
index 934faaf9..2d4534b4 100644
--- a/random-beans-validation/src/test/java/io/github/benas/randombeans/validation/BeanValidationTest.java
+++ b/random-beans-validation/src/test/java/io/github/benas/randombeans/validation/BeanValidationTest.java
@@ -23,19 +23,22 @@
  */
 package io.github.benas.randombeans.validation;
 
-import io.github.benas.randombeans.api.EnhancedRandom;
-import org.junit.Before;
-import org.junit.Test;
+import static io.github.benas.randombeans.EnhancedRandomBuilder.aNewEnhancedRandom;
+import static io.github.benas.randombeans.EnhancedRandomBuilder.aNewEnhancedRandomBuilder;
+import static org.assertj.core.api.Assertions.assertThat;
+
+import java.math.BigDecimal;
+import java.util.Set;
 
 import javax.validation.ConstraintViolation;
 import javax.validation.Validation;
 import javax.validation.Validator;
 import javax.validation.ValidatorFactory;
-import java.math.BigDecimal;
-import java.util.Set;
 
-import static io.github.benas.randombeans.EnhancedRandomBuilder.aNewEnhancedRandom;
-import static org.assertj.core.api.Assertions.assertThat;
+import org.junit.Before;
+import org.junit.Test;
+
+import io.github.benas.randombeans.api.EnhancedRandom;
 
 public class BeanValidationTest {
 
@@ -68,9 +71,9 @@ public class BeanValidationTest {
 
         assertThat(bean.getMinQuantity()).isGreaterThanOrEqualTo(5);// @Min(5) int minQuantity;
 
-        assertThat(bean.getMaxDiscount()).isLessThanOrEqualTo(new BigDecimal(""30.00""));// @DecimalMax(""30.00"") BigDecimal maxDiscount;;
+        assertThat(bean.getMaxDiscount()).isLessThanOrEqualTo(new BigDecimal(""30.00""));// @DecimalMax(""30.00"") BigDecimal maxDiscount;
 
-        assertThat(bean.getMinDiscount()).isGreaterThanOrEqualTo(new BigDecimal(""5.00""));// @DecimalMin(""5.00"") BigDecimal minDiscount;;
+        assertThat(bean.getMinDiscount()).isGreaterThanOrEqualTo(new BigDecimal(""5.00""));// @DecimalMin(""5.00"") BigDecimal minDiscount;
 
         assertThat(bean.getMinQuantity()).isGreaterThanOrEqualTo(5);// @Min(5) int minQuantity;
 
@@ -79,6 +82,26 @@ public class BeanValidationTest {
         assertThat(bean.getRegexString()).matches(""[a-z]{4}"");
     }
 
+    @Test
+    public void shouldGenerateTheSameValueForTheSameSeed() {
+        EnhancedRandom random = aNewEnhancedRandomBuilder().seed(123L).build();
+ 
+        BeanValidationAnnotatedBean bean = random.nextObject(BeanValidationAnnotatedBean.class);
+
+        assertThat(bean.getUsername()).isEqualTo(""eOMtThyhVNLWUZNRcBaQKxIy"");
+        // uses DateRange with now as end, so test is not repeatable
+        // assertThat(bean.getBirthday()).isEqualTo(""2007-07-22T13:20:35.628"");
+        // uses DateRange with now as start, so test is not repeatable
+        // assertThat(bean.getEventDate()).isEqualTo(""2017-07-22T13:20:35.628"");
+        assertThat(bean.getMaxQuantity()).isEqualTo(-2055951746);
+        assertThat(bean.getMinQuantity()).isEqualTo(91531906);
+        assertThat(bean.getMaxDiscount()).isEqualTo(new BigDecimal(30));
+        assertThat(bean.getMinDiscount()).isEqualTo(new BigDecimal(393126525614007301L));
+        assertThat(bean.getMinQuantity()).isEqualTo(91531906);
+        assertThat(bean.getBriefMessage()).isEqualTo(""tguu"");
+        assertThat(bean.getRegexString()).isEqualTo(""vuna"");
+    }
+
     @Test
     public void generatedBeanShouldBeValidUsingBeanValidationAPI() {
         BeanValidationAnnotatedBean bean = enhancedRandom.nextObject(BeanValidationAnnotatedBean.class);","['random-beans-validation/src/main/java/io/github/benas/randombeans/validation/PastAnnotationHandler.java', 'random-beans-validation/src/main/java/io/github/benas/randombeans/validation/MinMaxAnnotationHandler.java', 'random-beans-validation/src/main/java/io/github/benas/randombeans/validation/DecimaMinMaxAnnotationHandler.java', 'random-beans-validation/src/main/java/io/github/benas/randombeans/validation/SizeAnnotationHandler.java', 'random-beans-validation/src/test/java/io/github/benas/randombeans/validation/BeanValidationTest.java', 'random-beans-validation/src/main/java/io/github/benas/randombeans/validation/FutureAnnotationHandler.java', 'random-beans-validation/src/main/java/io/github/benas/randombeans/validation/PatternAnnotationHandler.java']",{'.java': 7},7,7,0,0,7,517748,113439,14137,170,3419,556,81,6,1313,121,271,7,3,0,2017-02-15 21:12:27,1478,Java,{'Java': 1051325},MIT License,"['random-beans-validation/src/main/java/io/github/benas/randombeans/validation/SizeAnnotationHandler.java', 'random-beans/src/main/java/io/github/benas/randombeans/randomizers/text/CharacterRandomizer.java', 'random-beans/src/main/java/io/github/benas/randombeans/randomizers/text/StringRandomizer.java', 'random-beans/src/main/java/io/github/benas/randombeans/randomizers/number/IntegerRandomizer.java', 'random-beans/src/main/java/io/github/benas/randombeans/randomizers/number/LongRandomizer.java']","['random-beans-validation/src/main/java/io/github/benas/randombeans/validation/SizeAnnotationHandler.java', 'random-beans/src/main/java/io/github/benas/randombeans/randomizers/text/CharacterRandomizer.java', 'random-beans/src/main/java/io/github/benas/randombeans/randomizers/text/StringRandomizer.java', 'random-beans/src/main/java/io/github/benas/randombeans/randomizers/number/IntegerRandomizer.java', 'random-beans/src/main/java/io/github/benas/randombeans/randomizers/number/LongRandomizer.java']","['```json\n{\n  ""files"": [\n    ""random-beans-validation/src/main/java/io/github/benas/randombeans/validation/SizeAnnotationHandler.java"",\n    ""random-beans/src/main/java/io/github/benas/randombeans/randomizers/text/CharacterRandomizer.java"",\n    ""random-beans/src/main/java/io/github/benas/randombeans/randomizers/text/StringRandomizer.java"",\n    ""random-beans/src/main/java/io/github/benas/randombeans/randomizers/number/IntegerRandomizer.java"",\n    ""random-beans/src/main/java/io/github/benas/randombeans/randomizers/number/LongRandomizer.java""\n  ]\n}\n```']",1,1720.1042175292969
9988,apache/eventmesh/3432/3431,apache,eventmesh,https://github.com/apache/eventmesh/issues/3431,https://github.com/apache/eventmesh/pull/3432,https://github.com/apache/eventmesh/pull/3432,1,fixes,[Bug]ProducerTopicManager throw NPE when runtime module started,"### Search before asking

- [X] I had searched in the [issues](https://github.com/apache/eventmesh/issues?q=is%3Aissue) and found no similar issues.


### Environment

Windows

### EventMesh version

master

### What happened

when I start eventmesh runtime module. when ProducerTopicManager.scheduler execute then will throw java.lang.NullPointerException:

```
2023-03-12 12:27:53,048 INFO  [eventMesh-metrics-2] HTTPMetricsServer(HTTPMetricsServer.java:155) - maxPushMsgTPS: 0.0, avgPushMsgTPS: 0.0, sum: 0, sumFail: 0, sumFailRate: 0.0, maxClientLatency: 0.0, avgClientLatency: 0.0
2023-03-12 12:27:53,048 INFO  [eventMesh-metrics-2] HTTPMetricsServer(HTTPMetricsServer.java:170) - batchMsgQ: 0, sendMsgQ: 0, pushMsgQ: 0, httpRetryQ: 0
2023-03-12 12:27:53,048 INFO  [eventMesh-metrics-2] HTTPMetricsServer(HTTPMetricsServer.java:178) - batchAvgSend2MQCost: 0.0, avgSend2MQCost: 0.0, avgReply2MQCost: 0.0
java.lang.NullPointerException
	at org.apache.eventmesh.runtime.core.protocol.http.producer.ProducerTopicManager.lambda$start$1(ProducerTopicManager.java:69)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset$$$capture(FutureTask.java:308)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2023-03-12 12:28:02,065 DEBUG [pool-4-thread-1] ConsumerManager(ConsumerManager.java:214) - grpc client info check
2023-03-12 12:28:02,065 DEBUG [pool-4-thread-1] ConsumerManager(ConsumerManager.java:223) - total number of ConsumerGroupClients: 0
2023-03-12 12:28:12,060 DEBUG [pool-4-thread-1] ConsumerManager(ConsumerManager.java:214) - grpc client info check
2023-03-12 12:28:12,060 DEBUG [pool-4-thread-1] ConsumerManager(ConsumerManager.java:223) - total number of ConsumerGroupClients: 0
java.lang.NullPointerException
	at org.apache.eventmesh.runtime.core.protocol.http.producer.ProducerTopicManager.lambda$start$1(ProducerTopicManager.java:69)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset$$$capture(FutureTask.java:308)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2023-03-12 12:28:22,063 DEBUG [pool-4-thread-1] ConsumerManager(ConsumerManager.java:214) - grpc client info check
2023-03-12 12:28:22,063 DEBUG [pool-4-thread-1] ConsumerManager(ConsumerManager.java:223) - total number of ConsumerGroupClients: 0
```


### How to reproduce

start eventmesh runtime

### Debug logs

```
2023-03-12 12:27:53,048 INFO  [eventMesh-metrics-2] HTTPMetricsServer(HTTPMetricsServer.java:155) - maxPushMsgTPS: 0.0, avgPushMsgTPS: 0.0, sum: 0, sumFail: 0, sumFailRate: 0.0, maxClientLatency: 0.0, avgClientLatency: 0.0
2023-03-12 12:27:53,048 INFO  [eventMesh-metrics-2] HTTPMetricsServer(HTTPMetricsServer.java:170) - batchMsgQ: 0, sendMsgQ: 0, pushMsgQ: 0, httpRetryQ: 0
2023-03-12 12:27:53,048 INFO  [eventMesh-metrics-2] HTTPMetricsServer(HTTPMetricsServer.java:178) - batchAvgSend2MQCost: 0.0, avgSend2MQCost: 0.0, avgReply2MQCost: 0.0
java.lang.NullPointerException
	at org.apache.eventmesh.runtime.core.protocol.http.producer.ProducerTopicManager.lambda$start$1(ProducerTopicManager.java:69)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset$$$capture(FutureTask.java:308)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2023-03-12 12:28:02,065 DEBUG [pool-4-thread-1] ConsumerManager(ConsumerManager.java:214) - grpc client info check
2023-03-12 12:28:02,065 DEBUG [pool-4-thread-1] ConsumerManager(ConsumerManager.java:223) - total number of ConsumerGroupClients: 0
2023-03-12 12:28:12,060 DEBUG [pool-4-thread-1] ConsumerManager(ConsumerManager.java:214) - grpc client info check
2023-03-12 12:28:12,060 DEBUG [pool-4-thread-1] ConsumerManager(ConsumerManager.java:223) - total number of ConsumerGroupClients: 0
java.lang.NullPointerException
	at org.apache.eventmesh.runtime.core.protocol.http.producer.ProducerTopicManager.lambda$start$1(ProducerTopicManager.java:69)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset$$$capture(FutureTask.java:308)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2023-03-12 12:28:22,063 DEBUG [pool-4-thread-1] ConsumerManager(ConsumerManager.java:214) - grpc client info check
2023-03-12 12:28:22,063 DEBUG [pool-4-thread-1] ConsumerManager(ConsumerManager.java:223) - total number of ConsumerGroupClients: 0
```

### Are you willing to submit PR?

- [X] Yes I am willing to submit a PR!",8aa97ac2df2fde85e8fbd5b0c51132f41f6447f4,38cb976a5ac0420f6a861be5a91393b1049ba292,https://github.com/apache/eventmesh/compare/8aa97ac2df2fde85e8fbd5b0c51132f41f6447f4...38cb976a5ac0420f6a861be5a91393b1049ba292,"diff --git a/eventmesh-runtime/src/main/java/org/apache/eventmesh/runtime/boot/EventMeshServer.java b/eventmesh-runtime/src/main/java/org/apache/eventmesh/runtime/boot/EventMeshServer.java
index dfbad0a38..5d0fd427a 100644
--- a/eventmesh-runtime/src/main/java/org/apache/eventmesh/runtime/boot/EventMeshServer.java
+++ b/eventmesh-runtime/src/main/java/org/apache/eventmesh/runtime/boot/EventMeshServer.java
@@ -218,4 +218,8 @@ public class EventMeshServer {
     public ProducerTopicManager getProducerTopicManager() {
         return producerTopicManager;
     }
+
+    public CommonConfiguration getConfiguration() {
+        return configuration;
+    }
 }
diff --git a/eventmesh-runtime/src/main/java/org/apache/eventmesh/runtime/core/protocol/http/producer/ProducerTopicManager.java b/eventmesh-runtime/src/main/java/org/apache/eventmesh/runtime/core/protocol/http/producer/ProducerTopicManager.java
index 785540424..5568cad59 100644
--- a/eventmesh-runtime/src/main/java/org/apache/eventmesh/runtime/core/protocol/http/producer/ProducerTopicManager.java
+++ b/eventmesh-runtime/src/main/java/org/apache/eventmesh/runtime/core/protocol/http/producer/ProducerTopicManager.java
@@ -23,39 +23,33 @@ import org.apache.eventmesh.common.ThreadPoolFactory;
 import org.apache.eventmesh.runtime.boot.EventMeshServer;
 
 import java.util.List;
+import java.util.Optional;
 import java.util.concurrent.ConcurrentHashMap;
 import java.util.concurrent.ScheduledExecutorService;
 import java.util.concurrent.ScheduledFuture;
 import java.util.concurrent.TimeUnit;
 
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
+import lombok.extern.slf4j.Slf4j;
 
+@Slf4j
 public class ProducerTopicManager {
 
-    private Logger retryLogger = LoggerFactory.getLogger(""p-topic-m"");
-
-    private Logger logger = LoggerFactory.getLogger(this.getClass());
-
     private EventMeshServer eventMeshServer;
 
-    public ProducerTopicManager(EventMeshServer eventMeshServer) {
-        this.eventMeshServer = eventMeshServer;
-    }
-
     private transient ScheduledFuture<?> scheduledTask;
 
     protected static ScheduledExecutorService scheduler;
 
-    private ConcurrentHashMap<String, EventMeshServicePubTopicInfo> eventMeshServicePubTopicInfoMap = new ConcurrentHashMap<>();
+    private ConcurrentHashMap<String, EventMeshServicePubTopicInfo> eventMeshServicePubTopicInfoMap = new ConcurrentHashMap<>(64);
 
-    public void init() {
+    public ProducerTopicManager(EventMeshServer eventMeshServer) {
+        this.eventMeshServer = eventMeshServer;
+    }
 
+    public void init() {
         scheduler = ThreadPoolFactory.createScheduledExecutor(Runtime.getRuntime().availableProcessors(),
             new EventMeshThreadFactory(""Producer-Topic-Manager"", true));
-        logger.info(""ProducerTopicManager inited......"");
-
+        log.info(""ProducerTopicManager inited......"");
     }
 
     public void start() {
@@ -63,29 +57,28 @@ public class ProducerTopicManager {
         if (scheduledTask == null) {
             synchronized (ProducerTopicManager.class) {
                 scheduledTask = scheduler.scheduleAtFixedRate(() -> {
-
                     try {
-                        List<EventMeshServicePubTopicInfo> list = eventMeshServer.getRegistry().findEventMeshServicePubTopicInfos();
-                        list.forEach(e -> {
-                            eventMeshServicePubTopicInfoMap.put(e.getService(), e);
-                        });
+                        if (!eventMeshServer.getConfiguration().isEventMeshServerRegistryEnable()) {
+                            return;
+                        }
+                        List<EventMeshServicePubTopicInfo> pubTopicInfoList = eventMeshServer.getRegistry().findEventMeshServicePubTopicInfos();
+                        Optional.ofNullable(pubTopicInfoList)
+                            .ifPresent(lt -> lt.forEach(item -> eventMeshServicePubTopicInfoMap.put(item.getService(), item)));
                     } catch (Exception e) {
-                        e.printStackTrace();
+                        log.error(""ProducerTopicManager update eventMesh pub topic info error. "", e);
                     }
 
                 }, 5, 20, TimeUnit.SECONDS);
             }
         }
-
-
-        logger.info(""ProducerTopicManager started......"");
+        log.info(""ProducerTopicManager started......"");
     }
 
     public void shutdown() {
         if (scheduledTask != null) {
             scheduledTask.cancel(false);
         }
-        logger.info(""ProducerTopicManager shutdown......"");
+        log.info(""ProducerTopicManager shutdown......"");
     }
 
     public ConcurrentHashMap<String, EventMeshServicePubTopicInfo> getEventMeshServicePubTopicInfoMap() {
@@ -97,4 +90,4 @@ public class ProducerTopicManager {
     }
 
 
-}
\\ No newline at end of file
+}
diff --git a/eventmesh-runtime/src/main/java/org/apache/eventmesh/runtime/core/protocol/tcp/client/session/Session.java b/eventmesh-runtime/src/main/java/org/apache/eventmesh/runtime/core/protocol/tcp/client/session/Session.java
index b76339c1d..9030fae02 100644
--- a/eventmesh-runtime/src/main/java/org/apache/eventmesh/runtime/core/protocol/tcp/client/session/Session.java
+++ b/eventmesh-runtime/src/main/java/org/apache/eventmesh/runtime/core/protocol/tcp/client/session/Session.java
@@ -326,19 +326,19 @@ public class Session {
 
     public void trySendListenResponse(Header header, long startTime, long taskExecuteTime) {
         if (!listenRspSend && listenRspLock.tryLock()) {
-                if (!listenRspSend) {
-                    if (header == null) {
-                        header = new Header(LISTEN_RESPONSE, OPStatus.SUCCESS.getCode(), ""succeed"", null);
-                    }
-                    Package msg = new Package();
-                    msg.setHeader(header);
-
-                    // TODO: if startTime is modified
-                    Utils.writeAndFlush(msg, startTime, taskExecuteTime, context, this);
-                    listenRspSend = true;
+            if (!listenRspSend) {
+                if (header == null) {
+                    header = new Header(LISTEN_RESPONSE, OPStatus.SUCCESS.getCode(), ""succeed"", null);
                 }
-                listenRspLock.unlock();
-            
+                Package msg = new Package();
+                msg.setHeader(header);
+
+                // TODO: if startTime is modified
+                Utils.writeAndFlush(msg, startTime, taskExecuteTime, context, this);
+                listenRspSend = true;
+            }
+            listenRspLock.unlock();
+
         }
     }
 ","['eventmesh-runtime/src/main/java/org/apache/eventmesh/runtime/core/protocol/http/producer/ProducerTopicManager.java', 'eventmesh-runtime/src/main/java/org/apache/eventmesh/runtime/boot/EventMeshServer.java', 'eventmesh-runtime/src/main/java/org/apache/eventmesh/runtime/core/protocol/tcp/client/session/Session.java']",{'.java': 3},3,3,0,0,3,3744368,733522,99974,796,3292,589,73,3,6449,365,1740,91,1,2,2023-03-12 04:54:04,1415,Java,"{'Java': 3911514, 'Go': 272517, 'Shell': 65032, 'Rust': 49060, 'Makefile': 3761, 'Dockerfile': 1322}",Apache License 2.0,['eventmesh-runtime/src/main/java/org/apache/eventmesh/runtime/core/protocol/http/producer/ProducerTopicManager.java'],['eventmesh-runtime/src/main/java/org/apache/eventmesh/runtime/core/protocol/http/producer/ProducerTopicManager.java'],"['```json\n{\n  ""files"": [\n    ""eventmesh-runtime/src/main/java/org/apache/eventmesh/runtime/core/protocol/http/producer/ProducerTopicManager.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""eventmesh-runtime/src/main/java/org/apache/eventmesh/runtime/core/protocol/http/producer/ProducerTopicManager.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""eventmesh-runtime/src/main/java/org/apache/eventmesh/runtime/core/protocol/http/producer/ProducerTopicManager.java""\n  ]\n}\n```']",2,3629.261016845703
9891,clickhouse/clickhouse-java/540/462,clickhouse,clickhouse-java,https://github.com/ClickHouse/clickhouse-java/issues/462,https://github.com/ClickHouse/clickhouse-java/pull/540,https://github.com/ClickHouse/clickhouse-java/pull/540,1,fix,NoHttpResponseException while intensive inserts,"Hi!
I catch an error using sendStream in RowBinary format intensive queries(1M rows in batch every 3 second) One batch inserts in ~10-15 seconds. 
Clickhouse machine cpu usage is about 25%.
It appears after 5 minutes of job start.

I tried to catch problematic batch and insert in separately. Everything was fine.

clickouse-jdbc 0.2.4

 #https://github.com/ClickHouse/ClickHouse/issues/11766

Sample of usage
```
try (ClickHouseStatement statement = clickHouseDataSource.getConnection().createStatement()) {
                statement.write().send(QUERY_INSERT, batch, ClickHouseFormat.RowBinary);
```

Simple schema
```
CREATE TABLE IF NOT EXISTS t1
(
    timestamp   DateTime,
    sid         FixedString(10),
    url1        String,
    url2        String,
    importMonth UInt32 default toYYYYMM(now()),
    sidHash     UInt32 DEFAULT xxHash32(sid),
    url1Domain  String DEFAULT domainWithoutWWW(url1)
)
    ENGINE = MergeTree
        PARTITION BY (importMonth)
        ORDER BY (sidHash);
```
Timeouts config
```
clickHouseDataSource.getProperties().setSessionTimeout(600_000L);
        clickHouseDataSource.getProperties().setConnectionTimeout(600_000);
        clickHouseDataSource.getProperties().setSocketTimeout(600_000);
        clickHouseDataSource.getProperties().setDataTransferTimeout(600_000);
        clickHouseDataSource.getProperties().setKeepAliveTimeout(600_000);
```

Exception

```
Caused by: org.apache.http.NoHttpResponseException: server:8123 failed to respond
	at org.apache.http.impl.conn.DefaultHttpResponseParser.parseHead(DefaultHttpResponseParser.java:141)
	at org.apache.http.impl.conn.DefaultHttpResponseParser.parseHead(DefaultHttpResponseParser.java:56)
	at org.apache.http.impl.io.AbstractMessageParser.parse(AbstractMessageParser.java:259)
	at org.apache.http.impl.DefaultBHttpClientConnection.receiveResponseHeader(DefaultBHttpClientConnection.java:163)
	at org.apache.http.impl.conn.CPoolProxy.receiveResponseHeader(CPoolProxy.java:157)
	at org.apache.http.protocol.HttpRequestExecutor.doReceiveResponse(HttpRequestExecutor.java:273)
	at org.apache.http.protocol.HttpRequestExecutor.execute(HttpRequestExecutor.java:125)
	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:272)
	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:186)
	at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)
	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:108)
	at ru.yandex.clickhouse.ClickHouseStatementImpl.sendStream(ClickHouseStatementImpl.java:849)
	... 13 common frames omitted
```

Error in clickhouse log 
```
2020.06.18 15:10:11.079888 [ 966 ] {c2912eff-d759-4b1b-80b3-151e5a96196a} <Error> executeQuery: Code: 23, e.displayText() = DB::Exception: Cannot read from istream at offset 22020096 (version 20.4.4.18 (official build)) (from server:53702) (in query: INSERT INTO tabl1(timestamp,sid,url1,url2) FORMAT RowBinary ), Stack trace (when copying this message, always include the lines below):

0. Poco::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int) @ 0x104191d0 in /usr/bin/clickhouse
1. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int) @ 0x8fff8ad in /usr/bin/clickhouse
2. ? @ 0x90db204 in /usr/bin/clickhouse
3. DB::CompressedReadBufferBase::readCompressedData(unsigned long&, unsigned long&) @ 0xcdf7dce in /usr/bin/clickhouse
4. DB::CompressedReadBuffer::nextImpl() @ 0xcdf616b in /usr/bin/clickhouse
5. DB::ConcatReadBuffer::nextImpl() @ 0x90e8912 in /usr/bin/clickhouse
6. DB::ConcatReadBuffer::nextImpl() @ 0x90e8912 in /usr/bin/clickhouse
7. DB::ReadBuffer::readStrict(char*, unsigned long) @ 0x903b525 in /usr/bin/clickhouse
8. DB::DataTypeString::deserializeBinary(DB::IColumn&, DB::ReadBuffer&) const @ 0xcf3ade5 in /usr/bin/clickhouse
9. DB::BinaryRowInputFormat::readRow(std::__1::vector<COW<DB::IColumn>::mutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::mutable_ptr<DB::IColumn> > >&, DB::RowReadExtension&) @ 0xdb683af in /usr/bin/clickhouse
10. DB::IRowInputFormat::generate() @ 0xdb5d151 in /usr/bin/clickhouse
11. DB::ISource::work() @ 0xdaf3d8b in /usr/bin/clickhouse
12. DB::InputStreamFromInputFormat::readImpl() @ 0xdab99fd in /usr/bin/clickhouse
13. DB::IBlockInputStream::read() @ 0xce4825d in /usr/bin/clickhouse
14. DB::AddingDefaultsBlockInputStream::readImpl() @ 0xce3896b in /usr/bin/clickhouse
15. DB::IBlockInputStream::read() @ 0xce4825d in /usr/bin/clickhouse
16. DB::InputStreamFromASTInsertQuery::readImpl() @ 0xd1cbc39 in /usr/bin/clickhouse
17. DB::IBlockInputStream::read() @ 0xce4825d in /usr/bin/clickhouse
18. DB::copyData(DB::IBlockInputStream&, DB::IBlockOutputStream&, std::__1::atomic<bool>*) @ 0xce7717e in /usr/bin/clickhouse
19. DB::executeQuery(DB::ReadBuffer&, DB::WriteBuffer&, bool, DB::Context&, std::__1::function<void (std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)>) @ 0xd54d5ab in /usr/bin/clickhouse
20. DB::HTTPHandler::processQuery(Poco::Net::HTTPServerRequest&, HTMLForm&, Poco::Net::HTTPServerResponse&, DB::HTTPHandler::Output&) @ 0x90e47fc in /usr/bin/clickhouse
21. DB::HTTPHandler::handleRequest(Poco::Net::HTTPServerRequest&, Poco::Net::HTTPServerResponse&) @ 0x90e8256 in /usr/bin/clickhouse
22. Poco::Net::HTTPServerConnection::run() @ 0x102c9b83 in /usr/bin/clickhouse
23. Poco::Net::TCPServerConnection::start() @ 0x10304f4b in /usr/bin/clickhouse
24. Poco::Net::TCPServerDispatcher::run() @ 0x103053db in /usr/bin/clickhouse
25. Poco::PooledThread::run() @ 0x104b2fa6 in /usr/bin/clickhouse
26. Poco::ThreadImpl::runnableEntry(void*) @ 0x104ae260 in /usr/bin/clickhouse
27. start_thread @ 0x7fa3 in /lib/x86_64-linux-gnu/libpthread-2.28.so
28. __clone @ 0xf94cf in /lib/x86_64-linux-gnu/libc-2.28.so

2020.06.18 15:10:11.080144 [ 966 ] {} <Error> DynamicQueryHandler: Code: 23, e.displayText() = DB::Exception: Cannot read from istream at offset 22020096, Stack trace (when copying this message, always include the lines below):

0. Poco::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int) @ 0x104191d0 in /usr/bin/clickhouse
1. DB::Exception::Exception(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, int) @ 0x8fff8ad in /usr/bin/clickhouse
2. ? @ 0x90db204 in /usr/bin/clickhouse
3. DB::CompressedReadBufferBase::readCompressedData(unsigned long&, unsigned long&) @ 0xcdf7dce in /usr/bin/clickhouse
4. DB::CompressedReadBuffer::nextImpl() @ 0xcdf616b in /usr/bin/clickhouse
5. DB::ConcatReadBuffer::nextImpl() @ 0x90e8912 in /usr/bin/clickhouse
6. DB::ConcatReadBuffer::nextImpl() @ 0x90e8912 in /usr/bin/clickhouse
7. DB::ReadBuffer::readStrict(char*, unsigned long) @ 0x903b525 in /usr/bin/clickhouse
8. DB::DataTypeString::deserializeBinary(DB::IColumn&, DB::ReadBuffer&) const @ 0xcf3ade5 in /usr/bin/clickhouse
9. DB::BinaryRowInputFormat::readRow(std::__1::vector<COW<DB::IColumn>::mutable_ptr<DB::IColumn>, std::__1::allocator<COW<DB::IColumn>::mutable_ptr<DB::IColumn> > >&, DB::RowReadExtension&) @ 0xdb683af in /usr/bin/clickhouse
10. DB::IRowInputFormat::generate() @ 0xdb5d151 in /usr/bin/clickhouse
11. DB::ISource::work() @ 0xdaf3d8b in /usr/bin/clickhouse
12. DB::InputStreamFromInputFormat::readImpl() @ 0xdab99fd in /usr/bin/clickhouse
13. DB::IBlockInputStream::read() @ 0xce4825d in /usr/bin/clickhouse
14. DB::AddingDefaultsBlockInputStream::readImpl() @ 0xce3896b in /usr/bin/clickhouse
15. DB::IBlockInputStream::read() @ 0xce4825d in /usr/bin/clickhouse
16. DB::InputStreamFromASTInsertQuery::readImpl() @ 0xd1cbc39 in /usr/bin/clickhouse
17. DB::IBlockInputStream::read() @ 0xce4825d in /usr/bin/clickhouse
18. DB::copyData(DB::IBlockInputStream&, DB::IBlockOutputStream&, std::__1::atomic<bool>*) @ 0xce7717e in /usr/bin/clickhouse
19. DB::executeQuery(DB::ReadBuffer&, DB::WriteBuffer&, bool, DB::Context&, std::__1::function<void (std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)>) @ 0xd54d5ab in /usr/bin/clickhouse
20. DB::HTTPHandler::processQuery(Poco::Net::HTTPServerRequest&, HTMLForm&, Poco::Net::HTTPServerResponse&, DB::HTTPHandler::Output&) @ 0x90e47fc in /usr/bin/clickhouse
21. DB::HTTPHandler::handleRequest(Poco::Net::HTTPServerRequest&, Poco::Net::HTTPServerResponse&) @ 0x90e8256 in /usr/bin/clickhouse
22. Poco::Net::HTTPServerConnection::run() @ 0x102c9b83 in /usr/bin/clickhouse
23. Poco::Net::TCPServerConnection::start() @ 0x10304f4b in /usr/bin/clickhouse
24. Poco::Net::TCPServerDispatcher::run() @ 0x103053db in /usr/bin/clickhouse
25. Poco::PooledThread::run() @ 0x104b2fa6 in /usr/bin/clickhouse
26. Poco::ThreadImpl::runnableEntry(void*) @ 0x104ae260 in /usr/bin/clickhouse
27. start_thread @ 0x7fa3 in /lib/x86_64-linux-gnu/libpthread-2.28.so
28. __clone @ 0xf94cf in /lib/x86_64-linux-gnu/libc-2.28.so
 (version 20.4.4.18 (official build))

```",8e68aa489d21fcb4a0f4d48c05028f804f048169,f90acb005c077b4b82dbb6d6d92d64930cef4d4d,https://github.com/clickhouse/clickhouse-java/compare/8e68aa489d21fcb4a0f4d48c05028f804f048169...f90acb005c077b4b82dbb6d6d92d64930cef4d4d,"diff --git a/src/main/java/ru/yandex/clickhouse/settings/ClickHouseConnectionSettings.java b/src/main/java/ru/yandex/clickhouse/settings/ClickHouseConnectionSettings.java
index 202574fe..6928a340 100644
--- a/src/main/java/ru/yandex/clickhouse/settings/ClickHouseConnectionSettings.java
+++ b/src/main/java/ru/yandex/clickhouse/settings/ClickHouseConnectionSettings.java
@@ -27,6 +27,7 @@ public enum ClickHouseConnectionSettings implements DriverPropertyCreator {
             + "" ClickHouse rejects request execution if its time exceeds max_execution_time""),
 
 
+    @Deprecated
     KEEP_ALIVE_TIMEOUT(""keepAliveTimeout"", 30 * 1000, """"),
 
     /**
@@ -35,6 +36,7 @@ public enum ClickHouseConnectionSettings implements DriverPropertyCreator {
     TIME_TO_LIVE_MILLIS(""timeToLiveMillis"", 60 * 1000, """"),
     DEFAULT_MAX_PER_ROUTE(""defaultMaxPerRoute"", 500, """"),
     MAX_TOTAL(""maxTotal"", 10000, """"),
+    MAX_RETRIES(""maxRetries"", 3, ""Maximum retries(default to 3) for idempotent operation. Set 0 to disable retry.""),
 
     /**
      * additional
diff --git a/src/main/java/ru/yandex/clickhouse/settings/ClickHouseProperties.java b/src/main/java/ru/yandex/clickhouse/settings/ClickHouseProperties.java
index b368917e..6c01b194 100644
--- a/src/main/java/ru/yandex/clickhouse/settings/ClickHouseProperties.java
+++ b/src/main/java/ru/yandex/clickhouse/settings/ClickHouseProperties.java
@@ -22,6 +22,7 @@ public class ClickHouseProperties {
     private int timeToLiveMillis;
     private int defaultMaxPerRoute;
     private int maxTotal;
+    private int maxRetries;
     private String host;
     private int port;
     private boolean usePathAsDb;
@@ -113,6 +114,7 @@ public class ClickHouseProperties {
         this.timeToLiveMillis = (Integer)getSetting(info, ClickHouseConnectionSettings.TIME_TO_LIVE_MILLIS);
         this.defaultMaxPerRoute = (Integer)getSetting(info, ClickHouseConnectionSettings.DEFAULT_MAX_PER_ROUTE);
         this.maxTotal = (Integer)getSetting(info, ClickHouseConnectionSettings.MAX_TOTAL);
+        this.maxRetries = (Integer)getSetting(info, ClickHouseConnectionSettings.MAX_RETRIES);
         this.maxCompressBufferSize = (Integer) getSetting(info, ClickHouseConnectionSettings.MAX_COMPRESS_BUFFER_SIZE);
         this.ssl = (Boolean) getSetting(info, ClickHouseConnectionSettings.SSL);
         this.sslRootCertificate = (String) getSetting(info, ClickHouseConnectionSettings.SSL_ROOT_CERTIFICATE);
@@ -179,6 +181,7 @@ public class ClickHouseProperties {
         ret.put(ClickHouseConnectionSettings.TIME_TO_LIVE_MILLIS.getKey(), String.valueOf(timeToLiveMillis));
         ret.put(ClickHouseConnectionSettings.DEFAULT_MAX_PER_ROUTE.getKey(), String.valueOf(defaultMaxPerRoute));
         ret.put(ClickHouseConnectionSettings.MAX_TOTAL.getKey(), String.valueOf(maxTotal));
+        ret.put(ClickHouseConnectionSettings.MAX_RETRIES.getKey(), String.valueOf(maxRetries));
         ret.put(ClickHouseConnectionSettings.MAX_COMPRESS_BUFFER_SIZE.getKey(), String.valueOf(maxCompressBufferSize));
         ret.put(ClickHouseConnectionSettings.SSL.getKey(), String.valueOf(ssl));
         ret.put(ClickHouseConnectionSettings.SSL_ROOT_CERTIFICATE.getKey(), String.valueOf(sslRootCertificate));
@@ -248,6 +251,7 @@ public class ClickHouseProperties {
         setTimeToLiveMillis(properties.timeToLiveMillis);
         setDefaultMaxPerRoute(properties.defaultMaxPerRoute);
         setMaxTotal(properties.maxTotal);
+        setMaxRetries(properties.maxRetries);
         setMaxCompressBufferSize(properties.maxCompressBufferSize);
         setSsl(properties.ssl);
         setSslRootCertificate(properties.sslRootCertificate);
@@ -594,6 +598,14 @@ public class ClickHouseProperties {
         this.maxTotal = maxTotal;
     }
 
+    public int getMaxRetries() {
+        return maxRetries;
+    }
+
+    public void setMaxRetries(int maxRetries) {
+        this.maxRetries = maxRetries;
+    }
+
     public int getMaxCompressBufferSize() {
         return maxCompressBufferSize;
     }
diff --git a/src/main/java/ru/yandex/clickhouse/util/ClickHouseHttpClientBuilder.java b/src/main/java/ru/yandex/clickhouse/util/ClickHouseHttpClientBuilder.java
index 59e89314..66bc9980 100644
--- a/src/main/java/ru/yandex/clickhouse/util/ClickHouseHttpClientBuilder.java
+++ b/src/main/java/ru/yandex/clickhouse/util/ClickHouseHttpClientBuilder.java
@@ -27,20 +27,19 @@ import javax.net.ssl.TrustManagerFactory;
 
 import org.apache.http.ConnectionReuseStrategy;
 import org.apache.http.Header;
-import org.apache.http.HeaderElement;
-import org.apache.http.HeaderElementIterator;
 import org.apache.http.HttpHeaders;
 import org.apache.http.HttpHost;
 import org.apache.http.HttpResponse;
+import org.apache.http.NoHttpResponseException;
 import org.apache.http.auth.AuthScope;
 import org.apache.http.auth.UsernamePasswordCredentials;
 import org.apache.http.client.AuthCache;
 import org.apache.http.client.CredentialsProvider;
+import org.apache.http.client.HttpRequestRetryHandler;
 import org.apache.http.client.config.RequestConfig;
 import org.apache.http.client.protocol.HttpClientContext;
 import org.apache.http.config.ConnectionConfig;
 import org.apache.http.config.RegistryBuilder;
-import org.apache.http.conn.ConnectionKeepAliveStrategy;
 import org.apache.http.conn.socket.ConnectionSocketFactory;
 import org.apache.http.conn.socket.PlainConnectionSocketFactory;
 import org.apache.http.conn.ssl.NoopHostnameVerifier;
@@ -50,11 +49,10 @@ import org.apache.http.impl.auth.BasicScheme;
 import org.apache.http.impl.client.BasicAuthCache;
 import org.apache.http.impl.client.BasicCredentialsProvider;
 import org.apache.http.impl.client.CloseableHttpClient;
+import org.apache.http.impl.client.DefaultHttpRequestRetryHandler;
 import org.apache.http.impl.client.HttpClientBuilder;
 import org.apache.http.impl.conn.PoolingHttpClientConnectionManager;
 import org.apache.http.message.BasicHeader;
-import org.apache.http.message.BasicHeaderElementIterator;
-import org.apache.http.protocol.HTTP;
 import org.apache.http.protocol.HttpContext;
 
 import ru.yandex.clickhouse.settings.ClickHouseProperties;
@@ -71,16 +69,32 @@ public class ClickHouseHttpClientBuilder {
     public CloseableHttpClient buildClient() throws Exception {
         return HttpClientBuilder.create()
                 .setConnectionManager(getConnectionManager())
+                .setRetryHandler(getRequestRetryHandler())
                 .setConnectionReuseStrategy(getConnectionReuseStrategy())
                 .setDefaultConnectionConfig(getConnectionConfig())
                 .setDefaultRequestConfig(getRequestConfig())
                 .setDefaultHeaders(getDefaultHeaders())
                 .setDefaultCredentialsProvider(getDefaultCredentialsProvider())
-                .disableContentCompression() // gzip здесь ни к чему. Используется lz4 при compress=1
+                .disableContentCompression() // gzip is not needed. Use lz4 when compress=1
                 .disableRedirectHandling()
                 .build();
     }
 
+    private HttpRequestRetryHandler getRequestRetryHandler() {
+        final int maxRetries = properties.getMaxRetries();
+        return new DefaultHttpRequestRetryHandler(maxRetries, false) {
+            @Override
+            public boolean retryRequest(IOException exception, int executionCount, HttpContext context) {
+                if (executionCount > maxRetries || context == null 
+                    || !Boolean.TRUE.equals(context.getAttribute(""is_idempotent""))) {
+                    return false;
+                }
+
+                return (exception instanceof NoHttpResponseException) || super.retryRequest(exception, executionCount, context);
+            }
+        };
+    }
+
     public static HttpClientContext createClientContext(ClickHouseProperties props) {
         if (props == null
             || !isConfigurationValidForAuth(props))
@@ -155,29 +169,6 @@ public class ClickHouseHttpClientBuilder {
         return headers;
     }
 
-    private ConnectionKeepAliveStrategy createKeepAliveStrategy() {
-        return new ConnectionKeepAliveStrategy() {
-            @Override
-            public long getKeepAliveDuration(HttpResponse httpResponse, HttpContext httpContext) {
-                // in case of errors keep-alive not always works. close connection just in case
-                if (httpResponse.getStatusLine().getStatusCode() != HttpURLConnection.HTTP_OK) {
-                    return -1;
-                }
-                HeaderElementIterator it = new BasicHeaderElementIterator(
-                        httpResponse.headerIterator(HTTP.CONN_DIRECTIVE));
-                while (it.hasNext()) {
-                    HeaderElement he = it.nextElement();
-                    String param = he.getName();
-                    //String value = he.getValue();
-                    if (param != null && param.equalsIgnoreCase(HTTP.CONN_KEEP_ALIVE)) {
-                        return properties.getKeepAliveTimeout();
-                    }
-                }
-                return -1;
-            }
-        };
-    }
-
     private SSLContext getSSLContext()
       throws CertificateException, NoSuchAlgorithmException, KeyStoreException, IOException, KeyManagementException {
       SSLContext ctx = SSLContext.getInstance(""TLS"");
diff --git a/src/test/java/ru/yandex/clickhouse/util/ClickHouseHttpClientBuilderTest.java b/src/test/java/ru/yandex/clickhouse/util/ClickHouseHttpClientBuilderTest.java
index e7cc8802..e7eee897 100644
--- a/src/test/java/ru/yandex/clickhouse/util/ClickHouseHttpClientBuilderTest.java
+++ b/src/test/java/ru/yandex/clickhouse/util/ClickHouseHttpClientBuilderTest.java
@@ -1,8 +1,12 @@
 package ru.yandex.clickhouse.util;
 
 import org.apache.http.HttpHost;
+import org.apache.http.NoHttpResponseException;
 import org.apache.http.client.methods.HttpPost;
+import org.apache.http.conn.HttpHostConnectException;
 import org.apache.http.impl.client.CloseableHttpClient;
+import org.apache.http.protocol.BasicHttpContext;
+import org.apache.http.protocol.HttpContext;
 import org.testng.annotations.AfterClass;
 import org.testng.annotations.AfterMethod;
 import org.testng.annotations.BeforeClass;
@@ -141,7 +145,72 @@ public class ClickHouseHttpClientBuilderTest {
                 null, null, ""baz"", ""Basic ZGVmYXVsdDpiYXo="" // default:baz
             },
         };
+    }
+
+    private static WireMockServer newServer() {
+        WireMockServer server = new WireMockServer(
+            WireMockConfiguration.wireMockConfig().dynamicPort());
+        server.start();
+        server.stubFor(WireMock.post(WireMock.urlPathMatching(""/*""))
+                .willReturn(WireMock.aResponse().withStatus(200).withHeader(""Connection"", ""Keep-Alive"")
+                        .withHeader(""Content-Type"", ""text/plain; charset=UTF-8"")
+                        .withHeader(""Transfer-Encoding"", ""chunked"").withHeader(""Keep-Alive"", ""timeout=3"")
+                        .withBody(""OK........................."").withFixedDelay(2)));
+        return server;
+    }
 
+    private static void shutDownServerWithDelay(final WireMockServer server, final long delayMs) {
+        new Thread() {
+            public void run() {
+                try {
+                    Thread.sleep(delayMs);
+                } catch (InterruptedException e) {
+                    e.printStackTrace();
+                }
+
+                server.shutdownServer();
+                server.stop();
+            }
+        }.start();
     }
 
+    // @Test(dependsOnMethods = { ""testWithRetry"" }, expectedExceptions = { NoHttpResponseException.class })
+    public void testWithoutRetry() throws Exception {
+        final WireMockServer server = newServer();
+
+        ClickHouseProperties props = new ClickHouseProperties();
+        props.setMaxRetries(0);
+        ClickHouseHttpClientBuilder builder = new ClickHouseHttpClientBuilder(props);
+        CloseableHttpClient client = builder.buildClient();
+        HttpPost post = new HttpPost(""http://localhost:"" + server.port() + ""/?db=system&query=select%201"");
+
+        shutDownServerWithDelay(server, 100);
+
+        try {
+            client.execute(post);
+        } finally {
+            client.close();
+        }
+    }
+
+    // @Test(expectedExceptions = { HttpHostConnectException.class })
+    public void testWithRetry() throws Exception {
+        final WireMockServer server = newServer();
+
+        ClickHouseProperties props = new ClickHouseProperties();
+        // props.setMaxRetries(3);
+        ClickHouseHttpClientBuilder builder = new ClickHouseHttpClientBuilder(props);
+        CloseableHttpClient client = builder.buildClient();
+        HttpContext context = new BasicHttpContext();
+        context.setAttribute(""is_idempotent"", Boolean.TRUE);
+        HttpPost post = new HttpPost(""http://localhost:"" + server.port() + ""/?db=system&query=select%202"");
+        
+        shutDownServerWithDelay(server, 100);
+
+        try {
+            client.execute(post, context);
+        } finally {
+            client.close();
+        }
+    }
 }","['src/test/java/ru/yandex/clickhouse/util/ClickHouseHttpClientBuilderTest.java', 'src/main/java/ru/yandex/clickhouse/util/ClickHouseHttpClientBuilder.java', 'src/main/java/ru/yandex/clickhouse/settings/ClickHouseConnectionSettings.java', 'src/main/java/ru/yandex/clickhouse/settings/ClickHouseProperties.java']",{'.java': 4},4,4,0,0,4,437607,90987,13597,69,3050,557,63,3,9958,698,2975,131,1,5,2021-01-07 14:19:05,1272,Java,"{'Java': 3989428, 'Shell': 397}",Apache License 2.0,"['src/main/java/ru/yandex/clickhouse/response/ClickHouseResultBuilder.java', 'src/main/java/ru/yandex/clickhouse/response/ClickHouseResponse.java', 'src/main/java/ru/yandex/clickhouse/response/ClickHouseResponseFactory.java', 'src/main/java/ru/yandex/clickhouse/response/ClickHouseResponseSummary.java', 'src/main/java/ru/yandex/clickhouse/ClickHouseStatementImpl.java']","['src/main/java/ru/yandex/clickhouse/response/ClickHouseResultBuilder.java', 'src/main/java/ru/yandex/clickhouse/response/ClickHouseResponse.java', 'src/main/java/ru/yandex/clickhouse/response/ClickHouseResponseFactory.java', 'src/main/java/ru/yandex/clickhouse/response/ClickHouseResponseSummary.java', 'src/main/java/ru/yandex/clickhouse/ClickHouseStatementImpl.java']","['```json\n{\n  ""files"": [\n    ""src/main/java/ru/yandex/clickhouse/ClickHouseStatementImpl.java"",\n    ""src/main/java/ru/yandex/clickhouse/response/ClickHouseResponseFactory.java"",\n    ""src/main/java/ru/yandex/clickhouse/response/ClickHouseResponseSummary.java"",\n    ""src/main/java/ru/yandex/clickhouse/response/ClickHouseResultBuilder.java"",\n    ""src/main/java/ru/yandex/clickhouse/response/ClickHouseResponse.java""\n  ]\n}\n```']",1,1423.3500957489014
1089,google/conscrypt/785/781,google,conscrypt,https://github.com/google/conscrypt/issues/781,https://github.com/google/conscrypt/pull/785,https://github.com/google/conscrypt/pull/785,1,fixes,NullPointerException in getAlpnSelectedProtocol,"We’ve got the exact same crash as #379 but this time we’re calling `getAlpnSelectedProtocol()` instead of `getProtocol()`. I presume the same fix will work: cache more session state when the connection is closed.

```
FATAL EXCEPTION: MockWebServer
Process: com.xxx.xxx.xxx, PID: 5607
java.lang.AssertionError: java.lang.reflect.InvocationTargetException
	at okhttp3.internal.platform.android.AndroidSocketAdapter.a(SourceFile:86)
	at okhttp3.internal.platform.AndroidPlatform.b(SourceFile:86)
	at okhttp3.mockwebserver.MockWebServer$SocketHandler.handle(MockWebServer.kt:516)
	at okhttp3.mockwebserver.MockWebServer$serveConnection$$inlined$execute$1.run(Util.kt:580)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1167)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:641)
	at java.lang.Thread.run(Thread.java:764)
Caused by: java.lang.reflect.InvocationTargetException
	at java.lang.reflect.Method.invoke(Native Method)
	at okhttp3.internal.platform.android.AndroidSocketAdapter.a(SourceFile:81)
	... 6 more
Caused by: java.lang.NullPointerException: ssl == null
	at com.android.org.conscrypt.NativeCrypto.getApplicationProtocol(Native Method)
	at com.android.org.conscrypt.NativeSsl.getApplicationProtocol(NativeSsl.java:568)
	at com.android.org.conscrypt.ConscryptFileDescriptorSocket.getApplicationProtocol(ConscryptFileDescriptorSocket.java:1085)
	at com.android.org.conscrypt.OpenSSLSocketImpl.getAlpnSelectedProtocol(OpenSSLSocketImpl.java:134)
	... 8 more
```

",d2aa6104ac4a9c92a36213bce65f144efdcd1a1b,d28d0a8d85a0461baa1cb29aec8dd813384f2ee1,https://github.com/google/conscrypt/compare/d2aa6104ac4a9c92a36213bce65f144efdcd1a1b...d28d0a8d85a0461baa1cb29aec8dd813384f2ee1,"diff --git a/common/src/main/java/org/conscrypt/ActiveSession.java b/common/src/main/java/org/conscrypt/ActiveSession.java
index 4726499a..b00a3fa5 100644
--- a/common/src/main/java/org/conscrypt/ActiveSession.java
+++ b/common/src/main/java/org/conscrypt/ActiveSession.java
@@ -37,6 +37,7 @@ final class ActiveSession implements ConscryptSession {
     private byte[] id;
     private long creationTime;
     private String protocol;
+    private String applicationProtocol;
     private String peerHost;
     private int peerPort = -1;
     private long lastAccessedTime = 0;
@@ -153,25 +154,25 @@ final class ActiveSession implements ConscryptSession {
     @Override
     public void putValue(String name, Object value) {
         throw new UnsupportedOperationException(
-                ""All calls to this method should be intercepted by ProvidedSessionDecorator."");
+                ""All calls to this method should be intercepted by ExternalSession."");
     }
 
     @Override
     public Object getValue(String name) {
         throw new UnsupportedOperationException(
-                ""All calls to this method should be intercepted by ProvidedSessionDecorator."");
+                ""All calls to this method should be intercepted by ExternalSession."");
     }
 
     @Override
     public void removeValue(String name) {
         throw new UnsupportedOperationException(
-                ""All calls to this method should be intercepted by ProvidedSessionDecorator."");
+                ""All calls to this method should be intercepted by ExternalSession."");
     }
 
     @Override
     public String[] getValueNames() {
         throw new UnsupportedOperationException(
-                ""All calls to this method should be intercepted by ProvidedSessionDecorator."");
+                ""All calls to this method should be intercepted by ExternalSession."");
     }
 
     @Override
@@ -275,6 +276,18 @@ final class ActiveSession implements ConscryptSession {
         return NativeConstants.SSL3_RT_MAX_PLAIN_LENGTH;
     }
 
+    @Override
+    public String getApplicationProtocol() {
+        String applicationProtocol = this.applicationProtocol;
+        if (applicationProtocol == null) {
+            synchronized (ssl) {
+                applicationProtocol = SSLUtils.toProtocolString(ssl.getApplicationProtocol());
+            }
+            this.applicationProtocol = applicationProtocol;
+        }
+        return applicationProtocol;
+    }
+
     /**
      * Configures the peer information once it has been received by the handshake.
      */
diff --git a/common/src/main/java/org/conscrypt/ConscryptFileDescriptorSocket.java b/common/src/main/java/org/conscrypt/ConscryptFileDescriptorSocket.java
index efbc80a0..aa17760a 100644
--- a/common/src/main/java/org/conscrypt/ConscryptFileDescriptorSocket.java
+++ b/common/src/main/java/org/conscrypt/ConscryptFileDescriptorSocket.java
@@ -1118,7 +1118,7 @@ class ConscryptFileDescriptorSocket extends OpenSSLSocketImpl
 
     @Override
     public final String getApplicationProtocol() {
-        return SSLUtils.toProtocolString(ssl.getApplicationProtocol());
+        return provideSession().getApplicationProtocol();
     }
 
     @Override
diff --git a/common/src/main/java/org/conscrypt/ConscryptSession.java b/common/src/main/java/org/conscrypt/ConscryptSession.java
index e59c1921..ce89b418 100644
--- a/common/src/main/java/org/conscrypt/ConscryptSession.java
+++ b/common/src/main/java/org/conscrypt/ConscryptSession.java
@@ -52,4 +52,6 @@ interface ConscryptSession extends SSLSession {
 
   @Override
   X509Certificate[] getPeerCertificates() throws SSLPeerUnverifiedException;
+
+  String getApplicationProtocol();
 }
diff --git a/common/src/main/java/org/conscrypt/ExternalSession.java b/common/src/main/java/org/conscrypt/ExternalSession.java
index 38a96c1b..18c67a3f 100644
--- a/common/src/main/java/org/conscrypt/ExternalSession.java
+++ b/common/src/main/java/org/conscrypt/ExternalSession.java
@@ -47,7 +47,7 @@ import javax.security.cert.X509Certificate;
  */
 final class ExternalSession implements ConscryptSession {
 
-  // Use an initialcapacity of 2 to keep it small in the average case.
+  // Use an initial capacity of 2 to keep it small in the average case.
   private final HashMap<String, Object> values = new HashMap<String, Object>(2);
   private final Provider provider;
 
@@ -156,6 +156,11 @@ final class ExternalSession implements ConscryptSession {
     return provider.provideSession().getApplicationBufferSize();
   }
 
+  @Override
+  public String getApplicationProtocol() {
+    return provider.provideSession().getApplicationProtocol();
+  }
+
   @Override
   public Object getValue(String name) {
     if (name == null) {
diff --git a/common/src/main/java/org/conscrypt/Java7ExtendedSSLSession.java b/common/src/main/java/org/conscrypt/Java7ExtendedSSLSession.java
index 32cb0823..10b11046 100644
--- a/common/src/main/java/org/conscrypt/Java7ExtendedSSLSession.java
+++ b/common/src/main/java/org/conscrypt/Java7ExtendedSSLSession.java
@@ -177,4 +177,9 @@ class Java7ExtendedSSLSession extends ExtendedSSLSession implements ConscryptSes
     public final int getApplicationBufferSize() {
         return delegate.getApplicationBufferSize();
     }
+
+    @Override
+    public String getApplicationProtocol() {
+        return delegate.getApplicationProtocol();
+    }
 }
diff --git a/common/src/main/java/org/conscrypt/SSLNullSession.java b/common/src/main/java/org/conscrypt/SSLNullSession.java
index 0cc9066a..b2668439 100644
--- a/common/src/main/java/org/conscrypt/SSLNullSession.java
+++ b/common/src/main/java/org/conscrypt/SSLNullSession.java
@@ -75,6 +75,11 @@ final class SSLNullSession implements ConscryptSession, Cloneable {
         return NativeConstants.SSL3_RT_MAX_PLAIN_LENGTH;
     }
 
+    @Override
+    public String getApplicationProtocol()  {
+        return null;
+    }
+
     @Override
     public String getCipherSuite() {
         return INVALID_CIPHER;
@@ -149,13 +154,13 @@ final class SSLNullSession implements ConscryptSession, Cloneable {
     @Override
     public Object getValue(String name) {
         throw new UnsupportedOperationException(
-                ""All calls to this method should be intercepted by ProvidedSessionDecorator."");
+                ""All calls to this method should be intercepted by ExternalSession."");
     }
 
     @Override
     public String[] getValueNames() {
         throw new UnsupportedOperationException(
-                ""All calls to this method should be intercepted by ProvidedSessionDecorator."");
+                ""All calls to this method should be intercepted by ExternalSession."");
     }
 
     @Override
@@ -170,12 +175,12 @@ final class SSLNullSession implements ConscryptSession, Cloneable {
     @Override
     public void putValue(String name, Object value) {
         throw new UnsupportedOperationException(
-                ""All calls to this method should be intercepted by ProvidedSessionDecorator."");
+                ""All calls to this method should be intercepted by ExternalSession."");
     }
 
     @Override
     public void removeValue(String name) {
         throw new UnsupportedOperationException(
-                ""All calls to this method should be intercepted by ProvidedSessionDecorator."");
+                ""All calls to this method should be intercepted by ExternalSession."");
     }
 }
diff --git a/common/src/main/java/org/conscrypt/SessionSnapshot.java b/common/src/main/java/org/conscrypt/SessionSnapshot.java
index d4a8bff4..28e63b96 100644
--- a/common/src/main/java/org/conscrypt/SessionSnapshot.java
+++ b/common/src/main/java/org/conscrypt/SessionSnapshot.java
@@ -39,6 +39,7 @@ final class SessionSnapshot implements ConscryptSession {
     private final String cipherSuite;
     private final String protocol;
     private final String peerHost;
+    private final String applicationProtocol;
     private final int peerPort;
 
     SessionSnapshot(ConscryptSession session) {
@@ -53,6 +54,7 @@ final class SessionSnapshot implements ConscryptSession {
         protocol = session.getProtocol();
         peerHost = session.getPeerHost();
         peerPort = session.getPeerPort();
+        applicationProtocol = session.getApplicationProtocol();
     }
 
     @Override
@@ -107,25 +109,25 @@ final class SessionSnapshot implements ConscryptSession {
     @Override
     public void putValue(String s, Object o) {
         throw new UnsupportedOperationException(
-                ""All calls to this method should be intercepted by ProvidedSessionDecorator."");
+                ""All calls to this method should be intercepted by ExternalSession."");
     }
 
     @Override
     public Object getValue(String s) {
         throw new UnsupportedOperationException(
-                ""All calls to this method should be intercepted by ProvidedSessionDecorator."");
+                ""All calls to this method should be intercepted by ExternalSession."");
     }
 
     @Override
     public void removeValue(String s) {
         throw new UnsupportedOperationException(
-                ""All calls to this method should be intercepted by ProvidedSessionDecorator."");
+                ""All calls to this method should be intercepted by ExternalSession."");
     }
 
     @Override
     public String[] getValueNames() {
         throw new UnsupportedOperationException(
-                ""All calls to this method should be intercepted by ProvidedSessionDecorator."");
+                ""All calls to this method should be intercepted by ExternalSession."");
     }
 
     @Override
@@ -183,4 +185,9 @@ final class SessionSnapshot implements ConscryptSession {
     public int getApplicationBufferSize() {
         return NativeConstants.SSL3_RT_MAX_PLAIN_LENGTH;
     }
+
+    @Override
+    public String getApplicationProtocol() {
+        return applicationProtocol;
+    }
 }
diff --git a/openjdk/src/test/java/org/conscrypt/ConscryptEngineTest.java b/openjdk/src/test/java/org/conscrypt/ConscryptEngineTest.java
index 6cdd235b..473cc738 100644
--- a/openjdk/src/test/java/org/conscrypt/ConscryptEngineTest.java
+++ b/openjdk/src/test/java/org/conscrypt/ConscryptEngineTest.java
@@ -375,16 +375,26 @@ public class ConscryptEngineTest {
 
     @Test
     public void savedSessionWorksAfterClose() throws Exception {
+        String alpnProtocol = ""spdy/2"";
+        String[] alpnProtocols = new String[]{alpnProtocol};
+
         setupEngines(TestKeyStore.getClient(), TestKeyStore.getServer());
+        Conscrypt.setApplicationProtocols(clientEngine, alpnProtocols);
+        Conscrypt.setApplicationProtocols(serverEngine, alpnProtocols);
+
         doHandshake(true);
 
         SSLSession session = clientEngine.getSession();
         String cipherSuite = session.getCipherSuite();
+        String protocol = session.getProtocol();
+        assertEquals(alpnProtocol, Conscrypt.getApplicationProtocol(clientEngine));
 
         clientEngine.closeOutbound();
         clientEngine.closeInbound();
 
         assertEquals(cipherSuite, session.getCipherSuite());
+        assertEquals(protocol, session.getProtocol());
+        assertEquals(alpnProtocol, Conscrypt.getApplicationProtocol(clientEngine));
     }
 
     private void doMutualAuthHandshake(
diff --git a/openjdk/src/test/java/org/conscrypt/ConscryptSocketTest.java b/openjdk/src/test/java/org/conscrypt/ConscryptSocketTest.java
index 7a15eefd..d0a7eb1d 100644
--- a/openjdk/src/test/java/org/conscrypt/ConscryptSocketTest.java
+++ b/openjdk/src/test/java/org/conscrypt/ConscryptSocketTest.java
@@ -623,15 +623,23 @@ public class ConscryptSocketTest {
 
     @Test
     public void savedSessionWorksAfterClose() throws Exception {
+        String alpnProtocol = ""spdy/2"";
+        String[] alpnProtocols = new String[]{alpnProtocol};
         TestConnection connection = new TestConnection(new X509Certificate[] {cert, ca}, certKey);
+        connection.clientHooks.alpnProtocols = alpnProtocols;
+        connection.serverHooks.alpnProtocols = alpnProtocols;
         connection.doHandshakeSuccess();
 
         SSLSession session = connection.client.getSession();
         String cipherSuite = session.getCipherSuite();
+        String protocol = session.getProtocol();
+        assertEquals(alpnProtocol, Conscrypt.getApplicationProtocol(connection.client));
 
         connection.client.close();
 
         assertEquals(cipherSuite, session.getCipherSuite());
+        assertEquals(protocol, session.getProtocol());
+        assertEquals(alpnProtocol, Conscrypt.getApplicationProtocol(connection.client));
     }
 
     private static ServerSocket newServerSocket() throws IOException {","['common/src/main/java/org/conscrypt/ActiveSession.java', 'common/src/main/java/org/conscrypt/SessionSnapshot.java', 'common/src/main/java/org/conscrypt/ConscryptFileDescriptorSocket.java', 'openjdk/src/test/java/org/conscrypt/ConscryptSocketTest.java', 'openjdk/src/test/java/org/conscrypt/ConscryptEngineTest.java', 'common/src/main/java/org/conscrypt/SSLNullSession.java', 'common/src/main/java/org/conscrypt/ConscryptSession.java', 'common/src/main/java/org/conscrypt/Java7ExtendedSSLSession.java', 'common/src/main/java/org/conscrypt/ExternalSession.java']",{'.java': 9},9,9,0,0,9,1746819,383662,47311,245,3562,589,65,7,1558,87,357,26,0,1,2019-11-07 17:31:25,1164,Java,"{'Java': 3533745, 'C++': 526129, 'C': 7529, 'Python': 6764, 'Shell': 5171, 'Dockerfile': 3414, 'CMake': 1784, 'PowerShell': 1675, 'Batchfile': 1140, 'HTML': 756}",Apache License 2.0,"['common/src/main/java/org/conscrypt/SSLUtils.java', 'common/src/main/java/org/conscrypt/SSLParametersImpl.java', 'android-stub/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLParametersImpl.java', 'common/src/main/java/org/conscrypt/ConscryptFileDescriptorSocket.java', 'android-stub/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java']","['common/src/main/java/org/conscrypt/SSLUtils.java', 'common/src/main/java/org/conscrypt/SSLParametersImpl.java', 'android-stub/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLParametersImpl.java', 'common/src/main/java/org/conscrypt/ConscryptFileDescriptorSocket.java', 'android-stub/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java']","['```json\n{\n  ""files"": [\n    ""common/src/main/java/org/conscrypt/SSLUtils.java"",\n    ""common/src/main/java/org/conscrypt/SSLParametersImpl.java"",\n    ""common/src/main/java/org/conscrypt/ConscryptFileDescriptorSocket.java"",\n    ""android-stub/src/main/java/org/apache/harmony/xnet/provider/jsse/OpenSSLSocketImpl.java"",\n    ""android-stub/src/main/java/org/apache/harmony/xnet/provider/jsse/SSLParametersImpl.java""\n  ]\n}\n```']",1,1387.8614902496338
507,appium/java-client/568/567,appium,java-client,https://github.com/appium/java-client/issues/567,https://github.com/appium/java-client/pull/568,https://github.com/appium/java-client/pull/568,1,fix,5.0.0-BETA2: ClassCastException: WebElement -> IOSElement,"## Description
Failed to cast WebElement into IOSElement. Worked with 5.0.0-BETA1.

## Environment

* java client build version or git revision if you use some shapshot: 5.0.0-BETA2
* Appium server version or git revision if you use some shapshot: 1.6.4-beta
* Mobile platform/version under test: iOS
* Real device or emulator/simulator: Simulator

## Code To Reproduce Issue [ Good To Have ]
`((IOSElement) driver.findElement(MobileBy.className(""XCUIElementTypePickerWheel""))).setValue(countryName);`

## Ecxeption stacktraces
java.lang.ClassCastException: org.openqa.selenium.remote.RemoteWebElement cannot be cast to io.appium.java_client.ios.IOSElement

",1d3e9705527435c48005f0a50a60b1371e03bbd1,b3351034ac0eb7b814ecfcacb1b097b8fd547a55,https://github.com/appium/java-client/compare/1d3e9705527435c48005f0a50a60b1371e03bbd1...b3351034ac0eb7b814ecfcacb1b097b8fd547a55,"diff --git a/src/main/java/io/appium/java_client/AppiumDriver.java b/src/main/java/io/appium/java_client/AppiumDriver.java
index a3adf2e9..fa9696cf 100644
--- a/src/main/java/io/appium/java_client/AppiumDriver.java
+++ b/src/main/java/io/appium/java_client/AppiumDriver.java
@@ -76,7 +76,6 @@ public class AppiumDriver<T extends WebElement>
     private ExecuteMethod executeMethod;
     private final String platformName;
     private final String automationName;
-    private String currentContext;
 
 
     /**
@@ -92,19 +91,6 @@ public class AppiumDriver<T extends WebElement>
         locationContext = new RemoteLocationContext(executeMethod);
         super.setErrorHandler(errorHandler);
         this.remoteAddress = executor.getAddressOfRemoteServer();
-        final AppiumDriver<?> driver = this;
-
-        HasSessionDetails hasSessionDetails = new HasSessionDetails() {
-            @Override
-            public Response execute(String driverCommand, Map<String, ?> parameters) {
-                return driver.execute(driverCommand, parameters);
-            }
-
-            @Override
-            public Response execute(String driverCommand) {
-                return driver.execute(driverCommand);
-            }
-        };
 
         Object capabilityPlatform1 = getCapabilities().getCapability(PLATFORM_NAME);
         Object capabilityAutomation1 = getCapabilities().getCapability(AUTOMATION_NAME);
@@ -112,15 +98,14 @@ public class AppiumDriver<T extends WebElement>
         Object capabilityPlatform2 = capabilities.getCapability(PLATFORM_NAME);
         Object capabilityAutomation2 = capabilities.getCapability(AUTOMATION_NAME);
 
-        platformName = ofNullable(ofNullable(hasSessionDetails.getPlatformName())
+        platformName = ofNullable(ofNullable(super.getPlatformName())
                 .orElse(capabilityPlatform1 != null ? String.valueOf(capabilityPlatform1) : null))
                 .orElse(capabilityPlatform2 != null ? String.valueOf(capabilityPlatform2) : null);
-        automationName = ofNullable(ofNullable(hasSessionDetails.getAutomationName())
+        automationName = ofNullable(ofNullable(super.getAutomationName())
                 .orElse(capabilityAutomation1 != null ? String.valueOf(capabilityAutomation1) : null))
                 .orElse(capabilityAutomation2 != null ? String.valueOf(capabilityAutomation2) : null);
 
         this.setElementConverter(new JsonToMobileElementConverter(this, this));
-        currentContext = getContext();
     }
 
     public AppiumDriver(URL remoteAddress, Capabilities desiredCapabilities) {
@@ -352,7 +337,6 @@ public class AppiumDriver<T extends WebElement>
     @Override public WebDriver context(String name) {
         checkNotNull(name, ""Must supply a context name"");
         execute(DriverCommand.SWITCH_TO_CONTEXT, ImmutableMap.of(""name"", name));
-        currentContext = name;
         return this;
     }
 
@@ -430,9 +414,6 @@ public class AppiumDriver<T extends WebElement>
     }
 
     @Override public boolean isBrowser() {
-        if  (super.isBrowser()) {
-            return true;
-        }
-        return !currentContext.toLowerCase().contains(""NATIVE_APP"".toLowerCase());
+        return !getContext().toLowerCase().contains(""NATIVE_APP"".toLowerCase());
     }
 }
diff --git a/src/main/java/io/appium/java_client/HasSessionDetails.java b/src/main/java/io/appium/java_client/HasSessionDetails.java
index 2e91b7b8..3106b290 100644
--- a/src/main/java/io/appium/java_client/HasSessionDetails.java
+++ b/src/main/java/io/appium/java_client/HasSessionDetails.java
@@ -55,8 +55,5 @@ public interface HasSessionDetails extends ExecutesMethod {
     /**
      * @return is focus on browser or on native content.
      */
-    default boolean isBrowser() {
-        Object browserName = getSessionDetail(""browserName"");
-        return browserName != null && !isBlank(String.valueOf(browserName));
-    }
+    boolean isBrowser();
 }
diff --git a/src/main/java/io/appium/java_client/internal/ElementMap.java b/src/main/java/io/appium/java_client/internal/ElementMap.java
index 3dacc2ce..9435a7e7 100644
--- a/src/main/java/io/appium/java_client/internal/ElementMap.java
+++ b/src/main/java/io/appium/java_client/internal/ElementMap.java
@@ -18,6 +18,7 @@ package io.appium.java_client.internal;
 
 import com.google.common.collect.ImmutableMap;
 
+import io.appium.java_client.HasSessionDetails;
 import io.appium.java_client.MobileElement;
 import io.appium.java_client.android.AndroidElement;
 import io.appium.java_client.ios.IOSElement;
@@ -69,14 +70,17 @@ public enum ElementMap {
     }
 
     /**
-     * @param platform platform name.
-     * @param automation automation name.
+     * @param hasSessionDetails something that implements {@link io.appium.java_client.HasSessionDetails}.
      * @return subclass of {@link io.appium.java_client.MobileElement} that convenient to current session details.
      */
-    public static Class<? extends RemoteWebElement> getElementClass(String platform, String automation) {
+    public static Class<? extends RemoteWebElement> getElementClass(HasSessionDetails hasSessionDetails) {
+        if (hasSessionDetails == null) {
+            return RemoteWebElement.class;
+        }
         ElementMap element = Optional.ofNullable(mobileElementMap.get(String
-                .valueOf(automation).toLowerCase().trim()))
-                .orElse(mobileElementMap.get(String.valueOf(platform).toLowerCase().trim()));
+                .valueOf(hasSessionDetails.getAutomationName()).toLowerCase().trim()))
+                .orElse(mobileElementMap
+                        .get(String.valueOf(hasSessionDetails.getPlatformName()).toLowerCase().trim()));
         if (element == null) {
             return RemoteWebElement.class;
         }
diff --git a/src/main/java/io/appium/java_client/internal/JsonToMobileElementConverter.java b/src/main/java/io/appium/java_client/internal/JsonToMobileElementConverter.java
index a2bb0143..103963d1 100644
--- a/src/main/java/io/appium/java_client/internal/JsonToMobileElementConverter.java
+++ b/src/main/java/io/appium/java_client/internal/JsonToMobileElementConverter.java
@@ -87,13 +87,7 @@ public class JsonToMobileElementConverter extends JsonToWebElementConverter {
 
     protected RemoteWebElement newMobileElement() {
         Class<? extends RemoteWebElement> target;
-        if (hasSessionDetails.isBrowser()) {
-            target = getElementClass(null, null);
-        } else {
-            target = getElementClass(hasSessionDetails.getPlatformName(),
-                    hasSessionDetails.getAutomationName());
-        }
-
+        target = getElementClass(hasSessionDetails);
         try {
             Constructor<? extends RemoteWebElement> constructor = target.getDeclaredConstructor();
             constructor.setAccessible(true);
diff --git a/src/main/java/io/appium/java_client/pagefactory/AppiumFieldDecorator.java b/src/main/java/io/appium/java_client/pagefactory/AppiumFieldDecorator.java
index 7ac6d1f0..0f7f3990 100644
--- a/src/main/java/io/appium/java_client/pagefactory/AppiumFieldDecorator.java
+++ b/src/main/java/io/appium/java_client/pagefactory/AppiumFieldDecorator.java
@@ -72,18 +72,8 @@ public class AppiumFieldDecorator implements FieldDecorator {
     private final String platform;
     private final String automation;
     private final TimeOutDuration timeOutDuration;
+    private final HasSessionDetails hasSessionDetails;
 
-    private static String extractSessionData(WebDriver driver, Supplier<String> dataSupplier) {
-        if (driver == null) {
-            return null;
-        }
-
-        if (!(driver instanceof HasSessionDetails)) {
-            return null;
-        }
-
-        return String.valueOf(dataSupplier.get());
-    }
 
     public AppiumFieldDecorator(SearchContext context, long implicitlyWaitTimeOut,
         TimeUnit timeUnit) {
@@ -100,10 +90,17 @@ public class AppiumFieldDecorator implements FieldDecorator {
      */
     public AppiumFieldDecorator(SearchContext context, TimeOutDuration timeOutDuration) {
         this.originalDriver = unpackWebDriverFromSearchContext(context);
-        platform = extractSessionData(originalDriver, () ->
-                HasSessionDetails.class.cast(originalDriver).getPlatformName());
-        automation = extractSessionData(originalDriver, () ->
-                HasSessionDetails.class.cast(originalDriver).getAutomationName());
+        if (originalDriver == null
+                || !HasSessionDetails.class.isAssignableFrom(originalDriver.getClass())) {
+            hasSessionDetails = null;
+            platform = null;
+            automation = null;
+        } else {
+            hasSessionDetails = HasSessionDetails.class.cast(originalDriver);
+            platform = hasSessionDetails.getPlatformName();
+            automation = hasSessionDetails.getAutomationName();
+        }
+
         this.timeOutDuration = timeOutDuration;
 
         defaultElementFieldDecoracor = new DefaultFieldDecorator(
@@ -221,6 +218,6 @@ public class AppiumFieldDecorator implements FieldDecorator {
 
     private WebElement proxyForAnElement(ElementLocator locator) {
         ElementInterceptor elementInterceptor = new ElementInterceptor(locator, originalDriver);
-        return getEnhancedProxy(getElementClass(platform, automation), elementInterceptor);
+        return getEnhancedProxy(getElementClass(hasSessionDetails), elementInterceptor);
     }
 }
diff --git a/src/test/java/io/appium/java_client/appium/element/generation/android/AndroidElementGeneratingTest.java b/src/test/java/io/appium/java_client/appium/element/generation/android/AndroidElementGeneratingTest.java
index ae2d1112..dc1d8947 100644
--- a/src/test/java/io/appium/java_client/appium/element/generation/android/AndroidElementGeneratingTest.java
+++ b/src/test/java/io/appium/java_client/appium/element/generation/android/AndroidElementGeneratingTest.java
@@ -13,7 +13,6 @@ import io.appium.java_client.remote.MobileCapabilityType;
 import io.appium.java_client.remote.MobilePlatform;
 import org.junit.Test;
 import org.openqa.selenium.remote.DesiredCapabilities;
-import org.openqa.selenium.remote.RemoteWebElement;
 
 import java.io.File;
 import java.util.function.Supplier;
@@ -49,7 +48,7 @@ public class AndroidElementGeneratingTest extends BaseElementGenerationTest {
         }, (by, aClass) -> {
                 driver.context(""WEBVIEW_io.appium.android.apis"");
                 return commonPredicate.test(by, aClass);
-            }, tagName(""a""), RemoteWebElement.class));
+            }, tagName(""a""), AndroidElement.class));
     }
 
     @Test public void whenAndroidBrowserIsLaunched() {
@@ -65,6 +64,6 @@ public class AndroidElementGeneratingTest extends BaseElementGenerationTest {
             }, (by, aClass) -> {
                 driver.get(""https://www.google.com"");
                 return commonPredicate.test(by, aClass);
-            }, className(""gsfi""), RemoteWebElement.class));
+            }, className(""gsfi""), AndroidElement.class));
     }
 }
diff --git a/src/test/java/io/appium/java_client/appium/element/generation/ios/IOSElementGenerationTest.java b/src/test/java/io/appium/java_client/appium/element/generation/ios/IOSElementGenerationTest.java
index 3c4cd9e7..3d0d995e 100644
--- a/src/test/java/io/appium/java_client/appium/element/generation/ios/IOSElementGenerationTest.java
+++ b/src/test/java/io/appium/java_client/appium/element/generation/ios/IOSElementGenerationTest.java
@@ -14,7 +14,6 @@ import io.appium.java_client.remote.MobilePlatform;
 import org.junit.Test;
 import org.openqa.selenium.Capabilities;
 import org.openqa.selenium.remote.DesiredCapabilities;
-import org.openqa.selenium.remote.RemoteWebElement;
 
 import java.io.File;
 import java.util.function.Function;
@@ -89,7 +88,7 @@ public class IOSElementGenerationTest extends BaseElementGenerationTest {
                     }
                 });
                 return commonPredicate.test(by, aClass);
-            }, className(""gsfi""), RemoteWebElement.class));
+            }, className(""gsfi""), IOSElement.class));
     }
 
     @Test public void whenIOSBrowserIsLaunched() {
@@ -97,7 +96,7 @@ public class IOSElementGenerationTest extends BaseElementGenerationTest {
                 clientBrowserCapabilitiesSupplier, (by, aClass) -> {
                 driver.get(""https://www.google.com"");
                 return commonPredicate.test(by, aClass);
-            }, className(""gsfi""), RemoteWebElement.class));
+            }, className(""gsfi""), IOSElement.class));
     }
 
     @Test
@@ -117,6 +116,6 @@ public class IOSElementGenerationTest extends BaseElementGenerationTest {
         }, clientBrowserCapabilitiesSupplier, (by, aClass) -> {
                 driver.get(""https://www.google.com"");
                 return commonPredicate.test(by, aClass);
-            }, className(""gsfi""), RemoteWebElement.class));
+            }, className(""gsfi""), IOSElement.class));
     }
 }","['src/main/java/io/appium/java_client/internal/ElementMap.java', 'src/main/java/io/appium/java_client/internal/JsonToMobileElementConverter.java', 'src/main/java/io/appium/java_client/pagefactory/AppiumFieldDecorator.java', 'src/main/java/io/appium/java_client/AppiumDriver.java', 'src/test/java/io/appium/java_client/appium/element/generation/android/AndroidElementGeneratingTest.java', 'src/test/java/io/appium/java_client/appium/element/generation/ios/IOSElementGenerationTest.java', 'src/main/java/io/appium/java_client/HasSessionDetails.java']",{'.java': 7},7,7,0,0,7,570684,119915,15588,167,3923,686,81,5,674,74,168,17,0,0,2017-02-10 22:03:53,1098,Java,"{'Java': 1674245, 'HTML': 80758}",Apache License 2.0,"['src/main/java/io/appium/java_client/MobileBy.java', 'src/main/java/io/appium/java_client/ios/IOSDriver.java', 'src/main/java/io/appium/java_client/MobileElement.java', 'src/main/java/io/appium/java_client/ios/IOSElement.java', 'src/main/java/io/appium/java_client/MobileDriver.java']","['src/main/java/io/appium/java_client/MobileBy.java', 'src/main/java/io/appium/java_client/ios/IOSDriver.java', 'src/main/java/io/appium/java_client/MobileElement.java', 'src/main/java/io/appium/java_client/ios/IOSElement.java', 'src/main/java/io/appium/java_client/MobileDriver.java']","['```json\n{\n  ""files"": [\n    ""src/main/java/io/appium/java_client/ios/IOSElement.java"",\n    ""src/main/java/io/appium/java_client/ios/IOSDriver.java"",\n    ""src/main/java/io/appium/java_client/MobileElement.java"",\n    ""src/main/java/io/appium/java_client/MobileBy.java"",\n    ""src/main/java/io/appium/java_client/MobileDriver.java""\n  ]\n}\n```']",1,1374.0997314453125
1260,vert-x3/vertx-web/1779/1778,vert-x3,vertx-web,https://github.com/vert-x3/vertx-web/issues/1778,https://github.com/vert-x3/vertx-web/pull/1779,https://github.com/vert-x3/vertx-web/pull/1779,1,fixes,HTTP server file upload cleanup fail to delete,"The HTTP server file upload cleanup mechanism implemented in `BodyHandler` can fail to delete uploaded files because it does not ensure that the file upload is finished before deleting the file. Fixing this in vertx-web would bring lot of complexity and instead this has been implemented in vertx-core HTTP server file upload that will delete any stream not successfully completed.
",7d91fc4471655c3d57bb0ef7210079cf8b483145,68dd64008a5312e67950bc7429a32a35b92f90ab,https://github.com/vert-x3/vertx-web/compare/7d91fc4471655c3d57bb0ef7210079cf8b483145...68dd64008a5312e67950bc7429a32a35b92f90ab,"diff --git a/vertx-web/src/main/java/io/vertx/ext/web/FileUpload.java b/vertx-web/src/main/java/io/vertx/ext/web/FileUpload.java
index bc812f747..a95a2cb30 100644
--- a/vertx-web/src/main/java/io/vertx/ext/web/FileUpload.java
+++ b/vertx-web/src/main/java/io/vertx/ext/web/FileUpload.java
@@ -62,5 +62,11 @@ public interface FileUpload {
    */
   String charSet();
 
+  /**
+   * Try to cancel the file upload.
+   *
+   * @return {@code true} when the upload was cancelled, {@code false} when the upload is finished and the file is available
+   */
+  boolean cancel();
 
 }
diff --git a/vertx-web/src/main/java/io/vertx/ext/web/handler/impl/BodyHandlerImpl.java b/vertx-web/src/main/java/io/vertx/ext/web/handler/impl/BodyHandlerImpl.java
index 02b56382e..23457b62e 100644
--- a/vertx-web/src/main/java/io/vertx/ext/web/handler/impl/BodyHandlerImpl.java
+++ b/vertx-web/src/main/java/io/vertx/ext/web/handler/impl/BodyHandlerImpl.java
@@ -24,6 +24,7 @@ import java.util.concurrent.atomic.AtomicInteger;
 
 import io.netty.handler.codec.DecoderException;
 import io.netty.handler.codec.http.HttpHeaderValues;
+import io.vertx.core.Future;
 import io.vertx.core.Handler;
 import io.vertx.core.buffer.Buffer;
 import io.vertx.core.file.FileSystem;
@@ -190,7 +191,7 @@ public class BodyHandlerImpl implements BodyHandler {
             long size = uploadSize + upload.size();
             if (size > bodyLimit) {
               failed = true;
-              deleteFileUploads();
+              cancelAndCleanupFileUploads();
               context.fail(413);
               return;
             }
@@ -199,20 +200,23 @@ public class BodyHandlerImpl implements BodyHandler {
             // we actually upload to a file with a generated filename
             uploadCount.incrementAndGet();
             String uploadedFileName = new File(uploadsDir, UUID.randomUUID().toString()).getPath();
-            upload.streamToFileSystem(uploadedFileName);
             FileUploadImpl fileUpload = new FileUploadImpl(uploadedFileName, upload);
             fileUploads.add(fileUpload);
-            upload.exceptionHandler(t -> {
-              deleteFileUploads();
-              context.fail(t);
+            Future<Void> fut = upload.streamToFileSystem(uploadedFileName);
+            fut.onComplete(ar -> {
+              if (fut.succeeded()) {
+                uploadEnded();
+              } else {
+                cancelAndCleanupFileUploads();
+                context.fail(ar.cause());
+              }
             });
-            upload.endHandler(v -> uploadEnded());
           }
         });
       }
 
       context.request().exceptionHandler(t -> {
-        deleteFileUploads();
+        cancelAndCleanupFileUploads();
         if (t instanceof DecoderException) {
           // bad request
           context.fail(400, t.getCause());
@@ -253,7 +257,7 @@ public class BodyHandlerImpl implements BodyHandler {
       uploadSize += buff.length();
       if (bodyLimit != -1 && uploadSize > bodyLimit) {
         failed = true;
-        deleteFileUploads();
+        cancelAndCleanupFileUploads();
         context.fail(413);
       } else {
         // multipart requests will not end up in the request body
@@ -290,12 +294,12 @@ public class BodyHandlerImpl implements BodyHandler {
     void doEnd() {
 
       if (failed) {
-        deleteFileUploads();
+        cancelAndCleanupFileUploads();
         return;
       }
 
       if (deleteUploadedFilesOnEnd) {
-        context.addBodyEndHandler(x -> deleteFileUploads());
+        context.addBodyEndHandler(x -> cancelAndCleanupFileUploads());
       }
 
       HttpServerRequest req = context.request();
@@ -309,22 +313,21 @@ public class BodyHandlerImpl implements BodyHandler {
       context.next();
     }
 
-    private void deleteFileUploads() {
+    /**
+     * Cancel all unfinished file upload in progress and delete all uploaded files.
+     */
+    private void cancelAndCleanupFileUploads() {
       if (cleanup.compareAndSet(false, true) && handleFileUploads) {
         for (FileUpload fileUpload : context.fileUploads()) {
           FileSystem fileSystem = context.vertx().fileSystem();
-          String uploadedFileName = fileUpload.uploadedFileName();
-          fileSystem.exists(uploadedFileName, existResult -> {
-            if (existResult.failed()) {
-              log.warn(""Could not detect if uploaded file exists, not deleting: "" + uploadedFileName, existResult.cause());
-            } else if (existResult.result()) {
-              fileSystem.delete(uploadedFileName, deleteResult -> {
-                if (deleteResult.failed()) {
-                  log.warn(""Delete of uploaded file failed: "" + uploadedFileName, deleteResult.cause());
-                }
-              });
-            }
-          });
+          if (!fileUpload.cancel()) {
+            String uploadedFileName = fileUpload.uploadedFileName();
+            fileSystem.delete(uploadedFileName, deleteResult -> {
+              if (deleteResult.failed()) {
+                log.warn(""Delete of uploaded file failed: "" + uploadedFileName, deleteResult.cause());
+              }
+            });
+          }
         }
       }
     }
diff --git a/vertx-web/src/main/java/io/vertx/ext/web/impl/FileUploadImpl.java b/vertx-web/src/main/java/io/vertx/ext/web/impl/FileUploadImpl.java
index 98d62b7c6..70c8fef42 100644
--- a/vertx-web/src/main/java/io/vertx/ext/web/impl/FileUploadImpl.java
+++ b/vertx-web/src/main/java/io/vertx/ext/web/impl/FileUploadImpl.java
@@ -67,4 +67,8 @@ public class FileUploadImpl implements FileUpload {
     return upload.charset();
   }
 
+  @Override
+  public boolean cancel() {
+    return upload.cancelStreamToFileSystem();
+  }
 }","['vertx-web/src/main/java/io/vertx/ext/web/FileUpload.java', 'vertx-web/src/main/java/io/vertx/ext/web/impl/FileUploadImpl.java', 'vertx-web/src/main/java/io/vertx/ext/web/handler/impl/BodyHandlerImpl.java']",{'.java': 3},3,3,0,0,3,1698077,375725,52586,412,2487,469,59,3,383,60,70,2,0,0,2020-11-17 11:39:44,1049,Java,"{'Java': 2911199, 'Python': 985896, 'HTML': 11069, 'JavaScript': 8466, 'Shell': 1414, 'Handlebars': 693, 'FreeMarker': 557, 'Batchfile': 249, 'Pug': 191, 'CSS': 113, 'Fluent': 27}",Apache License 2.0,"['vertx-web/src/main/java/io/vertx/ext/web/handler/impl/BodyHandlerImpl.java', 'vertx-web/src/main/java/io/vertx/ext/web/impl/ServerWebSocketWrapper.java', 'vertx-web/src/main/java/io/vertx/ext/web/handler/impl/BlockingHandlerDecorator.java', 'vertx-web/src/main/java/io/vertx/ext/web/impl/FileUploadImpl.java', 'vertx-web/src/main/java/io/vertx/ext/web/impl/HttpServerRequestWrapper.java']","['vertx-web/src/main/java/io/vertx/ext/web/handler/impl/BodyHandlerImpl.java', 'vertx-web/src/main/java/io/vertx/ext/web/impl/ServerWebSocketWrapper.java', 'vertx-web/src/main/java/io/vertx/ext/web/impl/FileUploadImpl.java', 'vertx-web/src/main/java/io/vertx/ext/web/impl/HttpServerRequestWrapper.java']","['```json\n{\n  ""files"": [\n    ""vertx-web/src/main/java/io/vertx/ext/web/handler/impl/BlockingHandlerDecorator.java"",\n    ""vertx-web/src/main/java/io/vertx/ext/web/impl/FileUploadImpl.java"",\n    ""vertx-web/src/main/java/io/vertx/ext/web/impl/HttpServerRequestWrapper.java"",\n    ""vertx-web/src/main/java/io/vertx/ext/web/impl/ServerWebSocketWrapper.java"",\n    ""vertx-web/src/main/java/io/vertx/ext/web/handler/impl/BodyHandlerImpl.java""\n  ]\n}\n```']",1,1900.6800651550293
1448,googlecloudplatform/dataflowtemplates/469/464,googlecloudplatform,dataflowtemplates,https://github.com/GoogleCloudPlatform/DataflowTemplates/issues/464,https://github.com/GoogleCloudPlatform/DataflowTemplates/pull/469,https://github.com/GoogleCloudPlatform/DataflowTemplates/pull/469,1,fixes,[Bug]: Datastream to BigQuery MERGE not running in correct project,"### Related Template(s)

Datastream to BigQuery

### What happened?

I'm running this template using a different BigQuery project than the Datastream/GCS/Dataflow resources. I'm supplying it as the `--outputProjectId` value and data is flowing into my temporary table, just the MERGE fails:

```
2022-09-09T20:40:23.171ZMerge Job Failed: Exception: com.google.cloud.bigquery.BigQueryException: Access Denied: Project <dataflowproject>: User does not have bigquery.jobs.create permission in project <dataflowproject>.
```

I'm not super familiar with the code, but should this [line](https://github.com/GoogleCloudPlatform/DataflowTemplates/blob/4a0664a0d7559ba81353f48dc1cd7e2e928a3fd1/v2/datastream-to-bigquery/src/main/java/com/google/cloud/teleport/v2/templates/DataStreamToBigQuery.java#L422) use the `options.getOutputProjectId()` value instead of the variable?

### Beam Version

Newer than 2.35.0

### Relevant log output

_No response_",9ad9285922b1911b2dda75bea4ece13ed75ef53b,a3e2433dbc5a00c142d143f99faa8348cb38ea6b,https://github.com/googlecloudplatform/dataflowtemplates/compare/9ad9285922b1911b2dda75bea4ece13ed75ef53b...a3e2433dbc5a00c142d143f99faa8348cb38ea6b,"diff --git a/v2/common/src/main/java/com/google/cloud/teleport/v2/cdc/merge/BigQueryMerger.java b/v2/common/src/main/java/com/google/cloud/teleport/v2/cdc/merge/BigQueryMerger.java
index 083478a5..ad6e0781 100644
--- a/v2/common/src/main/java/com/google/cloud/teleport/v2/cdc/merge/BigQueryMerger.java
+++ b/v2/common/src/main/java/com/google/cloud/teleport/v2/cdc/merge/BigQueryMerger.java
@@ -171,7 +171,11 @@ public class BigQueryMerger extends PTransform<PCollection<MergeInfo>, PCollecti
     @Setup
     public void setUp() {
       if (bigQueryClient == null) {
-        bigQueryClient = BigQueryOptions.getDefaultInstance().getService();
+        BigQueryOptions.Builder optionsBuilder = BigQueryOptions.newBuilder();
+        if (mergeConfiguration.projectId() != null && !mergeConfiguration.projectId().isEmpty()) {
+          optionsBuilder = optionsBuilder.setProjectId(mergeConfiguration.projectId());
+        }
+        bigQueryClient = optionsBuilder.build().getService();
       }
     }
 
diff --git a/v2/common/src/main/java/com/google/cloud/teleport/v2/cdc/merge/MergeConfiguration.java b/v2/common/src/main/java/com/google/cloud/teleport/v2/cdc/merge/MergeConfiguration.java
index f796823a..14914ab3 100644
--- a/v2/common/src/main/java/com/google/cloud/teleport/v2/cdc/merge/MergeConfiguration.java
+++ b/v2/common/src/main/java/com/google/cloud/teleport/v2/cdc/merge/MergeConfiguration.java
@@ -19,6 +19,7 @@ import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Prec
 
 import com.google.auto.value.AutoValue;
 import java.io.Serializable;
+import javax.annotation.Nullable;
 import org.joda.time.Duration;
 
 /** Class {@link MergeConfiguration}. */
@@ -64,6 +65,9 @@ public abstract class MergeConfiguration implements Serializable {
   // BigQuery-specific properties
   public static final String BIGQUERY_QUOTE_CHARACTER = ""`"";
 
+  @Nullable
+  public abstract String projectId();
+
   public abstract String quoteCharacter();
 
   public abstract Boolean supportPartitionedTables();
@@ -82,6 +86,10 @@ public abstract class MergeConfiguration implements Serializable {
     return MergeConfiguration.builder().setQuoteCharacter(BIGQUERY_QUOTE_CHARACTER).build();
   }
 
+  public MergeConfiguration withProjectId(String projectId) {
+    return this.toBuilder().setProjectId(projectId).build();
+  }
+
   public MergeConfiguration withPartitionRetention(int partitionRetention) {
     checkArgument(partitionRetention > 0, ""partitionRetention must be greater than 0"");
     return this.toBuilder().setPartitionRetention(Integer.valueOf(partitionRetention)).build();
@@ -115,6 +123,8 @@ public abstract class MergeConfiguration implements Serializable {
 
   @AutoValue.Builder
   abstract static class Builder {
+    abstract Builder setProjectId(String projectId);
+
     abstract Builder setQuoteCharacter(String quote);
 
     abstract Builder setSupportPartitionedTables(Boolean supportPartitionedTables);
diff --git a/v2/datastream-to-bigquery/src/main/java/com/google/cloud/teleport/v2/templates/DataStreamToBigQuery.java b/v2/datastream-to-bigquery/src/main/java/com/google/cloud/teleport/v2/templates/DataStreamToBigQuery.java
index b030e8ba..4096c287 100644
--- a/v2/datastream-to-bigquery/src/main/java/com/google/cloud/teleport/v2/templates/DataStreamToBigQuery.java
+++ b/v2/datastream-to-bigquery/src/main/java/com/google/cloud/teleport/v2/templates/DataStreamToBigQuery.java
@@ -571,6 +571,7 @@ public class DataStreamToBigQuery {
               ""BigQuery Merge/Merge into Replica Tables"",
               BigQueryMerger.of(
                   MergeConfiguration.bigQueryConfiguration()
+                      .withProjectId(bigqueryProjectId)
                       .withMergeWindowDuration(
                           Duration.standardMinutes(options.getMergeFrequencyMinutes()))
                       .withMergeConcurrency(options.getMergeConcurrency())","['v2/common/src/main/java/com/google/cloud/teleport/v2/cdc/merge/BigQueryMerger.java', 'v2/common/src/main/java/com/google/cloud/teleport/v2/cdc/merge/MergeConfiguration.java', 'v2/datastream-to-bigquery/src/main/java/com/google/cloud/teleport/v2/templates/DataStreamToBigQuery.java']",{'.java': 3},3,3,0,0,3,6066423,1284319,159928,935,751,135,17,3,949,92,244,21,1,1,2022-09-23 20:10:30,1005,Java,"{'Java': 9158571, 'Go': 39852, 'JavaScript': 34656, 'Python': 10437, 'Dockerfile': 925, 'PureBasic': 35}",Apache License 2.0,['v2/datastream-to-bigquery/src/main/java/com/google/cloud/teleport/v2/templates/DataStreamToBigQuery.java'],['v2/datastream-to-bigquery/src/main/java/com/google/cloud/teleport/v2/templates/DataStreamToBigQuery.java'],"['```json\n{\n  ""files"": [\n    ""v2/datastream-to-bigquery/src/main/java/com/google/cloud/teleport/v2/templates/DataStreamToBigQuery.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""v2/datastream-to-bigquery/src/main/java/com/google/cloud/teleport/v2/templates/DataStreamToBigQuery.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""v2/datastream-to-bigquery/src/main/java/com/google/cloud/teleport/v2/templates/DataStreamToBigQuery.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""v2/datastream-to-bigquery/src/main/java/com/google/cloud/teleport/v2/templates/DataStreamToBigQuery.java""\n  ]\n}\n```']",3,4656.87894821167
641,spring-cloud/spring-cloud-stream/402/403,spring-cloud,spring-cloud-stream,https://github.com/spring-cloud/spring-cloud-stream/issues/403,https://github.com/spring-cloud/spring-cloud-stream/pull/402,https://github.com/spring-cloud/spring-cloud-stream/pull/402,1,resolves,Support text/* content type for non-SCSt applications,"When deserializing the payload at the consumer endpoint, the non-byte stream payload type requires to use `String` object when the underlying message content-type is of any `text` type contentType (text/plain, text/xml and text/html)
",6acb825ad58107c42d5cc3ea7bc84035ef750315,4d8fa19a3ac68c5ac043302b21f79c3aeb885e65,https://github.com/spring-cloud/spring-cloud-stream/compare/6acb825ad58107c42d5cc3ea7bc84035ef750315...4d8fa19a3ac68c5ac043302b21f79c3aeb885e65,"diff --git a/spring-cloud-stream-binders/spring-cloud-stream-binder-test/src/test/java/org/springframework/cloud/stream/binder/MessageChannelBinderSupportTests.java b/spring-cloud-stream-binders/spring-cloud-stream-binder-test/src/test/java/org/springframework/cloud/stream/binder/MessageChannelBinderSupportTests.java
index c8389214e..3a2481f68 100644
--- a/spring-cloud-stream-binders/spring-cloud-stream-binder-test/src/test/java/org/springframework/cloud/stream/binder/MessageChannelBinderSupportTests.java
+++ b/spring-cloud-stream-binders/spring-cloud-stream-binder-test/src/test/java/org/springframework/cloud/stream/binder/MessageChannelBinderSupportTests.java
@@ -111,6 +111,19 @@ public class MessageChannelBinderSupportTests {
 		assertNull(reconstructed.get(MessageHeaders.CONTENT_TYPE));
 	}
 
+	@Test
+	public void testStringXML() throws IOException {
+		Message<?> message = MessageBuilder
+				.withPayload(""<?xml version=\\""1.0\\"" encoding=\\""UTF-8\\"" standalone=\\""no\\""?><test></test>"")
+				.setHeader(MessageHeaders.CONTENT_TYPE, MimeTypeUtils.TEXT_XML)
+				.build();
+		Message<?> converted = binder.serializePayloadIfNecessary(message).toMessage();
+		assertEquals(MimeTypeUtils.TEXT_PLAIN, contentTypeResolver.resolve(converted.getHeaders()));
+		MessageValues reconstructed = binder.deserializePayloadIfNecessary(converted);
+		assertEquals(""<?xml version=\\""1.0\\"" encoding=\\""UTF-8\\"" standalone=\\""no\\""?><test></test>"", reconstructed.getPayload());
+		assertEquals(MimeTypeUtils.TEXT_XML.toString(), reconstructed.get(MessageHeaders.CONTENT_TYPE));
+	}
+
 	@Test
 	public void testContentTypePreserved() throws IOException {
 		Message<String> inbound = MessageBuilder.withPayload(""{\\""foo\\"":\\""foo\\""}"")
diff --git a/spring-cloud-stream/src/main/java/org/springframework/cloud/stream/binder/AbstractBinder.java b/spring-cloud-stream/src/main/java/org/springframework/cloud/stream/binder/AbstractBinder.java
index a5a2bae91..540aa5f28 100644
--- a/spring-cloud-stream/src/main/java/org/springframework/cloud/stream/binder/AbstractBinder.java
+++ b/spring-cloud-stream/src/main/java/org/springframework/cloud/stream/binder/AbstractBinder.java
@@ -18,7 +18,6 @@ package org.springframework.cloud.stream.binder;
 
 import static org.springframework.util.MimeTypeUtils.APPLICATION_JSON;
 import static org.springframework.util.MimeTypeUtils.APPLICATION_OCTET_STREAM;
-import static org.springframework.util.MimeTypeUtils.TEXT_PLAIN;
 
 import java.io.ByteArrayOutputStream;
 import java.io.IOException;
@@ -426,7 +425,7 @@ public abstract class AbstractBinder<T> implements ApplicationContextAware, Init
 	}
 
 	private Object deserializePayload(byte[] bytes, MimeType contentType) {
-		if (TEXT_PLAIN.equals(contentType) || APPLICATION_JSON.equals(contentType)) {
+		if (""text"".equalsIgnoreCase(contentType.getType()) || APPLICATION_JSON.equals(contentType)) {
 			try {
 				return new String(bytes, ""UTF-8"");
 			}","['spring-cloud-stream-binders/spring-cloud-stream-binder-test/src/test/java/org/springframework/cloud/stream/binder/MessageChannelBinderSupportTests.java', 'spring-cloud-stream/src/main/java/org/springframework/cloud/stream/binder/AbstractBinder.java']",{'.java': 2},2,2,0,0,2,420230,86916,12431,106,243,48,3,1,234,33,48,2,0,0,2016-03-07 06:19:17,918,Java,"{'Java': 2946369, 'Shell': 3768, 'Kotlin': 1141}",Apache License 2.0,"['spring-cloud-stream/src/main/java/org/springframework/cloud/stream/converter/JsonToPojoMessageConverter.java', 'spring-cloud-stream/src/main/java/org/springframework/cloud/stream/converter/ByteArrayToStringMessageConverter.java', 'spring-cloud-stream/src/main/java/org/springframework/cloud/stream/converter/StringToByteArrayMessageConverter.java', 'spring-cloud-stream/src/main/java/org/springframework/cloud/stream/converter/PojoToStringMessageConverter.java', 'spring-cloud-stream/src/main/java/org/springframework/cloud/stream/converter/PojoToJsonMessageConverter.java']","['spring-cloud-stream/src/main/java/org/springframework/cloud/stream/converter/JsonToPojoMessageConverter.java', 'spring-cloud-stream/src/main/java/org/springframework/cloud/stream/converter/ByteArrayToStringMessageConverter.java', 'spring-cloud-stream/src/main/java/org/springframework/cloud/stream/converter/StringToByteArrayMessageConverter.java', 'spring-cloud-stream/src/main/java/org/springframework/cloud/stream/converter/PojoToStringMessageConverter.java', 'spring-cloud-stream/src/main/java/org/springframework/cloud/stream/converter/PojoToJsonMessageConverter.java']","['```json\n{\n  ""files"": [\n    ""spring-cloud-stream/src/main/java/org/springframework/cloud/stream/converter/StringToByteArrayMessageConverter.java"",\n    ""spring-cloud-stream/src/main/java/org/springframework/cloud/stream/converter/ByteArrayToStringMessageConverter.java"",\n    ""spring-cloud-stream/src/main/java/org/springframework/cloud/stream/converter/PojoToStringMessageConverter.java"",\n    ""spring-cloud-stream/src/main/java/org/springframework/cloud/stream/converter/PojoToJsonMessageConverter.java"",\n    ""spring-cloud-stream/src/main/java/org/springframework/cloud/stream/converter/JsonToPojoMessageConverter.java""\n  ]\n}\n```']",1,1633.5036754608154
672,zalando/nakadi/677/391,zalando,nakadi,https://github.com/zalando/nakadi/issues/391,https://github.com/zalando/nakadi/pull/677,https://github.com/zalando/nakadi/pull/677,1,fixes,Nakadi silently overrides metadata.flow_id,"When publishing an event, if the header `X-Flow-Id` is not provided, then Nakadi will silently override this field with a randomly generated value.

I would expect Nakadi not to override it, if it was provided, since it's mentioned in the API that ""No preexisting value might be changed"".

> 1. Once the validation succeeded, the content of the Event is updated according to the
>        enrichment rules in the order the rules are defined in the `EventType`.  No preexisting
>        value might be changed (even if added by an enrichment rule). Violations on this will force
>        the immediate **rejection** of the Event. The invalid overwrite attempt will be included in
>        the item's `BatchItemResponse` object.

It should either reject such event (which doesn't make much sense) or keep it, if present.
",ddbfc693362b49214d4d13507be36f9008173a2b,011015d32a29b8dad051fe9e6981cc47de50652e,https://github.com/zalando/nakadi/compare/ddbfc693362b49214d4d13507be36f9008173a2b...011015d32a29b8dad051fe9e6981cc47de50652e,"diff --git a/src/main/java/org/zalando/nakadi/enrichment/MetadataEnrichmentStrategy.java b/src/main/java/org/zalando/nakadi/enrichment/MetadataEnrichmentStrategy.java
index 145545f9c..ec4e154fe 100644
--- a/src/main/java/org/zalando/nakadi/enrichment/MetadataEnrichmentStrategy.java
+++ b/src/main/java/org/zalando/nakadi/enrichment/MetadataEnrichmentStrategy.java
@@ -30,7 +30,9 @@ public class MetadataEnrichmentStrategy implements EnrichmentStrategy {
     }
 
     private void setFlowId(final JSONObject metadata) {
-        metadata.put(""flow_id"", FlowIdUtils.peek());
+        if ("""".equals(metadata.optString(""flow_id""))) {
+            metadata.put(""flow_id"", FlowIdUtils.peek());
+        }
     }
 
     private void setEventTypeName(final JSONObject metadata, final EventType eventType) {
diff --git a/src/test/java/org/zalando/nakadi/enrichment/MetadataEnrichmentStrategyTest.java b/src/test/java/org/zalando/nakadi/enrichment/MetadataEnrichmentStrategyTest.java
index 768b9547c..642ec2568 100644
--- a/src/test/java/org/zalando/nakadi/enrichment/MetadataEnrichmentStrategyTest.java
+++ b/src/test/java/org/zalando/nakadi/enrichment/MetadataEnrichmentStrategyTest.java
@@ -90,6 +90,47 @@ public class MetadataEnrichmentStrategyTest {
         assertThat(batch.getEvent().getJSONObject(""metadata"").getString(""flow_id""), equalTo(flowId));
     }
 
+    @Test
+    public void whenFlowIdIsPresentDoNotOverride() throws Exception {
+        final EventType eventType = buildDefaultEventType();
+        final JSONObject event = buildBusinessEvent();
+        event.getJSONObject(""metadata"").put(""flow_id"", ""something"");
+        final BatchItem batch = createBatchItem(event);
+
+        FlowIdUtils.push(""something-else"");
+        strategy.enrich(batch, eventType);
+
+        assertThat(batch.getEvent().getJSONObject(""metadata"").getString(""flow_id""), equalTo(""something""));
+    }
+
+    @Test
+    public void whenFlowIsEmptyStringOverrideIt() throws Exception {
+        final EventType eventType = buildDefaultEventType();
+        final JSONObject event = buildBusinessEvent();
+        event.getJSONObject(""metadata"").put(""flow_id"", """");
+        final BatchItem batch = createBatchItem(event);
+
+        final String flowId = randomString();
+        FlowIdUtils.push(flowId);
+        strategy.enrich(batch, eventType);
+
+        assertThat(batch.getEvent().getJSONObject(""metadata"").getString(""flow_id""), equalTo(flowId));
+    }
+
+    @Test
+    public void whenFlowIsNullOverrideIt() throws Exception {
+        final EventType eventType = buildDefaultEventType();
+        final JSONObject event = buildBusinessEvent();
+        event.getJSONObject(""metadata"").put(""flow_id"", (Object)null);
+        final BatchItem batch = createBatchItem(event);
+
+        final String flowId = randomString();
+        FlowIdUtils.push(flowId);
+        strategy.enrich(batch, eventType);
+
+        assertThat(batch.getEvent().getJSONObject(""metadata"").getString(""flow_id""), equalTo(flowId));
+    }
+
     @Test
     public void setPartition() throws Exception {
         final EventType eventType = buildDefaultEventType();","['src/main/java/org/zalando/nakadi/enrichment/MetadataEnrichmentStrategy.java', 'src/test/java/org/zalando/nakadi/enrichment/MetadataEnrichmentStrategyTest.java']",{'.java': 2},2,2,0,0,2,832929,156211,21130,299,179,38,4,1,818,132,182,12,0,0,2017-06-07 16:36:56,904,Java,"{'Java': 2529825, 'Shell': 1956, 'PLpgSQL': 1208, 'Dockerfile': 872}",MIT License,"['src/main/java/org/zalando/nakadi/service/subscription/zk/ZkSubscriptionClient.java', 'src/main/java/org/zalando/nakadi/util/FlowIdUtils.java', 'src/main/java/org/zalando/nakadi/service/subscription/zk/ZKSubscription.java', 'src/main/java/org/zalando/nakadi/service/EventPublisher.java', 'src/main/java/org/zalando/nakadi/service/subscription/zk/ZkSubscriptionNode.java']","['src/main/java/org/zalando/nakadi/service/subscription/zk/ZkSubscriptionClient.java', 'src/main/java/org/zalando/nakadi/util/FlowIdUtils.java', 'src/main/java/org/zalando/nakadi/service/subscription/zk/ZKSubscription.java', 'src/main/java/org/zalando/nakadi/service/EventPublisher.java', 'src/main/java/org/zalando/nakadi/service/subscription/zk/ZkSubscriptionNode.java']","['```json\n{\n  ""files"": [\n    ""src/main/java/org/zalando/nakadi/service/EventPublisher.java"",\n    ""src/main/java/org/zalando/nakadi/service/subscription/zk/ZKSubscription.java"",\n    ""src/main/java/org/zalando/nakadi/service/subscription/zk/ZkSubscriptionClient.java"",\n    ""src/main/java/org/zalando/nakadi/service/subscription/zk/ZkSubscriptionNode.java"",\n    ""src/main/java/org/zalando/nakadi/util/FlowIdUtils.java""\n  ]\n}\n```']",1,2129.2178630828857
1004,apicurio/apicurio-studio/1604/1533,apicurio,apicurio-studio,https://github.com/Apicurio/apicurio-studio/issues/1533,https://github.com/Apicurio/apicurio-studio/pull/1604,https://github.com/Apicurio/apicurio-studio/pull/1604,1,fixes,Imports must be resolved before mocking in Microcks,"When trying to mock an API (that contains imported types) with microcks, the following errors occurs in the browser:

> io.apicurio.hub.core.exceptions.ServerError: Unexpected server error
>	at io.apicurio.hub.api.rest.impl.DesignsResource.mockApi(DesignsResource.java:933)
> […]
> Caused by: io.apicurio.hub.api.microcks.MicrocksConnectorException: InternalServerError returned by Microcks server
>	at io.apicurio.hub.api.microcks.MicrocksConnector.uploadResourceContent(MicrocksConnector.java:171)
> […]

Microcks logs the following:
> 12:21:55.071 ERROR 1 --- [080-exec-3] o.a.c.c.C.[.[.[.[dispatcherServlet]      : Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is java.lang.IllegalArgumentException: Invalid input: JSON Pointer expression must start with '/': ""picurio:9#/components/responses/ForbiddenResponse""] with root cause
> 
>java.lang.IllegalArgumentException: Invalid input: JSON Pointer expression must start with '/': ""picurio:9#/components/responses/ForbiddenResponse""

where `ForbiddenResponse` is the imported type.

This leads me to believe that imports are currently not resolved before sending the API definition to microcks and microcks itself is unable to do so (which makes sense).",cc51237c008d280a12e2ec730b5642f849a9af29,d6c7df3b236affee5b79bcac144f4f17f3d7f224,https://github.com/apicurio/apicurio-studio/compare/cc51237c008d280a12e2ec730b5642f849a9af29...d6c7df3b236affee5b79bcac144f4f17f3d7f224,"diff --git a/back-end/hub-api/src/main/java/io/apicurio/hub/api/microcks/MicrocksConnector.java b/back-end/hub-api/src/main/java/io/apicurio/hub/api/microcks/MicrocksConnector.java
index f9c30ba6..4aad04d7 100644
--- a/back-end/hub-api/src/main/java/io/apicurio/hub/api/microcks/MicrocksConnector.java
+++ b/back-end/hub-api/src/main/java/io/apicurio/hub/api/microcks/MicrocksConnector.java
@@ -17,6 +17,7 @@
 package io.apicurio.hub.api.microcks;
 
 import java.io.ByteArrayInputStream;
+import java.io.IOException;
 import java.nio.charset.Charset;
 import java.util.Collection;
 
@@ -25,6 +26,7 @@ import javax.enterprise.context.ApplicationScoped;
 import javax.enterprise.inject.Default;
 import javax.inject.Inject;
 
+import io.apicurio.hub.api.content.ContentDereferencer;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
@@ -39,7 +41,7 @@ import io.apicurio.hub.core.config.HubConfiguration;
 
 /**
  * Default implementation of a Microcks connector.
- * 
+ *
  * @author laurent.broudoux@gmail.com
  */
 @ApplicationScoped
@@ -50,6 +52,8 @@ public class MicrocksConnector implements IMicrocksConnector {
 
     @Inject
     private HubConfiguration config;
+    @Inject
+    private ContentDereferencer dereferencer;
 
     /** Microcks API URL (should ends with /api). */
     private String apiURL;
@@ -73,7 +77,7 @@ public class MicrocksConnector implements IMicrocksConnector {
 
     /**
      * Returns the OAuth token to use when accessing Microcks.
-     * 
+     *
      * @throws MicrocksConnectorException
      */
     private String getKeycloakOAuthToken() throws MicrocksConnectorException {
@@ -135,12 +139,18 @@ public class MicrocksConnector implements IMicrocksConnector {
     /**
      * Upload an OAS v3 specification content to Microcks. This will trigger service discovery and mock
      * endpoint publication on the Microcks side.
-     * 
+     *
      * @param content OAS v3 specification content
      * @throws MicrocksConnectorException if upload fails for many reasons
      */
     public String uploadResourceContent(String content) throws MicrocksConnectorException {
         String oauthToken = this.getKeycloakOAuthToken();
+        try {
+            content = dereferencer.dereference(content);
+        } catch (IOException e) {
+            logger.error(""Could not dereference imports in specification content"", e);
+            throw new MicrocksConnectorException(""Could not dereference imports before sending to Microcks"");
+        }
         MultipartBody uploadRequest = Unirest.post(this.apiURL + ""/artifact/upload"")
                 .header(""Authorization"", ""Bearer "" + oauthToken)
                 .field(""file"", new ByteArrayInputStream(content.getBytes(Charset.forName(""UTF-8""))), ""open-api-contract.yml"");
@@ -178,7 +188,7 @@ public class MicrocksConnector implements IMicrocksConnector {
 
     /**
      * Reserved for future usage.
-     * 
+     *
      * @return List of repository secrets managed by Microcks server
      * @throws MicrocksConnectorException if connection fails for any reasons
      */
@@ -188,7 +198,7 @@ public class MicrocksConnector implements IMicrocksConnector {
 
     /**
      * Reserved for future usage.
-     * 
+     *
      * @return List of import jobs managed by Microcks server
      * @throws MicrocksConnectorException if connection fails for any reasons
      */
@@ -198,7 +208,7 @@ public class MicrocksConnector implements IMicrocksConnector {
 
     /**
      * Reserved for future usage.
-     * 
+     *
      * @param job Import job to create in Microcks server.
      * @throws MicrocksConnectorException if connection fails for any reasons
      */
@@ -208,7 +218,7 @@ public class MicrocksConnector implements IMicrocksConnector {
 
     /**
      * Reserved for future usage.
-     * 
+     *
      * @param job Import job to force import in Microcks server.
      * @throws MicrocksConnectorException if connection fails for any reasons
      */",['back-end/hub-api/src/main/java/io/apicurio/hub/api/microcks/MicrocksConnector.java'],{'.java': 1},1,1,0,0,1,1094436,231785,33392,306,574,127,24,1,1310,133,301,17,0,0,2021-07-22 13:24:29,867,TypeScript,"{'TypeScript': 1453260, 'Java': 1410458, 'HTML': 647763, 'CSS': 241046, 'Shell': 5417, 'Scala': 4126, 'Dockerfile': 3804, 'Makefile': 2309, 'JavaScript': 382, 'Smarty': 176}",Apache License 2.0,"['back-end/hub-core/src/main/java/io/apicurio/hub/core/beans/ResourceContent.java', 'back-end/hub-api/src/main/java/io/apicurio/hub/api/microcks/MicrocksConnector.java', 'back-end/hub-api/src/main/java/io/apicurio/hub/api/microcks/MicrocksConnectorException.java', 'back-end/hub-core/src/main/java/io/apicurio/hub/core/exceptions/ServerError.java', 'back-end/hub-core/src/main/java/io/apicurio/hub/core/exceptions/ApiValidationException.java']","['back-end/hub-api/src/main/java/io/apicurio/hub/api/microcks/MicrocksConnector.java', 'back-end/hub-api/src/main/java/io/apicurio/hub/api/microcks/MicrocksConnectorException.java', 'back-end/hub-core/src/main/java/io/apicurio/hub/core/exceptions/ServerError.java', 'back-end/hub-core/src/main/java/io/apicurio/hub/core/exceptions/ApiValidationException.java']","['```json\n{\n  ""files"": [\n    ""back-end/hub-api/src/main/java/io/apicurio/hub/api/microcks/MicrocksConnector.java"",\n    ""back-end/hub-api/src/main/java/io/apicurio/hub/api/microcks/MicrocksConnectorException.java"",\n    ""back-end/hub-core/src/main/java/io/apicurio/hub/core/exceptions/ServerError.java"",\n    ""back-end/hub-core/src/main/java/io/apicurio/hub/core/exceptions/ApiValidationException.java"",\n    ""back-end/hub-core/src/main/java/io/apicurio/hub/core/beans/ResourceContent.java""\n  ]\n}\n```']",1,2474.3874073028564
9441,objectionary/eo/1263/1256,objectionary,eo,https://github.com/objectionary/eo/issues/1256,https://github.com/objectionary/eo/pull/1263,https://github.com/objectionary/eo/pull/1263,1,fix,`keepBinaries` property is not respected in `UnplaceMojo`,"Within `UnplaceMojo` we have config parameter `keepBinaries` which is supposed to prevent specified compiled (placed) files from removal. 
However current implementation ignore it since it calls consequently two steps:
1. `keepThem` step would remove everything but specified in `keepBinaries`
2. `killThem` step would remove everything with no respect to `keepBinaries`

Need to make `killThem` respect `keepBinaries` property.",17e240ebb323d2e12e0a79fc9e3656eef9f7895e,74e17969d5f4bfac96c1d26b0defa680083ee327,https://github.com/objectionary/eo/compare/17e240ebb323d2e12e0a79fc9e3656eef9f7895e...74e17969d5f4bfac96c1d26b0defa680083ee327,"diff --git a/eo-maven-plugin/src/main/java/org/eolang/maven/UnplaceMojo.java b/eo-maven-plugin/src/main/java/org/eolang/maven/UnplaceMojo.java
index fdbbe2150..8648526e6 100644
--- a/eo-maven-plugin/src/main/java/org/eolang/maven/UnplaceMojo.java
+++ b/eo-maven-plugin/src/main/java/org/eolang/maven/UnplaceMojo.java
@@ -150,6 +150,10 @@ public final class UnplaceMojo extends SafeMojo {
                     related, tojo.get(PlaceMojo.ATTR_ORIGIN)
                 );
             }
+            if (UnplaceMojo.inside(related, this.keepBinaries)
+                && !UnplaceMojo.inside(related, this.removeBinaries)) {
+                continue;
+            }
             if (UnplaceMojo.delete(path)) {
                 unplaced += 1;
                 Logger.debug(
diff --git a/eo-maven-plugin/src/test/java/org/eolang/maven/UnplaceMojoTest.java b/eo-maven-plugin/src/test/java/org/eolang/maven/UnplaceMojoTest.java
index 5b68695c3..890b50a70 100644
--- a/eo-maven-plugin/src/test/java/org/eolang/maven/UnplaceMojoTest.java
+++ b/eo-maven-plugin/src/test/java/org/eolang/maven/UnplaceMojoTest.java
@@ -25,6 +25,7 @@ package org.eolang.maven;
 
 import java.nio.file.Path;
 import java.nio.file.Paths;
+import org.cactoos.set.SetOf;
 import org.hamcrest.MatcherAssert;
 import org.hamcrest.Matchers;
 import org.junit.jupiter.api.Test;
@@ -37,6 +38,10 @@ import org.junit.jupiter.api.io.TempDir;
  * @checkstyle LocalFinalVariableNameCheck (100 lines)
  */
 final class UnplaceMojoTest {
+    /**
+     * Value for 'class' ATTR_KIND.
+     */
+    private static final String ATTR_KIND_CLASS = ""class"";
 
     @Test
     void testCleaning(@TempDir final Path temp) throws Exception {
@@ -52,25 +57,25 @@ final class UnplaceMojoTest {
         final Path list = temp.resolve(""placed.csv"");
         Catalogs.INSTANCE.make(list)
             .add(foo.toString())
-            .set(PlaceMojo.ATTR_KIND, ""class"")
+            .set(PlaceMojo.ATTR_KIND, UnplaceMojoTest.ATTR_KIND_CLASS)
             .set(PlaceMojo.ATTR_RELATED, ""---"")
             .set(PlaceMojo.ATTR_ORIGIN, ""some.jar"")
             .set(PlaceMojo.ATTR_HASH, new FileHash(foo));
         Catalogs.INSTANCE.make(list)
             .add(foo2.toString())
-            .set(PlaceMojo.ATTR_KIND, ""class"")
+            .set(PlaceMojo.ATTR_KIND, UnplaceMojoTest.ATTR_KIND_CLASS)
             .set(PlaceMojo.ATTR_RELATED, ""---"")
             .set(PlaceMojo.ATTR_ORIGIN, ""some.jar"")
             .set(PlaceMojo.ATTR_HASH, new FileHash(foo2));
         Catalogs.INSTANCE.make(list)
             .add(foo3.toString())
-            .set(PlaceMojo.ATTR_KIND, ""class"")
+            .set(PlaceMojo.ATTR_KIND, UnplaceMojoTest.ATTR_KIND_CLASS)
             .set(PlaceMojo.ATTR_RELATED, ""---"")
             .set(PlaceMojo.ATTR_ORIGIN, ""some.jar"")
             .set(PlaceMojo.ATTR_HASH, new FileHash(foo3));
         Catalogs.INSTANCE.make(list)
             .add(foo4.toString())
-            .set(PlaceMojo.ATTR_KIND, ""class"")
+            .set(PlaceMojo.ATTR_KIND, UnplaceMojoTest.ATTR_KIND_CLASS)
             .set(PlaceMojo.ATTR_RELATED, ""---"")
             .set(PlaceMojo.ATTR_ORIGIN, ""some.jar"")
             .set(PlaceMojo.ATTR_HASH, new FileHash(foo4));
@@ -99,4 +104,59 @@ final class UnplaceMojoTest {
             Matchers.is(false)
         );
     }
+
+    @Test
+    void testKeepBinaries(@TempDir final Path temp) throws Exception {
+        final Path foo = temp.resolve(""a/b/c/foo5.class"");
+        new Home().save(""testKeepBinaries"", foo);
+        final Path pparent = foo.getParent().getParent();
+        final Path list = temp.resolve(""placed.csv"");
+        Catalogs.INSTANCE.make(list)
+            .add(foo.toString())
+            .set(PlaceMojo.ATTR_KIND, UnplaceMojoTest.ATTR_KIND_CLASS)
+            .set(PlaceMojo.ATTR_RELATED, ""a/b/c/foo5.class"")
+            .set(PlaceMojo.ATTR_ORIGIN, ""some-keep.jar"")
+            .set(PlaceMojo.ATTR_HASH, new FileHash(foo));
+        new Moja<>(UnplaceMojo.class)
+            .with(""placed"", list.toFile())
+            .with(""placedFormat"", ""csv"")
+            .with(""keepBinaries"", new SetOf<>(""**foo5.class""))
+            .execute();
+        MatcherAssert.assertThat(
+            new Home().exists(foo),
+            Matchers.is(true)
+        );
+        MatcherAssert.assertThat(
+            new Home().exists(Paths.get(String.valueOf(pparent))),
+            Matchers.is(true)
+        );
+    }
+
+    @Test
+    void testKeepRemoveBinaries(@TempDir final Path temp) throws Exception {
+        final Path foo = temp.resolve(""a/b/c/foo6.class"");
+        new Home().save(""testKeepRemoveBinaries"", foo);
+        final Path pparent = foo.getParent().getParent();
+        final Path list = temp.resolve(""placed.csv"");
+        Catalogs.INSTANCE.make(list)
+            .add(foo.toString())
+            .set(PlaceMojo.ATTR_KIND, UnplaceMojoTest.ATTR_KIND_CLASS)
+            .set(PlaceMojo.ATTR_RELATED, ""a/b/c/foo6.class"")
+            .set(PlaceMojo.ATTR_ORIGIN, ""some-keep-remove.jar"")
+            .set(PlaceMojo.ATTR_HASH, new FileHash(foo));
+        new Moja<>(UnplaceMojo.class)
+            .with(""placed"", list.toFile())
+            .with(""placedFormat"", ""csv"")
+            .with(""keepBinaries"", new SetOf<>(""**foo6.class""))
+            .with(""removeBinaries"", new SetOf<>(""**foo6.class""))
+            .execute();
+        MatcherAssert.assertThat(
+            new Home().exists(foo),
+            Matchers.is(false)
+        );
+        MatcherAssert.assertThat(
+            new Home().exists(Paths.get(String.valueOf(pparent))),
+            Matchers.is(false)
+        );
+    }
 }","['eo-maven-plugin/src/test/java/org/eolang/maven/UnplaceMojoTest.java', 'eo-maven-plugin/src/main/java/org/eolang/maven/UnplaceMojo.java']",{'.java': 2},2,2,0,0,2,520737,114505,16826,156,178,40,4,1,433,57,96,6,0,0,2022-09-23 14:26:17,814,Java,"{'Java': 1396574, 'XSLT': 298556, 'TeX': 138771, 'Groovy': 16462, 'Rust': 5709, 'ANTLR': 3211, 'Makefile': 2212, 'Shell': 1454, 'Perl': 114}",MIT License,"['eo-maven-plugin/src/main/java/org/eolang/maven/OyFallbackSwap.java', 'eo-maven-plugin/src/main/java/org/eolang/maven/OyCaching.java', 'eo-maven-plugin/src/main/java/org/eolang/maven/UnplaceMojo.java', 'eo-maven-plugin/src/main/java/org/eolang/maven/OyEmpty.java', 'eo-maven-plugin/src/main/java/org/eolang/maven/OyFallback.java']","['eo-maven-plugin/src/main/java/org/eolang/maven/OyFallbackSwap.java', 'eo-maven-plugin/src/main/java/org/eolang/maven/OyCaching.java', 'eo-maven-plugin/src/main/java/org/eolang/maven/UnplaceMojo.java', 'eo-maven-plugin/src/main/java/org/eolang/maven/OyEmpty.java', 'eo-maven-plugin/src/main/java/org/eolang/maven/OyFallback.java']","['```json\n{\n  ""files"": [\n    ""eo-maven-plugin/src/main/java/org/eolang/maven/UnplaceMojo.java"",\n    ""eo-maven-plugin/src/main/java/org/eolang/maven/OyFallback.java"",\n    ""eo-maven-plugin/src/main/java/org/eolang/maven/OyFallbackSwap.java"",\n    ""eo-maven-plugin/src/main/java/org/eolang/maven/OyCaching.java"",\n    ""eo-maven-plugin/src/main/java/org/eolang/maven/OyEmpty.java""\n  ]\n}\n```']",1,1333.2347869873047
816,spring-cloud/spring-cloud-consul/230/229,spring-cloud,spring-cloud-consul,https://github.com/spring-cloud/spring-cloud-consul/issues/229,https://github.com/spring-cloud/spring-cloud-consul/pull/230,https://github.com/spring-cloud/spring-cloud-consul/pull/230,1,fix,Consul ConfigWatch not working for FILES config format,"Watching Consul for config changes stopped working with release 1.1 in case of using FILES config format. I ran into this as part of upgrading to Spring Camden.RELEASE (that updates from spring-cloud-consul 1.0.2 to 1.1.0).

I did some debugging and think I know what the root cause is:
- ConfigWatch always a trailing slash to the context paths looked at in Consul
- This essentially means that ConfigWatch always looks at folders - this is conceptually incorrect  'FILES' mode - this actually is the problem root cause
- Watching this incorrect path always leads to a HTTP 404 from Consul (since the file is no folder but a leaf in the Consul tree)
- This still worked with Brixton / 1.0.2 by accident since 1.02 did not even look at the response code and only at the index returned by Consul
- Release 1.1 added code in ConfigWatch that looks at the Consul response value and ignores HTTP 404 responses (which is correct)
- Any changes to the config files are now skipped with Camden / 1.1.0 and do not lead to config change events

The fix would require to look at the configured config format `spring.cloud.consul.config.format` and avoid implicitly adding a trailing slash in case `FILES` is desired.
",ee007651e58fc2530b5f893c1477afb3d78c7d24,68b4459c3b7494252d47f596f5818777b22b7008,https://github.com/spring-cloud/spring-cloud-consul/compare/ee007651e58fc2530b5f893c1477afb3d78c7d24...68b4459c3b7494252d47f596f5818777b22b7008,"diff --git a/spring-cloud-consul-config/src/main/java/org/springframework/cloud/consul/config/ConfigWatch.java b/spring-cloud-consul-config/src/main/java/org/springframework/cloud/consul/config/ConfigWatch.java
index d9622bfd..d7e174d3 100644
--- a/spring-cloud-consul-config/src/main/java/org/springframework/cloud/consul/config/ConfigWatch.java
+++ b/spring-cloud-consul-config/src/main/java/org/springframework/cloud/consul/config/ConfigWatch.java
@@ -36,6 +36,8 @@ import lombok.Data;
 import lombok.extern.apachecommons.CommonsLog;
 import org.springframework.util.ReflectionUtils;
 
+import static org.springframework.cloud.consul.config.ConsulConfigProperties.Format.FILES;
+
 /**
  * @author Spencer Gibb
  */
@@ -70,7 +72,9 @@ public class ConfigWatch implements Closeable, ApplicationEventPublisherAware {
 	public void watchConfigKeyValues() {
 		if (this.running.get()) {
 			for (String context : this.contexts) {
-				if (!context.endsWith(""/"")) {
+
+				// turn the context into a Consul folder path (unless our config format are FILES)
+				if (properties.getFormat() != FILES && !context.endsWith(""/"")) {
 					context = context + ""/"";
 				}
 
diff --git a/spring-cloud-consul-config/src/test/java/org/springframework/cloud/consul/config/ConfigWatchTests.java b/spring-cloud-consul-config/src/test/java/org/springframework/cloud/consul/config/ConfigWatchTests.java
index 37d2f0b2..5c271bda 100644
--- a/spring-cloud-consul-config/src/test/java/org/springframework/cloud/consul/config/ConfigWatchTests.java
+++ b/spring-cloud-consul-config/src/test/java/org/springframework/cloud/consul/config/ConfigWatchTests.java
@@ -20,6 +20,7 @@ import com.ecwid.consul.v1.ConsulClient;
 import com.ecwid.consul.v1.QueryParams;
 import com.ecwid.consul.v1.Response;
 import com.ecwid.consul.v1.kv.model.GetValue;
+import org.junit.Before;
 import org.junit.Test;
 import org.springframework.cloud.endpoint.event.RefreshEvent;
 import org.springframework.context.ApplicationEventPublisher;
@@ -34,17 +35,25 @@ import static org.mockito.Mockito.never;
 import static org.mockito.Mockito.times;
 import static org.mockito.Mockito.verify;
 import static org.mockito.Mockito.when;
+import static org.springframework.cloud.consul.config.ConsulConfigProperties.Format.FILES;
 
 /**
  * @author Spencer Gibb
  */
 public class ConfigWatchTests {
 
+	private ConsulConfigProperties configProperties;
+
+	@Before
+	public void setUp() throws Exception {
+		configProperties = new ConsulConfigProperties();
+	}
+
 	@Test
 	public void watchPublishesEvent() {
 		ApplicationEventPublisher eventPublisher = mock(ApplicationEventPublisher.class);
 
-		setupWatch(eventPublisher, new GetValue());
+		setupWatch(eventPublisher, new GetValue(), configProperties, ""/app/"");
 
 		verify(eventPublisher, times(1)).publishEvent(any(RefreshEvent.class));
 	}
@@ -53,12 +62,22 @@ public class ConfigWatchTests {
 	public void watchWithNullValueDoesNotPublishEvent() {
 		ApplicationEventPublisher eventPublisher = mock(ApplicationEventPublisher.class);
 
-		setupWatch(eventPublisher, null);
+		setupWatch(eventPublisher, null, configProperties, ""/app/"");
 
 		verify(eventPublisher, never()).publishEvent(any(RefreshEvent.class));
 	}
 
-	private void setupWatch(ApplicationEventPublisher eventPublisher, GetValue getValue) {
+	@Test
+	public void watchForFileFormatPublishesEvent() {
+		ApplicationEventPublisher eventPublisher = mock(ApplicationEventPublisher.class);
+
+		configProperties.setFormat(FILES);
+		setupWatch(eventPublisher, new GetValue(), configProperties, ""/config/app.yml"" );
+
+		verify(eventPublisher, times(1)).publishEvent(any(RefreshEvent.class));
+	}
+
+	private void setupWatch(ApplicationEventPublisher eventPublisher, GetValue getValue, ConsulConfigProperties configProperties, String context ) {
 		ConsulClient consul = mock(ConsulClient.class);
 		List<GetValue> getValues = null;
 
@@ -67,11 +86,11 @@ public class ConfigWatchTests {
 		}
 
 		Response<List<GetValue>> response = new Response<>(getValues, 1L, false, 1L);
-		when(consul.getKVValues(eq(""/app/""), any(QueryParams.class))).thenReturn(response);
+		when(consul.getKVValues(eq(context), any(QueryParams.class))).thenReturn(response);
 
-		ConfigWatch watch = new ConfigWatch(new ConsulConfigProperties(), Arrays.asList(""/app/""), consul);
+		ConfigWatch watch = new ConfigWatch(configProperties, Arrays.asList(context), consul);
 		watch.setApplicationEventPublisher(eventPublisher);
-		watch.getConsulIndexes().put(""/app/"", 0L);
+		watch.getConsulIndexes().put(context, 0L);
 		watch.start();
 
 		watch.watchConfigKeyValues();","['spring-cloud-consul-config/src/main/java/org/springframework/cloud/consul/config/ConfigWatch.java', 'spring-cloud-consul-config/src/test/java/org/springframework/cloud/consul/config/ConfigWatchTests.java']",{'.java': 2},2,2,0,0,2,110780,23740,3551,41,288,59,6,1,1207,209,282,12,0,0,2016-09-30 10:13:49,793,Java,"{'Java': 560522, 'CSS': 34264, 'HTML': 28643, 'Batchfile': 5822, 'Shell': 542}",Apache License 2.0,"['spring-cloud-consul-config/src/main/java/org/springframework/cloud/consul/config/ConsulConfigAutoConfiguration.java', 'spring-cloud-consul-config/src/main/java/org/springframework/cloud/consul/config/ConsulConfigProperties.java', 'spring-cloud-consul-config/src/main/java/org/springframework/cloud/consul/config/ConfigWatch.java']","['spring-cloud-consul-config/src/main/java/org/springframework/cloud/consul/config/ConsulConfigAutoConfiguration.java', 'spring-cloud-consul-config/src/main/java/org/springframework/cloud/consul/config/ConsulConfigProperties.java', 'spring-cloud-consul-config/src/main/java/org/springframework/cloud/consul/config/ConfigWatch.java']","['```json\n{\n  ""files"": [\n    ""spring-cloud-consul-config/src/main/java/org/springframework/cloud/consul/config/ConfigWatch.java"",\n    ""spring-cloud-consul-config/src/main/java/org/springframework/cloud/consul/config/ConsulConfigAutoConfiguration.java"",\n    ""spring-cloud-consul-config/src/main/java/org/springframework/cloud/consul/config/ConsulConfigProperties.java""\n  ]\n}\n```']",1,1761.0821723937988
529,opengamma/strata/1313/1312,opengamma,strata,https://github.com/OpenGamma/Strata/issues/1312,https://github.com/OpenGamma/Strata/pull/1313,https://github.com/OpenGamma/Strata/pull/1313,1,fixes,"MultiCurrencyAmountArray.of(size, fn) doesn't work with empty MultiCurrencyAmounts ","The following code produces a `MultiCurrencyAmountArray` of size zero even though it is created from two `MultiCurrencyAmounts`

```
MultiCurrencyAmountArray array = MultiCurrencyAmountArray.of(
    MultiCurrencyAmount.empty(),
    MultiCurrencyAmount.empty());
```

The following code always produces a `MultiCurrencyAmountArray` with a size of zero regardless of the requested size:

```
MultiCurrencyAmountArray.of(size, () -> MultiCurrencyAmount.empty());
```

The size of the array is derived from the size of the internal arrays holding the currency values. If there are no values a size of zero is incorrectly returned.
",e118c05ed7fb826ed8ce9cb019ce51297497e912,e558988a726306271478b1539eb440ca71efb400,https://github.com/opengamma/strata/compare/e118c05ed7fb826ed8ce9cb019ce51297497e912...e558988a726306271478b1539eb440ca71efb400,"diff --git a/modules/basics/src/main/java/com/opengamma/strata/basics/currency/MultiCurrencyAmountArray.java b/modules/basics/src/main/java/com/opengamma/strata/basics/currency/MultiCurrencyAmountArray.java
index c9ec298a4..129fd33a9 100644
--- a/modules/basics/src/main/java/com/opengamma/strata/basics/currency/MultiCurrencyAmountArray.java
+++ b/modules/basics/src/main/java/com/opengamma/strata/basics/currency/MultiCurrencyAmountArray.java
@@ -55,15 +55,17 @@ import com.opengamma.strata.collect.array.DoubleArray;
 public final class MultiCurrencyAmountArray
     implements FxConvertible<CurrencyAmountArray>, ImmutableBean, Serializable {
 
+  /**
+   * The size of this array.
+   */
+  @PropertyDefinition(validate = ""notNegative"")
+  private final int size;
+
   /**
    * The currency values, keyed by currency.
    */
   @PropertyDefinition(validate = ""notNull"")
   private final ImmutableSortedMap<Currency, DoubleArray> values;
-  /**
-   * The number of values for each currency.
-   */
-  private final int size;  // derived
 
   //-------------------------------------------------------------------------
   /**
@@ -93,7 +95,7 @@ public final class MultiCurrencyAmountArray
       }
     }
     Map<Currency, DoubleArray> doubleArrayMap = MapStream.of(valueMap).mapValues(v -> DoubleArray.ofUnsafe(v)).toMap();
-    return new MultiCurrencyAmountArray(doubleArrayMap);
+    return new MultiCurrencyAmountArray(size, doubleArrayMap);
   }
 
   /**
@@ -115,21 +117,26 @@ public final class MultiCurrencyAmountArray
         array[i] = ca.getAmount();
       }
     }
-    return new MultiCurrencyAmountArray(MapStream.of(map).mapValues(array -> DoubleArray.ofUnsafe(array)).toMap());
+    return new MultiCurrencyAmountArray(size, MapStream.of(map).mapValues(array -> DoubleArray.ofUnsafe(array)).toMap());
   }
 
   /**
    * Obtains an instance from a map of amounts.
    * <p>
    * Each currency is associated with an array of amounts.
-   * All the arrays must have the same number of elements in each array.
+   * All the arrays must have the same number of elements.
+   * <p>
+   * If the map is empty the returned array will have a size of zero. To create an empty array
+   * with a non-zero size use one of the other {@code of} methods.
    *
    * @param values  map of currencies to values
    * @return an instance containing the values from the map
    */
   public static MultiCurrencyAmountArray of(Map<Currency, DoubleArray> values) {
     values.values().stream().reduce((a1, a2) -> checkSize(a1, a2));
-    return new MultiCurrencyAmountArray(values);
+    // All of the values must have the same size so use the size of the first
+    int size = values.isEmpty() ? 0 : values.values().iterator().next().size();
+    return new MultiCurrencyAmountArray(size, values);
   }
 
   /**
@@ -152,14 +159,9 @@ public final class MultiCurrencyAmountArray
   }
 
   @ImmutableConstructor
-  private MultiCurrencyAmountArray(Map<Currency, DoubleArray> values) {
+  private MultiCurrencyAmountArray(int size, Map<Currency, DoubleArray> values) {
     this.values = ImmutableSortedMap.copyOf(values);
-    if (values.isEmpty()) {
-      size = 0;
-    } else {
-      // All currencies must have the same number of values so we can just take the size of the first
-      size = values.values().iterator().next().size();
-    }
+    this.size = size;
   }
 
   // validate when deserializing
@@ -405,6 +407,15 @@ public final class MultiCurrencyAmountArray
     return metaBean().metaPropertyMap().keySet();
   }
 
+  //-----------------------------------------------------------------------
+  /**
+   * Gets the size of this array.
+   * @return the value of the property
+   */
+  public int getSize() {
+    return size;
+  }
+
   //-----------------------------------------------------------------------
   /**
    * Gets the currency values, keyed by currency.
@@ -422,7 +433,8 @@ public final class MultiCurrencyAmountArray
     }
     if (obj != null && obj.getClass() == this.getClass()) {
       MultiCurrencyAmountArray other = (MultiCurrencyAmountArray) obj;
-      return JodaBeanUtils.equal(values, other.values);
+      return (size == other.size) &&
+          JodaBeanUtils.equal(values, other.values);
     }
     return false;
   }
@@ -430,14 +442,16 @@ public final class MultiCurrencyAmountArray
   @Override
   public int hashCode() {
     int hash = getClass().hashCode();
+    hash = hash * 31 + JodaBeanUtils.hashCode(size);
     hash = hash * 31 + JodaBeanUtils.hashCode(values);
     return hash;
   }
 
   @Override
   public String toString() {
-    StringBuilder buf = new StringBuilder(64);
+    StringBuilder buf = new StringBuilder(96);
     buf.append(""MultiCurrencyAmountArray{"");
+    buf.append(""size"").append('=').append(size).append(',').append(' ');
     buf.append(""values"").append('=').append(JodaBeanUtils.toString(values));
     buf.append('}');
     return buf.toString();
@@ -453,6 +467,11 @@ public final class MultiCurrencyAmountArray
      */
     static final Meta INSTANCE = new Meta();
 
+    /**
+     * The meta-property for the {@code size} property.
+     */
+    private final MetaProperty<Integer> size = DirectMetaProperty.ofImmutable(
+        this, ""size"", MultiCurrencyAmountArray.class, Integer.TYPE);
     /**
      * The meta-property for the {@code values} property.
      */
@@ -464,6 +483,7 @@ public final class MultiCurrencyAmountArray
      */
     private final Map<String, MetaProperty<?>> metaPropertyMap$ = new DirectMetaPropertyMap(
         this, null,
+        ""size"",
         ""values"");
 
     /**
@@ -475,6 +495,8 @@ public final class MultiCurrencyAmountArray
     @Override
     protected MetaProperty<?> metaPropertyGet(String propertyName) {
       switch (propertyName.hashCode()) {
+        case 3530753:  // size
+          return size;
         case -823812830:  // values
           return values;
       }
@@ -497,6 +519,14 @@ public final class MultiCurrencyAmountArray
     }
 
     //-----------------------------------------------------------------------
+    /**
+     * The meta-property for the {@code size} property.
+     * @return the meta-property, not null
+     */
+    public MetaProperty<Integer> size() {
+      return size;
+    }
+
     /**
      * The meta-property for the {@code values} property.
      * @return the meta-property, not null
@@ -509,6 +539,8 @@ public final class MultiCurrencyAmountArray
     @Override
     protected Object propertyGet(Bean bean, String propertyName, boolean quiet) {
       switch (propertyName.hashCode()) {
+        case 3530753:  // size
+          return ((MultiCurrencyAmountArray) bean).getSize();
         case -823812830:  // values
           return ((MultiCurrencyAmountArray) bean).getValues();
       }
@@ -532,6 +564,7 @@ public final class MultiCurrencyAmountArray
    */
   private static final class Builder extends DirectFieldsBeanBuilder<MultiCurrencyAmountArray> {
 
+    private int size;
     private SortedMap<Currency, DoubleArray> values = ImmutableSortedMap.of();
 
     /**
@@ -544,6 +577,8 @@ public final class MultiCurrencyAmountArray
     @Override
     public Object get(String propertyName) {
       switch (propertyName.hashCode()) {
+        case 3530753:  // size
+          return size;
         case -823812830:  // values
           return values;
         default:
@@ -555,6 +590,9 @@ public final class MultiCurrencyAmountArray
     @Override
     public Builder set(String propertyName, Object newValue) {
       switch (propertyName.hashCode()) {
+        case 3530753:  // size
+          this.size = (Integer) newValue;
+          break;
         case -823812830:  // values
           this.values = (SortedMap<Currency, DoubleArray>) newValue;
           break;
@@ -591,14 +629,16 @@ public final class MultiCurrencyAmountArray
     @Override
     public MultiCurrencyAmountArray build() {
       return new MultiCurrencyAmountArray(
+          size,
           values);
     }
 
     //-----------------------------------------------------------------------
     @Override
     public String toString() {
-      StringBuilder buf = new StringBuilder(64);
+      StringBuilder buf = new StringBuilder(96);
       buf.append(""MultiCurrencyAmountArray.Builder{"");
+      buf.append(""size"").append('=').append(JodaBeanUtils.toString(size)).append(',').append(' ');
       buf.append(""values"").append('=').append(JodaBeanUtils.toString(values));
       buf.append('}');
       return buf.toString();
diff --git a/modules/basics/src/test/java/com/opengamma/strata/basics/currency/MultiCurrencyAmountArrayTest.java b/modules/basics/src/test/java/com/opengamma/strata/basics/currency/MultiCurrencyAmountArrayTest.java
index 790322d1f..f8764f6bc 100644
--- a/modules/basics/src/test/java/com/opengamma/strata/basics/currency/MultiCurrencyAmountArrayTest.java
+++ b/modules/basics/src/test/java/com/opengamma/strata/basics/currency/MultiCurrencyAmountArrayTest.java
@@ -75,6 +75,15 @@ public class MultiCurrencyAmountArrayTest {
     assertThrowsIllegalArg(() -> raggedArray.getValues(Currency.AUD));
   }
 
+  public void test_empty_amounts() {
+    MultiCurrencyAmountArray array = MultiCurrencyAmountArray.of(
+        MultiCurrencyAmount.empty(),
+        MultiCurrencyAmount.empty());
+    assertThat(array.size()).isEqualTo(2);
+    assertThat(array.get(0)).isEqualTo(MultiCurrencyAmount.empty());
+    assertThat(array.get(1)).isEqualTo(MultiCurrencyAmount.empty());
+  }
+
   public void test_of_function() {
     MultiCurrencyAmount mca1 = MultiCurrencyAmount.of(CurrencyAmount.of(Currency.GBP, 10), CurrencyAmount.of(Currency.USD, 20));
     MultiCurrencyAmount mca2 = MultiCurrencyAmount.of(CurrencyAmount.of(Currency.GBP, 10), CurrencyAmount.of(Currency.EUR, 30));
@@ -87,14 +96,31 @@ public class MultiCurrencyAmountArrayTest {
     assertThat(test.get(2)).isEqualTo(mca3.plus(Currency.GBP, 0).plus(Currency.EUR, 0));
   }
 
+  public void test_of_function_empty_amounts() {
+    MultiCurrencyAmountArray test = MultiCurrencyAmountArray.of(3, i -> MultiCurrencyAmount.empty());
+    assertThat(test.size()).isEqualTo(3);
+  }
+
   public void test_of_map() {
     MultiCurrencyAmountArray array = MultiCurrencyAmountArray.of(
         ImmutableMap.of(
             Currency.GBP, DoubleArray.of(20, 21, 22),
-            Currency.USD, DoubleArray.of(30, 32, 33),
             Currency.EUR, DoubleArray.of(40, 43, 44)));
 
-    assertThat(array).isEqualTo(VALUES_ARRAY);
+    MultiCurrencyAmountArray expected = MultiCurrencyAmountArray.of(
+        ImmutableList.of(
+            MultiCurrencyAmount.of(
+                CurrencyAmount.of(Currency.GBP, 20),
+                CurrencyAmount.of(Currency.EUR, 40)),
+            MultiCurrencyAmount.of(
+                CurrencyAmount.of(Currency.GBP, 21),
+                CurrencyAmount.of(Currency.EUR, 43)),
+            MultiCurrencyAmount.of(
+                CurrencyAmount.of(Currency.GBP, 22),
+                CurrencyAmount.of(Currency.EUR, 44))));
+
+    assertThat(array.size()).isEqualTo(3);
+    assertThat(array).isEqualTo(expected);
 
     assertThrowsIllegalArg(
         () -> MultiCurrencyAmountArray.of(
@@ -102,6 +128,9 @@ public class MultiCurrencyAmountArrayTest {
                 Currency.GBP, DoubleArray.of(20, 21),
                 Currency.EUR, DoubleArray.of(40, 43, 44))),
         ""Arrays must have the same size.*"");
+
+    MultiCurrencyAmountArray empty = MultiCurrencyAmountArray.of(ImmutableMap.of());
+    assertThat(empty.size()).isEqualTo(0);
   }
 
   public void test_getValues() {
diff --git a/modules/data/src/test/java/com/opengamma/strata/data/scenario/MultiCurrencyScenarioArrayTest.java b/modules/data/src/test/java/com/opengamma/strata/data/scenario/MultiCurrencyScenarioArrayTest.java
index 79b2e1a5b..b0c108b0a 100644
--- a/modules/data/src/test/java/com/opengamma/strata/data/scenario/MultiCurrencyScenarioArrayTest.java
+++ b/modules/data/src/test/java/com/opengamma/strata/data/scenario/MultiCurrencyScenarioArrayTest.java
@@ -73,6 +73,15 @@ public class MultiCurrencyScenarioArrayTest {
     assertThrowsIllegalArg(() -> raggedArray.getValues(Currency.AUD));
   }
 
+  public void emptyAmounts() {
+    MultiCurrencyScenarioArray array = MultiCurrencyScenarioArray.of(
+        MultiCurrencyAmount.empty(),
+        MultiCurrencyAmount.empty());
+    assertThat(array.getScenarioCount()).isEqualTo(2);
+    assertThat(array.get(0)).isEqualTo(MultiCurrencyAmount.empty());
+    assertThat(array.get(1)).isEqualTo(MultiCurrencyAmount.empty());
+  }
+
   public void createByFunction() {
     MultiCurrencyAmount mca1 = MultiCurrencyAmount.of(CurrencyAmount.of(Currency.GBP, 10), CurrencyAmount.of(Currency.USD, 20));
     MultiCurrencyAmount mca2 = MultiCurrencyAmount.of(CurrencyAmount.of(Currency.GBP, 10), CurrencyAmount.of(Currency.EUR, 30));
@@ -85,6 +94,11 @@ public class MultiCurrencyScenarioArrayTest {
     assertThat(test.get(2)).isEqualTo(mca3.plus(Currency.GBP, 0).plus(Currency.EUR, 0));
   }
 
+  public void createByFunctionEmptyAmounts() {
+    MultiCurrencyScenarioArray test = MultiCurrencyScenarioArray.of(3, i -> MultiCurrencyAmount.empty());
+    assertThat(test.getScenarioCount()).isEqualTo(3);
+  }
+
   public void mapFactoryMethod() {
     MultiCurrencyScenarioArray array = MultiCurrencyScenarioArray.of(
         ImmutableMap.of(","['modules/basics/src/main/java/com/opengamma/strata/basics/currency/MultiCurrencyAmountArray.java', 'modules/basics/src/test/java/com/opengamma/strata/basics/currency/MultiCurrencyAmountArrayTest.java', 'modules/data/src/test/java/com/opengamma/strata/data/scenario/MultiCurrencyScenarioArrayTest.java']",{'.java': 3},3,3,0,0,3,14048268,3191096,400885,1526,3124,702,76,1,627,78,128,16,0,2,2016-08-25 15:10:16,771,Java,{'Java': 30371987},Apache License 2.0,"['modules/math/src/main/java/com/opengamma/strata/math/impl/function/ParameterizedSurface.java', 'modules/pricer/src/main/java/com/opengamma/strata/pricer/impl/credit/isda/CdsAnalytic.java', 'modules/pricer/src/main/java/com/opengamma/strata/pricer/option/TenorRawOptionData.java', 'modules/pricer/src/main/java/com/opengamma/strata/pricer/impl/credit/isda/CdsAnalyticFactory.java', 'modules/math/src/main/java/com/opengamma/strata/math/impl/function/ParameterizedCurve.java', 'modules/pricer/src/main/java/com/opengamma/strata/pricer/curve/CalibrationDerivative.java', 'modules/pricer/src/main/java/com/opengamma/strata/pricer/impl/credit/isda/CdsCoupon.java', 'modules/pricer/src/main/java/com/opengamma/strata/pricer/curve/CalibrationMeasures.java', 'modules/pricer/src/main/java/com/opengamma/strata/pricer/option/RawOptionData.java', 'modules/pricer/src/main/java/com/opengamma/strata/pricer/impl/volatility/smile/VolatilityFunctionProvider.java', 'modules/pricer/src/main/java/com/opengamma/strata/pricer/curve/CalibrationMeasure.java', 'modules/pricer/src/main/java/com/opengamma/strata/pricer/impl/credit/isda/AnalyticCdsPricer.java', 'modules/math/src/main/java/com/opengamma/strata/math/impl/function/ParameterizedCurveVectorFunction.java', 'basics/src/main/java/com/opengamma/strata/basics/currency/MultiCurrencyAmountArray.java', 'modules/pricer/src/main/java/com/opengamma/strata/pricer/impl/credit/isda/MultiAnalyticCdsPricer.java', 'modules/math/src/main/java/com/opengamma/strata/math/impl/function/ParameterizedCurveVectorFunctionProvider.java', 'modules/math/src/main/java/com/opengamma/strata/math/impl/function/ParameterizedFunction.java']","['modules/math/src/main/java/com/opengamma/strata/math/impl/function/ParameterizedCurveVectorFunctionProvider.java', 'modules/math/src/main/java/com/opengamma/strata/math/impl/function/ParameterizedCurve.java', 'modules/math/src/main/java/com/opengamma/strata/math/impl/function/ParameterizedFunction.java', 'modules/math/src/main/java/com/opengamma/strata/math/impl/function/ParameterizedCurveVectorFunction.java']","['```json\n{\n  ""files"": [\n    ""basics/src/main/java/com/opengamma/strata/basics/currency/MultiCurrencyAmountArray.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""modules/pricer/src/main/java/com/opengamma/strata/pricer/option/RawOptionData.java"",\n    ""modules/pricer/src/main/java/com/opengamma/strata/pricer/option/TenorRawOptionData.java"",\n    ""modules/pricer/src/main/java/com/opengamma/strata/pricer/curve/CalibrationDerivative.java"",\n    ""modules/pricer/src/main/java/com/opengamma/strata/pricer/curve/CalibrationMeasure.java"",\n    ""modules/pricer/src/main/java/com/opengamma/strata/pricer/curve/CalibrationMeasures.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""modules/math/src/main/java/com/opengamma/strata/math/impl/function/ParameterizedCurve.java"",\n    ""modules/math/src/main/java/com/opengamma/strata/math/impl/function/ParameterizedCurveVectorFunction.java"",\n    ""modules/math/src/main/java/com/opengamma/strata/math/impl/function/ParameterizedCurveVectorFunctionProvider.java"",\n    ""modules/math/src/main/java/com/opengamma/strata/math/impl/function/ParameterizedFunction.java"",\n    ""modules/math/src/main/java/com/opengamma/strata/math/impl/function/ParameterizedSurface.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""modules/pricer/src/main/java/com/opengamma/strata/pricer/impl/credit/isda/MultiAnalyticCdsPricer.java"",\n    ""modules/pricer/src/main/java/com/opengamma/strata/pricer/impl/credit/isda/AnalyticCdsPricer.java"",\n    ""modules/pricer/src/main/java/com/opengamma/strata/pricer/impl/credit/isda/CdsAnalytic.java"",\n    ""modules/pricer/src/main/java/com/opengamma/strata/pricer/impl/credit/isda/CdsAnalyticFactory.java"",\n    ""modules/pricer/src/main/java/com/opengamma/strata/pricer/impl/credit/isda/CdsCoupon.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""modules/pricer/src/main/java/com/opengamma/strata/pricer/impl/volatility/smile/VolatilityFunctionProvider.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""modules/math/src/main/java/com/opengamma/strata/math/impl/function/ParameterizedFunction.java"",\n    ""modules/math/src/main/java/com/opengamma/strata/math/impl/function/ParameterizedCurve.java"",\n    ""modules/math/src/main/java/com/opengamma/strata/math/impl/function/ParameterizedCurveVectorFunction.java"",\n    ""modules/math/src/main/java/com/opengamma/strata/math/impl/function/ParameterizedCurveVectorFunctionProvider.java""\n  ]\n}\n```']",5,10966.835975646973
49,citrusframework/citrus/598/588,citrusframework,citrus,https://github.com/citrusframework/citrus/issues/588,https://github.com/citrusframework/citrus/pull/598,https://github.com/citrusframework/citrus/pull/598,2,fixes,BooleanExpressionParser parses expression groups containing boolean strings inconsistently,"**Citrus Version**
2.7.8

**Expected behavior**
As a user I would expect Citrus to consistently parse valid boolean expression like `(i = 5) and (${conditional} = true)` in e.g. iteration containers.

**Actual behavior**
Expression groups containing strings, like `(${conditional} = true)`, are handled inconsistently by `BooleanExpressionParser`.  Due to its implementation, these groups require additional spaces between expression and parentheses, otherwise parsing will fail.

`com.consol.citrus.exceptions.CitrusRuntimeException: Unknown operator 'false)'`

Source: [stackoverflow](https://stackoverflow.com/questions/53928625/cannot-use-test-on-variable-to-exit-in-citrus-repeat-until-statement)

**Test case sample**
> Please, share the test case (as small as possible) which shows the issue

```
public class ExpressionParserTest extends TestNGCitrusTestRunner {

    /**
     * Test fails b/c '(${conditional} = true)' is not parsed correctly
     * @param runner Citrus TestRunner
     */
    @Test
    @Parameters(""runner"")
    @CitrusTest
    public void failingTest(@Optional @CitrusResource TestRunner runner) {
        runner.createVariable(""conditional"", String.valueOf(true));
        runner.repeat().until(""(i = 5) and (${conditional} = true)"").index(""i"").actions(
                runner.sleep(1000),
                new AbstractTestAction() {
                    @Override
                    public void doExecute(TestContext testContext) {
                        System.out.println(testContext.getVariable(""i""));
                    }
                }
        );
    }

    /**
     * Test succeeds due to spaces in expression
     * @param runner Citrus TestRunner
     */
    @Test
    @Parameters(""runner"")
    @CitrusTest
    public void successfulTest(@Optional @CitrusResource TestRunner runner) {
        runner.createVariable(""conditional"", String.valueOf(true));
        runner.repeat().until(""(j = 5) and ( ${conditional} = true )"").index(""j"").actions(
                runner.sleep(1000),
                new AbstractTestAction() {
                    @Override
                    public void doExecute(TestContext testContext) {
                        System.out.println(testContext.getVariable(""j""));
                    }
                }
        );
    }
}
```",dded6e61012d64a98d70e3a4be95c84eb0c52904,98575325fe8037e995c91b2d9cc8667938a0a67b,https://github.com/citrusframework/citrus/compare/dded6e61012d64a98d70e3a4be95c84eb0c52904...98575325fe8037e995c91b2d9cc8667938a0a67b,"diff --git a/modules/citrus-core/src/main/java/com/consol/citrus/util/BooleanExpressionParser.java b/modules/citrus-core/src/main/java/com/consol/citrus/util/BooleanExpressionParser.java
index 0b89a1796..8ea578945 100644
--- a/modules/citrus-core/src/main/java/com/consol/citrus/util/BooleanExpressionParser.java
+++ b/modules/citrus-core/src/main/java/com/consol/citrus/util/BooleanExpressionParser.java
@@ -1,5 +1,5 @@
 /*
- * Copyright 2006-2010 the original author or authors.
+ * Copyright 2006-2019 the original author or authors.
  *
  * Licensed under the Apache License, Version 2.0 (the ""License"");
  * you may not use this file except in compliance with the License.
@@ -19,164 +19,319 @@ package com.consol.citrus.util;
 import com.consol.citrus.exceptions.CitrusRuntimeException;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
-import org.springframework.util.CollectionUtils;
 
-import java.util.*;
+import java.util.ArrayDeque;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Deque;
+import java.util.List;
+import java.util.NoSuchElementException;
+
+import static java.lang.Boolean.FALSE;
+import static java.lang.Boolean.TRUE;
 
 /**
  * Parses boolean expression strings and evaluates to boolean result.
- * 
- * @author Christoph Deppisch
  */
-@SuppressWarnings(""unchecked"")
 public final class BooleanExpressionParser {
-    
-    /** List of known operators */
-    private static final List<String> OPERATORS = new ArrayList<String>(
-            CollectionUtils.arrayToList(new String[]{""("", ""="", ""and"", ""or"", ""lt"", ""lt="", ""gt"", ""gt="", "")""}));
 
-    /** List of known boolean values */
-    private static final List<String> BOOLEAN_VALUES = new ArrayList<String>(
-            CollectionUtils.arrayToList(new String[]{""true"", ""false""}));
-    
+    /**
+     * List of known non-boolean operators
+     */
+    private static final List<String> OPERATORS = new ArrayList<>(Arrays.asList(""lt"", ""lt="", ""gt"", ""gt=""));
+
+    /**
+     * List of known boolean operators
+     */
+    private static final List<String> BOOLEAN_OPERATORS = new ArrayList<>(Arrays.asList(""="", ""and"", ""or""));
+
+    /**
+     * List of known boolean values
+     */
+    private static final List<String> BOOLEAN_VALUES = new ArrayList<>(
+            Arrays.asList(TRUE.toString(), FALSE.toString()));
+
+    /**
+     * SeparatorToken is an explicit type to identify different kinds of separators.
+     */
+    private enum SeparatorToken {
+        SPACE(' '),
+        OPEN_PARENTHESIS('('),
+        CLOSE_PARENTHESIS(')');
+
+        private final Character value;
+
+        SeparatorToken(final Character value) {
+            this.value = value;
+        }
+
+        @Override
+        public String toString(){
+            return value.toString();
+        }
+    }
+
     /**
      * Logger
      */
-    private static Logger log = LoggerFactory.getLogger(BooleanExpressionParser.class);
+    private static final Logger log = LoggerFactory.getLogger(BooleanExpressionParser.class);
 
     /**
      * Prevent instantiation.
      */
     private BooleanExpressionParser() {
     }
-    
+
     /**
      * Perform evaluation of boolean expression string.
-     * @param expression
-     * @throws CitrusRuntimeException
-     * @return
+     *
+     * @param expression The expression to evaluate
+     * @return boolean result
+     * @throws CitrusRuntimeException When unable to parse expression
      */
-    public static boolean evaluate(String expression) {
-        Stack<String> operators = new Stack<String>();
-        Stack<String> values = new Stack<String>();
-        boolean result = true;
+    public static boolean evaluate(final String expression) {
+        final Deque<String> operators = new ArrayDeque<>();
+        final Deque<String> values = new ArrayDeque<>();
+        final boolean result;
 
-        char actChar;
+        char currentCharacter;
+        int currentCharacterIndex = 0;
 
         try {
-            for (int i = 0; i < expression.length(); i++) {
-                actChar = expression.charAt(i);
-    
-                if (actChar == '(') {
-                    operators.push(""("");
-                } else if (actChar == ' ') {
-                    continue; //ignore
-                } else if (actChar == ')') {
-                    String operator = operators.pop();
-                    while (!(operator).equals(""("")) {
-                        values.push(getBooleanResultAsString(operator, values.pop(), values.pop()));
-                        operator = operators.pop();
-                    }
-                } else if (!Character.isDigit(actChar)) {
-                    StringBuffer operatorBuffer = new StringBuffer();
-    
-                    int m = i;
-                    do {
-                        operatorBuffer.append(actChar);
-                        m++;
-                        
-                        if (m < expression.length()) {
-                            actChar = expression.charAt(m);
-                        }
-                    } while (m < expression.length() && !Character.isDigit(actChar) && !(actChar == ' ') && !(actChar == '('));
-    
-                    i = m - 1;
-
-                    if (BOOLEAN_VALUES.contains(operatorBuffer.toString())) {
-                        values.push(Boolean.valueOf(operatorBuffer.toString()) ? ""1"" : ""0"");
+            while (currentCharacterIndex < expression.length()) {
+                currentCharacter = expression.charAt(currentCharacterIndex);
+
+                if (SeparatorToken.OPEN_PARENTHESIS.value == currentCharacter) {
+                    operators.push(SeparatorToken.OPEN_PARENTHESIS.toString());
+                    currentCharacterIndex += moveCursor(SeparatorToken.OPEN_PARENTHESIS.toString());
+                } else if (SeparatorToken.SPACE.value == currentCharacter) {
+                    currentCharacterIndex += moveCursor(SeparatorToken.SPACE.toString());
+                } else if (SeparatorToken.CLOSE_PARENTHESIS.value == currentCharacter) {
+                    evaluateSubexpression(operators, values);
+                    currentCharacterIndex += moveCursor(SeparatorToken.CLOSE_PARENTHESIS.toString());
+                } else if (!Character.isDigit(currentCharacter)) {
+                    final String parsedNonDigit = parseNonDigits(expression, currentCharacterIndex);
+                    if (isBoolean(parsedNonDigit)) {
+                        values.push(replaceBooleanStringByIntegerRepresentation(parsedNonDigit));
                     } else {
-                        operators.push(validateOperator(operatorBuffer.toString()));
+                        operators.push(validateOperator(parsedNonDigit));
                     }
-                } else if (Character.isDigit(actChar)) {
-                    StringBuffer digitBuffer = new StringBuffer();
-    
-                    int m = i;
-                    do {
-                        digitBuffer.append(actChar);
-                        m++;
-                        
-                        if (m < expression.length()) {
-                            actChar = expression.charAt(m);
-                        }
-                    } while (m < expression.length() && Character.isDigit(actChar));
-    
-                    i = m - 1;
-    
-                    values.push(digitBuffer.toString());
+                    currentCharacterIndex += moveCursor(parsedNonDigit);
+                } else if (Character.isDigit(currentCharacter)) {
+                    final String parsedDigits = parseDigits(expression, currentCharacterIndex);
+                    values.push(parsedDigits);
+                    currentCharacterIndex += moveCursor(parsedDigits);
                 }
             }
-    
-            while (!operators.isEmpty()) {
-                values.push(getBooleanResultAsString(operators.pop(), values.pop(), values.pop()));
-            }
-    
-            String value = values.pop();
 
-            if (value.equals(""0"")) {
-                value = ""false"";
-            } else if (value.equals(""1"")) {
-                value = ""true"";
-            }
+            result = Boolean.valueOf(evaluateExpressionStack(operators, values));
 
-            result = Boolean.valueOf(value).booleanValue();
-    
             if (log.isDebugEnabled()) {
-                log.debug(""Boolean expression "" + expression + "" evaluates to "" + result);
+                log.debug(""Boolean expression {} evaluates to {}"", expression, result);
             }
-        } catch(EmptyStackException e) {
+        } catch (final NoSuchElementException e) {
             throw new CitrusRuntimeException(""Unable to parse boolean expression '"" + expression + ""'. Maybe expression is incomplete!"", e);
         }
 
         return result;
     }
-    
+
+    /**
+     * This method takes stacks of operators and values and evaluates possible expressions
+     * This is done by popping one operator and two values, applying the operator to the values and pushing the result back onto the value stack
+     *
+     * @param operators Operators to apply
+     * @param values    Values
+     * @return The final result popped of the values stack
+     */
+    private static String evaluateExpressionStack(final Deque<String> operators, final Deque<String> values) {
+        while (!operators.isEmpty()) {
+            values.push(getBooleanResultAsString(operators.pop(), values.pop(), values.pop()));
+        }
+        return replaceIntegerStringByBooleanRepresentation(values.pop());
+    }
+
+    /**
+     * Evaluates a sub expression within a pair of parentheses and pushes its result onto the stack of values
+     *
+     * @param operators Stack of operators
+     * @param values    Stack of values
+     */
+    private static void evaluateSubexpression(final Deque<String> operators, final Deque<String> values) {
+        String operator = operators.pop();
+        while (!(operator).equals(SeparatorToken.OPEN_PARENTHESIS.toString())) {
+            values.push(getBooleanResultAsString(operator,
+                    values.pop(),
+                    values.pop()));
+            operator = operators.pop();
+        }
+    }
+
+    /**
+     * This method reads digit characters from a given string, starting at a given index.
+     * It will read till the end of the string or up until it encounters a non-digit character
+     *
+     * @param expression The string to parse
+     * @param startIndex The start index from where to parse
+     * @return The parsed substring
+     */
+    private static String parseDigits(final String expression, final int startIndex) {
+        final StringBuilder digitBuffer = new StringBuilder();
+
+        char currentCharacter = expression.charAt(startIndex);
+        int subExpressionIndex = startIndex;
+
+        do {
+            digitBuffer.append(currentCharacter);
+            ++subExpressionIndex;
+
+            if (subExpressionIndex < expression.length()) {
+                currentCharacter = expression.charAt(subExpressionIndex);
+            }
+        } while (subExpressionIndex < expression.length() && Character.isDigit(currentCharacter));
+
+        return digitBuffer.toString();
+    }
+
+    /**
+     * This method reads non-digit characters from a given string, starting at a given index.
+     * It will read till the end of the string or up until it encounters
+     * <p>
+     * - a digit
+     * - a separator token
+     *
+     * @param expression The string to parse
+     * @param startIndex The start index from where to parse
+     * @return The parsed substring
+     */
+    private static String parseNonDigits(final String expression, final int startIndex) {
+        final StringBuilder operatorBuffer = new StringBuilder();
+
+        char currentCharacter = expression.charAt(startIndex);
+        int subExpressionIndex = startIndex;
+        do {
+            operatorBuffer.append(currentCharacter);
+            subExpressionIndex++;
+
+            if (subExpressionIndex < expression.length()) {
+                currentCharacter = expression.charAt(subExpressionIndex);
+            }
+        } while (subExpressionIndex < expression.length() && !Character.isDigit(currentCharacter) && !isSeparatorToken(currentCharacter));
+
+        return operatorBuffer.toString();
+    }
+
+    /**
+     * Checks whether a string can be interpreted as a boolean value.
+     *
+     * @param possibleBoolean The possible boolean value as string
+     * @return Either true or false
+     */
+    private static Boolean isBoolean(final String possibleBoolean) {
+        return BOOLEAN_VALUES.contains(possibleBoolean);
+    }
+
+    /**
+     * Checks whether a String is a Boolean value and replaces it with its Integer representation
+     * ""true"" -> ""1""
+     * ""false"" -> ""0""
+     *
+     * @param possibleBooleanString ""true"" or ""false""
+     * @return ""1"" or ""0""
+     */
+    private static String replaceBooleanStringByIntegerRepresentation(final String possibleBooleanString) {
+        if (possibleBooleanString.equals(TRUE.toString())) {
+            return ""1"";
+        } else if (possibleBooleanString.equals(FALSE.toString())) {
+            return ""0"";
+        }
+        return possibleBooleanString;
+    }
+
+    /**
+     * Counterpart of {@link #replaceBooleanStringByIntegerRepresentation}
+     * Checks whether a String is the Integer representation of a Boolean value and replaces it with its Boolean representation
+     * ""1"" -> ""true""
+     * ""0"" -> ""false""
+     * otherwise -> value
+     *
+     * @param value ""1"", ""0"" or other string
+     * @return ""true"", ""false"" or the input value
+     */
+    private static String replaceIntegerStringByBooleanRepresentation(final String value) {
+        if (value.equals(""0"")) {
+            return FALSE.toString();
+        } else if (value.equals(""1"")) {
+            return TRUE.toString();
+        }
+        return value;
+    }
+
+    /**
+     * Checks whether a given character is a known separator token or no
+     *
+     * @param possibleSeparatorChar The character to check
+     * @return True in case its a separator, false otherwise
+     */
+    private static boolean isSeparatorToken(final char possibleSeparatorChar) {
+        for (final SeparatorToken token : SeparatorToken.values()) {
+            if (token.value == possibleSeparatorChar) {
+                return true;
+            }
+        }
+        return false;
+    }
+
     /**
      * Check if operator is known to this class.
+     *
      * @param operator to validate
      * @return the operator itself.
-     * @throws CitrusRuntimeException
+     * @throws CitrusRuntimeException When encountering an unknown operator
      */
-    private static String validateOperator(String operator) {
-        if (!OPERATORS.contains(operator)) {
+    private static String validateOperator(final String operator) {
+        if (!OPERATORS.contains(operator) && !BOOLEAN_OPERATORS.contains(operator)) {
             throw new CitrusRuntimeException(""Unknown operator '"" + operator + ""'"");
         }
         return operator;
     }
 
+    /**
+     * Returns the amount of characters to move the cursor after parsing a token
+     *
+     * @param lastToken Last parsed token
+     * @return Amount of characters to move forward
+     */
+    private static int moveCursor(final String lastToken) {
+        return lastToken.length();
+    }
+
     /**
      * Evaluates a boolean expression to a String representation (true/false).
-     * @param operator
-     * @param value1
-     * @param value2
+     *
+     * @param operator     The operator to apply on operands
+     * @param rightOperand The right hand side of the expression
+     * @param leftOperand  The left hand side of the expression
      * @return true/false as String
      */
-    private static String getBooleanResultAsString(String operator, String value1, String value2) {
-        if (operator.equals(""lt"")) {
-            return Boolean.valueOf(Integer.valueOf(value2).intValue() < Integer.valueOf(value1).intValue()).toString();
-        } else if (operator.equals(""lt="")) {
-            return Boolean.valueOf(Integer.valueOf(value2).intValue() <= Integer.valueOf(value1).intValue()).toString();
-        } else if (operator.equals(""gt"")) {
-            return Boolean.valueOf(Integer.valueOf(value2).intValue() > Integer.valueOf(value1).intValue()).toString();
-        } else if (operator.equals(""gt="")) {
-            return Boolean.valueOf(Integer.valueOf(value2).intValue() >= Integer.valueOf(value1).intValue()).toString();
-        } else if (operator.equals(""="")) {
-            return Boolean.valueOf(Integer.valueOf(value2).intValue() == Integer.valueOf(value1).intValue()).toString();
-        } else if (operator.equals(""and"")) {
-            return Boolean.valueOf(Boolean.valueOf(value2).booleanValue() && Boolean.valueOf(value1).booleanValue()).toString();
-        } else if (operator.equals(""or"")) {
-            return Boolean.valueOf(Boolean.valueOf(value2).booleanValue() || Boolean.valueOf(value1).booleanValue()).toString();
-        } else {
-            throw new CitrusRuntimeException(""Unknown operator '"" + operator + ""'"");
+    private static String getBooleanResultAsString(final String operator, final String rightOperand, final String leftOperand) {
+        switch (operator) {
+            case ""lt"":
+                return Boolean.toString(Integer.valueOf(leftOperand) < Integer.valueOf(rightOperand));
+            case ""lt="":
+                return Boolean.toString(Integer.valueOf(leftOperand) <= Integer.valueOf(rightOperand));
+            case ""gt"":
+                return Boolean.toString(Integer.valueOf(leftOperand) > Integer.valueOf(rightOperand));
+            case ""gt="":
+                return Boolean.toString(Integer.valueOf(leftOperand) >= Integer.valueOf(rightOperand));
+            case ""="":
+                return Boolean.toString(Integer.parseInt(leftOperand) == Integer.parseInt(rightOperand));
+            case ""and"":
+                return Boolean.toString(Boolean.valueOf(leftOperand) && Boolean.valueOf(rightOperand));
+            case ""or"":
+                return Boolean.toString(Boolean.valueOf(leftOperand) || Boolean.valueOf(rightOperand));
+            default:
+                throw new CitrusRuntimeException(""Unknown operator '"" + operator + ""'"");
         }
     }
 }
diff --git a/modules/citrus-core/src/test/java/com/consol/citrus/util/BooleanExpressionParserTest.java b/modules/citrus-core/src/test/java/com/consol/citrus/util/BooleanExpressionParserTest.java
index 40aff4ac5..28d319b31 100644
--- a/modules/citrus-core/src/test/java/com/consol/citrus/util/BooleanExpressionParserTest.java
+++ b/modules/citrus-core/src/test/java/com/consol/citrus/util/BooleanExpressionParserTest.java
@@ -1,5 +1,5 @@
 /*
- * Copyright 2006-2010 the original author or authors.
+ * Copyright 2006-2019 the original author or authors.
  *
  * Licensed under the Apache License, Version 2.0 (the ""License"");
  * you may not use this file except in compliance with the License.
@@ -48,6 +48,10 @@ public class BooleanExpressionParserTest {
         Assert.assertFalse(BooleanExpressionParser.evaluate(""(1 lt 1) and (2 gt 2)""));
         Assert.assertFalse(BooleanExpressionParser.evaluate(""(1 gt 2) or (2 = 3)""));
         Assert.assertFalse(BooleanExpressionParser.evaluate(""((1 = 5) and (2 = 6)) or (2 lt 1)""));
+    }
+
+    @Test
+    public void testExpressionParserWithStringValues() {
         Assert.assertTrue(BooleanExpressionParser.evaluate(""true""));
         Assert.assertTrue(BooleanExpressionParser.evaluate(""true = true""));
         Assert.assertTrue(BooleanExpressionParser.evaluate(""false = false""));
@@ -56,13 +60,21 @@ public class BooleanExpressionParserTest {
         Assert.assertFalse(BooleanExpressionParser.evaluate(""false = true""));
         Assert.assertTrue(BooleanExpressionParser.evaluate(""( false = false ) and ( true = true )""));
         Assert.assertFalse(BooleanExpressionParser.evaluate(""( false = false ) and ( true = false )""));
+        Assert.assertTrue(BooleanExpressionParser.evaluate(""(false = false) and (true = true)""));
+        Assert.assertFalse(BooleanExpressionParser.evaluate(""(false = false) and (true = false)""));
+        Assert.assertTrue(BooleanExpressionParser.evaluate(""(   false = false) and (true = true    )""));
+        Assert.assertFalse(BooleanExpressionParser.evaluate(""(false = false    ) and     (    true = false)""));
+        Assert.assertTrue(BooleanExpressionParser.evaluate(""( true = false ) or ( false = false )""));
+        Assert.assertTrue(BooleanExpressionParser.evaluate(""(false = false) or (true = true)""));
+        Assert.assertTrue(BooleanExpressionParser.evaluate(""(false = false) or (true = false)""));
+        Assert.assertTrue(BooleanExpressionParser.evaluate(""(false = false    ) or (    true = false)""));
     }
     
     @Test
     public void testExpressionParserWithUnknownOperator() {
         try {
             BooleanExpressionParser.evaluate(""wahr"");
-        } catch(CitrusRuntimeException e) {
+        } catch(final CitrusRuntimeException e) {
             Assert.assertEquals(e.getLocalizedMessage(), ""Unknown operator 'wahr'"");
             return;
         }
@@ -74,7 +86,7 @@ public class BooleanExpressionParserTest {
     public void testExpressionParserWithBrokenExpression() {
         try {
             BooleanExpressionParser.evaluate(""1 = "");
-        } catch(CitrusRuntimeException e) {
+        } catch(final CitrusRuntimeException e) {
             Assert.assertEquals(e.getLocalizedMessage(), ""Unable to parse boolean expression '1 = '. Maybe expression is incomplete!"");
             return;
         }","['modules/citrus-core/src/test/java/com/consol/citrus/util/BooleanExpressionParserTest.java', 'modules/citrus-core/src/main/java/com/consol/citrus/util/BooleanExpressionParser.java']",{'.java': 2},2,2,0,0,2,5473150,1096313,161581,1557,16633,3069,375,1,2359,197,480,60,1,1,2019-01-18 18:09:59,399,Java,"{'Java': 12001798, 'Groovy': 120014, 'XSLT': 39429, 'Shell': 34409, 'HTML': 12074, 'Makefile': 1941, 'Gherkin': 798, 'Dockerfile': 107}",Apache License 2.0,"['modules/citrus-core/src/main/java/com/consol/citrus/validation/matcher/core/EqualsIgnoreCaseValidationMatcher.java', 'modules/citrus-java-dsl/src/main/java/com/consol/citrus/dsl/design/ExecutableTestDesigner.java', 'modules/citrus-java-dsl/src/main/java/com/consol/citrus/dsl/design/ExecutableTestDesignerComponent.java', 'modules/citrus-core/src/main/java/com/consol/citrus/validation/matcher/core/MatchesValidationMatcher.java', 'modules/citrus-java-dsl/src/main/java/com/consol/citrus/dsl/design/TestDesignerComponent.java', 'modules/citrus-core/src/main/java/com/consol/citrus/validation/matcher/core/ContainsValidationMatcher.java', 'modules/citrus-java-dsl/src/main/java/com/consol/citrus/dsl/design/TestDesigner.java', 'modules/citrus-core/src/main/java/com/consol/citrus/validation/matcher/ControlExpressionParser.java', 'modules/citrus-java-dsl/src/main/java/com/consol/citrus/dsl/design/TestDesignerSimulation.java', 'modules/citrus-core/src/main/java/com/consol/citrus/util/BooleanExpressionParser.java', 'tools/maven/citrus-maven-plugin/src/main/java/com/consol/citrus/mvn/plugin/config/docs/HtmlDocConfiguration.java', 'modules/citrus-core/src/main/java/com/consol/citrus/validation/matcher/core/StartsWithValidationMatcher.java', 'modules/citrus-core/src/main/java/com/consol/citrus/validation/matcher/core/EndsWithValidationMatcher.java']",['modules/citrus-core/src/main/java/com/consol/citrus/util/BooleanExpressionParser.java'],"['```json\n{\n  ""files"": [\n    ""modules/citrus-core/src/main/java/com/consol/citrus/util/BooleanExpressionParser.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""modules/citrus-core/src/main/java/com/consol/citrus/validation/matcher/ControlExpressionParser.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""modules/citrus-java-dsl/src/main/java/com/consol/citrus/dsl/design/ExecutableTestDesigner.java"",\n    ""modules/citrus-java-dsl/src/main/java/com/consol/citrus/dsl/design/ExecutableTestDesignerComponent.java"",\n    ""modules/citrus-java-dsl/src/main/java/com/consol/citrus/dsl/design/TestDesigner.java"",\n    ""modules/citrus-java-dsl/src/main/java/com/consol/citrus/dsl/design/TestDesignerComponent.java"",\n    ""modules/citrus-java-dsl/src/main/java/com/consol/citrus/dsl/design/TestDesignerSimulation.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""modules/citrus-core/src/main/java/com/consol/citrus/validation/matcher/core/ContainsValidationMatcher.java"",\n    ""modules/citrus-core/src/main/java/com/consol/citrus/validation/matcher/core/MatchesValidationMatcher.java"",\n    ""modules/citrus-core/src/main/java/com/consol/citrus/validation/matcher/core/StartsWithValidationMatcher.java"",\n    ""modules/citrus-core/src/main/java/com/consol/citrus/validation/matcher/core/EndsWithValidationMatcher.java"",\n    ""modules/citrus-core/src/main/java/com/consol/citrus/validation/matcher/core/EqualsIgnoreCaseValidationMatcher.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""tools/maven/citrus-maven-plugin/src/main/java/com/consol/citrus/mvn/plugin/config/docs/HtmlDocConfiguration.java""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""modules/citrus-core/src/main/java/com/consol/citrus/util/BooleanExpressionParser.java""\n  ]\n}\n```']",5,9827.091693878174
785,airbnb/lottie-android/2078/2077,airbnb,lottie-android,https://github.com/airbnb/lottie-android/issues/2077,https://github.com/airbnb/lottie-android/pull/2078,https://github.com/airbnb/lottie-android/pull/2078,1,fixes,Compose: LottieAnimation recomposes on every frame degrading performance,"Issue Repro Compose Fork : [https://github.com/MSDarwish2000/lottie-android-performance](Fork)

**Describe the bug**
`LottieAnimation` recomposes itself on every frame. This is completely unnecessary in most cases as the only actual change happens during the draw phase, not composition or layout phases. This happens as a result of passing `progress` to `LottieAnimation`. Even when using the function without progress, this happens internally reducing the scope of recomposition but not preventing it.

**Steps To Reproduce**
Steps to reproduce the behavior:

1. This can be reproduced with any Lottie Compose sample using Layout Inspector in Android Studio Dolphin
2. This can be benchmarked using the code in the issue above or any similar code

**Sample benchmark result**

- _While running minified release variant_
 Drawing time: 1174.3ms - Recomposition time: 979.4ms - percentage: 45.48%
- _While running debug variant_
 Drawing time: 1369.3ms - Recomposition time: 1219ms - percentage: 47.1%
- _While debugging_
 Drawing time: 2398.3ms - Recomposition time: 1837.2ms - percentage: 43.38%

_Note:_ The percentage of recomposition time may increase if the parent composable had more code which is very likely ",7dfb1f404b221a054f341a4a5fecaf575ac49ff6,b128105164949691a97e9f8717be1f7f6d10a118,https://github.com/airbnb/lottie-android/compare/7dfb1f404b221a054f341a4a5fecaf575ac49ff6...b128105164949691a97e9f8717be1f7f6d10a118,"diff --git a/issue-repro-compose/src/main/java/com/airbnb/lottie/issues/compose/ComposeIssueReproActivity.kt b/issue-repro-compose/src/main/java/com/airbnb/lottie/issues/compose/ComposeIssueReproActivity.kt
index 81acbedf..aeecf2fb 100755
--- a/issue-repro-compose/src/main/java/com/airbnb/lottie/issues/compose/ComposeIssueReproActivity.kt
+++ b/issue-repro-compose/src/main/java/com/airbnb/lottie/issues/compose/ComposeIssueReproActivity.kt
@@ -22,6 +22,6 @@ class ComposeIssueReproActivity : AppCompatActivity() {
     fun Content() {
         val composition by rememberLottieComposition(LottieCompositionSpec.RawRes(R.raw.heart))
         val progress by animateLottieCompositionAsState(composition)
-        LottieAnimation(composition, progress)
+        LottieAnimation(composition, { progress })
     }
 }
diff --git a/lottie-compose/src/main/java/com/airbnb/lottie/compose/LottieAnimation.kt b/lottie-compose/src/main/java/com/airbnb/lottie/compose/LottieAnimation.kt
index f22be003..fefea855 100644
--- a/lottie-compose/src/main/java/com/airbnb/lottie/compose/LottieAnimation.kt
+++ b/lottie-compose/src/main/java/com/airbnb/lottie/compose/LottieAnimation.kt
@@ -32,12 +32,12 @@ import kotlin.math.roundToInt
  *
  * @param composition The composition that will be rendered. To generate a [LottieComposition], you can use
  *                    [rememberLottieComposition].
- * @param progress The progress (between 0 and 1) that should be rendered. If you want to render a specific
- *                 frame, you can use [LottieComposition.getFrameForProgress]. In most cases, you will want
- *                 to use one of the overloaded LottieAnimation composables that drives the animation for you.
- *                 The overloads that have isPlaying as a parameter instead of progress will drive the
- *                 animation automatically. You may want to use this version if you want to drive the animation
- *                 from your own Animatable or via events such as download progress or a gesture.
+ * @param progressProvider A provider for the progress (between 0 and 1) that should be rendered. If you want to render a
+ *                         specific frame, you can use [LottieComposition.getFrameForProgress]. In most cases, you will want
+ *                         to use one of the overloaded LottieAnimation composables that drives the animation for you.
+ *                         The overloads that have isPlaying as a parameter instead of progress will drive the
+ *                         animation automatically. You may want to use this version if you want to drive the animation
+ *                         from your own Animatable or via events such as download progress or a gesture.
  * @param outlineMasksAndMattes Enable this to debug slow animations by outlining masks and mattes.
  *                              The performance overhead of the masks and mattes will be proportional to the
  *                              surface area of all of the masks/mattes combined.
@@ -69,7 +69,7 @@ import kotlin.math.roundToInt
 @Composable
 fun LottieAnimation(
     composition: LottieComposition?,
-    @FloatRange(from = 0.0, to = 1.0) progress: Float,
+    @FloatRange(from = 0.0, to = 1.0) progressProvider: () -> Float,
     modifier: Modifier = Modifier,
     outlineMasksAndMattes: Boolean = false,
     applyOpacityToLayers: Boolean = false,
@@ -114,16 +114,52 @@ fun LottieAnimation(
             drawable.isApplyingOpacityToLayersEnabled = applyOpacityToLayers
             drawable.maintainOriginalImageBounds = maintainOriginalImageBounds
             drawable.clipToCompositionBounds = clipToCompositionBounds
-            drawable.progress = progress
+            drawable.progress = progressProvider()
             drawable.setBounds(0, 0, composition.bounds.width(), composition.bounds.height())
             drawable.draw(canvas.nativeCanvas, matrix)
         }
     }
 }
 
+/**
+ * This is like [LottieAnimation] except that it takes a raw progress parameter instead of taking a progress provider.
+ *
+ * @see LottieAnimation
+ */
+@Composable
+fun LottieAnimation(
+    composition: LottieComposition?,
+    @FloatRange(from = 0.0, to = 1.0) progress: Float,
+    modifier: Modifier = Modifier,
+    outlineMasksAndMattes: Boolean = false,
+    applyOpacityToLayers: Boolean = false,
+    enableMergePaths: Boolean = false,
+    renderMode: RenderMode = RenderMode.AUTOMATIC,
+    maintainOriginalImageBounds: Boolean = false,
+    dynamicProperties: LottieDynamicProperties? = null,
+    alignment: Alignment = Alignment.Center,
+    contentScale: ContentScale = ContentScale.Fit,
+    clipToCompositionBounds: Boolean = true,
+) {
+    LottieAnimation(
+        composition,
+        { progress },
+        modifier,
+        outlineMasksAndMattes,
+        applyOpacityToLayers,
+        enableMergePaths,
+        renderMode,
+        maintainOriginalImageBounds,
+        dynamicProperties,
+        alignment,
+        contentScale,
+        clipToCompositionBounds,
+    )
+}
+
 /**
  * This is like [LottieAnimation] except that it handles driving the animation via [animateLottieCompositionAsState]
- * instead of taking a raw progress parameter.
+ * instead of taking a progress provider.
  *
  * @see LottieAnimation
  * @see animateLottieCompositionAsState
@@ -157,7 +193,7 @@ fun LottieAnimation(
     )
     LottieAnimation(
         composition,
-        progress,
+        { progress },
         modifier,
         outlineMasksAndMattes,
         applyOpacityToLayers,
diff --git a/sample-compose/src/main/java/com/airbnb/lottie/sample/compose/examples/AnimatableExamplesPage.kt b/sample-compose/src/main/java/com/airbnb/lottie/sample/compose/examples/AnimatableExamplesPage.kt
index 562b837a..f52b15dd 100644
--- a/sample-compose/src/main/java/com/airbnb/lottie/sample/compose/examples/AnimatableExamplesPage.kt
+++ b/sample-compose/src/main/java/com/airbnb/lottie/sample/compose/examples/AnimatableExamplesPage.kt
@@ -64,7 +64,7 @@ private fun Example1() {
             iterations = LottieConstants.IterateForever,
         )
     }
-    LottieAnimation(anim.composition, anim.progress)
+    LottieAnimation(anim.composition, { anim.progress })
 }
 
 @Composable
@@ -84,7 +84,7 @@ private fun Example2() {
         }
     }
     Box {
-        LottieAnimation(anim.composition, anim.progress)
+        LottieAnimation(anim.composition, { anim.progress })
         Slider(
             value = sliderGestureProgress ?: anim.progress,
             onValueChange = { sliderGestureProgress = it },
@@ -110,7 +110,7 @@ private fun Example3() {
         )
     }
     Box {
-        LottieAnimation(composition, anim.progress)
+        LottieAnimation(composition, { anim.progress })
         Slider(
             value = speed,
             onValueChange = { speed = it },
@@ -144,7 +144,7 @@ private fun Example4() {
     }
     LottieAnimation(
         composition,
-        animatable.progress,
+        { animatable.progress },
         modifier = Modifier
             .clickable { nonce++ }
     )
@@ -162,7 +162,7 @@ private fun Example5() {
     }
     LottieAnimation(
         composition,
-        animatable.progress,
+        { animatable.progress },
         modifier = Modifier
             .clickable { shouldPlay = !shouldPlay }
     )
diff --git a/sample-compose/src/main/java/com/airbnb/lottie/sample/compose/examples/BasicUsageExamplesPage.kt b/sample-compose/src/main/java/com/airbnb/lottie/sample/compose/examples/BasicUsageExamplesPage.kt
index d592c18f..f82e2ba9 100644
--- a/sample-compose/src/main/java/com/airbnb/lottie/sample/compose/examples/BasicUsageExamplesPage.kt
+++ b/sample-compose/src/main/java/com/airbnb/lottie/sample/compose/examples/BasicUsageExamplesPage.kt
@@ -140,7 +140,7 @@ private fun Example6() {
     )
     LottieAnimation(
         composition,
-        progress,
+        { progress },
     )
 }
 
diff --git a/sample-compose/src/main/java/com/airbnb/lottie/sample/compose/examples/TransitionsExamplesPage.kt b/sample-compose/src/main/java/com/airbnb/lottie/sample/compose/examples/TransitionsExamplesPage.kt
index e6eec4e3..0dbcd85d 100644
--- a/sample-compose/src/main/java/com/airbnb/lottie/sample/compose/examples/TransitionsExamplesPage.kt
+++ b/sample-compose/src/main/java/com/airbnb/lottie/sample/compose/examples/TransitionsExamplesPage.kt
@@ -90,7 +90,7 @@ fun SingleCompositionTransition(section: TransitionSection) {
             } while (s == TransitionSection.LoopMiddle)
         }
     }
-    LottieAnimation(composition, animatable.progress)
+    LottieAnimation(composition, { animatable.progress })
 }
 
 @Composable
@@ -113,5 +113,5 @@ fun SplitCompositionTransition(section: TransitionSection) {
         )
     }
 
-    LottieAnimation(animatable.composition, animatable.progress)
+    LottieAnimation(animatable.composition, { animatable.progress })
 }
\\ No newline at end of file
diff --git a/sample-compose/src/main/java/com/airbnb/lottie/sample/compose/examples/ViewPagerExample.kt b/sample-compose/src/main/java/com/airbnb/lottie/sample/compose/examples/ViewPagerExample.kt
index 26a51469..79945bef 100644
--- a/sample-compose/src/main/java/com/airbnb/lottie/sample/compose/examples/ViewPagerExample.kt
+++ b/sample-compose/src/main/java/com/airbnb/lottie/sample/compose/examples/ViewPagerExample.kt
@@ -60,7 +60,7 @@ private fun WalkthroughAnimation(pagerState: PagerState) {
     val progress by derivedStateOf { (pagerState.currentPage + pagerState.currentPageOffset) / (pagerState.pageCount - 1f) }
     LottieAnimation(
         composition,
-        progress,
+        { progress },
         modifier = Modifier
             .fillMaxSize()
     )
diff --git a/sample-compose/src/main/java/com/airbnb/lottie/sample/compose/player/PlayerPage.kt b/sample-compose/src/main/java/com/airbnb/lottie/sample/compose/player/PlayerPage.kt
index e050069d..3a640f27 100644
--- a/sample-compose/src/main/java/com/airbnb/lottie/sample/compose/player/PlayerPage.kt
+++ b/sample-compose/src/main/java/com/airbnb/lottie/sample/compose/player/PlayerPage.kt
@@ -255,7 +255,7 @@ fun PlayerPageContent(
         ) {
             PlayerPageLottieAnimation(
                 composition,
-                state.animatable.progress,
+                { state.animatable.progress },
                 modifier = Modifier
                     // TODO: figure out how maxWidth can play nice with the aspectRatio modifier inside of LottieAnimation.
                     .fillMaxWidth()
@@ -291,12 +291,12 @@ fun PlayerPageContent(
 @Composable
 private fun PlayerPageLottieAnimation(
     composition: LottieComposition?,
-    progress: Float,
+    progressProvider: () -> Float,
     modifier: Modifier = Modifier,
 ) {
     LottieAnimation(
         composition,
-        progress,
+        progressProvider,
         modifier = modifier,
     )
 }","['sample-compose/src/main/java/com/airbnb/lottie/sample/compose/examples/TransitionsExamplesPage.kt', 'sample-compose/src/main/java/com/airbnb/lottie/sample/compose/examples/AnimatableExamplesPage.kt', 'issue-repro-compose/src/main/java/com/airbnb/lottie/issues/compose/ComposeIssueReproActivity.kt', 'sample-compose/src/main/java/com/airbnb/lottie/sample/compose/examples/ViewPagerExample.kt', 'sample-compose/src/main/java/com/airbnb/lottie/sample/compose/player/PlayerPage.kt', 'lottie-compose/src/main/java/com/airbnb/lottie/compose/LottieAnimation.kt', 'sample-compose/src/main/java/com/airbnb/lottie/sample/compose/examples/BasicUsageExamplesPage.kt']",{'.kt': 7},7,0,7,0,7,298070,59976,8162,114,3915,797,82,7,1237,173,293,21,1,0,2022-05-19 17:45:55,34121,Java,"{'Java': 806601, 'Kotlin': 346277, 'Shell': 2268, 'JavaScript': 1036}",Apache License 2.0,"['lottie-compose/src/main/java/com/airbnb/lottie/compose/LottieAnimatable.kt', 'sample-compose/src/main/java/com/airbnb/lottie/sample/compose/player/PlayerPage.kt', 'lottie-compose/src/main/java/com/airbnb/lottie/compose/LottieAnimation.kt']","['lottie-compose/src/main/java/com/airbnb/lottie/compose/LottieAnimatable.kt', 'sample-compose/src/main/java/com/airbnb/lottie/sample/compose/player/PlayerPage.kt', 'lottie-compose/src/main/java/com/airbnb/lottie/compose/LottieAnimation.kt']","['```json\n{\n  ""files"": [\n    ""lottie-compose/src/main/java/com/airbnb/lottie/compose/LottieAnimation.kt"",\n    ""lottie-compose/src/main/java/com/airbnb/lottie/compose/LottieAnimatable.kt"",\n    ""sample-compose/src/main/java/com/airbnb/lottie/sample/compose/player/PlayerPage.kt""\n  ]\n}\n```']",1,1320.986270904541
1632,square/leakcanary/2144/2137,square,leakcanary,https://github.com/square/leakcanary/issues/2137,https://github.com/square/leakcanary/pull/2144,https://github.com/square/leakcanary/pull/2144,2,fixes,RootViewWatcher onRootViewAdd crashed,"### Description

```
android.content.res.Resources$NotFoundException: Resource ID #0x7f050008 type #0x5 is not valid
        at android.content.res.Resources.getBoolean(Resources.java:1088)
        at leakcanary.RootViewWatcher$listener$1.onRootViewAdded(RootViewWatcher.kt:49)
        at curtains.OnRootViewAddedListener$DefaultImpls.onRootViewsChanged(Listeners.kt:37)
        at leakcanary.RootViewWatcher$listener$1.onRootViewsChanged(RootViewWatcher.kt:43)
        at curtains.internal.RootViewsSpy$delegatingViewList$1.add(RootViewsSpy.kt:25)
        at curtains.internal.RootViewsSpy$delegatingViewList$1.add(RootViewsSpy.kt:23)
        at android.view.WindowManagerGlobal.addView(WindowManagerGlobal.java:350)
        at android.view.WindowManagerImpl.addView(WindowManagerImpl.java:94)
        at android.app.Dialog.show(Dialog.java:329)
        at org.chromium.content.browser.input.SelectPopupDialog.show(SelectPopupDialog.java:146)
        at org.chromium.content.browser.input.SelectPopup.show(SelectPopup.java:162)
        at android.os.MessageQueue.nativePollOnce(Native Method)
        at android.os.MessageQueue.next(MessageQueue.java:326)
        at android.os.Looper.loop(Looper.java:165)
        at android.app.ActivityThread.main(ActivityThread.java:6821)
        at java.lang.reflect.Method.invoke(Native Method)
        at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:547)
        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:873)
```
### Steps to Reproduce

just intergration to Project 

**Expected behavior:**  be normal

### Version Information

* LeakCanary version: 2.7
* Android OS version: android 9.0
* Gradle version:6.1.1

### Additional Information


",abb9c808902e503394facd90b752eb13b0577943,e2a24a1ecdd34b0a92bdea7ca7e733c5f2b18003,https://github.com/square/leakcanary/compare/abb9c808902e503394facd90b752eb13b0577943...e2a24a1ecdd34b0a92bdea7ca7e733c5f2b18003,"diff --git a/leakcanary-object-watcher-android/src/main/java/leakcanary/RootViewWatcher.kt b/leakcanary-object-watcher-android/src/main/java/leakcanary/RootViewWatcher.kt
index 4fbf1d535..c417e5a03 100644
--- a/leakcanary-object-watcher-android/src/main/java/leakcanary/RootViewWatcher.kt
+++ b/leakcanary-object-watcher-android/src/main/java/leakcanary/RootViewWatcher.kt
@@ -46,7 +46,12 @@ class RootViewWatcher(
         when (rootView.phoneWindow?.callback?.wrappedCallback) {
           // Activities are already tracked by ActivityWatcher
           is Activity -> false
-          is Dialog -> rootView.resources.getBoolean(R.bool.leak_canary_watcher_watch_dismissed_dialogs)
+          is Dialog -> {
+            // Use app context resources to avoid NotFoundException
+            // https://github.com/square/leakcanary/issues/2137
+            val resources = rootView.context.applicationContext.resources
+            resources.getBoolean(R.bool.leak_canary_watcher_watch_dismissed_dialogs)
+          }
           // Probably a DreamService
           else -> true
         }",['leakcanary-object-watcher-android/src/main/java/leakcanary/RootViewWatcher.kt'],{'.kt': 1},1,0,1,0,1,913889,208110,27542,215,439,85,7,1,1770,82,410,39,0,1,2021-06-29 15:27:41,28557,Kotlin,"{'Kotlin': 1363625, 'Java': 4762, 'Shell': 481, 'AIDL': 203}",Apache License 2.0,"['leakcanary-object-watcher-android/src/main/java/leakcanary/ActivityWatcher.kt', 'leakcanary-object-watcher-android/src/main/java/leakcanary/RootViewWatcher.kt', 'leakcanary-object-watcher-android/src/main/java/leakcanary/AppWatcher.kt', 'leakcanary-object-watcher-android/src/main/java/leakcanary/InstallableWatcher.kt', 'leakcanary-object-watcher-android/src/main/java/leakcanary/FragmentAndViewModelWatcher.kt']","['leakcanary-object-watcher-android/src/main/java/leakcanary/ActivityWatcher.kt', 'leakcanary-object-watcher-android/src/main/java/leakcanary/RootViewWatcher.kt', 'leakcanary-object-watcher-android/src/main/java/leakcanary/AppWatcher.kt', 'leakcanary-object-watcher-android/src/main/java/leakcanary/InstallableWatcher.kt', 'leakcanary-object-watcher-android/src/main/java/leakcanary/FragmentAndViewModelWatcher.kt']","['```json\n{\n  ""files"": [\n    ""leakcanary-object-watcher-android/src/main/java/leakcanary/RootViewWatcher.kt"",\n    ""leakcanary-object-watcher-android/src/main/java/leakcanary/ActivityWatcher.kt"",\n    ""leakcanary-object-watcher-android/src/main/java/leakcanary/AppWatcher.kt"",\n    ""leakcanary-object-watcher-android/src/main/java/leakcanary/FragmentAndViewModelWatcher.kt"",\n    ""leakcanary-object-watcher-android/src/main/java/leakcanary/InstallableWatcher.kt""\n  ]\n}\n```']",1,2340.6999111175537
3333,android/compose-samples/1045/1023,android,compose-samples,https://github.com/android/compose-samples/issues/1023,https://github.com/android/compose-samples/pull/1045,https://github.com/android/compose-samples/pull/1045,1,fixes,[JetSurvey]: RadioButton parent should have selectableGroup modifier,"### Is there an existing issue for this?

- [X] I have searched the existing issues

### Is there a StackOverflow question about this issue?

- [X] I have searched StackOverflow

### Is this an issue related to one of the samples?

- [X] Yes, this is a specific issue related to this samples repo.

### Sample app

Jetsurvey

### What happened?

RadioButton parent should have selectableGroup modifier set to help TalkBack. Children with selectable modifier should have role set to RadioButton.

### Relevant logcat output

_No response_

### Code of Conduct

- [X] I agree to follow this project's Code of Conduct",5ca49e1e9cad5617c836d28d735d683399f9c613,96277ba25ed19cdc7d1e27fb5bdbab1d94ea18aa,https://github.com/android/compose-samples/compare/5ca49e1e9cad5617c836d28d735d683399f9c613...96277ba25ed19cdc7d1e27fb5bdbab1d94ea18aa,"diff --git a/Jetsurvey/app/src/main/java/com/example/compose/jetsurvey/survey/question/ChoiceQuestion.kt b/Jetsurvey/app/src/main/java/com/example/compose/jetsurvey/survey/question/ChoiceQuestion.kt
index df0a19b6..18140fbf 100644
--- a/Jetsurvey/app/src/main/java/com/example/compose/jetsurvey/survey/question/ChoiceQuestion.kt
+++ b/Jetsurvey/app/src/main/java/com/example/compose/jetsurvey/survey/question/ChoiceQuestion.kt
@@ -46,6 +46,7 @@ import androidx.compose.ui.draw.clip
 import androidx.compose.ui.graphics.painter.Painter
 import androidx.compose.ui.res.painterResource
 import androidx.compose.ui.res.stringResource
+import androidx.compose.ui.semantics.Role
 import androidx.compose.ui.tooling.preview.Preview
 import androidx.compose.ui.tooling.preview.PreviewParameter
 import androidx.compose.ui.tooling.preview.PreviewParameterProvider
@@ -132,17 +133,22 @@ private fun Answer(
             }
         ),
         modifier = modifier
+            .clip(MaterialTheme.shapes.small)
+            .then(
+                if (isSingleChoice) {
+                    Modifier.selectable(
+                        selected,
+                        onClick = onOptionSelected,
+                        role = Role.RadioButton
+                    )
+                } else {
+                    Modifier.clickable(onClick = onOptionSelected)
+                }
+            )
     ) {
         Row(
             modifier = Modifier
                 .fillMaxWidth()
-                .then(
-                    if (isSingleChoice) {
-                        Modifier.selectable(selected, onClick = onOptionSelected)
-                    } else {
-                        Modifier.clickable(onClick = onOptionSelected)
-                    }
-                )
                 .padding(16.dp),
             verticalAlignment = Alignment.CenterVertically
         ) {",['Jetsurvey/app/src/main/java/com/example/compose/jetsurvey/survey/question/ChoiceQuestion.kt'],{'.kt': 1},1,0,1,0,1,1248138,254235,35760,295,772,113,20,1,614,103,133,27,0,0,2022-12-12 21:53:39,16563,Kotlin,"{'Kotlin': 1401714, 'Shell': 10287}",Apache License 2.0,"['Jetsurvey/app/src/main/java/com/example/compose/jetsurvey/survey/question/DateQuestion.kt', 'Jetsurvey/app/src/main/java/com/example/compose/jetsurvey/survey/question/PhotoQuestion.kt', 'Jetsurvey/app/src/main/java/com/example/compose/jetsurvey/survey/question/ChoiceQuestion.kt', 'Jetsurvey/app/src/main/java/com/example/compose/jetsurvey/survey/question/ActionQuestion.kt', 'Jetsurvey/app/src/main/java/com/example/compose/jetsurvey/survey/question/SliderQuestion.kt']","['Jetsurvey/app/src/main/java/com/example/compose/jetsurvey/survey/question/DateQuestion.kt', 'Jetsurvey/app/src/main/java/com/example/compose/jetsurvey/survey/question/PhotoQuestion.kt', 'Jetsurvey/app/src/main/java/com/example/compose/jetsurvey/survey/question/ChoiceQuestion.kt', 'Jetsurvey/app/src/main/java/com/example/compose/jetsurvey/survey/question/ActionQuestion.kt', 'Jetsurvey/app/src/main/java/com/example/compose/jetsurvey/survey/question/SliderQuestion.kt']","['```json\n{\n  ""files"": [\n    ""Jetsurvey/app/src/main/java/com/example/compose/jetsurvey/survey/question/ActionQuestion.kt"",\n    ""Jetsurvey/app/src/main/java/com/example/compose/jetsurvey/survey/question/ChoiceQuestion.kt"",\n    ""Jetsurvey/app/src/main/java/com/example/compose/jetsurvey/survey/question/DateQuestion.kt"",\n    ""Jetsurvey/app/src/main/java/com/example/compose/jetsurvey/survey/question/PhotoQuestion.kt"",\n    ""Jetsurvey/app/src/main/java/com/example/compose/jetsurvey/survey/question/SliderQuestion.kt""\n  ]\n}\n```']",1,1907.5148105621338
9447,android/nowinandroid/713/611,android,nowinandroid,https://github.com/android/nowinandroid/issues/611,https://github.com/android/nowinandroid/pull/713,https://github.com/android/nowinandroid/pull/713#issuecomment-1550093461,1,closes,[Bug]: shouldShowSettingsDialog is not persisted through activity recreation,"### Is there an existing issue for this?

- [X] I have searched the existing issues

### Is there a StackOverflow question about this issue?

- [X] I have searched StackOverflow

### What happened?

When the settings dialog is open, causing activity recreation through resizing or rotating the app causes the settings dialog to close.

We should likely keep this state saved via saved instance state so that the settings dialog remains open.

### Relevant logcat output

_No response_

### Code of Conduct

- [X] I agree to follow this project's Code of Conduct",6a8736d4d00e96a543ee496d3374ea612c32ea97,62a77321d3d9285dfba7899a9537ef8a2c8951b3,https://github.com/android/nowinandroid/compare/6a8736d4d00e96a543ee496d3374ea612c32ea97...62a77321d3d9285dfba7899a9537ef8a2c8951b3,"diff --git a/app/src/main/java/com/google/samples/apps/nowinandroid/ui/NiaApp.kt b/app/src/main/java/com/google/samples/apps/nowinandroid/ui/NiaApp.kt
index 83fa4d45..6f6ab060 100644
--- a/app/src/main/java/com/google/samples/apps/nowinandroid/ui/NiaApp.kt
+++ b/app/src/main/java/com/google/samples/apps/nowinandroid/ui/NiaApp.kt
@@ -15,7 +15,6 @@
  */
 
 package com.google.samples.apps.nowinandroid.ui
-
 import androidx.compose.foundation.layout.Column
 import androidx.compose.foundation.layout.ExperimentalLayoutApi
 import androidx.compose.foundation.layout.Row
@@ -41,7 +40,10 @@ import androidx.compose.material3.windowsizeclass.WindowSizeClass
 import androidx.compose.runtime.Composable
 import androidx.compose.runtime.LaunchedEffect
 import androidx.compose.runtime.getValue
+import androidx.compose.runtime.mutableStateOf
 import androidx.compose.runtime.remember
+import androidx.compose.runtime.saveable.rememberSaveable
+import androidx.compose.runtime.setValue
 import androidx.compose.ui.ExperimentalComposeUiApi
 import androidx.compose.ui.Modifier
 import androidx.compose.ui.draw.drawWithContent
@@ -94,6 +96,9 @@ fun NiaApp(
 ) {
     val shouldShowGradientBackground =
         appState.currentTopLevelDestination == TopLevelDestination.FOR_YOU
+    var showSettingsDialog by rememberSaveable {
+        mutableStateOf(false)
+    }
 
     NiaBackground {
         NiaGradientBackground(
@@ -118,9 +123,9 @@ fun NiaApp(
                 }
             }
 
-            if (appState.shouldShowSettingsDialog) {
+            if (showSettingsDialog) {
                 SettingsDialog(
-                    onDismiss = { appState.setShowSettingsDialog(false) },
+                    onDismiss = { showSettingsDialog = false },
                 )
             }
 
@@ -184,7 +189,7 @@ fun NiaApp(
                                 colors = TopAppBarDefaults.centerAlignedTopAppBarColors(
                                     containerColor = Color.Transparent,
                                 ),
-                                onActionClick = { appState.setShowSettingsDialog(true) },
+                                onActionClick = { showSettingsDialog = true },
                                 onNavigationClick = { appState.navigateToSearch() },
                             )
                         }
diff --git a/app/src/main/java/com/google/samples/apps/nowinandroid/ui/NiaAppState.kt b/app/src/main/java/com/google/samples/apps/nowinandroid/ui/NiaAppState.kt
index fb6ae1bc..09e70069 100644
--- a/app/src/main/java/com/google/samples/apps/nowinandroid/ui/NiaAppState.kt
+++ b/app/src/main/java/com/google/samples/apps/nowinandroid/ui/NiaAppState.kt
@@ -20,11 +20,8 @@ import androidx.compose.material3.windowsizeclass.WindowSizeClass
 import androidx.compose.material3.windowsizeclass.WindowWidthSizeClass
 import androidx.compose.runtime.Composable
 import androidx.compose.runtime.Stable
-import androidx.compose.runtime.getValue
-import androidx.compose.runtime.mutableStateOf
 import androidx.compose.runtime.remember
 import androidx.compose.runtime.rememberCoroutineScope
-import androidx.compose.runtime.setValue
 import androidx.navigation.NavController
 import androidx.navigation.NavDestination
 import androidx.navigation.NavGraph.Companion.findStartDestination
@@ -100,9 +97,6 @@ class NiaAppState(
             else -> null
         }
 
-    var shouldShowSettingsDialog by mutableStateOf(false)
-        private set
-
     val shouldShowBottomBar: Boolean
         get() = windowSizeClass.widthSizeClass == WindowWidthSizeClass.Compact
 
@@ -170,10 +164,6 @@ class NiaAppState(
         }
     }
 
-    fun setShowSettingsDialog(shouldShow: Boolean) {
-        shouldShowSettingsDialog = shouldShow
-    }
-
     fun navigateToSearch() {
         navController.navigateToSearch()
     }","['app/src/main/java/com/google/samples/apps/nowinandroid/ui/NiaAppState.kt', 'app/src/main/java/com/google/samples/apps/nowinandroid/ui/NiaApp.kt']",{'.kt': 2},2,0,2,0,2,607239,122229,16470,218,966,174,23,2,563,94,115,21,0,0,2023-05-05 23:26:26,12307,Kotlin,"{'Kotlin': 921089, 'Shell': 10235, 'Prolog': 62}",Apache License 2.0,"['core/ui/src/main/java/com/google/samples/apps/nowinandroid/core/ui/JankStatsExtensions.kt', 'feature/settings/src/main/java/com/google/samples/apps/nowinandroid/feature/settings/SettingsDialog.kt', 'core/ui/src/main/java/com/google/samples/apps/nowinandroid/core/ui/FollowableTopicPreviewParameterProvider.kt', 'core/ui/src/main/java/com/google/samples/apps/nowinandroid/core/ui/DevicePreviews.kt', 'core/ui/src/main/java/com/google/samples/apps/nowinandroid/core/ui/NewsFeed.kt']","['core/ui/src/main/java/com/google/samples/apps/nowinandroid/core/ui/JankStatsExtensions.kt', 'feature/settings/src/main/java/com/google/samples/apps/nowinandroid/feature/settings/SettingsDialog.kt', 'core/ui/src/main/java/com/google/samples/apps/nowinandroid/core/ui/FollowableTopicPreviewParameterProvider.kt', 'core/ui/src/main/java/com/google/samples/apps/nowinandroid/core/ui/DevicePreviews.kt', 'core/ui/src/main/java/com/google/samples/apps/nowinandroid/core/ui/NewsFeed.kt']","['```json\n{\n  ""files"": [\n    ""feature/settings/src/main/java/com/google/samples/apps/nowinandroid/feature/settings/SettingsDialog.kt"",\n    ""core/ui/src/main/java/com/google/samples/apps/nowinandroid/core/ui/DevicePreviews.kt"",\n    ""core/ui/src/main/java/com/google/samples/apps/nowinandroid/core/ui/FollowableTopicPreviewParameterProvider.kt"",\n    ""core/ui/src/main/java/com/google/samples/apps/nowinandroid/core/ui/JankStatsExtensions.kt"",\n    ""core/ui/src/main/java/com/google/samples/apps/nowinandroid/core/ui/NewsFeed.kt""\n  ]\n}\n```']",1,1751.446008682251
9448,android/nowinandroid/858/853,android,nowinandroid,https://github.com/android/nowinandroid/issues/853,https://github.com/android/nowinandroid/pull/858,https://github.com/android/nowinandroid/pull/858,2,closes,[Bug]: Running MacroBenchmark Throw NullPointerException on interestsScrollTopicsDownUp,"### Is there an existing issue for this?

- [X] I have searched the existing issues

### Is there a StackOverflow question about this issue?

- [X] I have searched StackOverflow

### What happened?

This PR is part of [GTC](https://www.facebook.com/groups/gazatechcommunity/) open source initiative

After run Genrate Baseline Profile I face exception
it looks like the emulator device stop before the interestsScrollTopicsDownUp happened

### Relevant logcat output

```shell
java.lang.NullPointerException
	at com.google.samples.apps.nowinandroid.interests.InterestsActionsKt.interestsScrollTopicsDownUp(InterestsActions.kt:38)
	at com.google.samples.apps.nowinandroid.baselineprofile.BaselineProfileGenerator$generate$1.invoke(BaselineProfileGenerator.kt:56)
	at com.google.samples.apps.nowinandroid.baselineprofile.BaselineProfileGenerator$generate$1.invoke(BaselineProfileGenerator.kt:38)
	at androidx.benchmark.macro.BaselineProfilesKt$collect$1$1.invoke(BaselineProfiles.kt:77)
	at androidx.benchmark.macro.BaselineProfilesKt$collect$1$1.invoke(BaselineProfiles.kt:71)
	at androidx.benchmark.macro.CompilationMode$Partial.compileImpl$benchmark_macro_release(CompilationMode.kt:319)
	at androidx.benchmark.macro.CompilationMode.resetAndCompile$benchmark_macro_release(CompilationMode.kt:115)
	at androidx.benchmark.macro.BaselineProfilesKt.collect(BaselineProfiles.kt:71)
	at androidx.benchmark.macro.junit4.BaselineProfileRule.collect(BaselineProfileRule.kt:136)
	at androidx.benchmark.macro.junit4.BaselineProfileRule.collect$default(BaselineProfileRule.kt:126)
	at com.google.samples.apps.nowinandroid.baselineprofile.BaselineProfileGenerator.generate(BaselineProfileGenerator.kt:38)
```


### Code of Conduct

- [X] I agree to follow this project's Code of Conduct",48041fcaa4e6e2cfe76b3d9e9b3fa24c4694c0ca,22ff97b3ae7e1abb68bcfed3a645d92b6a3dbc76,https://github.com/android/nowinandroid/compare/48041fcaa4e6e2cfe76b3d9e9b3fa24c4694c0ca...22ff97b3ae7e1abb68bcfed3a645d92b6a3dbc76,"diff --git a/benchmarks/src/main/java/com/google/samples/apps/nowinandroid/baselineprofile/BaselineProfileGenerator.kt b/benchmarks/src/main/java/com/google/samples/apps/nowinandroid/baselineprofile/BaselineProfileGenerator.kt
index b544fbde..7a08bc63 100644
--- a/benchmarks/src/main/java/com/google/samples/apps/nowinandroid/baselineprofile/BaselineProfileGenerator.kt
+++ b/benchmarks/src/main/java/com/google/samples/apps/nowinandroid/baselineprofile/BaselineProfileGenerator.kt
@@ -18,6 +18,7 @@ package com.google.samples.apps.nowinandroid.baselineprofile
 
 import androidx.benchmark.macro.junit4.BaselineProfileRule
 import com.google.samples.apps.nowinandroid.PACKAGE_NAME
+import com.google.samples.apps.nowinandroid.allowNotifications
 import com.google.samples.apps.nowinandroid.bookmarks.goToBookmarksScreen
 import com.google.samples.apps.nowinandroid.foryou.forYouScrollFeedDownUp
 import com.google.samples.apps.nowinandroid.foryou.forYouSelectTopics
@@ -42,6 +43,7 @@ class BaselineProfileGenerator {
 
             pressHome()
             startActivityAndWait()
+            allowNotifications()
 
             // Scroll the feed critical user journey
             forYouWaitForContent()
diff --git a/benchmarks/src/main/java/com/google/samples/apps/nowinandroid/interests/InterestsActions.kt b/benchmarks/src/main/java/com/google/samples/apps/nowinandroid/interests/InterestsActions.kt
index e94369ce..d9c563eb 100644
--- a/benchmarks/src/main/java/com/google/samples/apps/nowinandroid/interests/InterestsActions.kt
+++ b/benchmarks/src/main/java/com/google/samples/apps/nowinandroid/interests/InterestsActions.kt
@@ -34,7 +34,7 @@ fun MacrobenchmarkScope.goToInterestsScreen() {
 }
 
 fun MacrobenchmarkScope.interestsScrollTopicsDownUp() {
-    val topicsList = device.findObject(By.res(""interests:topics""))
+    val topicsList = device.wait(Until.findObject(By.res(""interests:topics"")), 2_000)
     device.flingElementDownUp(topicsList)
 }
 ","['benchmarks/src/main/java/com/google/samples/apps/nowinandroid/baselineprofile/BaselineProfileGenerator.kt', 'benchmarks/src/main/java/com/google/samples/apps/nowinandroid/interests/InterestsActions.kt']",{'.kt': 2},2,0,2,0,2,620586,124927,16858,226,251,56,4,2,1788,106,414,36,1,1,2023-07-25 22:39:57,12307,Kotlin,"{'Kotlin': 921089, 'Shell': 10235, 'Prolog': 62}",Apache License 2.0,"['sync/work/src/main/java/com/google/samples/apps/nowinandroid/sync/initializers/SyncInitializer.kt', 'benchmarks/src/main/java/com/google/samples/apps/nowinandroid/baselineprofile/BaselineProfileGenerator.kt', 'benchmarks/src/main/java/com/google/samples/apps/nowinandroid/interests/InterestsActions.kt', 'sync/work/src/main/java/com/google/samples/apps/nowinandroid/sync/workers/SyncWorker.kt', 'core/testing/src/main/java/com/google/samples/apps/nowinandroid/core/testing/util/TestSyncManager.kt']","['sync/work/src/main/java/com/google/samples/apps/nowinandroid/sync/initializers/SyncInitializer.kt', 'benchmarks/src/main/java/com/google/samples/apps/nowinandroid/baselineprofile/BaselineProfileGenerator.kt', 'benchmarks/src/main/java/com/google/samples/apps/nowinandroid/interests/InterestsActions.kt', 'sync/work/src/main/java/com/google/samples/apps/nowinandroid/sync/workers/SyncWorker.kt', 'core/testing/src/main/java/com/google/samples/apps/nowinandroid/core/testing/util/TestSyncManager.kt']","['```json\n{\n  ""files"": [\n    ""benchmarks/src/main/java/com/google/samples/apps/nowinandroid/interests/InterestsActions.kt"",\n    ""benchmarks/src/main/java/com/google/samples/apps/nowinandroid/baselineprofile/BaselineProfileGenerator.kt"",\n    ""core/testing/src/main/java/com/google/samples/apps/nowinandroid/core/testing/util/TestSyncManager.kt"",\n    ""sync/work/src/main/java/com/google/samples/apps/nowinandroid/sync/workers/SyncWorker.kt"",\n    ""sync/work/src/main/java/com/google/samples/apps/nowinandroid/sync/initializers/SyncInitializer.kt""\n  ]\n}\n```']",1,1818.657398223877
3328,kotlin/kotlinx.coroutines/3801/3789,kotlin,kotlinx.coroutines,https://github.com/Kotlin/kotlinx.coroutines/issues/3789,https://github.com/Kotlin/kotlinx.coroutines/pull/3801,https://github.com/Kotlin/kotlinx.coroutines/pull/3801,1,fixes,Flow.timeout documentation suggests generic `catch {}` operator.,"The API documentation for `Flow<T>.timeout` suggests using a `catch{}` without rethrowing:

```
flow {
    emit(1)
    delay(100)
    emit(2)
    delay(100)
    emit(3)
    delay(1000)
    emit(4)
}.timeout(100.milliseconds).catch {
    emit(-1) // Item to emit on timeout
}.onEach {
    delay(300) // This will not cause a timeout
}
```

This will emit -1 for any and all upstream exceptions (admittedly none other possible in this fizz buzz example). Can we update the documentation to be more targeted?

Such as this.

```
flow {
    emit(1)
    delay(100)
    emit(2)
    delay(100)
    emit(3)
    delay(1000)
    emit(4)
}.timeout(100.milliseconds).catch { exception ->
    if (exception is TimeoutCancellationException) {
      // Catch the TimeoutCancellationException emitted above.
      emit(-1) // Item to emit on timeout
    } else {
      throw exception
    }
}.onEach {
    delay(300) // This will not cause a timeout
}
```",5b64a1fcf36cbea6fbe3cf70966f4907a2a5f92f,65cada03f5aa833ba1ac0cf57d4a264be7955f79,https://github.com/kotlin/kotlinx.coroutines/compare/5b64a1fcf36cbea6fbe3cf70966f4907a2a5f92f...65cada03f5aa833ba1ac0cf57d4a264be7955f79,"diff --git a/kotlinx-coroutines-core/common/src/flow/operators/Delay.kt b/kotlinx-coroutines-core/common/src/flow/operators/Delay.kt
index 37505dc16..e498e5296 100644
--- a/kotlinx-coroutines-core/common/src/flow/operators/Delay.kt
+++ b/kotlinx-coroutines-core/common/src/flow/operators/Delay.kt
@@ -203,7 +203,7 @@ public fun <T> Flow<T>.debounce(timeout: (T) -> Duration): Flow<T> =
         timeout(emittedItem).toDelayMillis()
     }
 
-private fun <T> Flow<T>.debounceInternal(timeoutMillisSelector: (T) -> Long) : Flow<T> =
+private fun <T> Flow<T>.debounceInternal(timeoutMillisSelector: (T) -> Long): Flow<T> =
     scopedFlow { downstream ->
         // Produce the values using the default (rendezvous) channel
         val values = produce {
@@ -306,7 +306,10 @@ public fun <T> Flow<T>.sample(periodMillis: Long): Flow<T> {
 /*
  * TODO this design (and design of the corresponding operator) depends on #540
  */
-internal fun CoroutineScope.fixedPeriodTicker(delayMillis: Long, initialDelayMillis: Long = delayMillis): ReceiveChannel<Unit> {
+internal fun CoroutineScope.fixedPeriodTicker(
+    delayMillis: Long,
+    initialDelayMillis: Long = delayMillis
+): ReceiveChannel<Unit> {
     require(delayMillis >= 0) { ""Expected non-negative delay, but has $delayMillis ms"" }
     require(initialDelayMillis >= 0) { ""Expected non-negative initial delay, but has $initialDelayMillis ms"" }
     return produce(capacity = 0) {
@@ -359,8 +362,15 @@ public fun <T> Flow<T>.sample(period: Duration): Flow<T> = sample(period.toDelay
  *     emit(3)
  *     delay(1000)
  *     emit(4)
- * }.timeout(100.milliseconds).catch {
- *     emit(-1) // Item to emit on timeout
+ * }.timeout(100.milliseconds).catch { exception ->
+ *     if (exception is TimeoutCancellationException) {
+ *         // Catch the TimeoutCancellationException emitted above.
+ *         // Emit desired item on timeout.
+ *         emit(-1)
+ *     } else {
+ *         // Throw other exceptions.
+ *         throw exception
+ *     }
  * }.onEach {
  *     delay(300) // This will not cause a timeout
  * }
diff --git a/kotlinx-coroutines-core/jvm/test/examples/example-timeout-duration-01.kt b/kotlinx-coroutines-core/jvm/test/examples/example-timeout-duration-01.kt
index 5db6e6a52..5adda863c 100644
--- a/kotlinx-coroutines-core/jvm/test/examples/example-timeout-duration-01.kt
+++ b/kotlinx-coroutines-core/jvm/test/examples/example-timeout-duration-01.kt
@@ -19,8 +19,15 @@ flow {
     emit(3)
     delay(1000)
     emit(4)
-}.timeout(100.milliseconds).catch {
-    emit(-1) // Item to emit on timeout
+}.timeout(100.milliseconds).catch { exception ->
+    if (exception is TimeoutCancellationException) {
+        // Catch the TimeoutCancellationException emitted above.
+        // Emit desired item on timeout.
+        emit(-1)
+    } else {
+        // Throw other exceptions.
+        throw exception
+    }
 }.onEach {
     delay(300) // This will not cause a timeout
 }","['kotlinx-coroutines-core/common/src/flow/operators/Delay.kt', 'kotlinx-coroutines-core/jvm/test/examples/example-timeout-duration-01.kt']",{'.kt': 2},2,0,2,0,2,1783873,385237,43210,327,874,200,18,1,980,123,255,42,0,2,2023-07-05 21:20:43,12141,Kotlin,"{'Kotlin': 3843997, 'Java': 35255, 'Python': 3107, 'Shell': 2685, 'JavaScript': 544, 'CSS': 319}",Apache License 2.0,"['kotlinx-coroutines-core/common/src/flow/internal/FlowExceptions.common.kt', 'kotlinx-coroutines-core/common/src/flow/operators/Delay.kt', 'kotlinx-coroutines-core/common/src/flow/internal/SafeCollector.common.kt', 'kotlinx-coroutines-core/common/src/flow/internal/FlowExceptions.kt', 'kotlinx-coroutines-core/common/src/flow/internal/SafeCollector.kt']","['kotlinx-coroutines-core/common/src/flow/internal/FlowExceptions.common.kt', 'kotlinx-coroutines-core/common/src/flow/operators/Delay.kt', 'kotlinx-coroutines-core/common/src/flow/internal/SafeCollector.common.kt']","['```json\n{\n  ""files"": [\n    ""kotlinx-coroutines-core/common/src/flow/operators/Delay.kt"",\n    ""kotlinx-coroutines-core/common/src/flow/internal/FlowExceptions.common.kt"",\n    ""kotlinx-coroutines-core/common/src/flow/internal/FlowExceptions.kt"",\n    ""kotlinx-coroutines-core/common/src/flow/internal/SafeCollector.common.kt"",\n    ""kotlinx-coroutines-core/common/src/flow/internal/SafeCollector.kt""\n  ]\n}\n```']",1,1930.2079677581787
3329,kotlin/kotlinx.coroutines/3584/3578,kotlin,kotlinx.coroutines,https://github.com/Kotlin/kotlinx.coroutines/issues/3578,https://github.com/Kotlin/kotlinx.coroutines/pull/3584,https://github.com/Kotlin/kotlinx.coroutines/pull/3584,1,fixes,Closing newFixedThreadPoolContext on K/N may lead to an application crash,"We have a non-trivial bug on the edge of `MultiWorkerDispatcher` shutdown sequence and our channels' linearizability.

1) All tasks are dispatched within `newFixedThreadPoolContext` using the channel as a substitute for blocking queue
2) Shutdown sequence if dispatcher first closes the channel, then invokes `Worker.requestTermination` for each existing worker in the pool 
3) `Channels.close` is linearizable via helping technique: when any channel's operation detects `close` operation in progress, it starts helping it -- it processes a list of existing enqueued waiters about the close and `resume`s them.
3.1) Helping is ""non-atomic"", meaning that first helper removes the enqueued waiter from the internal list and then it resumes it.


Now consider the following scenario:

[T1] `close` starts closing the channel
[T2] one of the workers start helping, removes single waiter from the queue, gets preempted 
[T1] `close` finishes -- there are no more waiters, channel is in its final state
[T1] All the workers are closed via `requestTermination`. There is no work for workers, so they are terminated
[T2] finally gets scheduled back and invokes `resume` on the waiter, leading to `Worker.executeAfter` on an already destroyed worker


Relevant stacktrace:
```
Uncaught Kotlin exception: kotlin.IllegalStateException: Worker is already terminated
Invalid connection: com.apple.coresymbolicationd
    at 0   workerWithNewMM.kexe                0x1040bae7d        ThrowWorkerAlreadyTerminated + 157 (/opt/buildAgent/work/5f69639f351c4725/kotlin/kotlin-native/runtime/src/main/kotlin/kotlin/native/concurrent/Internal.kt:68:15)
    at 1   workerWithNewMM.kexe                0x1040bdd4f        kfun:kotlin.native.concurrent.Worker#executeAfter(kotlin.Long;kotlin.Function0<kotlin.Unit>){} + 639 (/opt/buildAgent/work/5f69639f351c4725/kotlin/kotlin-native/runtime/src/main/kotlin/kotlin/native/concurrent/Worker.kt:125:9)
    at 2   workerWithNewMM.kexe                0x10416097c        kfun:kotlinx.coroutines.EventLoopImplBase#enqueue(kotlinx.coroutines.Runnable){} + 140 (/opt/buildAgent/work/44ec6e850d5c63f0/kotlinx-coroutines-core/common/src/EventLoop.common.kt:291:13)
Child process terminated with signal 6: Abort trap
    at 3   workerWithNewMM.kexe                0x104156c10        kfun:kotlinx.coroutines.CancellableContinuationImpl.dispatchResume#internal + 688 (/opt/buildAgent/work/44ec6e850d5c63f0/kotlinx-coroutines-core/common/src/CancellableContinuationImpl.kt:<unknown>)
    at 4   workerWithNewMM.kexe                0x104157474        kfun:kotlinx.coroutines.CancellableContinuationImpl.resumeImpl#internal + 564 (/opt/buildAgent/work/44ec6e850d5c63f0/kotlinx-coroutines-core/common/src/CancellableContinuationImpl.kt:451:21)
    at 5   workerWithNewMM.kexe                0x10415758d        kfun:kotlinx.coroutines.CancellableContinuationImpl#resumeImpl$default(kotlin.Any?;kotlin.Int;kotlin.Function1<kotlin.Throwable,kotlin.Unit>?;kotlin.Int){} + 141 (/opt/buildAgent/work/44ec6e850d5c63f0/kotlinx-coroutines-core/common/src/CancellableContinuationImpl.kt:440:13)
    at 6   workerWithNewMM.kexe                0x1041561e7        kfun:kotlinx.coroutines.CancellableContinuationImpl#resumeWith(kotlin.Result<1:0>){} + 471 (/opt/buildAgent/work/44ec6e850d5c63f0/kotlinx-coroutines-core/common/src/CancellableContinuationImpl.kt:348:9)
    at 7   workerWithNewMM.kexe                0x1041871b1        kfun:kotlinx.coroutines.channels.BufferedChannel.closeWaiter#internal + 1441 (/opt/buildAgent/work/44ec6e850d5c63f0/kotlinx-coroutines-core/common/src/channels/BufferedChannel.kt:1753:37)
    at 8   workerWithNewMM.kexe                0x104185fb4        kfun:kotlinx.coroutines.channels.BufferedChannel.completeClose#internal + 2500 (/opt/buildAgent/work/44ec6e850d5c63f0/kotlinx-coroutines-core/common/src/channels/BufferedChannel.kt:1739:42)
    at 9   workerWithNewMM.kexe                0x104187802        kfun:kotlinx.coroutines.channels.BufferedChannel.isClosed#internal + 146 (/opt/buildAgent/work/44ec6e850d5c63f0/kotlinx-coroutines-core/common/src/channels/BufferedChannel.kt:<unknown>)
    at 10  workerWithNewMM.kexe                0x104183b92        kfun:kotlinx.coroutines.channels.BufferedChannel.BufferedChannelIterator.$hasNextCOROUTINE$2784#invokeSuspend(kotlin.Result<kotlin.Any?>){}kotlin.Any? + 418 (/opt/buildAgent/work/44ec6e850d5c63f0/kotlinx-coroutines-core/common/src/channels/BufferedChannel.kt:<unknown>)
    at 11  workerWithNewMM.kexe                0x104184846        kfun:kotlinx.coroutines.channels.BufferedChannel.BufferedChannelIterator#hasNext(){}kotlin.Boolean + 198 (/opt/buildAgent/work/44ec6e850d5c63f0/kotlinx-coroutines-core/common/src/channels/BufferedChannel.kt:1395:26)
```",67e21b2424937c234b83dc5acab5d8ae4d033533,0f67e17d5a0b23eae59827a04d8ae2608deaff65,https://github.com/kotlin/kotlinx.coroutines/compare/67e21b2424937c234b83dc5acab5d8ae4d033533...0f67e17d5a0b23eae59827a04d8ae2608deaff65,"diff --git a/kotlinx-coroutines-core/native/src/EventLoop.kt b/kotlinx-coroutines-core/native/src/EventLoop.kt
index 25c3c12b7..149c6fe0b 100644
--- a/kotlinx-coroutines-core/native/src/EventLoop.kt
+++ b/kotlinx-coroutines-core/native/src/EventLoop.kt
@@ -13,7 +13,14 @@ internal actual abstract class EventLoopImplPlatform : EventLoop() {
     private val current = Worker.current
 
     protected actual fun unpark() {
-        current.executeAfter(0L, {})// send an empty task to unpark the waiting event loop
+        try {
+            current.executeAfter(0L, {}) // send an empty task to unpark the waiting event loop
+        } catch (e: IllegalStateException) {
+            // We deliberately ignore ISE here as they are expected
+            // due to peculiarities of Workers API.
+            // Unfortunately, race-free termination of workers is unachievable by its current state,
+            // see https://github.com/Kotlin/kotlinx.coroutines/issues/3578
+        }
     }
 
     protected actual fun reschedule(now: Long, delayedTask: EventLoopImplBase.DelayedTask) {
diff --git a/kotlinx-coroutines-core/native/src/MultithreadedDispatchers.kt b/kotlinx-coroutines-core/native/src/MultithreadedDispatchers.kt
index bf91e7003..1f495a4b6 100644
--- a/kotlinx-coroutines-core/native/src/MultithreadedDispatchers.kt
+++ b/kotlinx-coroutines-core/native/src/MultithreadedDispatchers.kt
@@ -79,14 +79,23 @@ private class MultiWorkerDispatcher(
         }
     }
 
-    private fun workerRunLoop() = runBlocking {
-        // NB: we leverage tail-call optimization in this loop, do not replace it with
-        // .receive() without proper evaluation
-        for (task in tasksQueue) {
-            /**
-             * Any unhandled exception here will pass through worker's boundary and will be properly reported.
-             */
-            task.run()
+    private fun workerRunLoop() {
+        try {
+            runBlocking {
+                // NB: we leverage tail-call optimization in this loop, do not replace it with
+                // .receive() without proper evaluation
+                for (task in tasksQueue) {
+                    /**
+                     * Any unhandled exception here will pass through worker's boundary and will be properly reported.
+                     */
+                    task.run()
+                }
+            }
+        } catch (e: IllegalStateException) {
+            // We deliberately ignore ISE here as they are expected
+            // due to peculiarities of Workers API.
+            // Unfortunately, race-free termination is unachievable by its current state,
+            // see https://github.com/Kotlin/kotlinx.coroutines/issues/3578
         }
     }
 ","['kotlinx-coroutines-core/native/src/EventLoop.kt', 'kotlinx-coroutines-core/native/src/MultithreadedDispatchers.kt']",{'.kt': 2},2,0,2,0,2,1675945,364470,41257,326,1798,341,34,2,4779,304,1291,35,0,1,2023-01-10 15:51:19,12141,Kotlin,"{'Kotlin': 3843997, 'Java': 35255, 'Python': 3107, 'Shell': 2685, 'JavaScript': 544, 'CSS': 319}",Apache License 2.0,"['kotlinx-coroutines-core/common/src/channels/BufferedChannel.kt', 'kotlinx-coroutines-core/common/src/internal/ThreadContext.common.kt', 'kotlinx-coroutines-core/common/src/flow/internal/AbstractSharedFlow.kt', 'kotlinx-coroutines-core/common/src/internal/LocalAtomics.common.kt', 'kotlinx-coroutines-core/common/src/CancellableContinuationImpl.kt']","['kotlinx-coroutines-core/common/src/internal/ThreadContext.common.kt', 'kotlinx-coroutines-core/common/src/flow/internal/AbstractSharedFlow.kt', 'kotlinx-coroutines-core/common/src/internal/LocalAtomics.common.kt', 'kotlinx-coroutines-core/common/src/CancellableContinuationImpl.kt']","['```json\n{\n  ""files"": [\n    ""kotlinx-coroutines-core/common/src/channels/BufferedChannel.kt"",\n    ""kotlinx-coroutines-core/common/src/CancellableContinuationImpl.kt"",\n    ""kotlinx-coroutines-core/common/src/internal/LocalAtomics.common.kt"",\n    ""kotlinx-coroutines-core/common/src/internal/ThreadContext.common.kt"",\n    ""kotlinx-coroutines-core/common/src/flow/internal/AbstractSharedFlow.kt""\n  ]\n}\n```']",1,1695.711612701416
2587,quarkusio/quarkus/21328/21304,quarkusio,quarkus,https://github.com/quarkusio/quarkus/issues/21304,https://github.com/quarkusio/quarkus/pull/21328,https://github.com/quarkusio/quarkus/pull/21328,1,fixes,"RESTEasy Reactive and Kotlin coroutines throws ""No RESTEasy Reactive request in progress""","### Describe the bug

When implementing a RESTEasy Reactive endpoint using Kotlin coroutines any attempt to access the current request throws IllegalStateException(""No RESTEasy Reactive request in progress""). For example, any attempt at retrieving headers from an injected JAX-RS `HttpHeaders` interface throws the exception.

### Expected behavior

You are able to implement RESTEasy Reactive methods using Kotlin coroutines. That they work as expected and are able to access full range of API objects.

### Actual behavior

An IllegalStateException with ""No RESTEasy Reactive request in progress"" message is thrown.

### How to Reproduce?

[code-with-quarkus.zip](https://github.com/quarkusio/quarkus/files/7504012/code-with-quarkus.zip)


### Output of `uname -a` or `ver`

Darwin ... 21.1.0 Darwin Kernel Version 21.1.0: Wed Oct 13 17:33:24 PDT 2021; root:xnu-8019.41.5~1/RELEASE_ARM64_T8101 arm64

### Output of `java -version`

java version ""17"" 2021-09-14 LTS Java(TM) SE Runtime Environment (build 17+35-LTS-2724) Java HotSpot(TM) 64-Bit Server VM (build 17+35-LTS-2724, mixed mode, sharing)

### GraalVM version (if different from Java)

_No response_

### Quarkus version or git rev

`2.4.1` and current HEAD of `main`

### Build tool (ie. output of `mvnw --version` or `gradlew --version`)

Apache Maven 3.8.1 (05c21c65bdfed0f71a2f2ada8b84da59348c4c5d) Maven home: /Users/kdubb/.m2/wrapper/dists/apache-maven-3.8.1-bin/2l5mhf2pq2clrde7f7qp1rdt5m/apache-maven-3.8.1 Java version: 17, vendor: Oracle Corporation, runtime: /Library/Java/JavaVirtualMachines/jdk-17.jdk/Contents/Home Default locale: en_US, platform encoding: UTF-8 OS name: ""mac os x"", version: ""12.0.1"", arch: ""aarch64"", family: ""mac""

### Additional information

_No response_",7d4788108794b3499d89a7db9be306d0672a9424,c548d01b14f53da2c65af12ce1bb90b8f72e0b08,https://github.com/quarkusio/quarkus/compare/7d4788108794b3499d89a7db9be306d0672a9424...c548d01b14f53da2c65af12ce1bb90b8f72e0b08,"diff --git a/extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/ApplicationCoroutineScope.kt b/extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/ApplicationCoroutineScope.kt
index ff07849ae1c..036947f3b43 100644
--- a/extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/ApplicationCoroutineScope.kt
+++ b/extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/ApplicationCoroutineScope.kt
@@ -2,6 +2,8 @@ package org.jboss.resteasy.reactive.server.runtime.kotlin
 
 import io.vertx.core.Context
 import kotlinx.coroutines.*
+import org.jboss.resteasy.reactive.server.core.CurrentRequestManager
+import org.jboss.resteasy.reactive.server.core.ResteasyReactiveRequestContext
 import org.jboss.resteasy.reactive.spi.ThreadSetupAction
 import javax.annotation.PreDestroy
 import javax.inject.Singleton
@@ -27,14 +29,16 @@ class ApplicationCoroutineScope : CoroutineScope, AutoCloseable {
 /**
  * Dispatches the coroutine in Vertx IO thread.
  */
-class VertxDispatcher(private val vertxContext: Context, private val requestScope : ThreadSetupAction.ThreadState) : CoroutineDispatcher() {
+class VertxDispatcher(private val vertxContext: Context, private val requestScope : ThreadSetupAction.ThreadState, private val rrContext: ResteasyReactiveRequestContext) : CoroutineDispatcher() {
     override fun dispatch(context: CoroutineContext, block: Runnable) {
         // context propagation for suspending functions is not enabled yet, will be handled later
         vertxContext.runOnContext {
             requestScope.activate()
+            CurrentRequestManager.set(rrContext);
             try {
                 block.run()
             } finally {
+                CurrentRequestManager.set(null);
                 requestScope.deactivate()
             }
         }
diff --git a/extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/CoroutineInvocationHandler.kt b/extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/CoroutineInvocationHandler.kt
index 4cf40d8098d..97426b6a1ce 100644
--- a/extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/CoroutineInvocationHandler.kt
+++ b/extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/CoroutineInvocationHandler.kt
@@ -27,7 +27,7 @@ class CoroutineInvocationHandler(private val invoker: EndpointInvoker,
         }
 
         val requestScope = requestContext.captureCDIRequestScope()
-        val dispatcher: CoroutineDispatcher = Vertx.currentContext()?.let {VertxDispatcher(it,requestScope)}
+        val dispatcher: CoroutineDispatcher = Vertx.currentContext()?.let {VertxDispatcher(it,requestScope, requestContext)}
                 ?: throw IllegalStateException(""No Vertx context found"")
 
         logger.trace(""Handling request with dispatcher {}"", dispatcher)
diff --git a/extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/FilterUtils.kt b/extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/FilterUtils.kt
index 8ebd7e75820..07d8fe72e1d 100644
--- a/extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/FilterUtils.kt
+++ b/extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/FilterUtils.kt
@@ -7,7 +7,7 @@ import javax.enterprise.inject.spi.CDI
 
 fun prepareExecution(requestContext: ResteasyReactiveRequestContext): Pair<CoroutineDispatcher, ApplicationCoroutineScope> {
     val requestScope = requestContext.captureCDIRequestScope()
-    val dispatcher: CoroutineDispatcher = Vertx.currentContext()?.let {VertxDispatcher(it,requestScope)}
+    val dispatcher: CoroutineDispatcher = Vertx.currentContext()?.let {VertxDispatcher(it,requestScope, requestContext)}
             ?: throw IllegalStateException(""No Vertx context found"")
 
     val coroutineScope = CDI.current().select(ApplicationCoroutineScope::class.java)
diff --git a/extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/FlowToPublisherHandler.kt b/extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/FlowToPublisherHandler.kt
index 6d32cb6e939..0dee691bac3 100644
--- a/extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/FlowToPublisherHandler.kt
+++ b/extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/FlowToPublisherHandler.kt
@@ -19,7 +19,7 @@ class FlowToPublisherHandler : ServerRestHandler {
         if (result is Flow<*>) {
 
             val requestScope = requestContext.captureCDIRequestScope()
-            val dispatcher: CoroutineDispatcher = Vertx.currentContext()?.let {VertxDispatcher(it,requestScope)}
+            val dispatcher: CoroutineDispatcher = Vertx.currentContext()?.let {VertxDispatcher(it,requestScope, requestContext)}
                     ?: throw IllegalStateException(""No Vertx context found"")
 
             val coroutineScope = CDI.current().select(ApplicationCoroutineScope::class.java)
diff --git a/integration-tests/resteasy-reactive-kotlin/standard/src/main/kotlin/io/quarkus/it/resteasy/reactive/kotlin/GreetingResource.kt b/integration-tests/resteasy-reactive-kotlin/standard/src/main/kotlin/io/quarkus/it/resteasy/reactive/kotlin/GreetingResource.kt
index cb3e6529c0d..b4ceaaa4fcb 100644
--- a/integration-tests/resteasy-reactive-kotlin/standard/src/main/kotlin/io/quarkus/it/resteasy/reactive/kotlin/GreetingResource.kt
+++ b/integration-tests/resteasy-reactive-kotlin/standard/src/main/kotlin/io/quarkus/it/resteasy/reactive/kotlin/GreetingResource.kt
@@ -1,14 +1,19 @@
 package io.quarkus.it.resteasy.reactive.kotlin
 
 import org.jboss.resteasy.reactive.RestHeader
+import javax.inject.Inject
 import javax.ws.rs.GET
 import javax.ws.rs.Path
+import javax.ws.rs.core.HttpHeaders
 
 @Path(""/greeting"")
-class GreetingResource {
+class GreetingResource(val headers: HttpHeaders) {
 
     @GET
-    suspend fun testSuspend(@RestHeader(""firstName"") firstName: String, @RestHeader(""lastName"") lastName: String) = Greeting(""hello $firstName $lastName"")
+    suspend fun testSuspend(@RestHeader(""firstName"") firstName: String): Greeting {
+        val lastName = headers.getHeaderString(""lastName"");
+        return Greeting(""hello $firstName $lastName"")
+    }
 }
 
 data class Greeting(val message:String)","['extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/ApplicationCoroutineScope.kt', 'extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/FilterUtils.kt', 'extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/CoroutineInvocationHandler.kt', 'extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/FlowToPublisherHandler.kt', 'integration-tests/resteasy-reactive-kotlin/standard/src/main/kotlin/io/quarkus/it/resteasy/reactive/kotlin/GreetingResource.kt']",{'.kt': 5},5,0,5,0,5,216487,49534,6167,51,1293,250,12,4,1790,209,516,40,1,0,2021-11-10 03:53:44,12047,Java,"{'Java': 45174846, 'HTML': 1260641, 'Kotlin': 726044, 'JavaScript': 519044, 'Shell': 51146, 'Groovy': 25140, 'ANTLR': 23342, 'Batchfile': 13971, 'Mustache': 13199, 'Scala': 9778, 'FreeMarker': 8106, 'CSS': 5346, 'Dockerfile': 660, 'PLpgSQL': 109}",Apache License 2.0,"['extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/AbstractSuspendedResponseFilter.kt', 'extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/AbstractSuspendedRequestFilter.kt', 'extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/CoroutineEndpointInvoker.kt', 'extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/CoroutineInvocationHandler.kt', 'extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/ApplicationCoroutineScope.kt']","['extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/AbstractSuspendedResponseFilter.kt', 'extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/AbstractSuspendedRequestFilter.kt', 'extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/CoroutineEndpointInvoker.kt', 'extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/CoroutineInvocationHandler.kt', 'extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/ApplicationCoroutineScope.kt']","['```json\n{\n  ""files"": [\n    ""extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/AbstractSuspendedRequestFilter.kt"",\n    ""extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/AbstractSuspendedResponseFilter.kt"",\n    ""extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/ApplicationCoroutineScope.kt"",\n    ""extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/CoroutineEndpointInvoker.kt"",\n    ""extensions/resteasy-reactive/quarkus-resteasy-reactive-kotlin/runtime/src/main/kotlin/org/jboss/resteasy/reactive/server/runtime/kotlin/CoroutineInvocationHandler.kt""\n  ]\n}\n```']",1,2492.4707412719727
3331,ktorio/ktor/1359/1358,ktorio,ktor,https://github.com/ktorio/ktor/issues/1358,https://github.com/ktorio/ktor/pull/1359,https://github.com/ktorio/ktor/pull/1359,1,fixes,CIO client gets into the failed loop,"ktor-client-cio 1.2.4

I have setup when I need some ws connections to the same endpoint (and they are share the same client), but sometimes my connection loop stuck with following exception:
```java
java.nio.channels.UnresolvedAddressException
	at java.base/sun.nio.ch.Net.checkAddress(Net.java:130)
	at java.base/sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:675)
	at io.ktor.network.sockets.SocketImpl.connect$ktor_network(SocketImpl.kt:28)
	at io.ktor.network.sockets.TcpSocketBuilder.connect(Builders.kt:107)
	at io.ktor.network.sockets.TcpSocketBuilder.connect$default(Builders.kt:99)
	at io.ktor.client.engine.cio.ConnectionFactory.connect(ConnectionFactory.kt:23)
	at io.ktor.client.engine.cio.Endpoint$connect$$inlined$repeat$lambda$1.invokeSuspend(Endpoint.kt:145)
	at io.ktor.client.engine.cio.Endpoint$connect$$inlined$repeat$lambda$1.invoke(Endpoint.kt)
	at kotlinx.coroutines.intrinsics.UndispatchedKt.startUndispatchedOrReturnIgnoreTimeout(Undispatched.kt:102)
	at kotlinx.coroutines.TimeoutKt.setupTimeout(Timeout.kt:78)
	at kotlinx.coroutines.TimeoutKt.access$setupTimeout(Timeout.kt:1)
	at kotlinx.coroutines.TimeoutKt.withTimeoutOrNull(Timeout.kt:57)
	at io.ktor.client.engine.cio.Endpoint.connect(Endpoint.kt:145)
	at io.ktor.client.engine.cio.Endpoint$makeDedicatedRequest$1.invokeSuspend(Endpoint.kt:91)
	at kotlin.coroutines.jvm.internal.BaseContinuationImpl.resumeWith(ContinuationImpl.kt:33)
	at kotlinx.coroutines.DispatchedTask.run(Dispatched.kt:241)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:835)
```

See that line:
https://github.com/ktorio/ktor/blob/86f7192d2dddd2605d3f7b83a0b9a7ed45b64e09/ktor-client/ktor-client-cio/jvm/src/io/ktor/client/engine/cio/Endpoint.kt#L30

It leads to early resolving of hostname when creating endpoint, but constructor of `InetSocketAddress` doesn't guarantee that hostname will be resolved (temporary dns server failure or network outage can cause it). It leads to two bugs:
1. [Retry attempts](https://github.com/ktorio/ktor/blob/86f7192d2dddd2605d3f7b83a0b9a7ed45b64e09/ktor-client/ktor-client-cio/jvm/src/io/ktor/client/engine/cio/Endpoint.kt#L144) is no sense here, as it will try to connect N times to unresolved address (and each time it fails)
2. When endpoint used by more than one connection (like my case with 2+ ws connections to the same endpoint) endpoint will be never recycled and stale into failed state forever (ws1 tries to connect and failed, but at the same time ws2 tries to connect too and recycling doesn't triggered, ws2 failed, but at the same time ws1 tries to connect...)",86f7192d2dddd2605d3f7b83a0b9a7ed45b64e09,79e31d7eea097fb9df2657b7dc18a29773b80da1,https://github.com/ktorio/ktor/compare/86f7192d2dddd2605d3f7b83a0b9a7ed45b64e09...79e31d7eea097fb9df2657b7dc18a29773b80da1,"diff --git a/ktor-client/ktor-client-cio/jvm/src/io/ktor/client/engine/cio/Endpoint.kt b/ktor-client/ktor-client-cio/jvm/src/io/ktor/client/engine/cio/Endpoint.kt
index 655e3509b..328ea5efc 100644
--- a/ktor-client/ktor-client-cio/jvm/src/io/ktor/client/engine/cio/Endpoint.kt
+++ b/ktor-client/ktor-client-cio/jvm/src/io/ktor/client/engine/cio/Endpoint.kt
@@ -13,13 +13,15 @@ import io.ktor.util.date.*
 import kotlinx.atomicfu.*
 import kotlinx.coroutines.*
 import kotlinx.coroutines.channels.*
+import kotlinx.coroutines.channels.Channel
 import java.io.*
 import java.net.*
+import java.nio.channels.*
 import kotlin.coroutines.*
 
 internal class Endpoint(
-    host: String,
-    port: Int,
+    private val host: String,
+    private val port: Int,
     private val overProxy: Boolean,
     private val secure: Boolean,
     private val config: CIOEngineConfig,
@@ -27,8 +29,6 @@ internal class Endpoint(
     override val coroutineContext: CoroutineContext,
     private val onDone: () -> Unit
 ) : CoroutineScope, Closeable {
-    private val address = InetSocketAddress(host, port)
-
     private val connections: AtomicInt = atomic(0)
     private val tasks: Channel<RequestTask> = Channel(Channel.UNLIMITED)
     private val deliveryPoint: Channel<RequestTask> = Channel()
@@ -142,6 +142,10 @@ internal class Endpoint(
 
         try {
             repeat(retryAttempts) {
+                val address = InetSocketAddress(host, port)
+
+                if (address.isUnresolved) throw UnresolvedAddressException()
+
                 val connection = withTimeoutOrNull(connectTimeout) { connectionFactory.connect(address) }
                     ?: return@repeat
 ",['ktor-client/ktor-client-cio/jvm/src/io/ktor/client/engine/cio/Endpoint.kt'],{'.kt': 1},1,0,1,0,1,2800376,607472,86175,810,367,70,12,1,2799,197,716,32,2,1,2019-09-26 08:43:06,11367,Kotlin,"{'Kotlin': 6634901, 'C': 231751, 'Python': 948, 'JavaScript': 775, 'HTML': 336, 'Mustache': 77, 'Handlebars': 9}",Apache License 2.0,['ktor-client/ktor-client-cio/jvm/src/io/ktor/client/engine/cio/Endpoint.kt'],['ktor-client/ktor-client-cio/jvm/src/io/ktor/client/engine/cio/Endpoint.kt'],"['```json\n{\n  ""files"": [\n    ""ktor-client/ktor-client-cio/jvm/src/io/ktor/client/engine/cio/Endpoint.kt""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""ktor-client/ktor-client-cio/jvm/src/io/ktor/client/engine/cio/Endpoint.kt""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""ktor-client/ktor-client-cio/jvm/src/io/ktor/client/engine/cio/Endpoint.kt""\n  ]\n}\n```']",2,2889.6143436431885
541,square/moshi/791/775,square,moshi,https://github.com/square/moshi/issues/775,https://github.com/square/moshi/pull/791,https://github.com/square/moshi/pull/791,1,fixes,Kotlin multiple @Transient fields,"Having more than one @ Transient field is causing following exception.

```
Exception in thread ""main"" java.lang.IllegalArgumentException: duplicate option: [text=\\\\u0000""]
	at okio.Options.of(Options.java:66)
	at com.squareup.moshi.JsonReader$Options.of(JsonReader.java:538)
	at com.squareup.moshi.kotlin.reflect.KotlinJsonAdapterFactory.create(KotlinJsonAdapter.kt:260)
	at com.squareup.moshi.Moshi.adapter(Moshi.java:137)
	at com.squareup.moshi.Moshi.adapter(Moshi.java:97)
	at com.squareup.moshi.Moshi.adapter(Moshi.java:71)

```

Code to reproduce

```
data class TransientTest(
        val a: String,
        @Transient
        val b: String? = ""b"",
        @Transient
        val c: String? = ""c""
)

fun main(args: Array<String>) {

    val adapter = Moshi.Builder()
            .add(KotlinJsonAdapterFactory())
            .build()
            .adapter(TransientTest::class.java)

    val test = TransientTest(""a"")

    adapter.toJson(test)
}
```",5912dfaaf621af77e895273c63c94911fa7c967d,efb0fc09230b656387808cf78b47ce966e9322f6,https://github.com/square/moshi/compare/5912dfaaf621af77e895273c63c94911fa7c967d...efb0fc09230b656387808cf78b47ce966e9322f6,"diff --git a/kotlin/reflect/src/main/java/com/squareup/moshi/kotlin/reflect/KotlinJsonAdapter.kt b/kotlin/reflect/src/main/java/com/squareup/moshi/kotlin/reflect/KotlinJsonAdapter.kt
index 555638b..b33a5ce 100644
--- a/kotlin/reflect/src/main/java/com/squareup/moshi/kotlin/reflect/KotlinJsonAdapter.kt
+++ b/kotlin/reflect/src/main/java/com/squareup/moshi/kotlin/reflect/KotlinJsonAdapter.kt
@@ -54,35 +54,36 @@ private val ABSENT_VALUE = Any()
  * constructor, and then by setting any additional properties that exist, if any.
  */
 internal class KotlinJsonAdapter<T>(
-  private val constructor: KFunction<T>,
-  private val bindings: List<Binding<T, Any?>?>,
-  private val options: JsonReader.Options
+  val constructor: KFunction<T>,
+  val allBindings: List<Binding<T, Any?>?>,
+  val nonTransientBindings: List<Binding<T, Any?>>,
+  val options: JsonReader.Options
 ) : JsonAdapter<T>() {
 
   override fun fromJson(reader: JsonReader): T {
     val constructorSize = constructor.parameters.size
 
     // Read each value into its slot in the array.
-    val values = Array<Any?>(bindings.size) { ABSENT_VALUE }
+    val values = Array<Any?>(allBindings.size) { ABSENT_VALUE }
     reader.beginObject()
     while (reader.hasNext()) {
       val index = reader.selectName(options)
-      val binding = if (index != -1) bindings[index] else null
-
-      if (binding == null) {
+      if (index == -1) {
         reader.skipName()
         reader.skipValue()
         continue
       }
+      val binding = nonTransientBindings[index]
 
-      if (values[index] !== ABSENT_VALUE) {
+      val propertyIndex = binding.propertyIndex
+      if (values[propertyIndex] !== ABSENT_VALUE) {
         throw JsonDataException(
             ""Multiple values for '${binding.property.name}' at ${reader.path}"")
       }
 
-      values[index] = binding.adapter.fromJson(reader)
+      values[propertyIndex] = binding.adapter.fromJson(reader)
 
-      if (values[index] == null && !binding.property.returnType.isMarkedNullable) {
+      if (values[propertyIndex] == null && !binding.property.returnType.isMarkedNullable) {
         throw Util.unexpectedNull(
             binding.property.name,
             binding.jsonName,
@@ -98,7 +99,7 @@ internal class KotlinJsonAdapter<T>(
         if (!constructor.parameters[i].type.isMarkedNullable) {
           throw Util.missingProperty(
               constructor.parameters[i].name,
-              bindings[i]?.jsonName,
+              allBindings[i]?.jsonName,
               reader
           )
         }
@@ -110,8 +111,8 @@ internal class KotlinJsonAdapter<T>(
     val result = constructor.callBy(IndexedParameterMap(constructor.parameters, values))
 
     // Set remaining properties.
-    for (i in constructorSize until bindings.size) {
-      val binding = bindings[i]!!
+    for (i in constructorSize until allBindings.size) {
+      val binding = allBindings[i]!!
       val value = values[i]
       binding.set(result, value)
     }
@@ -123,7 +124,7 @@ internal class KotlinJsonAdapter<T>(
     if (value == null) throw NullPointerException(""value == null"")
 
     writer.beginObject()
-    for (binding in bindings) {
+    for (binding in allBindings) {
       if (binding == null) continue // Skip constructor parameters that aren't properties.
 
       writer.name(binding.name)
@@ -135,11 +136,13 @@ internal class KotlinJsonAdapter<T>(
   override fun toString() = ""KotlinJsonAdapter(${constructor.returnType})""
 
   data class Binding<K, P>(
-      val name: String,
-      val jsonName: String?,
-      val adapter: JsonAdapter<P>,
-      val property: KProperty1<K, P>,
-      val parameter: KParameter?) {
+    val name: String,
+    val jsonName: String?,
+    val adapter: JsonAdapter<P>,
+    val property: KProperty1<K, P>,
+    val parameter: KParameter?,
+    val propertyIndex: Int
+  ) {
     fun get(value: K) = property.get(value)
 
     fun set(result: K, value: P) {
@@ -257,7 +260,8 @@ class KotlinJsonAdapterFactory : JsonAdapter.Factory {
           jsonAnnotation?.name ?: name,
           adapter,
           property as KProperty1<Any, Any?>,
-          parameter
+          parameter,
+          parameter?.index ?: -1
       )
     }
 
@@ -271,9 +275,13 @@ class KotlinJsonAdapterFactory : JsonAdapter.Factory {
       bindings += binding
     }
 
-    bindings += bindingsByName.values
+    var index = bindings.size
+    for (bindingByName in bindingsByName) {
+      bindings += bindingByName.value.copy(propertyIndex = index++)
+    }
 
-    val options = JsonReader.Options.of(*bindings.map { it?.name ?: ""\\u0000"" }.toTypedArray())
-    return KotlinJsonAdapter(constructor, bindings, options).nullSafe()
+    val nonTransientBindings = bindings.filterNotNull()
+    val options = JsonReader.Options.of(*nonTransientBindings.map { it.name }.toTypedArray())
+    return KotlinJsonAdapter(constructor, bindings, nonTransientBindings, options).nullSafe()
   }
 }
diff --git a/kotlin/tests/src/test/kotlin/com/squareup/moshi/kotlin/codegen/GeneratedAdaptersTest.kt b/kotlin/tests/src/test/kotlin/com/squareup/moshi/kotlin/codegen/GeneratedAdaptersTest.kt
index 9466831..a583841 100644
--- a/kotlin/tests/src/test/kotlin/com/squareup/moshi/kotlin/codegen/GeneratedAdaptersTest.kt
+++ b/kotlin/tests/src/test/kotlin/com/squareup/moshi/kotlin/codegen/GeneratedAdaptersTest.kt
@@ -535,6 +535,22 @@ class GeneratedAdaptersTest {
   @JsonClass(generateAdapter = true)
   class TransientConstructorParameter(@Transient var a: Int = -1, var b: Int = -1)
 
+  @Test fun multipleTransientConstructorParameters() {
+    val moshi = Moshi.Builder().build()
+    val jsonAdapter = moshi.adapter(MultipleTransientConstructorParameters::class.java)
+
+    val encoded = MultipleTransientConstructorParameters(3, 5, 7)
+    assertThat(jsonAdapter.toJson(encoded)).isEqualTo(""""""{""b"":5}"""""")
+
+    val decoded = jsonAdapter.fromJson(""""""{""a"":4,""b"":6}"""""")!!
+    assertThat(decoded.a).isEqualTo(-1)
+    assertThat(decoded.b).isEqualTo(6)
+    assertThat(decoded.c).isEqualTo(-1)
+  }
+
+  @JsonClass(generateAdapter = true)
+  class MultipleTransientConstructorParameters(@Transient var a: Int = -1, var b: Int = -1, @Transient var c: Int = -1)
+
   @Test fun transientProperty() {
     val moshi = Moshi.Builder().build()
     val jsonAdapter = moshi.adapter<TransientProperty>()
diff --git a/kotlin/tests/src/test/kotlin/com/squareup/moshi/kotlin/reflect/KotlinJsonAdapterTest.kt b/kotlin/tests/src/test/kotlin/com/squareup/moshi/kotlin/reflect/KotlinJsonAdapterTest.kt
index 0cb9dc2..739bad4 100644
--- a/kotlin/tests/src/test/kotlin/com/squareup/moshi/kotlin/reflect/KotlinJsonAdapterTest.kt
+++ b/kotlin/tests/src/test/kotlin/com/squareup/moshi/kotlin/reflect/KotlinJsonAdapterTest.kt
@@ -294,6 +294,21 @@ class KotlinJsonAdapterTest {
 
   class TransientConstructorParameter(@Transient var a: Int = -1, var b: Int = -1)
 
+  @Test fun multipleTransientConstructorParameters() {
+    val moshi = Moshi.Builder().add(KotlinJsonAdapterFactory()).build()
+    val jsonAdapter = moshi.adapter(MultipleTransientConstructorParameters::class.java)
+
+    val encoded = MultipleTransientConstructorParameters(3, 5, 7)
+    assertThat(jsonAdapter.toJson(encoded)).isEqualTo(""""""{""b"":5}"""""")
+
+    val decoded = jsonAdapter.fromJson(""""""{""a"":4,""b"":6}"""""")!!
+    assertThat(decoded.a).isEqualTo(-1)
+    assertThat(decoded.b).isEqualTo(6)
+    assertThat(decoded.c).isEqualTo(-1)
+  }
+
+  class MultipleTransientConstructorParameters(@Transient var a: Int = -1, var b: Int = -1, @Transient var c: Int = -1)
+
   @Test fun requiredTransientConstructorParameterFails() {
     val moshi = Moshi.Builder().add(KotlinJsonAdapterFactory()).build()
     try {","['kotlin/tests/src/test/kotlin/com/squareup/moshi/kotlin/codegen/GeneratedAdaptersTest.kt', 'kotlin/reflect/src/main/java/com/squareup/moshi/kotlin/reflect/KotlinJsonAdapter.kt', 'kotlin/tests/src/test/kotlin/com/squareup/moshi/kotlin/reflect/KotlinJsonAdapterTest.kt']",{'.kt': 3},3,0,3,0,3,64420,14039,1789,15,2417,564,54,1,989,74,231,36,0,2,2019-01-15 18:49:05,9081,Kotlin,"{'Kotlin': 638860, 'Java': 422224, 'Shell': 785}",Apache License 2.0,"['kotlin/reflect/src/main/java/com/squareup/moshi/KotlinJsonAdapter.kt', 'kotlin/reflect/src/main/java/com/squareup/moshi/kotlin/reflect/KotlinJsonAdapter.kt']","['kotlin/reflect/src/main/java/com/squareup/moshi/KotlinJsonAdapter.kt', 'kotlin/reflect/src/main/java/com/squareup/moshi/kotlin/reflect/KotlinJsonAdapter.kt']","['```json\n{\n  ""files"": [\n    ""kotlin/reflect/src/main/java/com/squareup/moshi/KotlinJsonAdapter.kt"",\n    ""kotlin/reflect/src/main/java/com/squareup/moshi/kotlin/reflect/KotlinJsonAdapter.kt""\n  ]\n}\n```']",1,1098.3800888061523
543,square/moshi/604/602,square,moshi,https://github.com/square/moshi/issues/602,https://github.com/square/moshi/pull/604,https://github.com/square/moshi/pull/604,1,closes,Codegen @Json wrong name generation when using special characters,"When using something like:

```Kotlin
data class TimeStamp(@Json(name = ""\\$date"") val millis: Long)
```

In the generated adapter the name gets converted to:

```Kotlin
JsonReader.Options.of(""$date"")
```

Which causes an Unresolved reference error when compiling, since the compiler is looking for a variable named 'date'",78821bbc8041bbc1735aa3e1f41629c8d230ff7c,248be5805bb49c5fd9867e70a16ff6fb722cd36f,https://github.com/square/moshi/compare/78821bbc8041bbc1735aa3e1f41629c8d230ff7c...248be5805bb49c5fd9867e70a16ff6fb722cd36f,"diff --git a/kotlin/codegen/src/main/java/com/squareup/moshi/kotlin/codegen/AdapterGenerator.kt b/kotlin/codegen/src/main/java/com/squareup/moshi/kotlin/codegen/AdapterGenerator.kt
index 7008b9b..813c3a3 100644
--- a/kotlin/codegen/src/main/java/com/squareup/moshi/kotlin/codegen/AdapterGenerator.kt
+++ b/kotlin/codegen/src/main/java/com/squareup/moshi/kotlin/codegen/AdapterGenerator.kt
@@ -303,7 +303,7 @@ internal class AdapterGenerator(
 
     result.addStatement(""%N.beginObject()"", writerParam)
     propertyList.forEach { property ->
-      result.addStatement(""%N.name(%S)"", writerParam, property.jsonName)
+      result.addStatement(""%N.name(\\""${property.jsonName}\\"")"", writerParam)
       result.addStatement(""%N.toJson(%N, %N.%L)"",
           nameAllocator.get(property.delegateKey), writerParam, valueParam, property.name)
     }
diff --git a/kotlin/codegen/src/main/java/com/squareup/moshi/kotlin/codegen/TargetProperty.kt b/kotlin/codegen/src/main/java/com/squareup/moshi/kotlin/codegen/TargetProperty.kt
index a0decdc..e1b14e5 100644
--- a/kotlin/codegen/src/main/java/com/squareup/moshi/kotlin/codegen/TargetProperty.kt
+++ b/kotlin/codegen/src/main/java/com/squareup/moshi/kotlin/codegen/TargetProperty.kt
@@ -128,7 +128,7 @@ internal data class TargetProperty(
   private val Element?.jsonName: String?
     get() {
       if (this == null) return null
-      return getAnnotation(Json::class.java)?.name
+      return getAnnotation(Json::class.java)?.name?.replace(""$"", ""\\\\$"")
     }
 
   override fun toString() = name
diff --git a/kotlin/tests/src/test/kotlin/com/squareup/moshi/kotlin/codgen/GeneratedAdaptersTest.kt b/kotlin/tests/src/test/kotlin/com/squareup/moshi/kotlin/codgen/GeneratedAdaptersTest.kt
index f302c3e..300d827 100644
--- a/kotlin/tests/src/test/kotlin/com/squareup/moshi/kotlin/codgen/GeneratedAdaptersTest.kt
+++ b/kotlin/tests/src/test/kotlin/com/squareup/moshi/kotlin/codgen/GeneratedAdaptersTest.kt
@@ -55,6 +55,27 @@ class GeneratedAdaptersTest {
   @JsonClass(generateAdapter = true)
   data class JsonAnnotation(@Json(name = ""foo"") val bar: String)
 
+  @Test
+  fun jsonAnnotationWithDollarSign() {
+    val adapter = moshi.adapter(JsonAnnotationWithDollarSign::class.java)
+
+    // Read
+    @Language(""JSON"")
+    val json = ""{\\""\\$foo\\"": \\""bar\\""}""
+
+    val instance = adapter.fromJson(json)!!
+    assertThat(instance.bar).isEqualTo(""bar"")
+
+    // Write
+    @Language(""JSON"")
+    val expectedJson = ""{\\""\\$foo\\"":\\""baz\\""}""
+
+    assertThat(adapter.toJson(JsonAnnotationWithDollarSign(""baz""))).isEqualTo(expectedJson)
+  }
+
+  @JsonClass(generateAdapter = true)
+  data class JsonAnnotationWithDollarSign(@Json(name = ""\\$foo"") val bar: String)
+
   @Test
   fun defaultValues() {
     val adapter = moshi.adapter(DefaultValues::class.java)","['kotlin/tests/src/test/kotlin/com/squareup/moshi/kotlin/codgen/GeneratedAdaptersTest.kt', 'kotlin/codegen/src/main/java/com/squareup/moshi/kotlin/codegen/TargetProperty.kt', 'kotlin/codegen/src/main/java/com/squareup/moshi/kotlin/codegen/AdapterGenerator.kt']",{'.kt': 3},3,0,3,0,3,68851,14847,1823,15,274,62,4,2,333,44,73,13,0,2,2018-07-25 01:04:15,9081,Kotlin,"{'Kotlin': 638860, 'Java': 422224, 'Shell': 785}",Apache License 2.0,"['kotlin/codegen/src/main/java/com/squareup/moshi/kotlin/codegen/TypeRenderer.kt', 'kotlin/codegen/src/main/java/com/squareup/moshi/kotlin/codegen/JsonClassCodegenProcessor.kt', 'kotlin/codegen/src/main/java/com/squareup/moshi/kotlin/codegen/PropertyGenerator.kt']","['kotlin/codegen/src/main/java/com/squareup/moshi/kotlin/codegen/TypeRenderer.kt', 'kotlin/codegen/src/main/java/com/squareup/moshi/kotlin/codegen/JsonClassCodegenProcessor.kt', 'kotlin/codegen/src/main/java/com/squareup/moshi/kotlin/codegen/PropertyGenerator.kt']","['```json\n{\n  ""files"": [\n    ""kotlin/codegen/src/main/java/com/squareup/moshi/kotlin/codegen/PropertyGenerator.kt"",\n    ""kotlin/codegen/src/main/java/com/squareup/moshi/kotlin/codegen/TypeRenderer.kt"",\n    ""kotlin/codegen/src/main/java/com/squareup/moshi/kotlin/codegen/JsonClassCodegenProcessor.kt""\n  ]\n}\n```']",1,1576.7533779144287
9560,thundernest/k-9/5687/5661,thundernest,k-9,https://github.com/thundernest/k-9/issues/5661,https://github.com/thundernest/k-9/pull/5687,https://github.com/thundernest/k-9/pull/5687,1,fixes,some folders are not removed from K9 after a refresh folder list action,"hi all

firstly, i have searched for ""folders not removed"". I've looked at both open and closed issues and can't seem to find anything that matches my problem. This of course makes me wonder if it's something specific to me.



### **Describe the bug**
when i've renamed a folder in gmail, i would expect the k9 refresh folder list action to:

a) produce the newly named folder

b) remove the old / missing folder

As per your FAQ here https://k9mail.app/documentation/faq.html#anchor16

However, I've got K9 folders that no longer exist in the browser gmail experience (because i've renamed them), yet they are still visible in K9.

Refresh Folder List does not remove them.



### **To Reproduce**
i can only partially reproduce it now :(

I've literally just tested with a new folder in browser gmail (no emails in test folder), just so as to not waste your time.

- I refreshed the k9 folder list. New folder appeared.
- i then renamed in gmail (browser) and k9 folder refreshing changed the folder name. The previous folder name no longer exists in K9.
- As a final test, i deleted the gmail folder (""remove label"" command) and K9 folder refreshed. Folder disappears.

I retested the above with an email in it (admittedly a draft email).

- Test folder with emails in it appears in K9.
- Renamed test folder with email in it appears in K9.
- Old test folder with email disappears from K9.
- Removing test folder from gmail removes from K9 after folder refresh.

**However**, i DO have existing K9 folders which don't exist on gmail any more, yet i can't delete them from K9 because there's no delete function and refresh folder list doesn't remove them. 

- Although there were no emails showing the redundant K9 folders, i tried ""clear local messages"", in case there was some data marked against them. This didn't help.
- I've got 8 folders in K9 like this, which don't exist on gmail.
- I did think about the possibility of compacting the account but i think that functionality has been removed.



### **Expected behaviour**
all folders that no longer exist in gmail should get removed by K9's refresh folder list action.



### **Additional context**
using K9 v5.806 on Samsung S8 with official OTA android release 9 i.e. pie

Am using IMAP for gmail to K9 operations.



### **Logs**
~~didn't attach any as i get no errors~~

debug log attached for ""Refresh Folder List"" action on my the account in question.
[k9-log.txt](https://github.com/k9mail/k-9/files/7155866/k9-log.txt)




regards,

Gary",51e6820d9289973347c342cab9db763d7fcaee70,2e1b002b210e1a8e1662acce79ef644b50f69426,https://github.com/thundernest/k-9/compare/51e6820d9289973347c342cab9db763d7fcaee70...2e1b002b210e1a8e1662acce79ef644b50f69426,"diff --git a/app/core/src/main/java/com/fsck/k9/mailstore/FolderRepository.kt b/app/core/src/main/java/com/fsck/k9/mailstore/FolderRepository.kt
index 14dc62418..f40136d34 100644
--- a/app/core/src/main/java/com/fsck/k9/mailstore/FolderRepository.kt
+++ b/app/core/src/main/java/com/fsck/k9/mailstore/FolderRepository.kt
@@ -57,21 +57,28 @@ class FolderRepository(
 
     fun getDisplayFoldersFlow(account: Account, displayMode: FolderMode): Flow<List<DisplayFolder>> {
         val messagingController = DI.get<MessagingController>()
+        val messageStore = messageStoreManager.getMessageStore(account)
 
         return callbackFlow {
             send(getDisplayFolders(account, displayMode))
 
-            val listener = object : SimpleMessagingListener() {
+            val folderStatusChangedListener = object : SimpleMessagingListener() {
                 override fun folderStatusChanged(statusChangedAccount: Account, folderId: Long) {
                     if (statusChangedAccount.uuid == account.uuid) {
                         sendBlockingSilently(getDisplayFolders(account, displayMode))
                     }
                 }
             }
-            messagingController.addListener(listener)
+            messagingController.addListener(folderStatusChangedListener)
+
+            val folderSettingsChangedListener = FolderSettingsChangedListener {
+                sendBlockingSilently(getDisplayFolders(account, displayMode))
+            }
+            messageStore.addFolderSettingsChangedListener(folderSettingsChangedListener)
 
             awaitClose {
-                messagingController.removeListener(listener)
+                messagingController.removeListener(folderStatusChangedListener)
+                messageStore.removeFolderSettingsChangedListener(folderSettingsChangedListener)
             }
         }.buffer(capacity = Channel.CONFLATED)
             .distinctUntilChanged()",['app/core/src/main/java/com/fsck/k9/mailstore/FolderRepository.kt'],{'.kt': 1},1,0,1,0,1,1540929,314441,42237,546,857,120,13,1,2574,421,588,69,2,0,2021-09-21 12:43:14,8156,Kotlin,"{'Kotlin': 4058553, 'Java': 2375292, 'Shell': 7553, 'AIDL': 1946}",Apache License 2.0,"['app/ui/legacy/src/main/java/com/fsck/k9/ui/settings/account/AccountSettingsDataStore.kt', 'mail/protocols/imap/src/main/java/com/fsck/k9/mail/store/imap/ImapFolder.kt', 'mail/protocols/imap/src/main/java/com/fsck/k9/mail/store/imap/RealImapFolderIdler.kt', 'mail/protocols/imap/src/main/java/com/fsck/k9/mail/store/imap/RealImapFolder.kt', 'app/ui/legacy/src/main/java/com/fsck/k9/ui/settings/account/AccountSettingsDataStoreFactory.kt']","['app/ui/legacy/src/main/java/com/fsck/k9/ui/settings/account/AccountSettingsDataStore.kt', 'mail/protocols/imap/src/main/java/com/fsck/k9/mail/store/imap/ImapFolder.kt', 'mail/protocols/imap/src/main/java/com/fsck/k9/mail/store/imap/RealImapFolderIdler.kt', 'mail/protocols/imap/src/main/java/com/fsck/k9/mail/store/imap/RealImapFolder.kt', 'app/ui/legacy/src/main/java/com/fsck/k9/ui/settings/account/AccountSettingsDataStoreFactory.kt']","['```json\n{\n  ""files"": [\n    ""mail/protocols/imap/src/main/java/com/fsck/k9/mail/store/imap/ImapFolder.kt"",\n    ""mail/protocols/imap/src/main/java/com/fsck/k9/mail/store/imap/RealImapFolder.kt"",\n    ""mail/protocols/imap/src/main/java/com/fsck/k9/mail/store/imap/RealImapFolderIdler.kt"",\n    ""app/ui/legacy/src/main/java/com/fsck/k9/ui/settings/account/AccountSettingsDataStore.kt"",\n    ""app/ui/legacy/src/main/java/com/fsck/k9/ui/settings/account/AccountSettingsDataStoreFactory.kt""\n  ]\n}\n```']",1,2348.253011703491
9549,thundernest/k-9/5905/5873,thundernest,k-9,https://github.com/thundernest/k-9/issues/5873,https://github.com/thundernest/k-9/pull/5905,https://github.com/thundernest/k-9/pull/5905,2,fixes,"With 5.909, frequent blank screen when opening a message","### Checklist

- [X] I have used the search function to see if someone else has already submitted the same bug report.
- [X] I will describe the problem with as much detail as possible.

### App version

5.909

### Where did you get the app from?

Google Play

### Android version

12

### Device model

Pixel 6

### Steps to reproduce

1. View message list
2. Tap a message to open it

### Expected behavior

Message displays

### Actual behavior

I briefly see the loading progress bar at the top of the screen show activity, and then I am left with a completely blank screen. If I go back and tap the same message again it displays the second time.

### Logs

_No response_",c61b097f8b85c0ae543efccea3c6d39075632a0f,4d0bbd1e8af4cd06660f71eee5b6555a80f9f862,https://github.com/thundernest/k-9/compare/c61b097f8b85c0ae543efccea3c6d39075632a0f...4d0bbd1e8af4cd06660f71eee5b6555a80f9f862,"diff --git a/app/core/src/main/java/com/fsck/k9/notification/NotificationRepository.kt b/app/core/src/main/java/com/fsck/k9/notification/NotificationRepository.kt
index b18f3686a..f624810c9 100644
--- a/app/core/src/main/java/com/fsck/k9/notification/NotificationRepository.kt
+++ b/app/core/src/main/java/com/fsck/k9/notification/NotificationRepository.kt
@@ -39,7 +39,11 @@ internal class NotificationRepository(
     @Synchronized
     fun addNotification(account: Account, content: NotificationContent, timestamp: Long): AddNotificationResult {
         return notificationDataStore.addNotification(account, content, timestamp).also { result ->
-            persistNotificationDataStoreChanges(account, result.notificationStoreOperations)
+            persistNotificationDataStoreChanges(
+                account = account,
+                operations = result.notificationStoreOperations,
+                updateNewMessageState = true
+            )
         }
     }
 
@@ -50,9 +54,11 @@ internal class NotificationRepository(
         selector: (List<MessageReference>) -> List<MessageReference>
     ): RemoveNotificationsResult? {
         return notificationDataStore.removeNotifications(account, selector)?.also { result ->
-            if (clearNewMessageState) {
-                persistNotificationDataStoreChanges(account, result.notificationStoreOperations)
-            }
+            persistNotificationDataStoreChanges(
+                account = account,
+                operations = result.notificationStoreOperations,
+                updateNewMessageState = clearNewMessageState
+            )
         }
     }
 
@@ -66,11 +72,17 @@ internal class NotificationRepository(
         }
     }
 
-    private fun persistNotificationDataStoreChanges(account: Account, operations: List<NotificationStoreOperation>) {
+    private fun persistNotificationDataStoreChanges(
+        account: Account,
+        operations: List<NotificationStoreOperation>,
+        updateNewMessageState: Boolean
+    ) {
         val notificationStore = notificationStoreProvider.getNotificationStore(account)
         notificationStore.persistNotificationChanges(operations)
 
-        setNewMessageState(account, operations)
+        if (updateNewMessageState) {
+            setNewMessageState(account, operations)
+        }
     }
 
     private fun setNewMessageState(account: Account, operations: List<NotificationStoreOperation>) {",['app/core/src/main/java/com/fsck/k9/notification/NotificationRepository.kt'],{'.kt': 1},1,0,1,0,1,1636268,333595,45120,574,1144,185,24,1,677,125,156,37,0,0,2022-02-10 01:13:31,8156,Kotlin,"{'Kotlin': 4058553, 'Java': 2375292, 'Shell': 7553, 'AIDL': 1946}",Apache License 2.0,"['app/ui/legacy/src/main/java/com/fsck/k9/ui/messagelist/MessageListExtractor.kt', 'app/ui/legacy/src/main/java/com/fsck/k9/ui/messagelist/MessageListLiveDataFactory.kt', 'app/ui/legacy/src/main/java/com/fsck/k9/ui/messagelist/MessageListLoader.kt', 'app/ui/legacy/src/main/java/com/fsck/k9/ui/messagelist/MessageListLiveData.kt', 'app/ui/legacy/src/main/java/com/fsck/k9/ui/messagelist/MessageListViewModel.kt']","['app/ui/legacy/src/main/java/com/fsck/k9/ui/messagelist/MessageListExtractor.kt', 'app/ui/legacy/src/main/java/com/fsck/k9/ui/messagelist/MessageListLiveDataFactory.kt', 'app/ui/legacy/src/main/java/com/fsck/k9/ui/messagelist/MessageListLoader.kt', 'app/ui/legacy/src/main/java/com/fsck/k9/ui/messagelist/MessageListLiveData.kt', 'app/ui/legacy/src/main/java/com/fsck/k9/ui/messagelist/MessageListViewModel.kt']","['```json\n{\n  ""files"": [\n    ""app/ui/legacy/src/main/java/com/fsck/k9/ui/messagelist/MessageListLoader.kt"",\n    ""app/ui/legacy/src/main/java/com/fsck/k9/ui/messagelist/MessageListViewModel.kt"",\n    ""app/ui/legacy/src/main/java/com/fsck/k9/ui/messagelist/MessageListLiveDataFactory.kt"",\n    ""app/ui/legacy/src/main/java/com/fsck/k9/ui/messagelist/MessageListLiveData.kt"",\n    ""app/ui/legacy/src/main/java/com/fsck/k9/ui/messagelist/MessageListExtractor.kt""\n  ]\n}\n```']",1,2730.9956550598145
9579,thundernest/k-9/5250/5249,thundernest,k-9,https://github.com/thundernest/k-9/issues/5249,https://github.com/thundernest/k-9/pull/5250,https://github.com/thundernest/k-9/pull/5250,1,fixes,NPE when trying to change folder settings of outbox folder,"**Describe the bug**
I tried to change my folder settings for outbox folder but app crashes.

**To Reproduce**
Steps to reproduce the behavior:
1. Tab on sandwich icon to open side menu
2. Tab on 'Manage folders'
3. Tab on 'Outbox' (2nd list item)
4. App crashes

**Expected behavior**
App should show folder settings

**Environment (please complete the following information):**
 - K-9 Mail version: actual main (1a68adc8)
 - Android version: 10

**Logs**
FATAL EXCEPTION: main
    Process: com.fsck.k9.debug, PID: 9972
    java.lang.NullPointerException: cursor.getString(7) must not be null
        at com.fsck.k9.storage.messages.CursorFolderAccessor.getSyncClass(RetrieveFolderOperations.kt:151)
        at com.fsck.k9.mailstore.FolderRepository$getFolderDetails$1.map(FolderRepository.kt:62)
        at com.fsck.k9.mailstore.FolderRepository$getFolderDetails$1.map(FolderRepository.kt:8)
        at com.fsck.k9.storage.messages.RetrieveFolderOperations$getFolder$1.doDbWork(RetrieveFolderOperations.kt:44)
        at com.fsck.k9.mailstore.LockableDatabase.execute(LockableDatabase.java:273)
        at com.fsck.k9.storage.messages.RetrieveFolderOperations.getFolder(RetrieveFolderOperations.kt:32)
        at com.fsck.k9.storage.messages.RetrieveFolderOperations.getFolder(RetrieveFolderOperations.kt:16)
        at com.fsck.k9.storage.messages.K9MessageStore.getFolder(K9MessageStore.kt:94)
        at com.fsck.k9.mailstore.FolderRepository.getFolderDetails(FolderRepository.kt:52)
        at com.fsck.k9.ui.managefolders.FolderSettingsViewModel$loadFolderDetails$2.invokeSuspend(FolderSettingsViewModel.kt:74)
        at kotlin.coroutines.jvm.internal.BaseContinuationImpl.resumeWith(ContinuationImpl.kt:33)
        at kotlinx.coroutines.DispatchedTask.run(DispatchedTask.kt:106)
        at kotlinx.coroutines.scheduling.CoroutineScheduler.runSafely(CoroutineScheduler.kt:571)
        at kotlinx.coroutines.scheduling.CoroutineScheduler$Worker.executeTask(CoroutineScheduler.kt:738)
        at kotlinx.coroutines.scheduling.CoroutineScheduler$Worker.runWorker(CoroutineScheduler.kt:678)
        at kotlinx.coroutines.scheduling.CoroutineScheduler$Worker.run(CoroutineScheduler.kt:665)",4bfe03de35368e9e9dd58859c920f025b12df363,127e311385a9c97e5fe4d7b86d2ffd6a14e765a0,https://github.com/thundernest/k-9/compare/4bfe03de35368e9e9dd58859c920f025b12df363...127e311385a9c97e5fe4d7b86d2ffd6a14e765a0,"diff --git a/app/core/src/main/java/com/fsck/k9/mailstore/FolderMapper.kt b/app/core/src/main/java/com/fsck/k9/mailstore/FolderMapper.kt
index cb80505de..f283618e8 100644
--- a/app/core/src/main/java/com/fsck/k9/mailstore/FolderMapper.kt
+++ b/app/core/src/main/java/com/fsck/k9/mailstore/FolderMapper.kt
@@ -9,7 +9,7 @@ fun interface FolderMapper<T> {
 
 interface FolderDetailsAccessor {
     val id: Long
-    val serverId: String
+    val serverId: String?
     val name: String
     val type: FolderType
     val isLocalOnly: Boolean
@@ -22,4 +22,6 @@ interface FolderDetailsAccessor {
     val visibleLimit: Int
     val moreMessages: MoreMessages
     val messageCount: Int
+
+    fun serverIdOrThrow(): String
 }
diff --git a/app/core/src/main/java/com/fsck/k9/mailstore/FolderRepository.kt b/app/core/src/main/java/com/fsck/k9/mailstore/FolderRepository.kt
index 35972dd2c..cd18b0a85 100644
--- a/app/core/src/main/java/com/fsck/k9/mailstore/FolderRepository.kt
+++ b/app/core/src/main/java/com/fsck/k9/mailstore/FolderRepository.kt
@@ -72,7 +72,7 @@ class FolderRepository(
         return messageStore.getFolders(excludeLocalOnly = true) { folder ->
             RemoteFolder(
                 id = folder.id,
-                serverId = folder.serverId,
+                serverId = folder.serverIdOrThrow(),
                 name = folder.name,
                 type = folder.type.toFolderType()
             )
@@ -85,7 +85,7 @@ class FolderRepository(
             RemoteFolderDetails(
                 folder = RemoteFolder(
                     id = folder.id,
-                    serverId = folder.serverId,
+                    serverId = folder.serverIdOrThrow(),
                     name = folder.name,
                     type = folder.type.toFolderType()
                 ),
diff --git a/app/core/src/main/java/com/fsck/k9/mailstore/K9BackendStorage.kt b/app/core/src/main/java/com/fsck/k9/mailstore/K9BackendStorage.kt
index 4c86055e3..5fc159cba 100644
--- a/app/core/src/main/java/com/fsck/k9/mailstore/K9BackendStorage.kt
+++ b/app/core/src/main/java/com/fsck/k9/mailstore/K9BackendStorage.kt
@@ -17,7 +17,7 @@ class K9BackendStorage(
     }
 
     override fun getFolderServerIds(): List<String> {
-        return messageStore.getFolders(excludeLocalOnly = true) { folder -> folder.serverId }
+        return messageStore.getFolders(excludeLocalOnly = true) { folder -> folder.serverIdOrThrow() }
     }
 
     override fun createFolderUpdater(): BackendFolderUpdater {
diff --git a/app/storage/src/main/java/com/fsck/k9/storage/messages/RetrieveFolderOperations.kt b/app/storage/src/main/java/com/fsck/k9/storage/messages/RetrieveFolderOperations.kt
index 3b3593291..abe16112b 100644
--- a/app/storage/src/main/java/com/fsck/k9/storage/messages/RetrieveFolderOperations.kt
+++ b/app/storage/src/main/java/com/fsck/k9/storage/messages/RetrieveFolderOperations.kt
@@ -135,7 +135,7 @@ private class CursorFolderAccessor(val cursor: Cursor) : FolderDetailsAccessor {
     override val type: FolderType
         get() = cursor.getString(2).toFolderType()
 
-    override val serverId: String
+    override val serverId: String?
         get() = cursor.getString(3)
 
     override val isLocalOnly: Boolean
@@ -148,16 +148,16 @@ private class CursorFolderAccessor(val cursor: Cursor) : FolderDetailsAccessor {
         get() = cursor.getInt(6) == 1
 
     override val syncClass: FolderClass
-        get() = FolderClass.valueOf(cursor.getString(7))
+        get() = cursor.getString(7).toFolderClass(FolderClass.INHERITED)
 
     override val displayClass: FolderClass
-        get() = FolderClass.valueOf(cursor.getString(8))
+        get() = cursor.getString(8).toFolderClass(FolderClass.NO_CLASS)
 
     override val notifyClass: FolderClass
-        get() = FolderClass.valueOf(cursor.getString(9))
+        get() = cursor.getString(9).toFolderClass(FolderClass.INHERITED)
 
     override val pushClass: FolderClass
-        get() = FolderClass.valueOf(cursor.getString(10))
+        get() = cursor.getString(10).toFolderClass(FolderClass.SECOND_CLASS)
 
     override val visibleLimit: Int
         get() = cursor.getInt(11)
@@ -167,6 +167,14 @@ private class CursorFolderAccessor(val cursor: Cursor) : FolderDetailsAccessor {
 
     override val messageCount: Int
         get() = cursor.getInt(13)
+
+    override fun serverIdOrThrow(): String {
+        return serverId ?: error(""No server ID found for folder '$name' ($id)"")
+    }
+}
+
+private fun String?.toFolderClass(defaultValue: FolderClass): FolderClass {
+    return if (this == null) defaultValue else FolderClass.valueOf(this)
 }
 
 private val FOLDER_COLUMNS = arrayOf(
diff --git a/app/storage/src/test/java/com/fsck/k9/storage/messages/FolderHelpers.kt b/app/storage/src/test/java/com/fsck/k9/storage/messages/FolderHelpers.kt
index e4942f9f8..b2ea71b55 100644
--- a/app/storage/src/test/java/com/fsck/k9/storage/messages/FolderHelpers.kt
+++ b/app/storage/src/test/java/com/fsck/k9/storage/messages/FolderHelpers.kt
@@ -15,9 +15,9 @@ fun SQLiteDatabase.createFolder(
     integrate: Boolean = false,
     inTopGroup: Boolean = false,
     displayClass: String = ""NO_CLASS"",
-    syncClass: String = ""INHERITED"",
-    notifyClass: String = ""INHERITED"",
-    pushClass: String = ""SECOND_CLASS"",
+    syncClass: String? = ""INHERITED"",
+    notifyClass: String? = ""INHERITED"",
+    pushClass: String? = ""SECOND_CLASS"",
     lastUpdated: Long = 0L,
     unreadCount: Int = 0,
     visibleLimit: Int = 25,
diff --git a/app/storage/src/test/java/com/fsck/k9/storage/messages/RetrieveFolderOperationsTest.kt b/app/storage/src/test/java/com/fsck/k9/storage/messages/RetrieveFolderOperationsTest.kt
index 4b08dafe7..4ab153ec2 100644
--- a/app/storage/src/test/java/com/fsck/k9/storage/messages/RetrieveFolderOperationsTest.kt
+++ b/app/storage/src/test/java/com/fsck/k9/storage/messages/RetrieveFolderOperationsTest.kt
@@ -3,6 +3,7 @@ package com.fsck.k9.storage.messages
 import com.fsck.k9.Account.FolderMode
 import com.fsck.k9.mail.FolderClass
 import com.fsck.k9.mail.FolderType
+import com.fsck.k9.mailstore.toDatabaseFolderType
 import com.fsck.k9.storage.RobolectricTest
 import com.google.common.truth.Truth.assertThat
 import org.junit.Test
@@ -45,6 +46,40 @@ class RetrieveFolderOperationsTest : RobolectricTest() {
         assertThat(result).isTrue()
     }
 
+    @Test
+    fun `get local folder`() {
+        val name = ""Local outbox""
+        val folderId = sqliteDatabase.createFolder(
+            name = name,
+            type = FolderType.OUTBOX.toDatabaseFolderType(),
+            serverId = null,
+            isLocalOnly = true,
+            integrate = true,
+            inTopGroup = true,
+            displayClass = FolderClass.FIRST_CLASS.name,
+            syncClass = null,
+            notifyClass = null,
+            pushClass = null
+        )
+
+        val result = retrieveFolderOperations.getFolder(folderId) { folder ->
+            assertThat(folder.id).isEqualTo(folderId)
+            assertThat(folder.name).isEqualTo(name)
+            assertThat(folder.type).isEqualTo(FolderType.OUTBOX)
+            assertThat(folder.serverId).isNull()
+            assertThat(folder.isLocalOnly).isEqualTo(true)
+            assertThat(folder.isIntegrate).isEqualTo(true)
+            assertThat(folder.isInTopGroup).isEqualTo(true)
+            assertThat(folder.displayClass).isEqualTo(FolderClass.FIRST_CLASS)
+            assertThat(folder.syncClass).isEqualTo(FolderClass.INHERITED)
+            assertThat(folder.notifyClass).isEqualTo(FolderClass.INHERITED)
+            assertThat(folder.pushClass).isEqualTo(FolderClass.SECOND_CLASS)
+            true
+        }
+
+        assertThat(result).isTrue()
+    }
+
     @Test
     fun `get non-existent folder should return null`() {
         val result = retrieveFolderOperations.getFolder(1) { ""failed"" }
diff --git a/app/ui/legacy/src/main/java/com/fsck/k9/ui/managefolders/FolderSettingsFragment.kt b/app/ui/legacy/src/main/java/com/fsck/k9/ui/managefolders/FolderSettingsFragment.kt
index 362382e61..6e78838d3 100644
--- a/app/ui/legacy/src/main/java/com/fsck/k9/ui/managefolders/FolderSettingsFragment.kt
+++ b/app/ui/legacy/src/main/java/com/fsck/k9/ui/managefolders/FolderSettingsFragment.kt
@@ -77,6 +77,7 @@ class FolderSettingsFragment : PreferenceFragmentCompat(), ConfirmationDialogFra
 
         setCategoryTitle(folderSettings)
         updateMenu()
+        setPreferenceVisibility(folderSettings)
     }
 
     private fun updateMenu() {
@@ -106,6 +107,13 @@ class FolderSettingsFragment : PreferenceFragmentCompat(), ConfirmationDialogFra
         dialogFragment.show(requireFragmentManager(), TAG_CLEAR_FOLDER_CONFIRMATION)
     }
 
+    private fun setPreferenceVisibility(folderSettings: FolderSettingsData) {
+        if (folderSettings.folder.isLocalOnly) {
+            requirePreference<Preference>(PREFERENCE_POLL_CLASS).isVisible = false
+            requirePreference<Preference>(PREFERENCE_NOTIFICATION_CLASS).isVisible = false
+        }
+    }
+
     override fun doPositiveClick(dialogId: Int) {
         when (dialogId) {
             DIALOG_CLEAR_FOLDER -> {
@@ -118,6 +126,10 @@ class FolderSettingsFragment : PreferenceFragmentCompat(), ConfirmationDialogFra
 
     override fun dialogCancelled(dialogId: Int) = Unit
 
+    private fun <T : Preference> requirePreference(key: String): T {
+        return findPreference(key) ?: error(""Preference '$key' not found"")
+    }
+
     companion object {
         const val EXTRA_ACCOUNT = ""account""
         const val EXTRA_FOLDER_ID = ""folderId""
@@ -127,5 +139,7 @@ class FolderSettingsFragment : PreferenceFragmentCompat(), ConfirmationDialogFra
         private const val TAG_CLEAR_FOLDER_CONFIRMATION = ""clear_folder_confirmation""
 
         private const val PREFERENCE_TOP_CATEGORY = ""folder_settings""
+        private const val PREFERENCE_POLL_CLASS = ""folder_settings_folder_sync_mode""
+        private const val PREFERENCE_NOTIFICATION_CLASS = ""folder_settings_folder_notify_mode""
     }
 }","['app/ui/legacy/src/main/java/com/fsck/k9/ui/managefolders/FolderSettingsFragment.kt', 'app/core/src/main/java/com/fsck/k9/mailstore/FolderMapper.kt', 'app/storage/src/test/java/com/fsck/k9/storage/messages/RetrieveFolderOperationsTest.kt', 'app/core/src/main/java/com/fsck/k9/mailstore/K9BackendStorage.kt', 'app/storage/src/test/java/com/fsck/k9/storage/messages/FolderHelpers.kt', 'app/storage/src/main/java/com/fsck/k9/storage/messages/RetrieveFolderOperations.kt', 'app/core/src/main/java/com/fsck/k9/mailstore/FolderRepository.kt']",{'.kt': 7},7,0,7,0,7,1232729,253802,33892,459,2096,436,42,5,2228,117,536,37,0,0,2021-04-13 15:04:14,8156,Kotlin,"{'Kotlin': 4058553, 'Java': 2375292, 'Shell': 7553, 'AIDL': 1946}",Apache License 2.0,"['app/fsck/k9/storage/messages/RetrieveFolderOperations.kt', 'app/fsck/k9/mailstore/FolderRepository.kt', 'app/ui/legacy/src/main/java/com/fsck/k9/ui/managefolders/FolderSettingsViewModel.kt', 'app/fsck/k9/storage/messages/CursorFolderAccessor.kt', 'app/fsck/k9/mailstore/K9MessageStore.kt']",['app/ui/legacy/src/main/java/com/fsck/k9/ui/managefolders/FolderSettingsViewModel.kt'],"['```json\n{\n  ""files"": [\n    ""app/ui/legacy/src/main/java/com/fsck/k9/ui/managefolders/FolderSettingsViewModel.kt"",\n    ""app/fsck/k9/storage/messages/CursorFolderAccessor.kt"",\n    ""app/fsck/k9/mailstore/FolderRepository.kt"",\n    ""app/fsck/k9/storage/messages/RetrieveFolderOperations.kt"",\n    ""app/fsck/k9/mailstore/K9MessageStore.kt""\n  ]\n}\n```']",1,1689.7382736206055
1673,pinterest/ktlint/389/367,pinterest,ktlint,https://github.com/pinterest/ktlint/issues/367,https://github.com/pinterest/ktlint/pull/389,https://github.com/pinterest/ktlint/pull/389,1,fixes,Comma on newline preceded by // comment will move code into comment,"I got a when phrase. The case is


before
```java
when (type) {
            IHomeLivingConstant.LIVING_TYPE_GUESS_YOU_LIKE //a
                , IHomeLivingConstant.Live_MODULE_CONTENT_CODE // b
                , IHomeLivingConstant.LIVE_MODULE_AUTO_PLAY  //c
-> {
    // do something
}
```

after formatting, I turn out
```java
when (type) {
            IHomeLivingConstant.LIVING_TYPE_GUESS_YOU_LIKE //a, IHomeLivingConstant.Live_MODULE_CONTENT_CODE // b, IHomeLivingConstant.LIVE_MODULE_AUTO_PLAY  //c
-> {
    //do something
} 

```

This lead to bugs cause it will not invoke compile error, but is wrong logically.  And it is hard to find the bug in the hundreds of formatted files.",2b6602f3a716440d528a244efc4ae35ca2ed4efc,a037d8093f0c973f13d1f632ea2534e915c494e5,https://github.com/pinterest/ktlint/compare/2b6602f3a716440d528a244efc4ae35ca2ed4efc...a037d8093f0c973f13d1f632ea2534e915c494e5,"diff --git a/ktlint-ruleset-standard/src/main/kotlin/com/pinterest/ktlint/ruleset/standard/SpacingAroundCommaRule.kt b/ktlint-ruleset-standard/src/main/kotlin/com/pinterest/ktlint/ruleset/standard/SpacingAroundCommaRule.kt
index 5a947817..17485ea7 100644
--- a/ktlint-ruleset-standard/src/main/kotlin/com/pinterest/ktlint/ruleset/standard/SpacingAroundCommaRule.kt
+++ b/ktlint-ruleset-standard/src/main/kotlin/com/pinterest/ktlint/ruleset/standard/SpacingAroundCommaRule.kt
@@ -2,10 +2,14 @@ package com.pinterest.ktlint.ruleset.standard
 
 import com.pinterest.ktlint.core.Rule
 import com.pinterest.ktlint.core.ast.isPartOfString
+import com.pinterest.ktlint.core.ast.isWhiteSpaceWithNewline
 import com.pinterest.ktlint.core.ast.nextLeaf
+import com.pinterest.ktlint.core.ast.nextSibling
+import com.pinterest.ktlint.core.ast.prevCodeLeaf
 import com.pinterest.ktlint.core.ast.prevLeaf
 import com.pinterest.ktlint.core.ast.upsertWhitespaceAfterMe
 import org.jetbrains.kotlin.com.intellij.lang.ASTNode
+import org.jetbrains.kotlin.com.intellij.psi.PsiComment
 import org.jetbrains.kotlin.com.intellij.psi.PsiWhiteSpace
 import org.jetbrains.kotlin.com.intellij.psi.impl.source.tree.LeafPsiElement
 
@@ -21,7 +25,20 @@ class SpacingAroundCommaRule : Rule(""comma-spacing"") {
             if (prevLeaf is PsiWhiteSpace) {
                 emit(prevLeaf.startOffset, ""Unexpected spacing before \\""${node.text}\\"""", true)
                 if (autoCorrect) {
-                    prevLeaf.node.treeParent.removeChild(prevLeaf.node)
+                    val isPrecededByComment = prevLeaf.prevLeaf { it !is PsiWhiteSpace } is PsiComment
+                    if (isPrecededByComment && prevLeaf.isWhiteSpaceWithNewline()) {
+                        // If comma is on new line and preceded by a comment, it should be moved before this comment
+                        // https://github.com/pinterest/ktlint/issues/367
+                        val previousStatement = node.prevCodeLeaf()!!
+                        previousStatement.treeParent.addChild(node.clone(), previousStatement.nextSibling { true })
+                        val nextLeaf = node.nextLeaf()
+                        if (nextLeaf is PsiWhiteSpace) {
+                            nextLeaf.treeParent.removeChild(nextLeaf)
+                        }
+                        node.treeParent.removeChild(node)
+                    } else {
+                        prevLeaf.treeParent.removeChild(prevLeaf)
+                    }
                 }
             }
             if (node.nextLeaf() !is PsiWhiteSpace) {
diff --git a/ktlint-ruleset-standard/src/test/kotlin/com/pinterest/ktlint/ruleset/standard/SpacingAroundCommaRuleTest.kt b/ktlint-ruleset-standard/src/test/kotlin/com/pinterest/ktlint/ruleset/standard/SpacingAroundCommaRuleTest.kt
index 4a8db107..ee148da6 100644
--- a/ktlint-ruleset-standard/src/test/kotlin/com/pinterest/ktlint/ruleset/standard/SpacingAroundCommaRuleTest.kt
+++ b/ktlint-ruleset-standard/src/test/kotlin/com/pinterest/ktlint/ruleset/standard/SpacingAroundCommaRuleTest.kt
@@ -47,6 +47,8 @@ class SpacingAroundCommaRuleTest {
     fun testFormat() {
         assertThat(SpacingAroundCommaRule().format(""fun main() { x(1,3); x(1, 3) }""))
             .isEqualTo(""fun main() { x(1, 3); x(1, 3) }"")
+        assertThat(SpacingAroundCommaRule().format(""fun main() { x(1 /* comment */ , 3); x(1 /* comment */, 3) }""))
+            .isEqualTo(""fun main() { x(1 /* comment */, 3); x(1 /* comment */, 3) }"")
         assertThat(
             SpacingAroundCommaRule().format(
                 """"""
@@ -69,5 +71,28 @@ class SpacingAroundCommaRuleTest {
             ) = Unit
             """""".trimIndent()
         )
+        assertThat(
+            SpacingAroundCommaRule().format(
+                """"""
+                fun fn(
+                    arg1: Int ,
+                    arg2: Int // some comment
+                    , arg3: Int
+                    // other comment
+                    , arg4: Int
+                ) = Unit
+                """""".trimIndent()
+            )
+        ).isEqualTo(
+            """"""
+            fun fn(
+                arg1: Int,
+                arg2: Int, // some comment
+                arg3: Int,
+                // other comment
+                arg4: Int
+            ) = Unit
+            """""".trimIndent()
+        )
     }
 }","['ktlint-ruleset-standard/src/main/kotlin/com/pinterest/ktlint/ruleset/standard/SpacingAroundCommaRule.kt', 'ktlint-ruleset-standard/src/test/kotlin/com/pinterest/ktlint/ruleset/standard/SpacingAroundCommaRuleTest.kt']",{'.kt': 2},2,0,2,0,2,264214,55651,6212,63,1254,217,19,1,711,80,177,25,0,2,2019-04-20 22:54:31,5674,Kotlin,"{'Kotlin': 2696142, 'Python': 25862, 'Ruby': 21378, 'Shell': 4162, 'Batchfile': 425}",MIT License,"['ktlint-ruleset-standard/src/main/kotlin/com/pinterest/ktlint/ruleset/standard/SpacingAroundCommaRule.kt', 'ktlint/src/main/kotlin/com/pinterest/ktlint/internal/IntellijIDEAIntegration.kt']","['ktlint-ruleset-standard/src/main/kotlin/com/pinterest/ktlint/ruleset/standard/SpacingAroundCommaRule.kt', 'ktlint/src/main/kotlin/com/pinterest/ktlint/internal/IntellijIDEAIntegration.kt']","['```json\n{\n  ""files"": [\n    ""ktlint/src/main/kotlin/com/pinterest/ktlint/internal/IntellijIDEAIntegration.kt"",\n    ""ktlint-ruleset-standard/src/main/kotlin/com/pinterest/ktlint/ruleset/standard/SpacingAroundCommaRule.kt""\n  ]\n}\n```']",1,1178.917646408081
1668,pinterest/ktlint/1015/997,pinterest,ktlint,https://github.com/pinterest/ktlint/issues/997,https://github.com/pinterest/ktlint/pull/1015,https://github.com/pinterest/ktlint/pull/1015,1,fixes,FilenameRule does not find lint errors if missing editorconfig (new in 0.40.0),"## Expected Behavior
The `filename` rule should produce a lint error when the kotlin source file name does not match the symbol declared whether or not an editorconfig is present or if it is missing path section which includes the offending file.

## Observed Behavior
Starting in 0.40.0 it does not find this error.
However 0.39.0 does under the same circumstances.

## Steps to Reproduce
Create file `src/main/kotlin/Wrong.kt`
```kotlin
class Right
```
(no editorconfig)
`ktlint src/main/kotlin/Wrong.kt` and it does not find any errors

with editorconfig
```
[*.{kt,kts}]
indent_size = 4
```
a lint error will be found 
```
src/main/kotlin/Wrong.kt:1:1: class Right should be declared in a file named Right.kt (cannot be auto-corrected)
```

If you again change the editorconfig file to the below, the lint error will disappear again
```
[src/test/**/*.{kt,kts}]
indent_size = 4
```


## Your Environment
- MacOS
- ktlint 0.40.0
- Java 11
",2538730ec5a071aa7b6921d0ba9b909211217620,9ebf6ec166723e9f6402799ff5bffa057c9347bc,https://github.com/pinterest/ktlint/compare/2538730ec5a071aa7b6921d0ba9b909211217620...9ebf6ec166723e9f6402799ff5bffa057c9347bc,"diff --git a/ktlint-core/src/main/kotlin/com/pinterest/ktlint/core/KtLint.kt b/ktlint-core/src/main/kotlin/com/pinterest/ktlint/core/KtLint.kt
index 0d179a47..9cb236d8 100644
--- a/ktlint-core/src/main/kotlin/com/pinterest/ktlint/core/KtLint.kt
+++ b/ktlint-core/src/main/kotlin/com/pinterest/ktlint/core/KtLint.kt
@@ -29,6 +29,7 @@ public object KtLint {
     public val EDITOR_CONFIG_USER_DATA_KEY: Key<EditorConfig> = Key<EditorConfig>(""EDITOR_CONFIG"")
     public val ANDROID_USER_DATA_KEY: Key<Boolean> = Key<Boolean>(""ANDROID"")
     public val FILE_PATH_USER_DATA_KEY: Key<String> = Key<String>(""FILE_PATH"")
+    private const val FILE_PATH_PROPERTY = ""file_path""
     public val EDITOR_CONFIG_PROPERTIES_USER_DATA_KEY: Key<EditorConfigProperties> =
         Key<EditorConfigProperties>(""EDITOR_CONFIG_PROPERTIES"")
     public val DISABLED_RULES: Key<Set<String>> = Key<Set<String>>(""DISABLED_RULES"")
@@ -145,10 +146,15 @@ public object KtLint {
         )
 
         // Passed-in userData overrides .editorconfig
-        val mergedUserData = editorConfigProperties.convertToRawValues(
-            params.normalizedFilePath,
-            params.isStdIn
-        ) + params.userData
+        val mergedUserData = editorConfigProperties
+            .convertToRawValues() + params.userData
+            .run {
+                if (!params.isStdIn) {
+                    plus(FILE_PATH_PROPERTY to params.normalizedFilePath.toString())
+                } else {
+                    this
+                }
+            }
 
         injectUserData(rootNode, editorConfigProperties, mergedUserData)
 
@@ -188,7 +194,7 @@ public object KtLint {
             } else {
                 userData
             }
-        node.putUserData(FILE_PATH_USER_DATA_KEY, userData[""file_path""])
+        node.putUserData(FILE_PATH_USER_DATA_KEY, userData[FILE_PATH_PROPERTY])
         node.putUserData(EDITOR_CONFIG_USER_DATA_KEY, EditorConfig.fromMap(editorConfigMap - ""android"" - ""file_path""))
         node.putUserData(EDITOR_CONFIG_PROPERTIES_USER_DATA_KEY, editorConfigProperties)
         node.putUserData(ANDROID_USER_DATA_KEY, android)
diff --git a/ktlint-core/src/main/kotlin/com/pinterest/ktlint/core/internal/EditorConfigLoader.kt b/ktlint-core/src/main/kotlin/com/pinterest/ktlint/core/internal/EditorConfigLoader.kt
index 82f5a59c..ab6ebb71 100644
--- a/ktlint-core/src/main/kotlin/com/pinterest/ktlint/core/internal/EditorConfigLoader.kt
+++ b/ktlint-core/src/main/kotlin/com/pinterest/ktlint/core/internal/EditorConfigLoader.kt
@@ -121,7 +121,6 @@ class EditorConfigLoader(
     }
 
     companion object {
-        internal const val FILE_PATH_PROPERTY = ""file_path""
         /**
          * List of file extensions, editorconfig lookup will be performed.
          */
@@ -131,31 +130,17 @@ class EditorConfigLoader(
         )
 
         /**
-         * Converts loaded [editorConfigProperties] values to string representation.
+         * Converts loaded [EditorConfigProperties] values into string representation.
          *
-         * @param filePath added under [FILE_PATH_PROPERTY] key
-         * @param isStdIn indicate that input is from std-in and [filePath] should not be added to the map
-         *
-         * @return converted [editorConfigProperties]
+         * @return map of key as string and value as string property representation
          */
-        fun EditorConfigProperties.convertToRawValues(
-            filePath: Path?,
-            isStdIn: Boolean = false
-        ): Map<String, String> {
+        fun EditorConfigProperties.convertToRawValues(): Map<String, String> {
             return if (isEmpty()) {
                 emptyMap()
             } else {
-                this
-                    .mapValues {
-                        if (it.value.isUnset) ""unset"" else it.value.sourceValue
-                    }
-                    .run {
-                        if (!isStdIn) {
-                            plus(FILE_PATH_PROPERTY to filePath.toString())
-                        } else {
-                            this
-                        }
-                    }
+                mapValues {
+                    if (it.value.isUnset) ""unset"" else it.value.sourceValue
+                }
             }
         }
     }
diff --git a/ktlint-core/src/test/kotlin/com/pinterest/ktlint/core/internal/EditorConfigLoaderTest.kt b/ktlint-core/src/test/kotlin/com/pinterest/ktlint/core/internal/EditorConfigLoaderTest.kt
index 9808342d..9c8cf569 100644
--- a/ktlint-core/src/test/kotlin/com/pinterest/ktlint/core/internal/EditorConfigLoaderTest.kt
+++ b/ktlint-core/src/test/kotlin/com/pinterest/ktlint/core/internal/EditorConfigLoaderTest.kt
@@ -74,7 +74,7 @@ internal class EditorConfigLoaderTest {
 
             val lintFile = tempFileSystem.normalizedPath(projectDir).resolve(""test.kt"")
             val editorConfig = editorConfigLoader.loadPropertiesForFile(lintFile, rules = rules)
-            val parsedEditorConfig = editorConfig.convertToRawValues(lintFile)
+            val parsedEditorConfig = editorConfig.convertToRawValues()
 
             assertThat(parsedEditorConfig).isNotEmpty
             assertThat(parsedEditorConfig)
@@ -86,7 +86,6 @@ internal class EditorConfigLoaderTest {
                     mapOf(
                         ""indent_size"" to ""2"",
                         ""tab_width"" to ""2"",
-                        EditorConfigLoader.FILE_PATH_PROPERTY to lintFile.toString()
                     )
                 )
         }
@@ -130,38 +129,35 @@ internal class EditorConfigLoaderTest {
 
         val lintFileSubdirectory = tempFileSystem.normalizedPath(project1Subdirectory).resolve(""test.kt"")
         var editorConfigProperties = editorConfigLoader.loadPropertiesForFile(lintFileSubdirectory, rules = rules)
-        var parsedEditorConfig = editorConfigProperties.convertToRawValues(lintFileSubdirectory)
+        var parsedEditorConfig = editorConfigProperties.convertToRawValues()
 
         assertThat(parsedEditorConfig).isEqualTo(
             mapOf(
                 ""indent_size"" to ""2"",
                 ""tab_width"" to ""2"",
                 ""indent_style"" to ""space"",
-                EditorConfigLoader.FILE_PATH_PROPERTY to lintFileSubdirectory.toString()
             )
         )
 
         val lintFileMainDir = tempFileSystem.normalizedPath(project1Dir).resolve(""test.kts"")
         editorConfigProperties = editorConfigLoader.loadPropertiesForFile(lintFileMainDir, rules = rules)
-        parsedEditorConfig = editorConfigProperties.convertToRawValues(lintFileMainDir)
+        parsedEditorConfig = editorConfigProperties.convertToRawValues()
 
         assertThat(parsedEditorConfig).isEqualTo(
             mapOf(
                 ""indent_size"" to ""4"",
                 ""tab_width"" to ""4"",
                 ""indent_style"" to ""space"",
-                EditorConfigLoader.FILE_PATH_PROPERTY to lintFileMainDir.toString()
             )
         )
 
         val lintFileRoot = tempFileSystem.normalizedPath(rootDir).resolve(""test.kt"")
         editorConfigProperties = editorConfigLoader.loadPropertiesForFile(lintFileRoot, rules = rules)
-        parsedEditorConfig = editorConfigProperties.convertToRawValues(lintFileRoot)
+        parsedEditorConfig = editorConfigProperties.convertToRawValues()
 
         assertThat(parsedEditorConfig).isEqualTo(
             mapOf(
                 ""end_of_line"" to ""lf"",
-                EditorConfigLoader.FILE_PATH_PROPERTY to lintFileRoot.toString()
             )
         )
     }
@@ -179,14 +175,13 @@ internal class EditorConfigLoaderTest {
 
         val lintFile = tempFileSystem.normalizedPath(projectDir).resolve(""test.kt"")
         val editorConfigProperties = editorConfigLoader.loadPropertiesForFile(lintFile, rules = rules)
-        val parsedEditorConfig = editorConfigProperties.convertToRawValues(lintFile)
+        val parsedEditorConfig = editorConfigProperties.convertToRawValues()
 
         assertThat(parsedEditorConfig).isNotEmpty
         assertThat(parsedEditorConfig).isEqualTo(
             mapOf(
                 ""insert_final_newline"" to ""true"",
                 ""disabled_rules"" to ""import-ordering"",
-                EditorConfigLoader.FILE_PATH_PROPERTY to lintFile.toString()
             )
         )
     }
@@ -203,14 +198,13 @@ internal class EditorConfigLoaderTest {
 
         val lintFile = tempFileSystem.normalizedPath(projectDir).resolve(""test.kt"")
         val editorConfigProperties = editorConfigLoader.loadPropertiesForFile(lintFile, rules = rules)
-        val parsedEditorConfig = editorConfigProperties.convertToRawValues(lintFile)
+        val parsedEditorConfig = editorConfigProperties.convertToRawValues()
 
         assertThat(parsedEditorConfig).isNotEmpty
         assertThat(parsedEditorConfig).isEqualTo(
             mapOf(
                 ""indent_size"" to ""unset"",
                 ""tab_width"" to ""unset"",
-                EditorConfigLoader.FILE_PATH_PROPERTY to lintFile.toString()
             )
         )
     }
@@ -227,13 +221,12 @@ internal class EditorConfigLoaderTest {
         val lintFile = tempFileSystem.normalizedPath(projectDir).resolve(""test.kts"")
 
         val editorConfigProperties = editorConfigLoader.loadPropertiesForFile(lintFile, rules = rules)
-        val parsedEditorConfig = editorConfigProperties.convertToRawValues(lintFile)
+        val parsedEditorConfig = editorConfigProperties.convertToRawValues()
 
         assertThat(parsedEditorConfig).isNotEmpty
         assertThat(parsedEditorConfig).isEqualTo(
             mapOf(
                 ""disabled_rules"" to ""import-ordering, no-wildcard-imports"",
-                EditorConfigLoader.FILE_PATH_PROPERTY to lintFile.toString()
             )
         )
     }
@@ -251,7 +244,7 @@ internal class EditorConfigLoaderTest {
         val lintFile = tempFileSystem.normalizedPath(projectDir).resolve(""test.txt"")
 
         val editorConfigProperties = editorConfigLoader.loadPropertiesForFile(lintFile, rules = rules)
-        val parsedEditorConfig = editorConfigProperties.convertToRawValues(lintFile)
+        val parsedEditorConfig = editorConfigProperties.convertToRawValues()
 
         assertThat(parsedEditorConfig).isEmpty()
     }
@@ -272,13 +265,9 @@ internal class EditorConfigLoaderTest {
             rules = rules,
             debug = true,
         )
-        val parsedEditorConfig = editorConfigProperties.convertToRawValues(
-            null,
-            true
-        )
+        val parsedEditorConfig = editorConfigProperties.convertToRawValues()
 
         assertThat(parsedEditorConfig).isNotEmpty
-        assertThat(parsedEditorConfig).doesNotContainKey(EditorConfigLoader.FILE_PATH_PROPERTY)
         assertThat(parsedEditorConfig).isEqualTo(
             mapOf(
                 ""insert_final_newline"" to ""true"",
@@ -329,13 +318,12 @@ internal class EditorConfigLoaderTest {
             alternativeEditorConfig = tempFileSystem.normalizedPath(anotherDir).resolve("".editorconfig""),
             rules = rules
         )
-        val parsedEditorConfig = editorConfigProperties.convertToRawValues(lintFile)
+        val parsedEditorConfig = editorConfigProperties.convertToRawValues()
 
         assertThat(parsedEditorConfig).isNotEmpty
         assertThat(parsedEditorConfig).isEqualTo(
             mapOf(
                 ""end_of_line"" to ""lf"",
-                EditorConfigLoader.FILE_PATH_PROPERTY to lintFile.toString(),
                 ""indent_size"" to ""2"",
                 ""tab_width"" to ""2""
             )
@@ -372,7 +360,7 @@ internal class EditorConfigLoaderTest {
             isStdIn = true,
             rules = rules
         )
-        val parsedEditorConfig = editorConfigProperties.convertToRawValues(null, true)
+        val parsedEditorConfig = editorConfigProperties.convertToRawValues()
 
         assertThat(parsedEditorConfig).isNotEmpty
         assertThat(parsedEditorConfig).isEqualTo(
@@ -402,14 +390,13 @@ internal class EditorConfigLoaderTest {
         Files.createDirectories(lintFile)
 
         val editorConfigProperties = editorConfigLoader.loadPropertiesForFile(lintFile, debug = true, rules = rules)
-        val parsedEditorConfig = editorConfigProperties.convertToRawValues(lintFile)
+        val parsedEditorConfig = editorConfigProperties.convertToRawValues()
 
         assertThat(parsedEditorConfig).isNotEmpty
         assertThat(parsedEditorConfig).isEqualTo(
             mapOf(
                 ""insert_final_newline"" to ""true"",
                 ""disabled_rules"" to ""class-must-be-internal"",
-                EditorConfigLoader.FILE_PATH_PROPERTY to lintFile.toString()
             )
         )
     }
@@ -421,6 +408,8 @@ internal class EditorConfigLoaderTest {
             node: ASTNode,
             autoCorrect: Boolean,
             emit: (offset: Int, errorMessage: String, canBeAutoCorrected: Boolean) -> Unit
-        ) = TODO(""Not yet implemented"")
+        ) {
+            throw NotImplementedError()
+        }
     }
 }
diff --git a/ktlint-ruleset-standard/src/test/kotlin/com/pinterest/ktlint/ruleset/standard/FilenameRuleTest.kt b/ktlint-ruleset-standard/src/test/kotlin/com/pinterest/ktlint/ruleset/standard/FilenameRuleTest.kt
index 9372cc1a..c5281681 100644
--- a/ktlint-ruleset-standard/src/test/kotlin/com/pinterest/ktlint/ruleset/standard/FilenameRuleTest.kt
+++ b/ktlint-ruleset-standard/src/test/kotlin/com/pinterest/ktlint/ruleset/standard/FilenameRuleTest.kt
@@ -25,6 +25,7 @@ class FilenameRuleTest {
         ) {
             assertThat(
                 FilenameRule().lint(
+                    ""/some/path/A.kt"",
                     """"""
                     /*
                      * license
@@ -35,7 +36,6 @@ class FilenameRuleTest {
                     $src
                     //
                     """""".trimIndent(),
-                    fileName(""/some/path/A.kt"")
                 )
             ).isEmpty()
         }
@@ -56,6 +56,7 @@ class FilenameRuleTest {
         ) {
             assertThat(
                 FilenameRule().lint(
+                    ""/some/path/B.kt"",
                     """"""
                     /*
                      * license
@@ -66,7 +67,6 @@ class FilenameRuleTest {
                     ${src.key}
                     //
                     """""".trimIndent(),
-                    fileName(""/some/path/B.kt"")
                 )
             ).isEqualTo(
                 listOf(
@@ -80,12 +80,12 @@ class FilenameRuleTest {
     fun testFileWithoutTopLevelDeclarations() {
         assertThat(
             FilenameRule().lint(
+                ""A.kt"",
                 """"""
                 /*
                  * copyright
                  */
                 """""".trimIndent(),
-                fileName(""A.kt"")
             )
         ).isEmpty()
     }
@@ -94,11 +94,11 @@ class FilenameRuleTest {
     fun testMultipleTopLevelClasses() {
         assertThat(
             FilenameRule().lint(
+                ""A.kt"",
                 """"""
                 class B
                 class C
                 """""".trimIndent(),
-                fileName(""A.kt"")
             )
         ).isEmpty()
     }
@@ -107,13 +107,13 @@ class FilenameRuleTest {
     fun testMultipleNonTopLevelClasses() {
         assertThat(
             FilenameRule().lint(
+                ""A.kt"",
                 """"""
                 class B {
                     class C
                     class D
                 }
                 """""".trimIndent(),
-                fileName(""A.kt"")
             )
         ).isEqualTo(
             listOf(
@@ -126,10 +126,10 @@ class FilenameRuleTest {
     fun testCaseSensitiveMatching() {
         assertThat(
             FilenameRule().lint(
+                ""woohoo.kt"",
                 """"""
                 interface Woohoo
                 """""".trimIndent(),
-                fileName(""woohoo.kt"")
             )
         ).isEqualTo(
             listOf(
@@ -142,10 +142,10 @@ class FilenameRuleTest {
     fun testCaseEscapedClassNames() {
         assertThat(
             FilenameRule().lint(
+                ""B.kt"",
                 """"""
                 class `A`
                 """""".trimIndent(),
-                fileName(""B.kt"")
             )
         ).isEqualTo(
             listOf(
@@ -158,13 +158,11 @@ class FilenameRuleTest {
     fun testIgnoreKotlinScriptFiles() {
         assertThat(
             FilenameRule().lint(
+                ""A.kts"",
                 """"""
                 class B
                 """""".trimIndent(),
-                fileName(""A.kts"")
             )
         ).isEmpty()
     }
-
-    private fun fileName(fileName: String) = mapOf(""file_path"" to fileName)
 }
diff --git a/ktlint/src/main/kotlin/com/pinterest/ktlint/internal/IntellijIDEAIntegration.kt b/ktlint/src/main/kotlin/com/pinterest/ktlint/internal/IntellijIDEAIntegration.kt
index f2e42936..3c28271a 100644
--- a/ktlint/src/main/kotlin/com/pinterest/ktlint/internal/IntellijIDEAIntegration.kt
+++ b/ktlint/src/main/kotlin/com/pinterest/ktlint/internal/IntellijIDEAIntegration.kt
@@ -31,10 +31,7 @@ object IntellijIDEAIntegration {
         }
         val editorConfigProperties = EditorConfigLoader(FileSystems.getDefault())
             .loadPropertiesForFile(null, isStdIn = true, rules = emptySet())
-        val editorConfig: Map<String, String> = editorConfigProperties.convertToRawValues(
-            null,
-            isStdIn = true
-        )
+        val editorConfig: Map<String, String> = editorConfigProperties.convertToRawValues()
         val indentSize = editorConfig[""indent_size""]?.toIntOrNull() ?: 4
         val continuationIndentSize = editorConfig[""continuation_indent_size""]?.toIntOrNull() ?: 4
         val updates = if (local) {","['ktlint/src/main/kotlin/com/pinterest/ktlint/internal/IntellijIDEAIntegration.kt', 'ktlint-core/src/test/kotlin/com/pinterest/ktlint/core/internal/EditorConfigLoaderTest.kt', 'ktlint-core/src/main/kotlin/com/pinterest/ktlint/core/internal/EditorConfigLoader.kt', 'ktlint-ruleset-standard/src/test/kotlin/com/pinterest/ktlint/ruleset/standard/FilenameRuleTest.kt', 'ktlint-core/src/main/kotlin/com/pinterest/ktlint/core/KtLint.kt']",{'.kt': 5},5,0,5,0,5,359918,75677,8873,99,2306,419,48,3,978,146,258,37,0,4,2020-12-16 20:31:12,5674,Kotlin,"{'Kotlin': 2696142, 'Python': 25862, 'Ruby': 21378, 'Shell': 4162, 'Batchfile': 425}",MIT License,"['ktlint/src/main/kotlin/com/pinterest/ktlint/internal/RuleSetsLoader.kt', 'ktlint-core/src/main/kotlin/com/pinterest/ktlint/core/RuleSetProvider.kt', 'ktlint-core/src/main/kotlin/com/pinterest/ktlint/core/EditorConfig.kt', 'ktlint-core/src/main/kotlin/com/pinterest/ktlint/core/RuleSet.kt', 'ktlint-ruleset-standard/src/main/kotlin/com/pinterest/ktlint/ruleset/standard/FilenameRule.kt']","['ktlint/src/main/kotlin/com/pinterest/ktlint/internal/RuleSetsLoader.kt', 'ktlint-core/src/main/kotlin/com/pinterest/ktlint/core/RuleSetProvider.kt', 'ktlint-core/src/main/kotlin/com/pinterest/ktlint/core/EditorConfig.kt', 'ktlint-core/src/main/kotlin/com/pinterest/ktlint/core/RuleSet.kt', 'ktlint-ruleset-standard/src/main/kotlin/com/pinterest/ktlint/ruleset/standard/FilenameRule.kt']","['```json\n{\n  ""files"": [\n    ""ktlint-ruleset-standard/src/main/kotlin/com/pinterest/ktlint/ruleset/standard/FilenameRule.kt"",\n    ""ktlint-core/src/main/kotlin/com/pinterest/ktlint/core/EditorConfig.kt"",\n    ""ktlint-core/src/main/kotlin/com/pinterest/ktlint/core/RuleSet.kt"",\n    ""ktlint-core/src/main/kotlin/com/pinterest/ktlint/core/RuleSetProvider.kt"",\n    ""ktlint/src/main/kotlin/com/pinterest/ktlint/internal/RuleSetsLoader.kt""\n  ]\n}\n```']",1,1926.2840747833252
3336,detekt/detekt/483/466,detekt,detekt,https://github.com/detekt/detekt/issues/466,https://github.com/detekt/detekt/pull/483,https://github.com/detekt/detekt/pull/483,1,fixes,UselessPostfixExpression: Postfix on field in return,"detekt marks the postfix expressions in the following case as useless. However the value of the field will be updated and affects the next call of the function.

```
class Test {
    private var runningId: Long = 0

    fun getId(): Long {
        return runningId++
    }
}
```",a7e20b134bd24308e36424a7aa137cbe6e12b902,36abf51931d2b6df66f0925f7592c147ba759c0b,https://github.com/detekt/detekt/compare/a7e20b134bd24308e36424a7aa137cbe6e12b902...36abf51931d2b6df66f0925f7592c147ba759c0b,"diff --git a/detekt-rules/src/main/kotlin/io/gitlab/arturbosch/detekt/rules/bugs/UselessPostfixExpression.kt b/detekt-rules/src/main/kotlin/io/gitlab/arturbosch/detekt/rules/bugs/UselessPostfixExpression.kt
index 6bf686276f..fc71df417a 100644
--- a/detekt-rules/src/main/kotlin/io/gitlab/arturbosch/detekt/rules/bugs/UselessPostfixExpression.kt
+++ b/detekt-rules/src/main/kotlin/io/gitlab/arturbosch/detekt/rules/bugs/UselessPostfixExpression.kt
@@ -6,21 +6,37 @@ import io.gitlab.arturbosch.detekt.api.Entity
 import io.gitlab.arturbosch.detekt.api.Issue
 import io.gitlab.arturbosch.detekt.api.Rule
 import io.gitlab.arturbosch.detekt.api.Severity
+import io.gitlab.arturbosch.detekt.rules.collectByType
 import org.jetbrains.kotlin.psi.KtBinaryExpression
+import org.jetbrains.kotlin.psi.KtClass
 import org.jetbrains.kotlin.psi.KtExpression
+import org.jetbrains.kotlin.psi.KtNamedFunction
 import org.jetbrains.kotlin.psi.KtPostfixExpression
+import org.jetbrains.kotlin.psi.KtProperty
 import org.jetbrains.kotlin.psi.KtReturnExpression
+import org.jetbrains.kotlin.psi.psiUtil.getNonStrictParentOfType
 
 class UselessPostfixExpression(config: Config = Config.empty) : Rule(config) {
 
 	override val issue: Issue = Issue(""UselessPostfixExpression"", Severity.Defect,
 			""The incremented or decremented value is unused. This value is replaced with the original value."")
 
+	var properties = setOf<String?>()
+
+	override fun visitClass(klass: KtClass) {
+		properties = klass.getProperties()
+				.map { it.name }
+				.toSet()
+		super.visitClass(klass)
+	}
+
 	override fun visitReturnExpression(expression: KtReturnExpression) {
 		val postfixExpression = expression.returnedExpression as? KtPostfixExpression
-		if (postfixExpression != null) {
+
+		if (postfixExpression != null && postfixExpression.shouldBeReported()) {
 			report(postfixExpression)
 		}
+
 		getPostfixExpressionChilds(expression.returnedExpression)
 				?.forEach { report(it) }
 	}
@@ -39,6 +55,20 @@ class UselessPostfixExpression(config: Config = Config.empty) : Rule(config) {
 		}
 	}
 
+	private fun KtPostfixExpression.shouldBeReported(): Boolean {
+		val functionProperties = this.getNonStrictParentOfType(KtNamedFunction::class.java)
+				?.collectByType<KtProperty>()
+				?.map { it.name }
+				?.toSet()
+		val postfixReceiverName = this.baseExpression?.text
+
+		if (functionProperties != null && functionProperties.contains(postfixReceiverName)) {
+			return true
+		}
+		return !properties.contains(postfixReceiverName)
+
+	}
+
 	private fun report(postfixExpression: KtPostfixExpression) {
 		report(CodeSmell(issue, Entity.from(postfixExpression)))
 	}
diff --git a/detekt-rules/src/test/kotlin/io/gitlab/arturbosch/detekt/rules/bugs/UselessPostfixExpressionSpec.kt b/detekt-rules/src/test/kotlin/io/gitlab/arturbosch/detekt/rules/bugs/UselessPostfixExpressionSpec.kt
index 28bc2b1a2c..f28da7dd04 100644
--- a/detekt-rules/src/test/kotlin/io/gitlab/arturbosch/detekt/rules/bugs/UselessPostfixExpressionSpec.kt
+++ b/detekt-rules/src/test/kotlin/io/gitlab/arturbosch/detekt/rules/bugs/UselessPostfixExpressionSpec.kt
@@ -1,10 +1,10 @@
 package io.gitlab.arturbosch.detekt.rules.bugs
 
 import io.gitlab.arturbosch.detekt.test.lint
+import org.assertj.core.api.Assertions.assertThat
 import org.jetbrains.spek.api.dsl.describe
 import org.jetbrains.spek.api.dsl.it
 import org.jetbrains.spek.subject.SubjectSpek
-import org.assertj.core.api.Assertions.assertThat
 
 class UselessPostfixExpressionSpec : SubjectSpek<UselessPostfixExpression>({
 	subject { UselessPostfixExpression() }
@@ -33,5 +33,36 @@ class UselessPostfixExpressionSpec : SubjectSpek<UselessPostfixExpression>({
 				}""""""
 			assertThat(subject.lint(code)).hasSize(2)
 		}
+
+		it(""should not report field increments"") {
+			val code = """"""
+				class Test {
+					private var runningId: Long = 0
+
+					fun increment() {
+						runningId++
+					}
+
+					fun getId(): Long {
+						return runningId++
+					}
+				}
+				""""""
+			assertThat(subject.lint(code)).isEmpty()
+		}
+
+		it(""should detect properties shadowing fields that are incremented"") {
+			val code = """"""
+				class Test {
+					private var runningId: Long = 0
+
+					fun getId(): Long {
+						val runningId: Long = 0
+						return runningId++
+					}
+				}
+				""""""
+			assertThat(subject.lint(code)).hasSize(1)
+		}
 	}
 })","['detekt-rules/src/main/kotlin/io/gitlab/arturbosch/detekt/rules/bugs/UselessPostfixExpression.kt', 'detekt-rules/src/test/kotlin/io/gitlab/arturbosch/detekt/rules/bugs/UselessPostfixExpressionSpec.kt']",{'.kt': 2},2,0,2,0,2,317375,77920,9732,234,1011,233,32,1,288,47,63,11,0,1,2017-10-11 06:22:38,5576,Kotlin,"{'Kotlin': 3859835, 'MDX': 123649, 'JavaScript': 30545, 'HTML': 21009, 'CSS': 2763, 'Java': 852, 'Shell': 249}",Apache License 2.0,['detekt-rules/src/main/kotlin/io/gitlab/arturbosch/detekt/rules/bugs/UselessPostfixExpression.kt'],['detekt-rules/src/main/kotlin/io/gitlab/arturbosch/detekt/rules/bugs/UselessPostfixExpression.kt'],"['```json\n{\n  ""files"": [\n    ""detekt-rules/src/main/kotlin/io/gitlab/arturbosch/detekt/rules/bugs/UselessPostfixExpression.kt""\n  ]\n}\n```']",1,1176.107406616211
1528,cashapp/sqldelight/2516/2382,cashapp,sqldelight,https://github.com/cashapp/sqldelight/issues/2382,https://github.com/cashapp/sqldelight/pull/2516,https://github.com/cashapp/sqldelight/pull/2516,1,closes,java.lang.NullPointerException in SqlDelightFoldingBuilder.kt:79,"## Error in SQL Delight IntelliJ Plugin

**java.lang.NullPointerException** in **SqlDelightFoldingBuilder.kt:79**
nextSibling must not be null

[View on Bugsnag](https://app.bugsnag.com/square-inc/sql-delight-intellij-plugin/errors/60967a6f7d8e8d000751a733?event_id=60967a6f007a892c354a0000&i=gh&m=ci)

## Stacktrace

    SqlDelightFoldingBuilder.kt:79 - com.squareup.sqldelight.intellij.lang.SqlDelightFoldingBuilder.toCreateTableDescriptor
    SqlDelightFoldingBuilder.kt:56 - com.squareup.sqldelight.intellij.lang.SqlDelightFoldingBuilder.createFoldingDescriptors
    SqlDelightFoldingBuilder.kt:39 - com.squareup.sqldelight.intellij.lang.SqlDelightFoldingBuilder.buildFoldRegions

[View full stacktrace](https://app.bugsnag.com/square-inc/sql-delight-intellij-plugin/errors/60967a6f7d8e8d000751a733?event_id=60967a6f007a892c354a0000&i=gh&m=ci)

*Created automatically via Bugsnag*",c615037309c7cda6dd20b6076ef0ee91c5739825,4f9b87fda7d6ae2dd96ba3094c7e42ceaa5e8dc7,https://github.com/cashapp/sqldelight/compare/c615037309c7cda6dd20b6076ef0ee91c5739825...4f9b87fda7d6ae2dd96ba3094c7e42ceaa5e8dc7,"diff --git a/sqldelight-idea-plugin/src/main/kotlin/com/squareup/sqldelight/intellij/lang/SqlDelightFoldingBuilder.kt b/sqldelight-idea-plugin/src/main/kotlin/com/squareup/sqldelight/intellij/lang/SqlDelightFoldingBuilder.kt
index cb35f7e56..f4057b916 100644
--- a/sqldelight-idea-plugin/src/main/kotlin/com/squareup/sqldelight/intellij/lang/SqlDelightFoldingBuilder.kt
+++ b/sqldelight-idea-plugin/src/main/kotlin/com/squareup/sqldelight/intellij/lang/SqlDelightFoldingBuilder.kt
@@ -76,7 +76,7 @@ class SqlDelightFoldingBuilder : FoldingBuilder, DumbAware {
   private fun PsiElement.toCreateTableDescriptor(createTableStmt: PsiElement?): FoldingDescriptor? {
     val openingBraceElement = createTableStmt?.node?.findChildByType(SqlTypes.LP) ?: return null
     val start = openingBraceElement.startOffset
-    val end = nextSibling.endOffset
+    val end = nextSibling?.endOffset ?: 0
     if (start >= end) return null
     return FoldingDescriptor(this, start, end, null, ""(...);"")
   }",['sqldelight-idea-plugin/src/main/kotlin/com/squareup/sqldelight/intellij/lang/SqlDelightFoldingBuilder.kt'],{'.kt': 1},1,0,1,0,1,511692,114734,14522,208,79,22,2,1,884,36,270,16,2,0,2021-08-06 08:09:28,5384,Kotlin,"{'Kotlin': 1791719, 'Assembly': 42765, 'Java': 11038, 'JavaScript': 4786, 'HTML': 1924, 'Dockerfile': 310, 'Shell': 188}",Apache License 2.0,['sqldelight-idea-plugin/src/main/kotlin/com/squareup/sqldelight/intellij/lang/SqlDelightFoldingBuilder.kt'],['sqldelight-idea-plugin/src/main/kotlin/com/squareup/sqldelight/intellij/lang/SqlDelightFoldingBuilder.kt'],"['```json\n{\n  ""files"": [\n    ""sqldelight-idea-plugin/src/main/kotlin/com/squareup/sqldelight/intellij/lang/SqlDelightFoldingBuilder.kt""\n  ]\n}\n```']",1,1053.1415939331055
1936,kotlin/kotlinx.serialization/1257/1251,kotlin,kotlinx.serialization,https://github.com/Kotlin/kotlinx.serialization/issues/1251,https://github.com/Kotlin/kotlinx.serialization/pull/1257,https://github.com/Kotlin/kotlinx.serialization/pull/1257,1,fixes,"A compiler-generated serializer for a Collection property works, serializer<Collection<…>>() does not","**Describe the bug**

- A property of type `Collection<String>` is serialized as `[ … ]`.
- Serializing a value of type `Collection<String>` using `serializer<Collection<String>>()` fails with an error.

**To Reproduce**
```kt
@Serializable
class Foo(val value: Collection<String>)

fun main() {
    val foo = Foo(listOf(""foo""))
    val bar: Collection<String> = listOf(""bar"")

    println(Json.encodeToString(foo)) // outputs {""value"":[""foo""]}
    println(Json.encodeToString(bar)) // Class 'SingletonList' is not registered for polymorphic serialization in the scope of 'Collection'.
}
```

**Expected behavior**
`Collection` should consistently be serialized as a list, independent of the actual implementation of `Collection`.

Should output:
```
{""value"":[""foo""]}
[""bar""]
```

**Environment**
 - Kotlin version: 1.4.21
 - Library version: 1.0.1
 - Kotlin platforms: JVM
 - Gradle version: 6.5.1",5bae104ffdf56af8f008cd4c72ef92cad2de3022,2c7f07709ba38b98a5e9af886f52c501aa18fef7,https://github.com/kotlin/kotlinx.serialization/compare/5bae104ffdf56af8f008cd4c72ef92cad2de3022...2c7f07709ba38b98a5e9af886f52c501aa18fef7,"diff --git a/core/commonMain/src/kotlinx/serialization/Serializers.kt b/core/commonMain/src/kotlinx/serialization/Serializers.kt
index 4087c884..cae088de 100644
--- a/core/commonMain/src/kotlinx/serialization/Serializers.kt
+++ b/core/commonMain/src/kotlinx/serialization/Serializers.kt
@@ -79,7 +79,7 @@ private fun SerializersModule.builtinSerializerOrNull(
         .map(::serializer)
     // Array is not supported, see KT-32839
     return when (rootClass) {
-        List::class, MutableList::class, ArrayList::class -> ArrayListSerializer(serializers[0])
+        Collection::class, List::class, MutableList::class, ArrayList::class -> ArrayListSerializer(serializers[0])
         HashSet::class -> HashSetSerializer(serializers[0])
         Set::class, MutableSet::class, LinkedHashSet::class -> LinkedHashSetSerializer(serializers[0])
         HashMap::class -> HashMapSerializer(serializers[0], serializers[1])
diff --git a/core/jvmMain/src/kotlinx/serialization/SerializersJvm.kt b/core/jvmMain/src/kotlinx/serialization/SerializersJvm.kt
index 83d9b92a..901e633d 100644
--- a/core/jvmMain/src/kotlinx/serialization/SerializersJvm.kt
+++ b/core/jvmMain/src/kotlinx/serialization/SerializersJvm.kt
@@ -47,8 +47,8 @@ public fun SerializersModule.serializer(type: Type): KSerializer<Any> = when (ty
         val rootClass = (type.rawType as Class<*>)
         val args = (type.actualTypeArguments)
         when {
-            List::class.java.isAssignableFrom(rootClass) -> ListSerializer(serializer(args[0])) as KSerializer<Any>
             Set::class.java.isAssignableFrom(rootClass) -> SetSerializer(serializer(args[0])) as KSerializer<Any>
+            List::class.java.isAssignableFrom(rootClass) || Collection::class.java.isAssignableFrom(rootClass) -> ListSerializer(serializer(args[0])) as KSerializer<Any>
             Map::class.java.isAssignableFrom(rootClass) -> MapSerializer(
                 serializer(args[0]),
                 serializer(args[1])
diff --git a/formats/json/commonTest/src/kotlinx/serialization/SerializersLookupTest.kt b/formats/json/commonTest/src/kotlinx/serialization/SerializersLookupTest.kt
index f447b7d4..c40d8f9f 100644
--- a/formats/json/commonTest/src/kotlinx/serialization/SerializersLookupTest.kt
+++ b/formats/json/commonTest/src/kotlinx/serialization/SerializersLookupTest.kt
@@ -6,9 +6,7 @@ package kotlinx.serialization
 
 import kotlinx.serialization.builtins.*
 import kotlinx.serialization.descriptors.*
-import kotlinx.serialization.descriptors.PrimitiveSerialDescriptor
 import kotlinx.serialization.encoding.*
-import kotlinx.serialization.internal.*
 import kotlinx.serialization.json.*
 import kotlinx.serialization.modules.*
 import kotlinx.serialization.test.*
@@ -45,6 +43,13 @@ class SerializersLookupTest : JsonTestBase() {
         assertSerializedWithType(""""""[""a"",""b"",""c""]"""""", myArr)
     }
 
+    @Test
+    fun testListAsCollection() {
+        val myArr: Collection<String> = listOf(""a"", ""b"", ""c"")
+        assertSerializedWithType(""""""[""a"",""b"",""c""]"""""", myArr)
+    }
+
+
     @Test
     fun testPrimitiveSet() {
         val mySet = setOf(""a"", ""b"", ""c"", ""c"")
diff --git a/formats/json/jvmTest/src/kotlinx/serialization/features/SerializerByTypeTest.kt b/formats/json/jvmTest/src/kotlinx/serialization/features/SerializerByTypeTest.kt
index 46162e09..b29c6694 100644
--- a/formats/json/jvmTest/src/kotlinx/serialization/features/SerializerByTypeTest.kt
+++ b/formats/json/jvmTest/src/kotlinx/serialization/features/SerializerByTypeTest.kt
@@ -78,6 +78,19 @@ class SerializerByTypeTest {
         assertEquals(""""""[""a"",""b"",""c""]"""""", s)
     }
 
+    @Test
+    fun testListAsCollection() {
+        val myArr: Collection<String> = listOf(""a"", ""b"", ""c"")
+        val token = object : ParameterizedType {
+            override fun getRawType(): Type = Collection::class.java
+            override fun getOwnerType(): Type? = null
+            override fun getActualTypeArguments(): Array<Type> = arrayOf(String::class.java)
+        }
+        val serial = serializer(token)
+        val s = json.encodeToString(serial, myArr)
+        assertEquals(""""""[""a"",""b"",""c""]"""""", s)
+    }
+
 
     @Test
     fun testReifiedArrayResolving() {","['formats/json/commonTest/src/kotlinx/serialization/SerializersLookupTest.kt', 'core/commonMain/src/kotlinx/serialization/Serializers.kt', 'formats/json/jvmTest/src/kotlinx/serialization/features/SerializerByTypeTest.kt', 'core/jvmMain/src/kotlinx/serialization/SerializersJvm.kt']",{'.kt': 4},4,0,4,0,4,620363,133192,16463,196,501,98,4,2,931,109,222,33,0,2,2020-12-18 14:11:18,4616,Kotlin,"{'Kotlin': 1874921, 'Shell': 1546, 'Java': 1343}",Apache License 2.0,"['core/commonMain/src/kotlinx/serialization/internal/ObjectSerializer.kt', 'core/commonMain/src/kotlinx/serialization/internal/NullableSerializer.kt', 'core/commonMain/src/kotlinx/serialization/internal/Primitives.kt', 'core/commonMain/src/kotlinx/serialization/internal/CollectionSerializers.kt', 'core/commonMain/src/kotlinx/serialization/internal/CollectionDescriptors.kt']","['core/commonMain/src/kotlinx/serialization/internal/ObjectSerializer.kt', 'core/commonMain/src/kotlinx/serialization/internal/NullableSerializer.kt', 'core/commonMain/src/kotlinx/serialization/internal/Primitives.kt', 'core/commonMain/src/kotlinx/serialization/internal/CollectionSerializers.kt', 'core/commonMain/src/kotlinx/serialization/internal/CollectionDescriptors.kt']","['```json\n{\n  ""files"": [\n    ""core/commonMain/src/kotlinx/serialization/internal/CollectionSerializers.kt"",\n    ""core/commonMain/src/kotlinx/serialization/internal/CollectionDescriptors.kt"",\n    ""core/commonMain/src/kotlinx/serialization/internal/Primitives.kt"",\n    ""core/commonMain/src/kotlinx/serialization/internal/NullableSerializer.kt"",\n    ""core/commonMain/src/kotlinx/serialization/internal/ObjectSerializer.kt""\n  ]\n}\n```']",1,1630.1195621490479
1706,intellij-rust/intellij-rust/9545/9543,intellij-rust,intellij-rust,https://github.com/intellij-rust/intellij-rust/issues/9543,https://github.com/intellij-rust/intellij-rust/pull/9545,https://github.com/intellij-rust/intellij-rust/pull/9545,2,fixes,completion failed when typing “.unwrap()”,"## Environment

* **IntelliJ Rust plugin version:** 0.4.180.4932-222
* **Rust toolchain version:** stable-x86_64-pc-windows-msvc rustc 1.64.0 (a55dd71d5 2022-09-19)
* **IDE name and version:** CLion 2022.2.4 CL-222.4345.21
* **Operating system:** windows 11 

## Problem description 
completion failed when typing “.unwrap()”

## Steps to reproduce

```rust
use std::mem::size_of;
use windows::core::*;
use windows::Win32::Foundation::*;
use windows::Win32::Graphics::Gdi::{GetStockObject, GRAY_BRUSH, HBRUSH};
use windows::Win32::System::LibraryLoader::*;
use windows::Win32::UI::WindowsAndMessaging::*;

pub struct Window {
    window:HWND,
}

impl Window {
    pub fn create(title:String,width:i32,height:i32)->Window{
        unsafe {
            let style = WS_VISIBLE|WS_OVERLAPPEDWINDOW;
            let mut rect = RECT{
                left : 0,
                top : 0,
                right : width,
                bottom : height,
            };
            AdjustWindowRect(&mut rect,style,BOOL(0));
            let wc = WNDCLASSEXW{
                cbSize : size_of::<WNDCLASSEXW>() as u32,
                style : CS_HREDRAW|CS_VREDRAW,
                lpfnWndProc : Some(Window::window_proc),
                /*
                    hInstance : GetModuleHandleW(None).un... <- Completion Failed
                 */
                _hInstance : GetModuleHandleW(None).unwrap(),_   //<- Here
                lpszClassName : w!(""ClassName"").into(),
                hbrBackground : HBRUSH(GetStockObject(GRAY_BRUSH).0),
                ..Default::default()
            };
            println!(""0:{}"",GetLastError().0);
            RegisterClassExW(&wc);
            println!(""1:{}"",GetLastError().0);
            let hwnd = CreateWindowExW(
                WINDOW_EX_STYLE::default(),
                w!(""ClassName""),
                &HSTRING::from(title).into(),
                style,
                CW_USEDEFAULT,CW_USEDEFAULT,
                rect.right-rect.left,
                rect.bottom-rect.top,
                None,None,
                GetModuleHandleW(None).unwrap(),
                None
            );
            println!(""2:{}"",GetLastError().0);
            assert_ne!(hwnd.0, 0);
            ShowWindow(hwnd,SW_SHOW);
            Window{
                window:hwnd,
            }
        }
    }
    pub fn pump_message(&self)->bool{
        unsafe {
            let mut msg = MSG::default();
            while PeekMessageW(&mut msg,None,0,0,PM_REMOVE).into() {
                if msg.message == WM_QUIT {
                    return false;
                }
                TranslateMessage(&msg);
                DispatchMessageW(&msg);
            }
        true
        }
    }
    extern ""system"" fn window_proc(window: HWND, message: u32, wparam: WPARAM, lparam: LPARAM)->LRESULT{
        unsafe{
            if message == WM_DESTROY {
                PostQuitMessage(0);
            }
            DefWindowProcW(window,message,wparam,lparam)
        }
    }
}

impl Drop for Window {
    fn drop(&mut self) {
        unsafe {
            UnregisterClassW(w!(""ClassName""),GetModuleHandleW(None).unwrap());
            println!(""3:{}"",GetLastError().0);
        }
    }
}
```",04debb2bc0353af091d764e31a68e30f85c5f312,dc6b635428bc3b56d18b3c76e0c0d2f4c2886fd9,https://github.com/intellij-rust/intellij-rust/compare/04debb2bc0353af091d764e31a68e30f85c5f312...dc6b635428bc3b56d18b3c76e0c0d2f4c2886fd9,"diff --git a/src/main/kotlin/org/rust/lang/core/resolve/NameResolution.kt b/src/main/kotlin/org/rust/lang/core/resolve/NameResolution.kt
index d3168a677..86b273c7d 100644
--- a/src/main/kotlin/org/rust/lang/core/resolve/NameResolution.kt
+++ b/src/main/kotlin/org/rust/lang/core/resolve/NameResolution.kt
@@ -257,6 +257,20 @@ fun processModDeclResolveVariants(modDecl: RsModDeclItem, processor: RsResolvePr
     return false
 }
 
+/**
+ * Variants from [processExternCrateResolveVariants] + all renamings `extern crate name as alias;`
+ * See https://doc.rust-lang.org/reference/names/preludes.html#extern-prelude
+ */
+fun processExternPreludeResolveVariants(ctx: PathResolutionContext, processor: RsResolveProcessor): Boolean {
+    val (project, defMap) = ctx.containingModInfo ?: return false
+    for ((name, externCrateDefMap) in defMap.externPrelude.entriesWithNames(processor.names)) {
+        val externCrateRoot = externCrateDefMap.rootAsRsMod(project) ?: continue
+        if (processor(name, externCrateRoot)) return true
+    }
+    return false
+}
+
+/** Processes dependencies crates (specified in Cargo.toml) */
 fun processExternCrateResolveVariants(
     element: RsElement,
     isCompletion: Boolean,
@@ -371,7 +385,7 @@ fun processPathResolveVariants(ctx: PathResolutionContext, pathKind: RsPathResol
             }
         }
         is RsPathResolveKind.ExternCratePath -> {
-            processExternCrateResolveVariants(ctx.crateRoot ?: ctx.context, ctx.isCompletion, processor)
+            processExternPreludeResolveVariants(ctx, processor)
         }
         is RsPathResolveKind.AssocTypeBindingPath -> {
             processAssocTypeVariants(pathKind.parent, processor)
diff --git a/src/main/kotlin/org/rust/lang/core/resolve/PathResolutionContext.kt b/src/main/kotlin/org/rust/lang/core/resolve/PathResolutionContext.kt
index f50ac5bca..29672dd0c 100644
--- a/src/main/kotlin/org/rust/lang/core/resolve/PathResolutionContext.kt
+++ b/src/main/kotlin/org/rust/lang/core/resolve/PathResolutionContext.kt
@@ -29,6 +29,7 @@ class PathResolutionContext(
     var lazyContainingModInfo: Lazy<RsModInfo?> = lazy(NONE) {
         getModInfo(containingMod)
     }
+    val containingModInfo: RsModInfo? get() = lazyContainingModInfo.value
     val implLookup: ImplLookup by lazy(NONE) {
         givenImplLookup ?: ImplLookup.relativeTo(context)
     }
diff --git a/src/main/kotlin/org/rust/lang/core/resolve2/FacadeResolve.kt b/src/main/kotlin/org/rust/lang/core/resolve2/FacadeResolve.kt
index 3bc22e35c..5b7341ed4 100644
--- a/src/main/kotlin/org/rust/lang/core/resolve2/FacadeResolve.kt
+++ b/src/main/kotlin/org/rust/lang/core/resolve2/FacadeResolve.kt
@@ -86,10 +86,7 @@ fun processItemDeclarationsUsingModInfo(
             val existingItemInScope = modData.visibleItems[name]
             if (existingItemInScope != null && existingItemInScope.types.any { !it.visibility.isInvisible }) continue
 
-            val externCrateRoot = externCrateDefMap.root.toRsMod(info)
-                // crate root can't multiresolve
-                .singleOrNull()
-                ?: continue
+            val externCrateRoot = externCrateDefMap.rootAsRsMod(info.project) ?: continue
             processor(name, externCrateRoot) && return true
         }
     }
@@ -465,7 +462,7 @@ private fun isModShadowedByOtherMod(mod: RsMod, modData: ModData, crate: Crate):
     }
 }
 
-private fun <T> Map<String, T>.entriesWithNames(names: Set<String>?): Map<String, T> {
+fun <T> Map<String, T>.entriesWithNames(names: Set<String>?): Map<String, T> {
     return if (names.isNullOrEmpty()) {
         this
     } else if (names.size == 1) {
@@ -646,6 +643,8 @@ private fun ModData.toRsModNullable(project: Project): List<RsMod> {
         }
 }
 
+fun CrateDefMap.rootAsRsMod(project: Project): RsMod? = root.toRsMod(project).singleOrNull()
+
 private inline fun <reified T : RsNamedElement> RsItemsOwner.getExpandedItemsWithName(name: String): List<T> =
     expandedItemsCached.named[name]?.filterIsInstance<T>() ?: emptyList()
 
diff --git a/src/test/kotlin/org/rust/lang/core/completion/RsCompletionTestBase.kt b/src/test/kotlin/org/rust/lang/core/completion/RsCompletionTestBase.kt
index 71e2207c4..1d34f174e 100644
--- a/src/test/kotlin/org/rust/lang/core/completion/RsCompletionTestBase.kt
+++ b/src/test/kotlin/org/rust/lang/core/completion/RsCompletionTestBase.kt
@@ -80,6 +80,12 @@ abstract class RsCompletionTestBase(private val defaultFileName: String = ""main.
         render: LookupElement.() -> String = { lookupString }
     ) = completionFixture.checkContainsCompletion(code, variants, render)
 
+    protected fun checkContainsCompletionByFileTree(
+        variant: String,
+        @Language(""Rust"") code: String,
+        render: LookupElement.() -> String = { lookupString }
+    ) = completionFixture.checkContainsCompletionByFileTree(code, listOf(variant), render)
+
     protected fun checkContainsCompletionByFileTree(
         variants: List<String>,
         @Language(""Rust"") code: String,
diff --git a/src/test/kotlin/org/rust/lang/core/completion/RsCompletionTestFixtureBase.kt b/src/test/kotlin/org/rust/lang/core/completion/RsCompletionTestFixtureBase.kt
index 7d6eb3f11..3e35f8d8a 100644
--- a/src/test/kotlin/org/rust/lang/core/completion/RsCompletionTestFixtureBase.kt
+++ b/src/test/kotlin/org/rust/lang/core/completion/RsCompletionTestFixtureBase.kt
@@ -82,22 +82,26 @@ abstract class RsCompletionTestFixtureBase<IN>(
         }
     }
 
-    fun checkContainsCompletion(
-        code: IN,
-        variants: Iterable<String>,
-        render: LookupElement.() -> String = { lookupString }
-    ) {
+    private fun withNoInsertCompletion(action: () -> Unit) {
         val oldAutocomplete = CodeInsightSettings.getInstance().AUTOCOMPLETE_ON_CODE_COMPLETION
         CodeInsightSettings.getInstance().AUTOCOMPLETE_ON_CODE_COMPLETION = false
         try {
-            prepare(code)
-            doContainsCompletion(variants.toSet(), render)
+            action()
         } finally {
             CodeInsightSettings.getInstance().AUTOCOMPLETE_ON_CODE_COMPLETION = oldAutocomplete
         }
     }
 
-    fun doContainsCompletion(variants: Set<String>, render: LookupElement.() -> String) {
+    fun checkContainsCompletion(
+        code: IN,
+        variants: Iterable<String>,
+        render: LookupElement.() -> String = { lookupString }
+    ) {
+        prepare(code)
+        doContainsCompletion(variants.toSet(), render)
+    }
+
+    fun doContainsCompletion(variants: Set<String>, render: LookupElement.() -> String) = withNoInsertCompletion {
         val lookups = myFixture.completeBasic()
 
         checkNotNull(lookups) {
@@ -115,7 +119,7 @@ abstract class RsCompletionTestFixtureBase<IN>(
         code: IN,
         variants: Set<String>,
         render: LookupElement.() -> String = { lookupString }
-    ) {
+    ) = withNoInsertCompletion {
         prepare(code)
         val lookups = myFixture.completeBasic()
         checkNotNull(lookups) {
@@ -126,7 +130,7 @@ abstract class RsCompletionTestFixtureBase<IN>(
         }
     }
 
-    fun checkContainsCompletionPrefixes(code: IN, prefixes: List<String>) {
+    fun checkContainsCompletionPrefixes(code: IN, prefixes: List<String>) = withNoInsertCompletion {
         prepare(code)
         val lookups = myFixture.completeBasic()
 
diff --git a/src/test/kotlin/org/rust/lang/core/completion/RsExternCrateCompletionTest.kt b/src/test/kotlin/org/rust/lang/core/completion/RsExternCrateCompletionTest.kt
index 1a923c58a..3bd0cd10d 100644
--- a/src/test/kotlin/org/rust/lang/core/completion/RsExternCrateCompletionTest.kt
+++ b/src/test/kotlin/org/rust/lang/core/completion/RsExternCrateCompletionTest.kt
@@ -35,4 +35,37 @@ class RsExternCrateCompletionTest : RsCompletionTestBase() {
     fun `test extern crate does not suggest transitive dependency`() = checkNoCompletion(""""""
         extern crate trans_l/*caret*/
     """""")
+
+    fun `test absolute path suggest dependency`() = checkContainsCompletionByFileTree(""test_package"", """"""
+    //- lib.rs
+    //- main.rs
+        fn main() {
+            ::test_packa/*caret*/
+        }
+    """""")
+
+    fun `test absolute path suggest std`() = checkContainsCompletionByFileTree(""std"", """"""
+    //- lib.rs
+    //- main.rs
+        fn main() {
+            ::st/*caret*/
+        }
+    """""")
+
+    fun `test absolute path suggest aliased extern crate`() = checkContainsCompletionByFileTree(
+        listOf(""test_package"", ""test_package2""), """"""
+    //- lib.rs
+    //- main.rs
+        extern crate test_package as test_package2;
+        fn main() {
+            ::test_packa/*caret*/
+        }
+    """""")
+
+    fun `test absolute path don't suggest self`() = checkNoCompletionByFileTree(""""""
+    //- lib.rs
+        fn main() {
+            ::self/*caret*/
+        }
+    """""")
 }
diff --git a/src/test/kotlin/org/rust/lang/core/resolve/RsPackageLibraryResolveTest.kt b/src/test/kotlin/org/rust/lang/core/resolve/RsPackageLibraryResolveTest.kt
index 763f3f441..1410eaf68 100644
--- a/src/test/kotlin/org/rust/lang/core/resolve/RsPackageLibraryResolveTest.kt
+++ b/src/test/kotlin/org/rust/lang/core/resolve/RsPackageLibraryResolveTest.kt
@@ -765,6 +765,35 @@ class RsPackageLibraryResolveTest : RsResolveTestBase() {
                                    //^ dep-lib/lib.rs
     """""")
 
+    fun `test absolute path using aliased extern crate 1`() = stubOnlyResolve(""""""
+    //- lib.rs
+        pub fn func() {}
+    //- main.rs
+        extern crate test_package as foo;
+
+        fn main() {
+            ::foo::func();
+        }        //^ lib.rs
+    """""")
+
+    fun `test absolute path using aliased extern crate 2`() = stubOnlyResolve(""""""
+    //- lib.rs
+        extern crate self as foo;
+
+        fn main() {
+            ::foo::func();
+        }        //^ lib.rs
+        pub fn func() {}
+    """""")
+
+    fun `test unresolved absolute path self`() = stubOnlyResolve(""""""
+    //- lib.rs
+        pub fn func() {}
+        fn main() {
+            ::self::func();
+        }         //^ unresolved
+    """""")
+
     fun `test extern crate in super chain (edition 2018)`() = stubOnlyResolve(""""""
     //- dep-lib/lib.rs
         pub struct Foo;","['src/test/kotlin/org/rust/lang/core/completion/RsCompletionTestBase.kt', 'src/test/kotlin/org/rust/lang/core/completion/RsCompletionTestFixtureBase.kt', 'src/main/kotlin/org/rust/lang/core/resolve/PathResolutionContext.kt', 'src/test/kotlin/org/rust/lang/core/completion/RsExternCrateCompletionTest.kt', 'src/test/kotlin/org/rust/lang/core/resolve/RsPackageLibraryResolveTest.kt', 'src/main/kotlin/org/rust/lang/core/resolve/NameResolution.kt', 'src/main/kotlin/org/rust/lang/core/resolve2/FacadeResolve.kt']",{'.kt': 7},7,0,7,0,7,5283829,1159755,137408,1263,1481,354,26,3,3314,226,755,102,0,1,2022-10-16 05:26:03,4385,Kotlin,"{'Kotlin': 10774035, 'Rust': 169226, 'Python': 110372, 'HTML': 22176, 'Lex': 12189, 'ANTLR': 3304, 'Java': 688, 'RenderScript': 481, 'Shell': 377}",MIT License,"['src/main/kotlin/org/rust/lang/core/psi/ext/RsPath.kt', 'src/main/kotlin/org/rust/lang/core/psi/ext/RsReferenceElement.kt', 'src/main/kotlin/org/rust/ide/annotator/fixes/ApplySuggestionFix.kt', 'src/main/kotlin/org/rust/ide/annotator/fixes/ConvertToTyFix.kt', 'src/main/kotlin/org/rust/lang/core/psi/ext/RsPathReferenceElement.kt', 'src/main/kotlin/org/rust/lang/core/dfa/borrowck/gatherLoans/GatherMoves.kt', 'src/main/kotlin/org/rust/ide/annotator/fixes/ChangeFunctionSignatureFix.kt', 'src/main/kotlin/org/rust/lang/core/psi/ext/RsMethodOrPath.kt', 'src/main/kotlin/org/rust/ide/annotator/fixes/ChangeReturnTypeFix.kt', 'src/main/kotlin/org/rust/ide/annotator/fixes/ConvertToTyUsingFromTraitFix.kt', 'src/main/kotlin/org/rust/lang/core/psi/ext/RsMethodCall.kt']","['src/main/kotlin/org/rust/ide/annotator/fixes/ApplySuggestionFix.kt', 'src/main/kotlin/org/rust/ide/annotator/fixes/ConvertToTyFix.kt', 'src/main/kotlin/org/rust/ide/annotator/fixes/ChangeFunctionSignatureFix.kt', 'src/main/kotlin/org/rust/ide/annotator/fixes/ChangeReturnTypeFix.kt', 'src/main/kotlin/org/rust/ide/annotator/fixes/ConvertToTyUsingFromTraitFix.kt']","['```json\n{\n  ""files"": [\n    ""src/main/kotlin/org/rust/ide/annotator/fixes/ApplySuggestionFix.kt"",\n    ""src/main/kotlin/org/rust/ide/annotator/fixes/ChangeFunctionSignatureFix.kt"",\n    ""src/main/kotlin/org/rust/ide/annotator/fixes/ChangeReturnTypeFix.kt"",\n    ""src/main/kotlin/org/rust/ide/annotator/fixes/ConvertToTyFix.kt"",\n    ""src/main/kotlin/org/rust/ide/annotator/fixes/ConvertToTyUsingFromTraitFix.kt""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""src/main/kotlin/org/rust/lang/core/psi/ext/RsMethodCall.kt"",\n    ""src/main/kotlin/org/rust/lang/core/psi/ext/RsPath.kt"",\n    ""src/main/kotlin/org/rust/lang/core/psi/ext/RsPathReferenceElement.kt"",\n    ""src/main/kotlin/org/rust/lang/core/psi/ext/RsReferenceElement.kt"",\n    ""src/main/kotlin/org/rust/lang/core/psi/ext/RsMethodOrPath.kt""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""src/main/kotlin/org/rust/lang/core/dfa/borrowck/gatherLoans/GatherMoves.kt""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""src/main/kotlin/org/rust/ide/annotator/fixes/ApplySuggestionFix.kt"",\n    ""src/main/kotlin/org/rust/ide/annotator/fixes/ConvertToTyFix.kt"",\n    ""src/main/kotlin/org/rust/ide/annotator/fixes/ChangeFunctionSignatureFix.kt"",\n    ""src/main/kotlin/org/rust/ide/annotator/fixes/ChangeReturnTypeFix.kt"",\n    ""src/main/kotlin/org/rust/ide/annotator/fixes/ConvertToTyUsingFromTraitFix.kt""\n  ]\n}\n```']",3,7973.976373672485
1700,intellij-rust/intellij-rust/9695/9414,intellij-rust,intellij-rust,https://github.com/intellij-rust/intellij-rust/issues/9414,https://github.com/intellij-rust/intellij-rust/pull/9695,https://github.com/intellij-rust/intellij-rust/pull/9695,2,fixes,custom target spec not resolved correctly,"<!--
Hello and thank you for the issue!
If you would like to report a bug, we have added some points below that you can fill out.
Consider using ""Help | Create New Issue"" action that fills out all necessary information automatically.
Feel free to remove all the irrelevant text to request a new feature.
-->

## Environment

* **IntelliJ Rust plugin version:** 0.4.179.4903-221
* **Rust toolchain version:** 1.63.0 & 1.64.0 (displayed in settings, actually 1.66 nightly)
* **IDE name and version:** CLion 2022.1.3, Build #CL-221.5921.27, built on June 21, 2022
* **Operating system:** macOS 12.5.1, 12.6 (Intel & M2 chip)

## Problem description
When having a relative path to a custom target definition json file in `.cargo/config.toml`, `Refresh Cargo project` fails with

```text
Execution failed (exit code 101).
/Users/tsatke/.cargo/bin/cargo +nightly-aarch64-apple-darwin metadata --verbose --format-version 1 --all-features --filter-platform x86_64-martim.json
stdout : error: target path ""x86_64-martim.json"" is not a valid file

Caused by:
  No such file or directory (os error 2)

stderr : 

```

## Steps to reproduce

Put the following into `.cargo/config.toml`.

```toml
[build]
target = ""x86_64-martim.json""
```

The file is valid and is located in the project root.

When executing the above command manually in the project root, it succeeds and prints a lot of information (as is probably expected). **Changing the target path to an absolute one makes the problems disappear**, which makes me think that the command may be executed in the wrong directory?

<!--
Please include as much of your codebase as needed to reproduce the error.
If the relevant files are large, please provide a link to a public repository or a [Gist](https://gist.github.com/).

If you provide a screenshot of some code, please also copy-paste the corresponding code snippet here.
-->
",cf91f6420b33f93d9393e7d940fa19b5d7a377bb,cb6901c127a8169cc8080ff24161f07dc5c0f471,https://github.com/intellij-rust/intellij-rust/compare/cf91f6420b33f93d9393e7d940fa19b5d7a377bb...cb6901c127a8169cc8080ff24161f07dc5c0f471,"diff --git a/src/main/kotlin/org/rust/cargo/toolchain/tools/Cargo.kt b/src/main/kotlin/org/rust/cargo/toolchain/tools/Cargo.kt
index b6a7901a9..1e1f215a2 100644
--- a/src/main/kotlin/org/rust/cargo/toolchain/tools/Cargo.kt
+++ b/src/main/kotlin/org/rust/cargo/toolchain/tools/Cargo.kt
@@ -24,6 +24,7 @@ import com.intellij.openapi.util.registry.Registry
 import com.intellij.openapi.util.registry.RegistryValue
 import com.intellij.openapi.vfs.VirtualFile
 import com.intellij.util.execution.ParametersListUtil
+import com.intellij.util.io.systemIndependentPath
 import com.intellij.util.net.HttpConfigurable
 import com.intellij.util.text.SemVer
 import org.jetbrains.annotations.TestOnly
@@ -230,7 +231,7 @@ class Cargo(
      */
     fun getConfig(
         owner: Project,
-        projectDirectory: Path?
+        projectDirectory: Path
     ): RsResult<CargoConfig, RsProcessExecutionOrDeserializationException> {
         val parameters = mutableListOf(""-Z"", ""unstable-options"", ""config"", ""get"")
 
@@ -248,7 +249,7 @@ class Cargo(
         }
 
         val buildTargetNode = tree.at(""/build/target"")
-        val buildTarget = if (buildTargetNode.isMissingNode) null else buildTargetNode.asText()
+        var buildTarget = if (buildTargetNode.isMissingNode) null else buildTargetNode.asText()
         val env = tree.at(""/env"").fields().asSequence().toList().mapNotNull { field ->
             // Value can be either string or object with additional `forced` and `relative` params.
             // https://doc.rust-lang.org/cargo/reference/config.html#env
@@ -267,6 +268,12 @@ class Cargo(
             }
         }.toMap()
 
+        // If build target ends with `.json`, it's a custom toolchain.
+        // To make it work in all cases (for example, fetching stdlib metadata for the same build target),
+        // we save the corresponding path as absolute one not to depend on working directory
+        if (buildTarget != null && buildTarget.endsWith("".json"")) {
+            buildTarget = projectDirectory.resolve(buildTarget).toAbsolutePath().systemIndependentPath
+        }
         return Ok(CargoConfig(buildTarget, env))
     }
 
diff --git a/src/test/kotlin/org/rust/cargo/project/model/CargoPackagesTest.kt b/src/test/kotlin/org/rust/cargo/project/model/CargoPackagesTest.kt
index fb734297a..b90cb2639 100644
--- a/src/test/kotlin/org/rust/cargo/project/model/CargoPackagesTest.kt
+++ b/src/test/kotlin/org/rust/cargo/project/model/CargoPackagesTest.kt
@@ -90,6 +90,64 @@ class CargoPackagesTest : RsWithToolchainTestBase() {
         workspace.checkPackage(""windows_package"", shouldExist = true)
     }
 
+    @MinRustcVersion(""1.53.0"")
+    fun `test target specific dependencies with custom build target`() {
+        buildProject {
+            dir("".cargo"") {
+                toml(""config"", """"""
+                    [build]
+                    target = ""custom-target.json""
+                """""")
+            }
+            file(""custom-target.json"", """"""
+                {
+                    ""llvm-target"": ""aarch64-unknown-none"",
+                    ""data-layout"": ""e-m:e-i64:64-f80:128-n8:16:32:64-S128"",
+                    ""arch"": ""aarch64"",
+                    ""target-endian"": ""little"",
+                    ""target-pointer-width"": ""64"",
+                    ""target-c-int-width"": ""32"",
+                    ""os"": ""none"",
+                    ""executables"": true,
+                    ""linker-flavor"": ""ld.lld"",
+                    ""linker"": ""rust-lld"",
+                    ""panic-strategy"": ""abort"",
+                    ""disable-redzone"": true,
+                    ""features"": ""-mmx,-sse,+soft-float""
+                }
+            """""")
+            toml(""Cargo.toml"", """"""
+                [package]
+                name = ""sandbox""
+                version = ""0.1.0""
+                authors = []
+
+                [dependencies]
+                common_package = { path = ""common_package"" }
+
+                [target.'cfg(target_arch = ""aarch64"")'.dependencies]
+                arm_package = { path = ""arm_package"" }
+
+                [target.'cfg(target_arch = ""x86_64"")'.dependencies]
+                x86_package = { path = ""x86_package"" }
+            """""")
+
+            dir(""src"") {
+                rust(""lib.rs"", """")
+            }
+
+            dependencyPackage(""common_package"")
+            dependencyPackage(""arm_package"")
+            dependencyPackage(""x86_package"")
+        }
+
+        val workspace = project.cargoProjects.singleProject().workspaceOrFail()
+
+        workspace.checkPackage(""common_package"", shouldExist = true)
+        workspace.checkPackage(""arm_package"", shouldExist = true)
+        workspace.checkPackage(""x86_package"", shouldExist = false)
+    }
+
     private fun FileTreeBuilder.dependencyPackage(name: String) {
         dir(name) {
             toml(""Cargo.toml"", """"""
diff --git a/src/test/kotlin/org/rust/cargo/project/model/CargoStdlibPackagesTest.kt b/src/test/kotlin/org/rust/cargo/project/model/CargoStdlibPackagesTest.kt
index 53305412d..60afe4651 100644
--- a/src/test/kotlin/org/rust/cargo/project/model/CargoStdlibPackagesTest.kt
+++ b/src/test/kotlin/org/rust/cargo/project/model/CargoStdlibPackagesTest.kt
@@ -43,6 +43,48 @@ class CargoStdlibPackagesTest : RsWithToolchainTestBase() {
         }
     }
 
+    fun `test target specific dependencies with custom build target`() {
+        buildProject {
+            dir("".cargo"") {
+                toml(""config"", """"""
+                    [build]
+                    target = ""custom-target.json""
+                """""")
+            }
+            file(""custom-target.json"", """"""
+                {
+                    ""llvm-target"": ""aarch64-unknown-none"",
+                    ""data-layout"": ""e-m:e-i64:64-f80:128-n8:16:32:64-S128"",
+                    ""arch"": ""aarch64"",
+                    ""target-endian"": ""little"",
+                    ""target-pointer-width"": ""64"",
+                    ""target-c-int-width"": ""32"",
+                    ""os"": ""none"",
+                    ""executables"": true,
+                    ""linker-flavor"": ""ld.lld"",
+                    ""linker"": ""rust-lld"",
+                    ""panic-strategy"": ""abort"",
+                    ""disable-redzone"": true,
+                    ""features"": ""-mmx,-sse,+soft-float""
+                }
+            """""")
+            toml(""Cargo.toml"", """"""
+                [package]
+                name = ""sandbox""
+                version = ""0.1.0""
+                authors = []
+            """""")
+
+            dir(""src"") {
+                rust(""lib.rs"", """")
+            }
+        }
+
+        val workspace = project.cargoProjects.singleProject().workspaceOrFail()
+        val hashbrownPkg = workspace.packages.first { it.name == HASHBROWN }
+        assertEquals(PackageOrigin.STDLIB_DEPENDENCY, hashbrownPkg.origin)
+    }
+
     fun `test recover corrupted stdlib dependency directory`() {
         buildProject {
             toml(""Cargo.toml"", """"""
diff --git a/src/test/kotlin/org/rust/cargo/toolchain/CargoConfigTest.kt b/src/test/kotlin/org/rust/cargo/toolchain/CargoConfigTest.kt
index 412685a79..f8cfc999a 100644
--- a/src/test/kotlin/org/rust/cargo/toolchain/CargoConfigTest.kt
+++ b/src/test/kotlin/org/rust/cargo/toolchain/CargoConfigTest.kt
@@ -43,6 +43,40 @@ class CargoConfigTest : RsWithToolchainTestBase() {
         assertEquals(""wasm32-unknown-unknown"", buildTarget)
     }
 
+    fun `test custom build target`() {
+        val testProject = buildProject {
+            dir("".cargo"") {
+                toml(""config"", """"""
+                    [build]
+                    target = ""custom-target.json""
+                """""")
+            }
+            file(""custom-target.json"", """"""
+                {
+                    ""llvm-target"": ""aarch64-unknown-none"",
+                    ""data-layout"": ""e-m:e-i64:64-f80:128-n8:16:32:64-S128"",
+                    ""arch"": ""aarch64"",
+                    ""target-endian"": ""little"",
+                    ""target-pointer-width"": ""64"",
+                    ""target-c-int-width"": ""32"",
+                    ""os"": ""none"",
+                    ""executables"": true,
+                    ""linker-flavor"": ""ld.lld"",
+                    ""linker"": ""rust-lld"",
+                    ""panic-strategy"": ""abort"",
+                    ""disable-redzone"": true,
+                    ""features"": ""-mmx,-sse,+soft-float""
+                }
+            """""")
+            file(""Cargo.toml"", CARGO_TOML)
+            dir(""src"") { file(""main.rs"") }
+        }
+
+        val buildTarget = project.cargoProjects.singleWorkspace().cargoConfig.buildTarget
+
+        assertEquals(testProject.root.findChild(""custom-target.json"")!!.path, buildTarget)
+    }
+
     fun `test env`() {
         buildProject {
             dir("".cargo"") {","['src/test/kotlin/org/rust/cargo/toolchain/CargoConfigTest.kt', 'src/main/kotlin/org/rust/cargo/toolchain/tools/Cargo.kt', 'src/test/kotlin/org/rust/cargo/project/model/CargoPackagesTest.kt', 'src/test/kotlin/org/rust/cargo/project/model/CargoStdlibPackagesTest.kt']",{'.kt': 4},4,0,4,0,4,5328856,1170094,138599,1274,767,156,11,1,1924,284,485,49,1,2,2022-11-07 11:55:30,4385,Kotlin,"{'Kotlin': 10774035, 'Rust': 169226, 'Python': 110372, 'HTML': 22176, 'Lex': 12189, 'ANTLR': 3304, 'Java': 688, 'RenderScript': 481, 'Shell': 377}",MIT License,"['src/main/kotlin/org/rust/cargo/project/model/impl/CargoTomlWatcher.kt', 'src/main/kotlin/org/rust/cargo/project/workspace/CargoWorkspaceData.kt', 'src/main/kotlin/org/rust/cargo/project/model/impl/CargoProjectImpl.kt', 'src/main/kotlin/org/rust/cargo/project/model/impl/TestCargoProjectsServiceImpl.kt', 'src/main/kotlin/org/rust/cargo/project/workspace/PackageFeature.kt', 'src/main/kotlin/org/rust/cargo/project/workspace/CargoWorkspace.kt', 'src/main/kotlin/org/rust/cargo/project/workspace/FeatureGraph.kt', 'src/main/kotlin/org/rust/cargo/project/workspace/PackageOrigin.kt', 'src/main/kotlin/org/rust/cargo/project/model/impl/CargoSyncTask.kt', 'src/main/kotlin/org/rust/cargo/project/model/impl/CargoSettingsFilesService.kt']","['CargoTomlWatcher.kt', 'CargoSettingsFilesService.kt', 'CargoProjectImpl.kt']","['```json\n{\n  ""files"": [\n    ""src/main/kotlin/org/rust/cargo/project/workspace/CargoWorkspace.kt"",\n    ""src/main/kotlin/org/rust/cargo/project/workspace/CargoWorkspaceData.kt"",\n    ""src/main/kotlin/org/rust/cargo/project/workspace/FeatureGraph.kt"",\n    ""src/main/kotlin/org/rust/cargo/project/workspace/PackageFeature.kt"",\n    ""src/main/kotlin/org/rust/cargo/project/workspace/PackageOrigin.kt""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""src/main/kotlin/org/rust/cargo/project/model/impl/CargoSettingsFilesService.kt"",\n    ""src/main/kotlin/org/rust/cargo/project/model/impl/CargoProjectImpl.kt"",\n    ""src/main/kotlin/org/rust/cargo/project/model/impl/CargoSyncTask.kt"",\n    ""src/main/kotlin/org/rust/cargo/project/model/impl/CargoTomlWatcher.kt"",\n    ""src/main/kotlin/org/rust/cargo/project/model/impl/TestCargoProjectsServiceImpl.kt""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""CargoTomlWatcher.kt"",\n    ""CargoSettingsFilesService.kt"",\n    ""CargoProjectImpl.kt""\n  ]\n}\n```']",2,5560.062646865845
1675,square/wire/1472/1446,square,wire,https://github.com/square/wire/issues/1446,https://github.com/square/wire/pull/1472,https://github.com/square/wire/pull/1472,1,fixes,Generated Kotlin code with member `adapter` is hiding supertype member,"## About:
If the proto definition contains field named `adapter` it will cause that the generated Kotlin code will contain conflicting member.

This is caused by the fact that `nameAllocatorStore` in `KotlinGenerator` is [set only with the constant variant (uppercase)](https://github.com/square/wire/blob/7aab9195bf1c898d355b117a9b5e3c954219789f/wire-library/wire-kotlin-generator/src/main/java/com/squareup/wire/kotlin/KotlinGenerator.kt#L257) of the member name but in the supertype `Message` it is defined lowercase.

## Example proto:
```proto
message Broken {

    // This will hide supertype member
    optional string adapter = 1;

    // This is changed to `unknownFields_`
    repeated string unknownFields = 2;
}
```

This issue is present in current master (3.2.0-SNAPSHOT).",4d79487cc8bee1991fcae37aadd84b04485c6190,edde55760b6c91bfbaca1bf869a7fff1aeedf475,https://github.com/square/wire/compare/4d79487cc8bee1991fcae37aadd84b04485c6190...edde55760b6c91bfbaca1bf869a7fff1aeedf475,"diff --git a/wire-library/wire-kotlin-generator/src/main/java/com/squareup/wire/kotlin/KotlinGenerator.kt b/wire-library/wire-kotlin-generator/src/main/java/com/squareup/wire/kotlin/KotlinGenerator.kt
index bf2aabc29..a170f509d 100644
--- a/wire-library/wire-kotlin-generator/src/main/java/com/squareup/wire/kotlin/KotlinGenerator.kt
+++ b/wire-library/wire-kotlin-generator/src/main/java/com/squareup/wire/kotlin/KotlinGenerator.kt
@@ -295,6 +295,7 @@ class KotlinGenerator private constructor(
           is MessageType -> {
             newName(""unknownFields"", ""unknownFields"")
             newName(""ADAPTER"", ""ADAPTER"")
+            newName(""adapter"", ""adapter"")
             newName(""reader"", ""reader"")
             newName(""Builder"", ""Builder"")
             newName(""builder"", ""builder"")
diff --git a/wire-library/wire-kotlin-generator/src/test/java/com/squareup/wire/kotlin/KotlinGeneratorTest.kt b/wire-library/wire-kotlin-generator/src/test/java/com/squareup/wire/kotlin/KotlinGeneratorTest.kt
index 366be2fd8..91e18784a 100644
--- a/wire-library/wire-kotlin-generator/src/test/java/com/squareup/wire/kotlin/KotlinGeneratorTest.kt
+++ b/wire-library/wire-kotlin-generator/src/test/java/com/squareup/wire/kotlin/KotlinGeneratorTest.kt
@@ -76,10 +76,12 @@ class KotlinGeneratorTest {
         |message Message {
         |  required float when = 1;
         |  required int32 ADAPTER = 2;
+        |  optional int64 adapter = 3;
         |}"""""".trimMargin())
     val code = repoBuilder.generateKotlin(""Message"")
     assertTrue(code.contains(""val when_: Float""))
     assertTrue(code.contains(""val ADAPTER_: Int""))
+    assertTrue(code.contains(""val adapter_: Long?""))
     assertTrue(code.contains(""ProtoAdapter.FLOAT.encodedSizeWithTag(1, value.when_) +""))
     assertTrue(code.contains(""ProtoAdapter.FLOAT.encodeWithTag(writer, 1, value.when_)""))
     assertTrue(code.contains(""ProtoAdapter.FLOAT.encodeWithTag(writer, 1, value.when_)""))","['wire-library/wire-kotlin-generator/src/main/java/com/squareup/wire/kotlin/KotlinGenerator.kt', 'wire-library/wire-kotlin-generator/src/test/java/com/squareup/wire/kotlin/KotlinGeneratorTest.kt']",{'.kt': 2},2,0,2,0,2,624038,143566,19005,171,42,8,1,1,803,92,201,18,1,1,2020-03-27 17:14:56,4048,Kotlin,"{'Kotlin': 4283282, 'Java': 2161553, 'Swift': 540484, 'Ruby': 3972, 'Shell': 1673, 'CSS': 1149, 'JavaScript': 210}",Apache License 2.0,"['wire-library/wire-kotlin-generator/src/main/java/com/squareup/wire/kotlin/KotlinGenerator.kt', 'wire-library/wire-runtime/src/commonMain/kotlin/com/squareup/wire/Message.kt']","['wire-library/wire-kotlin-generator/src/main/java/com/squareup/wire/kotlin/KotlinGenerator.kt', 'wire-library/wire-runtime/src/commonMain/kotlin/com/squareup/wire/Message.kt']","['```json\n{\n  ""files"": [\n    ""wire-library/wire-kotlin-generator/src/main/java/com/squareup/wire/kotlin/KotlinGenerator.kt"",\n    ""wire-library/wire-runtime/src/commonMain/kotlin/com/squareup/wire/Message.kt""\n  ]\n}\n```']",1,1093.2512283325195
1676,square/wire/1232/1230,square,wire,https://github.com/square/wire/issues/1230,https://github.com/square/wire/pull/1232,https://github.com/square/wire/pull/1232,1,fixes,Inconsistent fromValue() implementation for enums in Kotlin and Java,"Java returns null for unknown tags:
```java
public static NestedEnum fromValue(int value) {
  switch (value) {
    case 1: return A;
    default: return null;
  }
}
```
While Kotlin throws:
```kotlin
fun fromValue(value: Int): NestedEnum = when (value) {
  1 -> A
  else -> throw IllegalArgumentException(""""""Unexpected value: $value"""""")
}
```
Kotlin implementation should be changed to mirror Java.",261ecdf48b77f098abe5de6636c66bcf2f4dd36e,bb97dc1bec255819b6f38ae4d1fea9f7b9cc8727,https://github.com/square/wire/compare/261ecdf48b77f098abe5de6636c66bcf2f4dd36e...bb97dc1bec255819b6f38ae4d1fea9f7b9cc8727,"diff --git a/wire-kotlin-generator/src/main/java/com/squareup/wire/kotlin/KotlinGenerator.kt b/wire-kotlin-generator/src/main/java/com/squareup/wire/kotlin/KotlinGenerator.kt
index 61338be0e..a7d0acabb 100644
--- a/wire-kotlin-generator/src/main/java/com/squareup/wire/kotlin/KotlinGenerator.kt
+++ b/wire-kotlin-generator/src/main/java/com/squareup/wire/kotlin/KotlinGenerator.kt
@@ -1136,13 +1136,13 @@ class KotlinGenerator private constructor(
     val fromValue = FunSpec.builder(""fromValue"")
         .jvmStatic()
         .addParameter(valueName, Int::class)
-        .returns(parentClassName)
+        .returns(parentClassName.copy(nullable = true))
         .apply {
           addCode(""return when (value) {\\n⇥"")
           message.constants().forEach { constant ->
             addCode(""%L -> %L\\n"", constant.tag, nameAllocator[constant])
           }
-          addCode(""else -> throw IllegalArgumentException(%P)"", ""Unexpected value: \\$value"")
+          addCode(""else -> null"")
           addCode(""\\n⇤}\\n"") // close the block
         }
         .build()
@@ -1175,7 +1175,7 @@ class KotlinGenerator private constructor(
         .addFunction(FunSpec.builder(""fromValue"")
             .addModifiers(OVERRIDE)
             .addParameter(valueName, Int::class)
-            .returns(parentClassName)
+            .returns(parentClassName.copy(nullable = true))
             .addStatement(""return %T.fromValue(value)"", parentClassName)
             .build())
         .build()
diff --git a/wire-kotlin-generator/src/test/java/com/squareup/wire/kotlin/KotlinGeneratorTest.kt b/wire-kotlin-generator/src/test/java/com/squareup/wire/kotlin/KotlinGeneratorTest.kt
index cdf9ad00a..8b6c87fc7 100644
--- a/wire-kotlin-generator/src/test/java/com/squareup/wire/kotlin/KotlinGeneratorTest.kt
+++ b/wire-kotlin-generator/src/test/java/com/squareup/wire/kotlin/KotlinGeneratorTest.kt
@@ -49,6 +49,7 @@ class KotlinGeneratorTest {
     assertTrue(code.contains(""PhoneNumber::class""))
     assertTrue(code.contains(""override fun encode(writer: ProtoWriter, value: Person)""))
     assertTrue(code.contains(""enum class PhoneType(    override val value: Int  ) : WireEnum""))
+    assertTrue(code.contains(""fun fromValue(value: Int): PhoneType?""))
     assertTrue(code.contains(""WORK(1),""))
   }
 
diff --git a/wire-moshi-adapter/src/test/java/com/squareup/wire/protos/geology/javainteropkotlin/Period.kt b/wire-moshi-adapter/src/test/java/com/squareup/wire/protos/geology/javainteropkotlin/Period.kt
index a9020269d..595433734 100644
--- a/wire-moshi-adapter/src/test/java/com/squareup/wire/protos/geology/javainteropkotlin/Period.kt
+++ b/wire-moshi-adapter/src/test/java/com/squareup/wire/protos/geology/javainteropkotlin/Period.kt
@@ -32,15 +32,15 @@ enum class Period(
     val ADAPTER: ProtoAdapter<Period> = object : EnumAdapter<Period>(
       Period::class
     ) {
-      override fun fromValue(value: Int): Period = Period.fromValue(value)
+      override fun fromValue(value: Int): Period? = Period.fromValue(value)
     }
 
     @JvmStatic
-    fun fromValue(value: Int): Period = when (value) {
+    fun fromValue(value: Int): Period? = when (value) {
       1 -> CRETACEOUS
       2 -> JURASSIC
       3 -> TRIASSIC
-      else -> throw IllegalArgumentException(""""""Unexpected value: $value"""""")
+      else -> null
     }
   }
 }
diff --git a/wire-moshi-adapter/src/test/java/com/squareup/wire/protos/geology/kotlin/Period.kt b/wire-moshi-adapter/src/test/java/com/squareup/wire/protos/geology/kotlin/Period.kt
index 17f7c031f..f65473ac3 100644
--- a/wire-moshi-adapter/src/test/java/com/squareup/wire/protos/geology/kotlin/Period.kt
+++ b/wire-moshi-adapter/src/test/java/com/squareup/wire/protos/geology/kotlin/Period.kt
@@ -32,15 +32,15 @@ enum class Period(
     val ADAPTER: ProtoAdapter<Period> = object : EnumAdapter<Period>(
       Period::class
     ) {
-      override fun fromValue(value: Int): Period = Period.fromValue(value)
+      override fun fromValue(value: Int): Period? = Period.fromValue(value)
     }
 
     @JvmStatic
-    fun fromValue(value: Int): Period = when (value) {
+    fun fromValue(value: Int): Period? = when (value) {
       1 -> CRETACEOUS
       2 -> JURASSIC
       3 -> TRIASSIC
-      else -> throw IllegalArgumentException(""""""Unexpected value: $value"""""")
+      else -> null
     }
   }
 }
diff --git a/wire-moshi-adapter/src/test/java/com/squareup/wire/protos/person/javainteropkotlin/Person.kt b/wire-moshi-adapter/src/test/java/com/squareup/wire/protos/person/javainteropkotlin/Person.kt
index be9cde5f2..ea04406ef 100644
--- a/wire-moshi-adapter/src/test/java/com/squareup/wire/protos/person/javainteropkotlin/Person.kt
+++ b/wire-moshi-adapter/src/test/java/com/squareup/wire/protos/person/javainteropkotlin/Person.kt
@@ -244,15 +244,15 @@ class Person(
       val ADAPTER: ProtoAdapter<PhoneType> = object : EnumAdapter<PhoneType>(
         PhoneType::class
       ) {
-        override fun fromValue(value: Int): PhoneType = PhoneType.fromValue(value)
+        override fun fromValue(value: Int): PhoneType? = PhoneType.fromValue(value)
       }
 
       @JvmStatic
-      fun fromValue(value: Int): PhoneType = when (value) {
+      fun fromValue(value: Int): PhoneType? = when (value) {
         0 -> MOBILE
         1 -> HOME
         2 -> WORK
-        else -> throw IllegalArgumentException(""""""Unexpected value: $value"""""")
+        else -> null
       }
     }
   }
diff --git a/wire-moshi-adapter/src/test/java/com/squareup/wire/protos/person/kotlin/Person.kt b/wire-moshi-adapter/src/test/java/com/squareup/wire/protos/person/kotlin/Person.kt
index a28a9f0ab..11973387b 100644
--- a/wire-moshi-adapter/src/test/java/com/squareup/wire/protos/person/kotlin/Person.kt
+++ b/wire-moshi-adapter/src/test/java/com/squareup/wire/protos/person/kotlin/Person.kt
@@ -184,15 +184,15 @@ class Person(
       val ADAPTER: ProtoAdapter<PhoneType> = object : EnumAdapter<PhoneType>(
         PhoneType::class
       ) {
-        override fun fromValue(value: Int): PhoneType = PhoneType.fromValue(value)
+        override fun fromValue(value: Int): PhoneType? = PhoneType.fromValue(value)
       }
 
       @JvmStatic
-      fun fromValue(value: Int): PhoneType = when (value) {
+      fun fromValue(value: Int): PhoneType? = when (value) {
         0 -> MOBILE
         1 -> HOME
         2 -> WORK
-        else -> throw IllegalArgumentException(""""""Unexpected value: $value"""""")
+        else -> null
       }
     }
   }
diff --git a/wire-tests/src/commonTest/proto-kotlin/com/squareup/wire/protos/kotlin/DeprecatedEnum.kt b/wire-tests/src/commonTest/proto-kotlin/com/squareup/wire/protos/kotlin/DeprecatedEnum.kt
index 358e617b1..d2b0be5e0 100644
--- a/wire-tests/src/commonTest/proto-kotlin/com/squareup/wire/protos/kotlin/DeprecatedEnum.kt
+++ b/wire-tests/src/commonTest/proto-kotlin/com/squareup/wire/protos/kotlin/DeprecatedEnum.kt
@@ -28,16 +28,16 @@ enum class DeprecatedEnum(
     val ADAPTER: ProtoAdapter<DeprecatedEnum> = object : EnumAdapter<DeprecatedEnum>(
       DeprecatedEnum::class
     ) {
-      override fun fromValue(value: Int): DeprecatedEnum = DeprecatedEnum.fromValue(value)
+      override fun fromValue(value: Int): DeprecatedEnum? = DeprecatedEnum.fromValue(value)
     }
 
     @JvmStatic
-    fun fromValue(value: Int): DeprecatedEnum = when (value) {
+    fun fromValue(value: Int): DeprecatedEnum? = when (value) {
       1 -> DISABLED
       2 -> ENABLED
       3 -> ON
       4 -> OFF
-      else -> throw IllegalArgumentException(""""""Unexpected value: $value"""""")
+      else -> null
     }
   }
 }
diff --git a/wire-tests/src/commonTest/proto-kotlin/com/squareup/wire/protos/kotlin/MessageWithStatus.kt b/wire-tests/src/commonTest/proto-kotlin/com/squareup/wire/protos/kotlin/MessageWithStatus.kt
index a2e83bc3d..a68cf2848 100644
--- a/wire-tests/src/commonTest/proto-kotlin/com/squareup/wire/protos/kotlin/MessageWithStatus.kt
+++ b/wire-tests/src/commonTest/proto-kotlin/com/squareup/wire/protos/kotlin/MessageWithStatus.kt
@@ -79,13 +79,13 @@ class MessageWithStatus(
       val ADAPTER: ProtoAdapter<Status> = object : EnumAdapter<Status>(
         Status::class
       ) {
-        override fun fromValue(value: Int): Status = Status.fromValue(value)
+        override fun fromValue(value: Int): Status? = Status.fromValue(value)
       }
 
       @JvmStatic
-      fun fromValue(value: Int): Status = when (value) {
+      fun fromValue(value: Int): Status? = when (value) {
         1 -> A
-        else -> throw IllegalArgumentException(""""""Unexpected value: $value"""""")
+        else -> null
       }
     }
   }
diff --git a/wire-tests/src/commonTest/proto-kotlin/com/squareup/wire/protos/kotlin/OptionalEnumUser.kt b/wire-tests/src/commonTest/proto-kotlin/com/squareup/wire/protos/kotlin/OptionalEnumUser.kt
index 553d9f627..0467f3645 100644
--- a/wire-tests/src/commonTest/proto-kotlin/com/squareup/wire/protos/kotlin/OptionalEnumUser.kt
+++ b/wire-tests/src/commonTest/proto-kotlin/com/squareup/wire/protos/kotlin/OptionalEnumUser.kt
@@ -110,14 +110,14 @@ class OptionalEnumUser(
       val ADAPTER: ProtoAdapter<OptionalEnum> = object : EnumAdapter<OptionalEnum>(
         OptionalEnum::class
       ) {
-        override fun fromValue(value: Int): OptionalEnum = OptionalEnum.fromValue(value)
+        override fun fromValue(value: Int): OptionalEnum? = OptionalEnum.fromValue(value)
       }
 
       @JvmStatic
-      fun fromValue(value: Int): OptionalEnum = when (value) {
+      fun fromValue(value: Int): OptionalEnum? = when (value) {
         1 -> FOO
         2 -> BAR
-        else -> throw IllegalArgumentException(""""""Unexpected value: $value"""""")
+        else -> null
       }
     }
   }
diff --git a/wire-tests/src/commonTest/proto-kotlin/com/squareup/wire/protos/kotlin/OtherMessageWithStatus.kt b/wire-tests/src/commonTest/proto-kotlin/com/squareup/wire/protos/kotlin/OtherMessageWithStatus.kt
index 7e01fa55b..9d9762397 100644
--- a/wire-tests/src/commonTest/proto-kotlin/com/squareup/wire/protos/kotlin/OtherMessageWithStatus.kt
+++ b/wire-tests/src/commonTest/proto-kotlin/com/squareup/wire/protos/kotlin/OtherMessageWithStatus.kt
@@ -80,13 +80,13 @@ class OtherMessageWithStatus(
       val ADAPTER: ProtoAdapter<Status> = object : EnumAdapter<Status>(
         Status::class
       ) {
-        override fun fromValue(value: Int): Status = Status.fromValue(value)
+        override fun fromValue(value: Int): Status? = Status.fromValue(value)
       }
 
       @JvmStatic
-      fun fromValue(value: Int): Status = when (value) {
+      fun fromValue(value: Int): Status? = when (value) {
         1 -> A
-        else -> throw IllegalArgumentException(""""""Unexpected value: $value"""""")
+        else -> null
       }
     }
   }
diff --git a/wire-tests/src/commonTest/proto-kotlin/com/squareup/wire/protos/kotlin/alltypes/AllTypes.kt b/wire-tests/src/commonTest/proto-kotlin/com/squareup/wire/protos/kotlin/alltypes/AllTypes.kt
index 405811ce6..abf7cad39 100644
--- a/wire-tests/src/commonTest/proto-kotlin/com/squareup/wire/protos/kotlin/alltypes/AllTypes.kt
+++ b/wire-tests/src/commonTest/proto-kotlin/com/squareup/wire/protos/kotlin/alltypes/AllTypes.kt
@@ -2206,13 +2206,13 @@ class AllTypes(
       val ADAPTER: ProtoAdapter<NestedEnum> = object : EnumAdapter<NestedEnum>(
         NestedEnum::class
       ) {
-        override fun fromValue(value: Int): NestedEnum = NestedEnum.fromValue(value)
+        override fun fromValue(value: Int): NestedEnum? = NestedEnum.fromValue(value)
       }
 
       @JvmStatic
-      fun fromValue(value: Int): NestedEnum = when (value) {
+      fun fromValue(value: Int): NestedEnum? = when (value) {
         1 -> A
-        else -> throw IllegalArgumentException(""""""Unexpected value: $value"""""")
+        else -> null
       }
     }
   }
diff --git a/wire-tests/src/commonTest/proto-kotlin/com/squareup/wire/protos/kotlin/foreign/ForeignEnum.kt b/wire-tests/src/commonTest/proto-kotlin/com/squareup/wire/protos/kotlin/foreign/ForeignEnum.kt
index 61a939ce2..a03cfc468 100644
--- a/wire-tests/src/commonTest/proto-kotlin/com/squareup/wire/protos/kotlin/foreign/ForeignEnum.kt
+++ b/wire-tests/src/commonTest/proto-kotlin/com/squareup/wire/protos/kotlin/foreign/ForeignEnum.kt
@@ -21,14 +21,14 @@ enum class ForeignEnum(
     val ADAPTER: ProtoAdapter<ForeignEnum> = object : EnumAdapter<ForeignEnum>(
       ForeignEnum::class
     ) {
-      override fun fromValue(value: Int): ForeignEnum = ForeignEnum.fromValue(value)
+      override fun fromValue(value: Int): ForeignEnum? = ForeignEnum.fromValue(value)
     }
 
     @JvmStatic
-    fun fromValue(value: Int): ForeignEnum = when (value) {
+    fun fromValue(value: Int): ForeignEnum? = when (value) {
       0 -> BAV
       1 -> BAX
-      else -> throw IllegalArgumentException(""""""Unexpected value: $value"""""")
+      else -> null
     }
   }
 }
diff --git a/wire-tests/src/commonTest/proto-kotlin/com/squareup/wire/protos/kotlin/person/Person.kt b/wire-tests/src/commonTest/proto-kotlin/com/squareup/wire/protos/kotlin/person/Person.kt
index f42b65a48..f6d6dc128 100644
--- a/wire-tests/src/commonTest/proto-kotlin/com/squareup/wire/protos/kotlin/person/Person.kt
+++ b/wire-tests/src/commonTest/proto-kotlin/com/squareup/wire/protos/kotlin/person/Person.kt
@@ -184,15 +184,15 @@ class Person(
       val ADAPTER: ProtoAdapter<PhoneType> = object : EnumAdapter<PhoneType>(
         PhoneType::class
       ) {
-        override fun fromValue(value: Int): PhoneType = PhoneType.fromValue(value)
+        override fun fromValue(value: Int): PhoneType? = PhoneType.fromValue(value)
       }
 
       @JvmStatic
-      fun fromValue(value: Int): PhoneType = when (value) {
+      fun fromValue(value: Int): PhoneType? = when (value) {
         0 -> MOBILE
         1 -> HOME
         2 -> WORK
-        else -> throw IllegalArgumentException(""""""Unexpected value: $value"""""")
+        else -> null
       }
     }
   }
diff --git a/wire-tests/src/commonTest/proto-kotlin/com/squareup/wire/protos/kotlin/simple/SimpleMessage.kt b/wire-tests/src/commonTest/proto-kotlin/com/squareup/wire/protos/kotlin/simple/SimpleMessage.kt
index fa596d68b..b5c9efad8 100644
--- a/wire-tests/src/commonTest/proto-kotlin/com/squareup/wire/protos/kotlin/simple/SimpleMessage.kt
+++ b/wire-tests/src/commonTest/proto-kotlin/com/squareup/wire/protos/kotlin/simple/SimpleMessage.kt
@@ -410,16 +410,16 @@ class SimpleMessage(
       val ADAPTER: ProtoAdapter<NestedEnum> = object : EnumAdapter<NestedEnum>(
         NestedEnum::class
       ) {
-        override fun fromValue(value: Int): NestedEnum = NestedEnum.fromValue(value)
+        override fun fromValue(value: Int): NestedEnum? = NestedEnum.fromValue(value)
       }
 
       @JvmStatic
-      fun fromValue(value: Int): NestedEnum = when (value) {
+      fun fromValue(value: Int): NestedEnum? = when (value) {
         1 -> FOO
         2 -> BAR
         3 -> BAZ
         3 -> BUZ
-        else -> throw IllegalArgumentException(""""""Unexpected value: $value"""""")
+        else -> null
       }
     }
   }
diff --git a/wire-tests/src/jvmKotlinAndroidTest/proto-kotlin/com/squareup/wire/protos/kotlin/person/Person.kt b/wire-tests/src/jvmKotlinAndroidTest/proto-kotlin/com/squareup/wire/protos/kotlin/person/Person.kt
index 944415ea0..e00282aaf 100644
--- a/wire-tests/src/jvmKotlinAndroidTest/proto-kotlin/com/squareup/wire/protos/kotlin/person/Person.kt
+++ b/wire-tests/src/jvmKotlinAndroidTest/proto-kotlin/com/squareup/wire/protos/kotlin/person/Person.kt
@@ -188,15 +188,15 @@ class Person(
       val ADAPTER: ProtoAdapter<PhoneType> = object : EnumAdapter<PhoneType>(
         PhoneType::class
       ) {
-        override fun fromValue(value: Int): PhoneType = PhoneType.fromValue(value)
+        override fun fromValue(value: Int): PhoneType? = PhoneType.fromValue(value)
       }
 
       @JvmStatic
-      fun fromValue(value: Int): PhoneType = when (value) {
+      fun fromValue(value: Int): PhoneType? = when (value) {
         0 -> MOBILE
         1 -> HOME
         2 -> WORK
-        else -> throw IllegalArgumentException(""""""Unexpected value: $value"""""")
+        else -> null
       }
     }
   }
diff --git a/wire-tests/src/jvmKotlinInteropTest/proto-kotlin/com/squareup/wire/protos/kotlin/MessageWithStatus.kt b/wire-tests/src/jvmKotlinInteropTest/proto-kotlin/com/squareup/wire/protos/kotlin/MessageWithStatus.kt
index b15397d27..cf8350467 100644
--- a/wire-tests/src/jvmKotlinInteropTest/proto-kotlin/com/squareup/wire/protos/kotlin/MessageWithStatus.kt
+++ b/wire-tests/src/jvmKotlinInteropTest/proto-kotlin/com/squareup/wire/protos/kotlin/MessageWithStatus.kt
@@ -81,13 +81,13 @@ class MessageWithStatus(
       val ADAPTER: ProtoAdapter<Status> = object : EnumAdapter<Status>(
         Status::class
       ) {
-        override fun fromValue(value: Int): Status = Status.fromValue(value)
+        override fun fromValue(value: Int): Status? = Status.fromValue(value)
       }
 
       @JvmStatic
-      fun fromValue(value: Int): Status = when (value) {
+      fun fromValue(value: Int): Status? = when (value) {
         1 -> A
-        else -> throw IllegalArgumentException(""""""Unexpected value: $value"""""")
+        else -> null
       }
     }
   }
diff --git a/wire-tests/src/jvmKotlinInteropTest/proto-kotlin/com/squareup/wire/protos/kotlin/OtherMessageWithStatus.kt b/wire-tests/src/jvmKotlinInteropTest/proto-kotlin/com/squareup/wire/protos/kotlin/OtherMessageWithStatus.kt
index 1ccf2bdf8..38b762575 100644
--- a/wire-tests/src/jvmKotlinInteropTest/proto-kotlin/com/squareup/wire/protos/kotlin/OtherMessageWithStatus.kt
+++ b/wire-tests/src/jvmKotlinInteropTest/proto-kotlin/com/squareup/wire/protos/kotlin/OtherMessageWithStatus.kt
@@ -82,13 +82,13 @@ class OtherMessageWithStatus(
       val ADAPTER: ProtoAdapter<Status> = object : EnumAdapter<Status>(
         Status::class
       ) {
-        override fun fromValue(value: Int): Status = Status.fromValue(value)
+        override fun fromValue(value: Int): Status? = Status.fromValue(value)
       }
 
       @JvmStatic
-      fun fromValue(value: Int): Status = when (value) {
+      fun fromValue(value: Int): Status? = when (value) {
         1 -> A
-        else -> throw IllegalArgumentException(""""""Unexpected value: $value"""""")
+        else -> null
       }
     }
   }
diff --git a/wire-tests/src/jvmKotlinInteropTest/proto-kotlin/com/squareup/wire/protos/kotlin/alltypes/AllTypes.kt b/wire-tests/src/jvmKotlinInteropTest/proto-kotlin/com/squareup/wire/protos/kotlin/alltypes/AllTypes.kt
index 9d1721a11..7a920678c 100644
--- a/wire-tests/src/jvmKotlinInteropTest/proto-kotlin/com/squareup/wire/protos/kotlin/alltypes/AllTypes.kt
+++ b/wire-tests/src/jvmKotlinInteropTest/proto-kotlin/com/squareup/wire/protos/kotlin/alltypes/AllTypes.kt
@@ -3780,13 +3780,13 @@ class AllTypes(
       val ADAPTER: ProtoAdapter<NestedEnum> = object : EnumAdapter<NestedEnum>(
         NestedEnum::class
       ) {
-        override fun fromValue(value: Int): NestedEnum = NestedEnum.fromValue(value)
+        override fun fromValue(value: Int): NestedEnum? = NestedEnum.fromValue(value)
       }
 
       @JvmStatic
-      fun fromValue(value: Int): NestedEnum = when (value) {
+      fun fromValue(value: Int): NestedEnum? = when (value) {
         1 -> A
-        else -> throw IllegalArgumentException(""""""Unexpected value: $value"""""")
+        else -> null
       }
     }
   }
diff --git a/wire-tests/src/jvmKotlinInteropTest/proto-kotlin/com/squareup/wire/protos/kotlin/person/Person.kt b/wire-tests/src/jvmKotlinInteropTest/proto-kotlin/com/squareup/wire/protos/kotlin/person/Person.kt
index 5ec51e9ab..66abddff0 100644
--- a/wire-tests/src/jvmKotlinInteropTest/proto-kotlin/com/squareup/wire/protos/kotlin/person/Person.kt
+++ b/wire-tests/src/jvmKotlinInteropTest/proto-kotlin/com/squareup/wire/protos/kotlin/person/Person.kt
@@ -244,15 +244,15 @@ class Person(
       val ADAPTER: ProtoAdapter<PhoneType> = object : EnumAdapter<PhoneType>(
         PhoneType::class
       ) {
-        override fun fromValue(value: Int): PhoneType = PhoneType.fromValue(value)
+        override fun fromValue(value: Int): PhoneType? = PhoneType.fromValue(value)
       }
 
       @JvmStatic
-      fun fromValue(value: Int): PhoneType = when (value) {
+      fun fromValue(value: Int): PhoneType? = when (value) {
         0 -> MOBILE
         1 -> HOME
         2 -> WORK
-        else -> throw IllegalArgumentException(""""""Unexpected value: $value"""""")
+        else -> null
       }
     }
   }","['wire-kotlin-generator/src/main/java/com/squareup/wire/kotlin/KotlinGenerator.kt', 'wire-tests/src/jvmKotlinInteropTest/proto-kotlin/com/squareup/wire/protos/kotlin/MessageWithStatus.kt', 'wire-tests/src/commonTest/proto-kotlin/com/squareup/wire/protos/kotlin/OptionalEnumUser.kt', 'wire-moshi-adapter/src/test/java/com/squareup/wire/protos/geology/kotlin/Period.kt', 'wire-tests/src/jvmKotlinInteropTest/proto-kotlin/com/squareup/wire/protos/kotlin/person/Person.kt', 'wire-tests/src/commonTest/proto-kotlin/com/squareup/wire/protos/kotlin/foreign/ForeignEnum.kt', 'wire-moshi-adapter/src/test/java/com/squareup/wire/protos/person/kotlin/Person.kt', 'wire-moshi-adapter/src/test/java/com/squareup/wire/protos/person/javainteropkotlin/Person.kt', 'wire-tests/src/jvmKotlinInteropTest/proto-kotlin/com/squareup/wire/protos/kotlin/OtherMessageWithStatus.kt', 'wire-tests/src/commonTest/proto-kotlin/com/squareup/wire/protos/kotlin/simple/SimpleMessage.kt', 'wire-tests/src/jvmKotlinInteropTest/proto-kotlin/com/squareup/wire/protos/kotlin/alltypes/AllTypes.kt', 'wire-kotlin-generator/src/test/java/com/squareup/wire/kotlin/KotlinGeneratorTest.kt', 'wire-tests/src/commonTest/proto-kotlin/com/squareup/wire/protos/kotlin/person/Person.kt', 'wire-tests/src/commonTest/proto-kotlin/com/squareup/wire/protos/kotlin/MessageWithStatus.kt', 'wire-tests/src/commonTest/proto-kotlin/com/squareup/wire/protos/kotlin/alltypes/AllTypes.kt', 'wire-tests/src/commonTest/proto-kotlin/com/squareup/wire/protos/kotlin/DeprecatedEnum.kt', 'wire-tests/src/jvmKotlinAndroidTest/proto-kotlin/com/squareup/wire/protos/kotlin/person/Person.kt', 'wire-tests/src/commonTest/proto-kotlin/com/squareup/wire/protos/kotlin/OtherMessageWithStatus.kt', 'wire-moshi-adapter/src/test/java/com/squareup/wire/protos/geology/javainteropkotlin/Period.kt']",{'.kt': 19},19,0,19,0,19,405501,92920,12096,122,320,58,6,1,414,57,100,17,0,2,2019-10-08 20:23:31,4048,Kotlin,"{'Kotlin': 4283282, 'Java': 2161553, 'Swift': 540484, 'Ruby': 3972, 'Shell': 1673, 'CSS': 1149, 'JavaScript': 210}",Apache License 2.0,"['wire-runtime/src/commonMain/kotlin/com/squareup/wire/WireEnum.kt', 'wire-runtime/src/jvmMain/kotlin/com/squareup/wire/internal/RuntimeEnumAdapter.kt', 'wire-runtime/src/jsMain/kotlin/com/squareup/wire/EnumAdapter.kt', 'wire-runtime/src/nativeMain/kotlin/com/squareup/wire/EnumAdapter.kt', 'wire-runtime/src/commonMain/kotlin/com/squareup/wire/EnumAdapter.kt']","['wire-runtime/src/commonMain/kotlin/com/squareup/wire/WireEnum.kt', 'wire-runtime/src/jsMain/kotlin/com/squareup/wire/EnumAdapter.kt', 'wire-runtime/src/nativeMain/kotlin/com/squareup/wire/EnumAdapter.kt', 'wire-runtime/src/commonMain/kotlin/com/squareup/wire/EnumAdapter.kt']","['```json\n{\n  ""files"": [\n    ""wire-runtime/src/commonMain/kotlin/com/squareup/wire/WireEnum.kt"",\n    ""wire-runtime/src/commonMain/kotlin/com/squareup/wire/EnumAdapter.kt"",\n    ""wire-runtime/src/jvmMain/kotlin/com/squareup/wire/internal/RuntimeEnumAdapter.kt"",\n    ""wire-runtime/src/jsMain/kotlin/com/squareup/wire/EnumAdapter.kt"",\n    ""wire-runtime/src/nativeMain/kotlin/com/squareup/wire/EnumAdapter.kt""\n  ]\n}\n```']",1,1631.1078071594238
1538,square/kotlinpoet/1519/1518,square,kotlinpoet,https://github.com/square/kotlinpoet/issues/1518,https://github.com/square/kotlinpoet/pull/1519,https://github.com/square/kotlinpoet/pull/1519,2,fixes,Infinite loop in CodeWriter.generateImportAliases,"**Describe the bug**

Ambiguous import aliases can result in the call to `CodeWriter.generateImportAliases` failing to return.

**To Reproduce**

I've narrowed this down in the debugger. The call to `generateImportAliases` passes these arguments:

- `simpleName`: `""Round""`
- `qualifiedNames`: `setOf(MemberName(""androidx.compose.ui.graphics.StrokeCap.Companion.Round""), MemberName(""androidx.compose.ui.graphics.StrokeJoin.Companion.Round""))`
- `packageName`: `CodeWriter$Companion$withCollectedImports$suggestedMemberImports$2@10685`
- `capitalizeAliases`: `false`

This results in the `while` loop repeating forever, clearing `aliasNames` and writing both qualified names to the same key `""androidxComposeUiGraphicsRound""`. This fails the length check, which expects there to be a unique alias for both qualified names.


**Expected behavior**

`generateImportAliases` should take the containing class names into account, so there isn't a collision between nested types with the same name in the same package.",633d4ab27f5095daf34965df81ef2ba87f7f9d88,9bd7451076317ddd6cc9535b2863783958a7560a,https://github.com/square/kotlinpoet/compare/633d4ab27f5095daf34965df81ef2ba87f7f9d88...9bd7451076317ddd6cc9535b2863783958a7560a,"diff --git a/kotlinpoet/src/main/java/com/squareup/kotlinpoet/CodeWriter.kt b/kotlinpoet/src/main/java/com/squareup/kotlinpoet/CodeWriter.kt
index 2884c65b..5d827276 100644
--- a/kotlinpoet/src/main/java/com/squareup/kotlinpoet/CodeWriter.kt
+++ b/kotlinpoet/src/main/java/com/squareup/kotlinpoet/CodeWriter.kt
@@ -706,14 +706,12 @@ internal class CodeWriter constructor(
         .generateImports(
           generatedImports,
           canonicalName = ClassName::canonicalName,
-          packageName = ClassName::packageName,
           capitalizeAliases = true,
         )
       val suggestedMemberImports = importsCollector.suggestedMemberImports()
         .generateImports(
           generatedImports,
           canonicalName = MemberName::canonicalName,
-          packageName = MemberName::packageName,
           capitalizeAliases = false,
         )
       importsCollector.close()
@@ -730,7 +728,6 @@ internal class CodeWriter constructor(
     private fun <T> Map<String, Set<T>>.generateImports(
       generatedImports: MutableMap<String, Import>,
       canonicalName: T.() -> String,
-      packageName: T.() -> String,
       capitalizeAliases: Boolean,
     ): Map<String, T> {
       return flatMap { (simpleName, qualifiedNames) ->
@@ -740,7 +737,7 @@ internal class CodeWriter constructor(
             generatedImports[canonicalName] = Import(canonicalName)
           }
         } else {
-          generateImportAliases(simpleName, qualifiedNames, packageName, capitalizeAliases)
+          generateImportAliases(simpleName, qualifiedNames, canonicalName, capitalizeAliases)
             .onEach { (alias, qualifiedName) ->
               val canonicalName = qualifiedName.canonicalName()
               generatedImports[canonicalName] = Import(canonicalName, alias)
@@ -752,11 +749,14 @@ internal class CodeWriter constructor(
     private fun <T> generateImportAliases(
       simpleName: String,
       qualifiedNames: Set<T>,
-      packageName: T.() -> String,
+      canonicalName: T.() -> String,
       capitalizeAliases: Boolean,
     ): List<Pair<String, T>> {
-      val packageNameSegments = qualifiedNames.associateWith { qualifiedName ->
-        qualifiedName.packageName().split('.').map { it.replaceFirstChar(Char::uppercaseChar) }
+      val canonicalNameSegments = qualifiedNames.associateWith { qualifiedName ->
+        qualifiedName.canonicalName().split('.')
+          .dropLast(1) // Last segment of the canonical name is the simple name, drop it to avoid repetition.
+          .filter { it != ""Companion"" }
+          .map { it.replaceFirstChar(Char::uppercaseChar) }
       }
       val aliasNames = mutableMapOf<String, T>()
       var segmentsToUse = 0
@@ -764,7 +764,7 @@ internal class CodeWriter constructor(
       while (aliasNames.size != qualifiedNames.size) {
         segmentsToUse += 1
         aliasNames.clear()
-        for ((qualifiedName, segments) in packageNameSegments) {
+        for ((qualifiedName, segments) in canonicalNameSegments) {
           val aliasPrefix = segments.takeLast(min(segmentsToUse, segments.size))
             .joinToString(separator = """")
             .replaceFirstChar { if (!capitalizeAliases) it.lowercaseChar() else it }
diff --git a/kotlinpoet/src/test/java/com/squareup/kotlinpoet/KotlinPoetTest.kt b/kotlinpoet/src/test/java/com/squareup/kotlinpoet/KotlinPoetTest.kt
index 9d3f1711..bd021020 100644
--- a/kotlinpoet/src/test/java/com/squareup/kotlinpoet/KotlinPoetTest.kt
+++ b/kotlinpoet/src/test/java/com/squareup/kotlinpoet/KotlinPoetTest.kt
@@ -1333,6 +1333,41 @@ class KotlinPoetTest {
     )
   }
 
+  // https://github.com/square/kotlinpoet/issues/1518
+  @Test fun generatedImportAliasesSamePackageDifferentContainingClasses() {
+    val strokeCapRound = MemberName(
+      enclosingClassName = ClassName(""androidx.compose.ui.graphics"", ""StrokeCap"").nestedClass(""Companion""),
+      simpleName = ""Round"",
+    )
+    val strokeJoinRound = MemberName(
+      enclosingClassName = ClassName(""androidx.compose.ui.graphics"", ""StrokeJoin"").nestedClass(""Companion""),
+      simpleName = ""Round"",
+    )
+    val file = FileSpec.builder(""com.example"", ""Test"")
+      .addFunction(
+        FunSpec.builder(""main"")
+          .addStatement(""val strokeCapRound = %M()"", strokeCapRound)
+          .addStatement(""val strokeJoinRound = %M()"", strokeJoinRound)
+          .build(),
+      )
+      .build()
+    assertThat(file.toString()).isEqualTo(
+      """"""
+      |package com.example
+      |
+      |import kotlin.Unit
+      |import androidx.compose.ui.graphics.StrokeCap.Companion.Round as strokeCapRound
+      |import androidx.compose.ui.graphics.StrokeJoin.Companion.Round as strokeJoinRound
+      |
+      |public fun main(): Unit {
+      |  val strokeCapRound = strokeCapRound()
+      |  val strokeJoinRound = strokeJoinRound()
+      |}
+      |
+      """""".trimMargin(),
+    )
+  }
+
   @Test fun memberImportsOverGeneratedImportAliases() {
     val squareTaco = ClassName(""com.squareup.tacos"", ""Taco"")
     val blockTaco = ClassName(""xyz.block.tacos"", ""Taco"")
diff --git a/kotlinpoet/src/test/java/com/squareup/kotlinpoet/MemberNameTest.kt b/kotlinpoet/src/test/java/com/squareup/kotlinpoet/MemberNameTest.kt
index 308aeb2c..565e61e2 100644
--- a/kotlinpoet/src/test/java/com/squareup/kotlinpoet/MemberNameTest.kt
+++ b/kotlinpoet/src/test/java/com/squareup/kotlinpoet/MemberNameTest.kt
@@ -171,11 +171,11 @@ class MemberNameTest {
       |package com.example
       |
       |import kotlin.Unit
-      |import com.squareup.tacos.SquareTacos.Companion.createTaco as squareupTacosCreateTaco
+      |import com.squareup.tacos.SquareTacos.Companion.createTaco as squareTacosCreateTaco
       |import com.twitter.tacos.TwitterTacos.Companion.createTaco as twitterTacosCreateTaco
       |
       |public fun makeTastyTacos(): Unit {
-      |  squareupTacosCreateTaco()
+      |  squareTacosCreateTaco()
       |  twitterTacosCreateTaco()
       |}
       |
@@ -416,11 +416,11 @@ class MemberNameTest {
       |package com.example
       |
       |import kotlin.Unit
-      |import com.squareup.tacos.SquareTacos.Companion.`when` as squareupTacosWhen
+      |import com.squareup.tacos.SquareTacos.Companion.`when` as squareTacosWhen
       |import com.twitter.tacos.TwitterTacos.Companion.`when` as twitterTacosWhen
       |
       |public fun whenTastyTacos(): Unit {
-      |  squareupTacosWhen()
+      |  squareTacosWhen()
       |  twitterTacosWhen()
       |}
       |","['kotlinpoet/src/main/java/com/squareup/kotlinpoet/CodeWriter.kt', 'kotlinpoet/src/test/java/com/squareup/kotlinpoet/KotlinPoetTest.kt', 'kotlinpoet/src/test/java/com/squareup/kotlinpoet/MemberNameTest.kt']",{'.kt': 3},3,0,3,0,3,463590,105329,12864,62,1054,215,16,1,1029,109,225,19,0,0,2023-04-15 19:21:51,3598,Kotlin,"{'Kotlin': 1153574, 'Java': 7139}",Apache License 2.0,['kotlinpoet/src/main/java/com/squareup/kotlinpoet/CodeWriter.kt'],['kotlinpoet/src/main/java/com/squareup/kotlinpoet/CodeWriter.kt'],"['```json\n{\n  ""files"": [\n    ""kotlinpoet/src/main/java/com/squareup/kotlinpoet/CodeWriter.kt""\n  ]\n}\n```']",1,991.6038513183594
1541,square/kotlinpoet/1174/1076,square,kotlinpoet,https://github.com/square/kotlinpoet/issues/1076,https://github.com/square/kotlinpoet/pull/1174,https://github.com/square/kotlinpoet/pull/1174,1,fix,Type names in a line comment may break the line,"`addComment()` replaces all the spaces in the format string with `·` for nonbreaking space, but not spaces in type arguments. 

```kotlin
builder.addComment(""this is a long line with a possibly long type: %T"", someLongParamterizedTypeName);
```

The above could end up generating code like

```kotlin
// this is a long line with a possibly long type: List<Map<String, Collection<Map<WackyKey,
  OhNoThisDoesNotCompile>>>>
```",43de7084390504c637f9d12c8beab51aa4c0e388,d34c32b6fdc04a41ca7cd44ca45d10bccee93446,https://github.com/square/kotlinpoet/compare/43de7084390504c637f9d12c8beab51aa4c0e388...d34c32b6fdc04a41ca7cd44ca45d10bccee93446,"diff --git a/kotlinpoet/src/main/java/com/squareup/kotlinpoet/LambdaTypeName.kt b/kotlinpoet/src/main/java/com/squareup/kotlinpoet/LambdaTypeName.kt
index 8b31ee96..3f8514a3 100644
--- a/kotlinpoet/src/main/java/com/squareup/kotlinpoet/LambdaTypeName.kt
+++ b/kotlinpoet/src/main/java/com/squareup/kotlinpoet/LambdaTypeName.kt
@@ -59,7 +59,7 @@ public class LambdaTypeName private constructor(
     }
 
     if (isSuspending) {
-      out.emit(""suspend "")
+      out.emit(""suspend·"")
     }
 
     receiver?.let {
@@ -71,7 +71,7 @@ public class LambdaTypeName private constructor(
     }
 
     parameters.emit(out)
-    out.emitCode(if (returnType is LambdaTypeName) "" -> (%T)"" else "" -> %T"", returnType)
+    out.emitCode(if (returnType is LambdaTypeName) ""·->·(%T)"" else ""·->·%T"", returnType)
 
     if (isNullable) {
       out.emit("")"")
diff --git a/kotlinpoet/src/main/java/com/squareup/kotlinpoet/ParameterizedTypeName.kt b/kotlinpoet/src/main/java/com/squareup/kotlinpoet/ParameterizedTypeName.kt
index af726bd4..fee91816 100644
--- a/kotlinpoet/src/main/java/com/squareup/kotlinpoet/ParameterizedTypeName.kt
+++ b/kotlinpoet/src/main/java/com/squareup/kotlinpoet/ParameterizedTypeName.kt
@@ -83,7 +83,7 @@ public class ParameterizedTypeName internal constructor(
     if (typeArguments.isNotEmpty()) {
       out.emit(""<"")
       typeArguments.forEachIndexed { index, parameter ->
-        if (index > 0) out.emit("", "")
+        if (index > 0) out.emit("",·"")
         parameter.emitAnnotations(out)
         parameter.emit(out)
         parameter.emitNullable(out)
diff --git a/kotlinpoet/src/main/java/com/squareup/kotlinpoet/WildcardTypeName.kt b/kotlinpoet/src/main/java/com/squareup/kotlinpoet/WildcardTypeName.kt
index 803091be..914df5a5 100644
--- a/kotlinpoet/src/main/java/com/squareup/kotlinpoet/WildcardTypeName.kt
+++ b/kotlinpoet/src/main/java/com/squareup/kotlinpoet/WildcardTypeName.kt
@@ -46,9 +46,9 @@ public class WildcardTypeName private constructor(
 
   override fun emit(out: CodeWriter): CodeWriter {
     return when {
-      inTypes.size == 1 -> out.emitCode(""in %T"", inTypes[0])
+      inTypes.size == 1 -> out.emitCode(""in·%T"", inTypes[0])
       outTypes == STAR.outTypes -> out.emit(""*"")
-      else -> out.emitCode(""out %T"", outTypes[0])
+      else -> out.emitCode(""out·%T"", outTypes[0])
     }
   }
 
diff --git a/kotlinpoet/src/test/java/com/squareup/kotlinpoet/FileSpecTest.kt b/kotlinpoet/src/test/java/com/squareup/kotlinpoet/FileSpecTest.kt
index 2ac486bf..ef71a607 100644
--- a/kotlinpoet/src/test/java/com/squareup/kotlinpoet/FileSpecTest.kt
+++ b/kotlinpoet/src/test/java/com/squareup/kotlinpoet/FileSpecTest.kt
@@ -1055,4 +1055,47 @@ class FileSpecTest {
       |"""""".trimMargin()
     )
   }
+
+  class WackyKey
+  class OhNoThisDoesNotCompile
+
+  @OptIn(ExperimentalStdlibApi::class)
+  @Test fun longCommentWithTypes() {
+    val someLongParameterizedTypeName = typeNameOf<List<Map<in String, Collection<Map<WackyKey, out OhNoThisDoesNotCompile>>>>>()
+    val param = ParameterSpec.builder(""foo"", someLongParameterizedTypeName).build()
+    val someLongLambdaTypeName = LambdaTypeName.get(STRING, listOf(param), STRING).copy(suspending = true)
+    val file = FileSpec.builder(""com.squareup.tacos"", ""Taco"")
+      .addFunction(
+        FunSpec.builder(""f1"")
+          .addComment(""this is a long line with a possibly long parameterized type with annotation: %T"", someLongParameterizedTypeName)
+          .build()
+      )
+      .addFunction(
+        FunSpec.builder(""f2"")
+          .addComment(""this is a very very very very very very very very very very long line with a very long lambda type: %T"", someLongLambdaTypeName)
+          .build()
+      )
+      .build()
+
+    assertThat(file.toString()).isEqualTo(
+      """"""
+      |package com.squareup.tacos
+      |
+      |import com.squareup.kotlinpoet.FileSpecTest
+      |import kotlin.String
+      |import kotlin.Unit
+      |import kotlin.collections.Collection
+      |import kotlin.collections.List
+      |import kotlin.collections.Map
+      |
+      |public fun f1(): Unit {
+      |  // this is a long line with a possibly long parameterized type with annotation: List<Map<in String, Collection<Map<FileSpecTest.WackyKey, out FileSpecTest.OhNoThisDoesNotCompile>>>>
+      |}
+      |
+      |public fun f2(): Unit {
+      |  // this is a very very very very very very very very very very long line with a very long lambda type: suspend String.(foo: List<Map<in String, Collection<Map<FileSpecTest.WackyKey, out FileSpecTest.OhNoThisDoesNotCompile>>>>) -> String
+      |}
+      |"""""".trimMargin()
+    )
+  }
 }","['kotlinpoet/src/main/java/com/squareup/kotlinpoet/ParameterizedTypeName.kt', 'kotlinpoet/src/main/java/com/squareup/kotlinpoet/LambdaTypeName.kt', 'kotlinpoet/src/test/java/com/squareup/kotlinpoet/FileSpecTest.kt', 'kotlinpoet/src/main/java/com/squareup/kotlinpoet/WildcardTypeName.kt']",{'.kt': 4},4,0,4,0,4,432956,98275,11856,60,537,168,10,3,436,58,105,12,0,2,2021-10-15 20:59:57,3598,Kotlin,"{'Kotlin': 1153574, 'Java': 7139}",Apache License 2.0,"['kotlinpoet/src/main/java/com/squareup/kotlinpoet/CodeWriter.kt', 'kotlinpoet/src/main/java/com/squareup/kotlinpoet/Util.kt', 'kotlinpoet/src/main/java/com/squareup/kotlinpoet/TypeSpec.kt', 'kotlinpoet/src/main/java/com/squareup/kotlinpoet/CodeBlock.kt', 'kotlinpoet/src/main/java/com/squareup/kotlinpoet/TypeName.kt']","['kotlinpoet/src/main/java/com/squareup/kotlinpoet/CodeWriter.kt', 'kotlinpoet/src/main/java/com/squareup/kotlinpoet/Util.kt', 'kotlinpoet/src/main/java/com/squareup/kotlinpoet/TypeSpec.kt', 'kotlinpoet/src/main/java/com/squareup/kotlinpoet/CodeBlock.kt', 'kotlinpoet/src/main/java/com/squareup/kotlinpoet/TypeName.kt']","['```json\n{\n  ""files"": [\n    ""kotlinpoet/src/main/java/com/squareup/kotlinpoet/CodeBlock.kt"",\n    ""kotlinpoet/src/main/java/com/squareup/kotlinpoet/CodeWriter.kt"",\n    ""kotlinpoet/src/main/java/com/squareup/kotlinpoet/TypeName.kt"",\n    ""kotlinpoet/src/main/java/com/squareup/kotlinpoet/Util.kt"",\n    ""kotlinpoet/src/main/java/com/squareup/kotlinpoet/TypeSpec.kt""\n  ]\n}\n```']",1,1798.8362312316895
3564,netflix/dgs-framework/268/262,netflix,dgs-framework,https://github.com/Netflix/dgs-framework/issues/262,https://github.com/Netflix/dgs-framework/pull/268,https://github.com/Netflix/dgs-framework/pull/268,1,fixes,bug: graphql-dgs-spring-boot-micrometer uses a Timer.Sampler API not supported in micrometer 1.6 ,"## Expected behavior

Developers should be able to use the`graphql-dgs-spring-boot-micrometer` module with Spring Boot 2.3 and Spring Boot 2.4. The first recommends micrometer 1.5 while the latter 1.6.

## Actual behavior

There's an API breakage in micrometer regarding the `Timer.Sampler` between micrometer-core 1.5 and 1.6. 
The following call pattern is not supported in 1.6:

```
 timerSampler.stop(registry, Timer.builder(""some.key""))
```

Ref.
* https://javadoc.io/doc/io.micrometer/micrometer-core/1.5.12/io/micrometer/core/instrument/Timer.Sample.html


---
Thanks @paulbakker for finding this!",7b8f85822784eea3f210aa59e1b018fbdf9d77fb,0a8508e02ab3c6edf03a2acd1d1f3b43f899247e,https://github.com/netflix/dgs-framework/compare/7b8f85822784eea3f210aa59e1b018fbdf9d77fb...0a8508e02ab3c6edf03a2acd1d1f3b43f899247e,"diff --git a/graphql-dgs-spring-boot-micrometer/src/main/kotlin/com/netflix/graphql/dgs/metrics/micrometer/DgsGraphQLMetricsInstrumentation.kt b/graphql-dgs-spring-boot-micrometer/src/main/kotlin/com/netflix/graphql/dgs/metrics/micrometer/DgsGraphQLMetricsInstrumentation.kt
index 29cd8052..56da986a 100644
--- a/graphql-dgs-spring-boot-micrometer/src/main/kotlin/com/netflix/graphql/dgs/metrics/micrometer/DgsGraphQLMetricsInstrumentation.kt
+++ b/graphql-dgs-spring-boot-micrometer/src/main/kotlin/com/netflix/graphql/dgs/metrics/micrometer/DgsGraphQLMetricsInstrumentation.kt
@@ -110,11 +110,7 @@ class DgsGraphQLMetricsInstrumentation(
         baseTags: Iterable<Tag>
     ) {
         val recordedTags = Tags.of(baseTags).and(tagsProvider.getFieldFetchTags(parameters, error))
-
-        timerSampler.stop(
-            registry,
-            Timer.builder(GqlMetric.RESOLVER.key).tags(recordedTags)
-        )
+        timerSampler.stop(Timer.builder(GqlMetric.RESOLVER.key).tags(recordedTags).register(registry))
     }
 
     class MetricsInstrumentationState(private val registry: MeterRegistry) : InstrumentationState {
diff --git a/graphql-dgs-spring-boot-micrometer/src/main/kotlin/com/netflix/graphql/dgs/metrics/micrometer/dataloader/BatchLoaderInterceptor.kt b/graphql-dgs-spring-boot-micrometer/src/main/kotlin/com/netflix/graphql/dgs/metrics/micrometer/dataloader/BatchLoaderInterceptor.kt
index 6a180adf..14fe146b 100644
--- a/graphql-dgs-spring-boot-micrometer/src/main/kotlin/com/netflix/graphql/dgs/metrics/micrometer/dataloader/BatchLoaderInterceptor.kt
+++ b/graphql-dgs-spring-boot-micrometer/src/main/kotlin/com/netflix/graphql/dgs/metrics/micrometer/dataloader/BatchLoaderInterceptor.kt
@@ -29,14 +29,13 @@ internal class BatchLoaderInterceptor(
             pipe.to(batchLoader).whenComplete { result, _ ->
                 logger.debug(""Finished timer[{}] for BatchLoader."", ID)
                 timerSampler.stop(
-                    registry,
                     Timer.builder(ID)
                         .tags(
                             Tags.of(
                                 Tag.of(GqlTag.LOADER_NAME.key, name),
                                 Tag.of(GqlTag.LOADER_BATCH_SIZE.key, result.size.toString())
                             )
-                        )
+                        ).register(registry)
                 )
             }
         } catch (exception: Exception) {
diff --git a/graphql-dgs-spring-boot-micrometer/src/main/kotlin/com/netflix/graphql/dgs/metrics/micrometer/dataloader/BatchLoaderWithContextInterceptor.kt b/graphql-dgs-spring-boot-micrometer/src/main/kotlin/com/netflix/graphql/dgs/metrics/micrometer/dataloader/BatchLoaderWithContextInterceptor.kt
index 3c7fd593..f2be6704 100644
--- a/graphql-dgs-spring-boot-micrometer/src/main/kotlin/com/netflix/graphql/dgs/metrics/micrometer/dataloader/BatchLoaderWithContextInterceptor.kt
+++ b/graphql-dgs-spring-boot-micrometer/src/main/kotlin/com/netflix/graphql/dgs/metrics/micrometer/dataloader/BatchLoaderWithContextInterceptor.kt
@@ -28,14 +28,13 @@ internal class BatchLoaderWithContextInterceptor(
             pipe.to(batchLoader).whenComplete { result, _ ->
                 logger.debug(""Stopping timer[{}] for {}"", ID, javaClass.simpleName)
                 timerSampler.stop(
-                    registry,
                     Timer.builder(ID)
                         .tags(
                             Tags.of(
                                 Tag.of(GqlTag.LOADER_NAME.key, name),
                                 Tag.of(GqlTag.LOADER_BATCH_SIZE.key, result.size.toString())
                             )
-                        )
+                        ).register(registry)
                 )
             }
         } catch (exception: Exception) {
diff --git a/graphql-dgs-spring-boot-micrometer/src/main/kotlin/com/netflix/graphql/dgs/metrics/micrometer/dataloader/MappedBatchLoaderInterceptor.kt b/graphql-dgs-spring-boot-micrometer/src/main/kotlin/com/netflix/graphql/dgs/metrics/micrometer/dataloader/MappedBatchLoaderInterceptor.kt
index 6d998244..b8c9ac13 100644
--- a/graphql-dgs-spring-boot-micrometer/src/main/kotlin/com/netflix/graphql/dgs/metrics/micrometer/dataloader/MappedBatchLoaderInterceptor.kt
+++ b/graphql-dgs-spring-boot-micrometer/src/main/kotlin/com/netflix/graphql/dgs/metrics/micrometer/dataloader/MappedBatchLoaderInterceptor.kt
@@ -28,14 +28,13 @@ internal class MappedBatchLoaderInterceptor(
             pipe.to(batchLoader).whenComplete { result, _ ->
                 logger.debug(""Stopping timer[{}] for {}"", ID, javaClass.simpleName)
                 timerSampler.stop(
-                    registry,
                     Timer.builder(ID)
                         .tags(
                             Tags.of(
                                 Tag.of(GqlTag.LOADER_NAME.key, name),
                                 Tag.of(GqlTag.LOADER_BATCH_SIZE.key, result.size.toString())
                             )
-                        )
+                        ).register(registry)
                 )
             }
         } catch (exception: Exception) {
diff --git a/graphql-dgs-spring-boot-micrometer/src/main/kotlin/com/netflix/graphql/dgs/metrics/micrometer/dataloader/MappedBatchLoaderWithContextInterceptor.kt b/graphql-dgs-spring-boot-micrometer/src/main/kotlin/com/netflix/graphql/dgs/metrics/micrometer/dataloader/MappedBatchLoaderWithContextInterceptor.kt
index cb7f8585..e09e8fd2 100644
--- a/graphql-dgs-spring-boot-micrometer/src/main/kotlin/com/netflix/graphql/dgs/metrics/micrometer/dataloader/MappedBatchLoaderWithContextInterceptor.kt
+++ b/graphql-dgs-spring-boot-micrometer/src/main/kotlin/com/netflix/graphql/dgs/metrics/micrometer/dataloader/MappedBatchLoaderWithContextInterceptor.kt
@@ -29,14 +29,13 @@ internal class MappedBatchLoaderWithContextInterceptor(
             pipe.to(batchLoader).whenComplete { result, _ ->
                 logger.debug(""Stopping timer[{}] for {}"", ID, javaClass.simpleName)
                 timerSampler.stop(
-                    registry,
                     Timer.builder(ID)
                         .tags(
                             Tags.of(
                                 Tag.of(GqlTag.LOADER_NAME.key, name),
                                 Tag.of(GqlTag.LOADER_BATCH_SIZE.key, result.size.toString())
                             )
-                        )
+                        ).register(registry)
                 )
             }
         } catch (exception: Exception) {","['graphql-dgs-spring-boot-micrometer/src/main/kotlin/com/netflix/graphql/dgs/metrics/micrometer/dataloader/MappedBatchLoaderWithContextInterceptor.kt', 'graphql-dgs-spring-boot-micrometer/src/main/kotlin/com/netflix/graphql/dgs/metrics/micrometer/DgsGraphQLMetricsInstrumentation.kt', 'graphql-dgs-spring-boot-micrometer/src/main/kotlin/com/netflix/graphql/dgs/metrics/micrometer/dataloader/BatchLoaderWithContextInterceptor.kt', 'graphql-dgs-spring-boot-micrometer/src/main/kotlin/com/netflix/graphql/dgs/metrics/micrometer/dataloader/BatchLoaderInterceptor.kt', 'graphql-dgs-spring-boot-micrometer/src/main/kotlin/com/netflix/graphql/dgs/metrics/micrometer/dataloader/MappedBatchLoaderInterceptor.kt']",{'.kt': 5},5,0,5,0,5,223867,44628,5461,79,649,95,18,5,622,67,166,19,1,1,2021-04-15 02:33:18,2726,Kotlin,"{'Kotlin': 1330215, 'Java': 211478, 'HTML': 14098, 'Python': 8827, 'TypeScript': 3328, 'JavaScript': 2934, 'Makefile': 1328}",Apache License 2.0,"['graphql-dgs-spring-boot-micrometer/src/main/kotlin/com/netflix/graphql/dgs/metrics/micrometer/DgsGraphQLMetricsInstrumentationUtils.kt', 'graphql-dgs-spring-boot-micrometer/src/main/kotlin/com/netflix/graphql/dgs/metrics/micrometer/dataloader/DgsDataLoaderInstrumentationProvider.kt', 'graphql-dgs-spring-boot-micrometer/src/main/kotlin/com/netflix/graphql/dgs/metrics/micrometer/dataloader/Forwarder.kt', 'graphql-dgs-spring-boot-micrometer/src/main/kotlin/com/netflix/graphql/dgs/metrics/micrometer/DgsGraphQLMetricsProperties.kt', 'graphql-dgs-spring-boot-micrometer/src/main/kotlin/com/netflix/graphql/dgs/metrics/micrometer/DgsGraphQLMetricsInstrumentation.kt']","['graphql-dgs-spring-boot-micrometer/src/main/kotlin/com/netflix/graphql/dgs/metrics/micrometer/DgsGraphQLMetricsInstrumentationUtils.kt', 'graphql-dgs-spring-boot-micrometer/src/main/kotlin/com/netflix/graphql/dgs/metrics/micrometer/dataloader/DgsDataLoaderInstrumentationProvider.kt', 'graphql-dgs-spring-boot-micrometer/src/main/kotlin/com/netflix/graphql/dgs/metrics/micrometer/dataloader/Forwarder.kt', 'graphql-dgs-spring-boot-micrometer/src/main/kotlin/com/netflix/graphql/dgs/metrics/micrometer/DgsGraphQLMetricsProperties.kt', 'graphql-dgs-spring-boot-micrometer/src/main/kotlin/com/netflix/graphql/dgs/metrics/micrometer/DgsGraphQLMetricsInstrumentation.kt']","['```json\n{\n  ""files"": [\n    ""graphql-dgs-spring-boot-micrometer/src/main/kotlin/com/netflix/graphql/dgs/metrics/micrometer/DgsGraphQLMetricsInstrumentation.kt"",\n    ""graphql-dgs-spring-boot-micrometer/src/main/kotlin/com/netflix/graphql/dgs/metrics/micrometer/DgsGraphQLMetricsInstrumentationUtils.kt"",\n    ""graphql-dgs-spring-boot-micrometer/src/main/kotlin/com/netflix/graphql/dgs/metrics/micrometer/DgsGraphQLMetricsProperties.kt"",\n    ""graphql-dgs-spring-boot-micrometer/src/main/kotlin/com/netflix/graphql/dgs/metrics/micrometer/dataloader/DgsDataLoaderInstrumentationProvider.kt"",\n    ""graphql-dgs-spring-boot-micrometer/src/main/kotlin/com/netflix/graphql/dgs/metrics/micrometer/dataloader/Forwarder.kt""\n  ]\n}\n```']",1,2200.8681297302246
3565,netflix/dgs-framework/168/167,netflix,dgs-framework,https://github.com/Netflix/dgs-framework/issues/167,https://github.com/Netflix/dgs-framework/pull/168,https://github.com/Netflix/dgs-framework/pull/168,1,fixes,The gql.field tag should reflect the actual field name and not the client-specified aliased,"If a _client_ aliases a field in the query the tag for the `gql.resolver` metric will use such an alias and not the actual field name.

For example, lets use [MicrometerServletSmokeTest], if a request has... 
```
mvc.perform(
    // Note that the query below uses an aliased field, aliasing `ping` to `not_ping`.
    // We will also assert that the tag reflected by the metric is not affected by the alias.
    MockMvcRequestBuilders
        .post(""/graphql"")
        .content(""""""{ ""query"": ""{not_ping: ping}"" }"""""")
).andExpect(status().isOk)
  .andExpect(content().json(""""""{""data"":{""not_ping"":""pong""}}"""""", false))
```

The `gql.resolver` meter should be tagged with the name of the field, in this case `Query.ping`, not the alias used by the client, `Query.not_ping`.",26045aade4115899416bb2d20b646f1a9fab1ae1,ffd309e8f58c8d4b7f8656f9413e129c6c39b771,https://github.com/netflix/dgs-framework/compare/26045aade4115899416bb2d20b646f1a9fab1ae1...ffd309e8f58c8d4b7f8656f9413e129c6c39b771,"diff --git a/graphql-dgs-spring-boot-micrometer/src/main/kotlin/com/netflix/graphql/dgs/metrics/micrometer/DgsGraphQLMetricsInstrumentationUtils.kt b/graphql-dgs-spring-boot-micrometer/src/main/kotlin/com/netflix/graphql/dgs/metrics/micrometer/DgsGraphQLMetricsInstrumentationUtils.kt
index 565fa0f8..ca83c88c 100644
--- a/graphql-dgs-spring-boot-micrometer/src/main/kotlin/com/netflix/graphql/dgs/metrics/micrometer/DgsGraphQLMetricsInstrumentationUtils.kt
+++ b/graphql-dgs-spring-boot-micrometer/src/main/kotlin/com/netflix/graphql/dgs/metrics/micrometer/DgsGraphQLMetricsInstrumentationUtils.kt
@@ -37,7 +37,7 @@ internal object DgsGraphQLMetricsInstrumentationUtils {
             type as GraphQLObjectType
         }
 
-        return ""${parentType.name}.${parameters.executionStepInfo.path.segmentName}""
+        return ""${parentType.name}.${parameters.executionStepInfo.field.singleField.name}""
     }
 
     fun shouldIgnoreTag(tag: String): Boolean {
diff --git a/graphql-dgs-spring-boot-micrometer/src/test/kotlin/com/netflix/graphql/dgs/metrics/micrometer/MicrometerServletSmokeTest.kt b/graphql-dgs-spring-boot-micrometer/src/test/kotlin/com/netflix/graphql/dgs/metrics/micrometer/MicrometerServletSmokeTest.kt
index 7eb9c93e..98d38da7 100644
--- a/graphql-dgs-spring-boot-micrometer/src/test/kotlin/com/netflix/graphql/dgs/metrics/micrometer/MicrometerServletSmokeTest.kt
+++ b/graphql-dgs-spring-boot-micrometer/src/test/kotlin/com/netflix/graphql/dgs/metrics/micrometer/MicrometerServletSmokeTest.kt
@@ -91,11 +91,13 @@ class MicrometerServletSmokeTest {
     @Test
     fun `Metrics for a successful request`() {
         mvc.perform(
+            // Note that the query below uses an aliased field, aliasing `ping` to `not_ping`.
+            // We will also assert that the tag reflected by the metric is not affected by the alias.
             MockMvcRequestBuilders
                 .post(""/graphql"")
-                .content(""""""{ ""query"": ""{ping}"" }"""""")
+                .content(""""""{ ""query"": ""{not_ping: ping}"" }"""""")
         ).andExpect(status().isOk)
-            .andExpect(content().json(""""""{""data"":{""ping"":""pong""}}"""""", false))
+            .andExpect(content().json(""""""{""data"":{""not_ping"":""pong""}}"""""", false))
 
         val meters = fetchMeters()
 ","['graphql-dgs-spring-boot-micrometer/src/main/kotlin/com/netflix/graphql/dgs/metrics/micrometer/DgsGraphQLMetricsInstrumentationUtils.kt', 'graphql-dgs-spring-boot-micrometer/src/test/kotlin/com/netflix/graphql/dgs/metrics/micrometer/MicrometerServletSmokeTest.kt']",{'.kt': 2},2,0,2,0,2,207414,41720,5023,77,177,31,2,1,782,104,195,15,0,1,2021-03-18 19:15:05,2726,Kotlin,"{'Kotlin': 1330215, 'Java': 211478, 'HTML': 14098, 'Python': 8827, 'TypeScript': 3328, 'JavaScript': 2934, 'Makefile': 1328}",Apache License 2.0,"['graphql-dgs/src/main/kotlin/com/netflix/graphql/dgs/federation/DefaultDgsFederationResolver.kt', 'graphql-dgs/src/main/kotlin/com/netflix/graphql/dgs/internal/utils/DgsComponentUtils.kt', 'graphql-dgs/src/main/kotlin/com/netflix/graphql/dgs/DgsQueryExecutor.kt', 'graphql-dgs/src/main/kotlin/com/netflix/graphql/dgs/internal/DefaultDgsQueryExecutor.kt', 'graphql-dgs/src/main/kotlin/com/netflix/graphql/dgs/exceptions/QueryException.kt']","['graphql-dgs/src/main/kotlin/com/netflix/graphql/dgs/federation/DefaultDgsFederationResolver.kt', 'graphql-dgs/src/main/kotlin/com/netflix/graphql/dgs/internal/utils/DgsComponentUtils.kt', 'graphql-dgs/src/main/kotlin/com/netflix/graphql/dgs/DgsQueryExecutor.kt', 'graphql-dgs/src/main/kotlin/com/netflix/graphql/dgs/internal/DefaultDgsQueryExecutor.kt', 'graphql-dgs/src/main/kotlin/com/netflix/graphql/dgs/exceptions/QueryException.kt']","['```json\n{\n  ""files"": [\n    ""graphql-dgs/src/main/kotlin/com/netflix/graphql/dgs/DgsQueryExecutor.kt"",\n    ""graphql-dgs/src/main/kotlin/com/netflix/graphql/dgs/federation/DefaultDgsFederationResolver.kt"",\n    ""graphql-dgs/src/main/kotlin/com/netflix/graphql/dgs/exceptions/QueryException.kt"",\n    ""graphql-dgs/src/main/kotlin/com/netflix/graphql/dgs/internal/DefaultDgsQueryExecutor.kt"",\n    ""graphql-dgs/src/main/kotlin/com/netflix/graphql/dgs/internal/utils/DgsComponentUtils.kt""\n  ]\n}\n```']",1,1812.1085166931152
1508,cashapp/paparazzi/645/610,cashapp,paparazzi,https://github.com/cashapp/paparazzi/issues/610,https://github.com/cashapp/paparazzi/pull/645,https://github.com/cashapp/paparazzi/pull/645#issuecomment-1338156863,1,close,ConcurrentModificationException when running a lot of tests at once,"**Description**
We have a lot of modules, so we run our tests in parallel all at once. We have about 10 modules using paparazzi. Occasionally, the tests for Paparazzi will fail with:

```
java.util.ConcurrentModificationException
	at java.base/java.util.WeakHashMap.forEach(WeakHashMap.java:1031)
	at com.android.layoutlib.bridge.util.HandlerMessageQueue.extractFirst(HandlerMessageQueue.java:73)
	at android.os.Handler_Delegate.executeCallbacks(Handler_Delegate.java:95)
	at app.cash.paparazzi.Paparazzi.withTime(Paparazzi.kt:330)
	at app.cash.paparazzi.Paparazzi.takeSnapshots(Paparazzi.kt:295)
	at app.cash.paparazzi.Paparazzi.snapshot(Paparazzi.kt:211)
	at app.cash.paparazzi.Paparazzi.snapshot(Paparazzi.kt:204)
	at app.cash.paparazzi.Paparazzi.snapshot$default(Paparazzi.kt:195)
```

Seems as though this line:
```kotlin
Handler_Delegate.executeCallbacks()
```
Cannot handle multiple calls at once. My best suggestion is to synchronize this block so that it allows the concurrency to succeed.

**Steps to Reproduce**
Can't share my work repo. I imagine a project with a few modules, and running `testDebugUnitTest` on the top level project.

**Expected behavior**
Should successfully run.

**Additional information:**
- Paparazzi Version: 1.0.0
- OS: macOS Monterey 12.6
- Compile SDK: 32
- Gradle Version: 7.5
- Android Gradle Plugin Version: 7.2.1

JDK:
```
openjdk 11.0.16.1 2022-08-12 LTS
OpenJDK Runtime Environment Corretto-11.0.16.9.1 (build 11.0.16.1+9-LTS)
OpenJDK 64-Bit Server VM Corretto-11.0.16.9.1 (build 11.0.16.1+9-LTS, mixed mode)
```

",07cefe8fb380d07af581761ab4dac32fbc310e8a,10c5938445cc0d9ec7b6cbec49af1da2c3d6b8df,https://github.com/cashapp/paparazzi/compare/07cefe8fb380d07af581761ab4dac32fbc310e8a...10c5938445cc0d9ec7b6cbec49af1da2c3d6b8df,"diff --git a/paparazzi/paparazzi/src/main/java/app/cash/paparazzi/Paparazzi.kt b/paparazzi/paparazzi/src/main/java/app/cash/paparazzi/Paparazzi.kt
index 90ebd8a5..01fc9c72 100644
--- a/paparazzi/paparazzi/src/main/java/app/cash/paparazzi/Paparazzi.kt
+++ b/paparazzi/paparazzi/src/main/java/app/cash/paparazzi/Paparazzi.kt
@@ -328,9 +328,14 @@ class Paparazzi @JvmOverloads constructor(
     try {
       areCallbacksRunningField.setBoolean(choreographer, true)
 
-      // https://android.googlesource.com/platform/frameworks/layoutlib/+/d58aa4703369e109b24419548f38b422d5a44738/bridge/src/com/android/layoutlib/bridge/BridgeRenderSession.java#171
-      // BridgeRenderSession.executeCallbacks aggressively tears down the main Looper and BridgeContext, so we call the static delegates ourselves.
-      Handler_Delegate.executeCallbacks()
+      // Avoid ConcurrentModificationException in
+      // RenderAction.currentContext.sessionInteractiveData.handlerMessageQueue.runnablesMap which is a WeakHashMap
+      // https://android.googlesource.com/platform/tools/adt/idea/+/c331c9b2f4334748c55c29adec3ad1cd67e45df2/designer/src/com/android/tools/idea/uibuilder/scene/LayoutlibSceneManager.java#1558
+      synchronized(this) {
+        // https://android.googlesource.com/platform/frameworks/layoutlib/+/d58aa4703369e109b24419548f38b422d5a44738/bridge/src/com/android/layoutlib/bridge/BridgeRenderSession.java#171
+        // BridgeRenderSession.executeCallbacks aggressively tears down the main Looper and BridgeContext, so we call the static delegates ourselves.
+        Handler_Delegate.executeCallbacks()
+      }
       val currentTimeMs = SystemClock_Delegate.uptimeMillis()
       val choreographerCallbacks =
         RenderAction.getCurrentContext().sessionInteractiveData.choreographerCallbacks",['paparazzi/paparazzi/src/main/java/app/cash/paparazzi/Paparazzi.kt'],{'.kt': 1},1,0,1,0,1,159586,36603,4715,42,1158,277,11,1,1600,157,466,42,0,3,2022-12-05 01:22:46,1916,Kotlin,"{'Kotlin': 603257, 'Java': 135263, 'JavaScript': 5934, 'HTML': 1716, 'Shell': 1283}",Apache License 2.0,"['app.cash.paparazzi.Paparazzi.kt', 'android.os.Handler_Delegate.java', 'com.android.layoutlib.bridge.util.HandlerMessageQueue.java']",[],"['```json\n{\n  ""files"": [\n    ""app.cash.paparazzi.Paparazzi.kt"",\n    ""android.os.Handler_Delegate.java"",\n    ""com.android.layoutlib.bridge.util.HandlerMessageQueue.java""\n  ]\n}\n```']",1,972.2611904144287
1524,carlosesco/neko/104/67,carlosesco,neko,https://github.com/CarlosEsco/Neko/issues/67,https://github.com/CarlosEsco/Neko/pull/104,https://github.com/CarlosEsco/Neko/pull/104,1,closes,[bug] Filters Main Dropdown minimize issue,"This issue is caused in browse section of the app, When you scroll down in filter and try to minimize the main dropdown headers (theme) they dont minimize which leads to scrolling upwards for a long time 

**To Reproduce**
Steps to reproduce the behavior:
1. Go to 'Browse section'
2. Click on '☰'
3. Scroll down to bottom. 
4. Try to minimize main dropdown header 

**Expected behavior**
When clicking on Main Dropdown Header, It should minimize reducing time in scrolling 
",47914635dea669faf49a5a429ed1a75f233c105f,8bd1436b06811e6f6c46c1d9b8210c37c3f335d8,https://github.com/carlosesco/neko/compare/47914635dea669faf49a5a429ed1a75f233c105f...8bd1436b06811e6f6c46c1d9b8210c37c3f335d8,"diff --git a/app/src/main/java/eu/kanade/tachiyomi/ui/catalogue/filter/GroupItem.kt b/app/src/main/java/eu/kanade/tachiyomi/ui/catalogue/filter/GroupItem.kt
index 1e99d53f8..def59eb78 100644
--- a/app/src/main/java/eu/kanade/tachiyomi/ui/catalogue/filter/GroupItem.kt
+++ b/app/src/main/java/eu/kanade/tachiyomi/ui/catalogue/filter/GroupItem.kt
@@ -49,7 +49,7 @@ class GroupItem(val filter: Filter.Group<*>) : AbstractExpandableHeaderItem<Grou
                         .colorInt(Color.WHITE)
                         .sizeDp(16))
 
-        holder.itemView.setOnClickListener(holder)
+        holder.contentView.setOnClickListener(holder)
 
     }
 
diff --git a/app/src/main/java/eu/kanade/tachiyomi/ui/catalogue/filter/SortGroup.kt b/app/src/main/java/eu/kanade/tachiyomi/ui/catalogue/filter/SortGroup.kt
index d91126caf..e30a32069 100644
--- a/app/src/main/java/eu/kanade/tachiyomi/ui/catalogue/filter/SortGroup.kt
+++ b/app/src/main/java/eu/kanade/tachiyomi/ui/catalogue/filter/SortGroup.kt
@@ -45,7 +45,7 @@ class SortGroup(val filter: Filter.Sort) : AbstractExpandableHeaderItem<SortGrou
                         .icon(icon)
                         .colorInt(Color.WHITE).sizeDp(16))
 
-        holder.itemView.setOnClickListener(holder)
+        holder.contentView.setOnClickListener(holder)
 
     }
 ","['app/src/main/java/eu/kanade/tachiyomi/ui/catalogue/filter/GroupItem.kt', 'app/src/main/java/eu/kanade/tachiyomi/ui/catalogue/filter/SortGroup.kt']",{'.kt': 2},2,0,2,0,2,1162982,242056,34281,357,212,24,4,2,486,80,104,12,0,0,2019-10-29 19:35:26,1609,Kotlin,{'Kotlin': 3267571},Apache License 2.0,"['app/src/main/java/eu/kanade/tachiyomi/ui/catalogue/filter/SelectItem.kt', 'app/src/main/java/eu/kanade/tachiyomi/ui/catalogue/filter/SectionItems.kt', 'app/src/main/java/eu/kanade/tachiyomi/ui/catalogue/filter/SortItem.kt', 'app/src/main/java/eu/kanade/tachiyomi/ui/catalogue/filter/SortGroup.kt', 'app/src/main/java/eu/kanade/tachiyomi/ui/catalogue/filter/CheckboxItem.kt']","['app/src/main/java/eu/kanade/tachiyomi/ui/catalogue/filter/SelectItem.kt', 'app/src/main/java/eu/kanade/tachiyomi/ui/catalogue/filter/SectionItems.kt', 'app/src/main/java/eu/kanade/tachiyomi/ui/catalogue/filter/SortItem.kt', 'app/src/main/java/eu/kanade/tachiyomi/ui/catalogue/filter/SortGroup.kt', 'app/src/main/java/eu/kanade/tachiyomi/ui/catalogue/filter/CheckboxItem.kt']","['```json\n{\n  ""files"": [\n    ""app/src/main/java/eu/kanade/tachiyomi/ui/catalogue/filter/SectionItems.kt"",\n    ""app/src/main/java/eu/kanade/tachiyomi/ui/catalogue/filter/SortGroup.kt"",\n    ""app/src/main/java/eu/kanade/tachiyomi/ui/catalogue/filter/SortItem.kt"",\n    ""app/src/main/java/eu/kanade/tachiyomi/ui/catalogue/filter/CheckboxItem.kt"",\n    ""app/src/main/java/eu/kanade/tachiyomi/ui/catalogue/filter/SelectItem.kt""\n  ]\n}\n```']",1,1955.6491374969482
3437,autonomousapps/dependency-analysis-android-gradle-plugin/301/295,autonomousapps,dependency-analysis-android-gradle-plugin,https://github.com/autonomousapps/dependency-analysis-android-gradle-plugin/issues/295,https://github.com/autonomousapps/dependency-analysis-android-gradle-plugin/pull/301,https://github.com/autonomousapps/dependency-analysis-android-gradle-plugin/pull/301,1,resolves,AdviceAggregateReportTask class cast exception,"`AdviceAggregateReportTask` crashes when trying to cast `(dependency as ProjectDependency)`

**Plugin version**
`0.61.0`

**Gradle version**
`6.6.1`

**Android Gradle Plugin (AGP) version**
`4.2.0-alpha13` - yes, I know it's not supported yet

**Describe the bug**
```
Caused by: java.lang.ClassCastException: org.gradle.api.internal.artifacts.dependencies.DefaultExternalModuleDependency_Decorated incompatible with org.gradle.api.artifacts.ProjectDependency
        at com.autonomousapps.tasks.AdviceAggregateReportTask.action(AdviceAggregateReportTask.kt:40)
        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at org.gradle.internal.reflect.JavaMethod.invoke(JavaMethod.java:104)
```

**To Reproduce**
Steps to reproduce the behavior:
Running `./gradlew buildHealth` fails with exception

Seems to happen because of a `compileOnly` dependency.

**Expected behavior**
Running `./gradlew buildHealth` should gracefully handle unsupported dependencies",ada4ab9e7d9a0ea740a8c9072d43fd67fede3193,99f46a09d1f1b9a539010d6e6fa8aaf492241d3d,https://github.com/autonomousapps/dependency-analysis-android-gradle-plugin/compare/ada4ab9e7d9a0ea740a8c9072d43fd67fede3193...99f46a09d1f1b9a539010d6e6fa8aaf492241d3d,"diff --git a/src/main/kotlin/com/autonomousapps/tasks/AdviceAggregateReportTask.kt b/src/main/kotlin/com/autonomousapps/tasks/AdviceAggregateReportTask.kt
index d8ce9b81..5e7488f7 100644
--- a/src/main/kotlin/com/autonomousapps/tasks/AdviceAggregateReportTask.kt
+++ b/src/main/kotlin/com/autonomousapps/tasks/AdviceAggregateReportTask.kt
@@ -35,15 +35,19 @@ abstract class AdviceAggregateReportTask : DefaultTask() {
     val projectReportPrettyFile = projectReportPretty.getAndDelete()
 
     val comprehensiveAdvice: Map<String, Set<ComprehensiveAdvice>> =
-      adviceAllReports.dependencies.map { dependency ->
-        val path = (dependency as ProjectDependency).dependencyProject.path
+      adviceAllReports.dependencies
+        // They should all be project dependencies, but
+        // https://github.com/autonomousapps/dependency-analysis-android-gradle-plugin/issues/295
+        .filterIsInstance<ProjectDependency>()
+        .map { dependency ->
+          val path = dependency.dependencyProject.path
 
-        val compAdvice: Set<ComprehensiveAdvice> = adviceAllReports.fileCollection(dependency)
-          .filter { it.exists() }
-          .mapToSet { it.readText().fromJson() }
+          val compAdvice: Set<ComprehensiveAdvice> = adviceAllReports.fileCollection(dependency)
+            .filter { it.exists() }
+            .mapToSet { it.readText().fromJson() }
 
-        path to compAdvice.toMutableSet()
-      }.mergedMap()
+          path to compAdvice.toMutableSet()
+        }.mergedMap()
 
     val buildHealth = comprehensiveAdvice.map { (path, advice) ->
       ComprehensiveAdvice(",['src/main/kotlin/com/autonomousapps/tasks/AdviceAggregateReportTask.kt'],{'.kt': 1},1,0,1,0,1,474793,106660,14102,144,960,198,18,1,1250,83,274,29,0,1,2020-10-09 22:40:55,1314,Kotlin,"{'Kotlin': 844183, 'Groovy': 439022, 'ANTLR': 46857, 'Java': 15991, 'Shell': 579}",Apache License 2.0,['src/main/kotlin/com/autonomousapps/tasks/AdviceAggregateReportTask.kt'],['src/main/kotlin/com/autonomousapps/tasks/AdviceAggregateReportTask.kt'],"['```json\n{\n  ""files"": [\n    ""src/main/kotlin/com/autonomousapps/tasks/AdviceAggregateReportTask.kt""\n  ]\n}\n```']",1,826.9224166870117
1523,fwcd/kotlin-language-server/194/174,fwcd,kotlin-language-server,https://github.com/fwcd/kotlin-language-server/issues/174,https://github.com/fwcd/kotlin-language-server/pull/194,https://github.com/fwcd/kotlin-language-server/pull/194,1,fix,VSCode Format on Save deletes any file changes,"Having fwcd-kotlin and editor.formatOnSave enabled in VSCode makes saving files impossible.
https://i.gyazo.com/9bdfba2d927450a0a8aac00c545f1384.mp4
",1a8da75cd3c1d4c40a3892b20da8c123a7fdbde5,23935fad0daa607369f41ad483e806465d05195c,https://github.com/fwcd/kotlin-language-server/compare/1a8da75cd3c1d4c40a3892b20da8c123a7fdbde5...23935fad0daa607369f41ad483e806465d05195c,"diff --git a/server/src/main/kotlin/org/javacs/kt/KotlinTextDocumentService.kt b/server/src/main/kotlin/org/javacs/kt/KotlinTextDocumentService.kt
index fd3e1f0..a7c89ce 100644
--- a/server/src/main/kotlin/org/javacs/kt/KotlinTextDocumentService.kt
+++ b/server/src/main/kotlin/org/javacs/kt/KotlinTextDocumentService.kt
@@ -61,7 +61,10 @@ class KotlinTextDocumentService(
         get() = uri.endsWith("".kts"")
 
     private val TextDocumentIdentifier.content: String
-        get() = uriContentProvider.contentOf(parseURI(uri))
+        get() {
+            val uri = parseURI(uri)
+            return sf.contentOfTracked(uri) ?: uriContentProvider.contentOf(uri)
+        }
 
     fun connect(client: LanguageClient) {
         this.client = client
diff --git a/server/src/main/kotlin/org/javacs/kt/SourceFiles.kt b/server/src/main/kotlin/org/javacs/kt/SourceFiles.kt
index b1d67e9..9153d51 100644
--- a/server/src/main/kotlin/org/javacs/kt/SourceFiles.kt
+++ b/server/src/main/kotlin/org/javacs/kt/SourceFiles.kt
@@ -113,6 +113,10 @@ class SourceFiles(
         }
     }
 
+    fun contentOfTracked(uri: URI):String? {
+        return files[uri]?.content
+    }
+
     fun createdOnDisk(uri: URI) {
         changedOnDisk(uri)
     }","['server/src/main/kotlin/org/javacs/kt/SourceFiles.kt', 'server/src/main/kotlin/org/javacs/kt/KotlinTextDocumentService.kt']",{'.kt': 2},2,0,2,0,2,220820,47025,5818,58,297,67,9,2,151,12,49,3,1,0,2020-02-24 12:56:53,1235,Kotlin,"{'Kotlin': 501563, 'Python': 10015, 'Java': 1400, 'Dockerfile': 456}",MIT License,"['server/src/main/kotlin/org/javacs/kt/util/DelegatePrintStream.kt', 'server/src/main/kotlin/org/javacs/kt/util/LoggingMessageCollector.kt', 'server/src/main/kotlin/org/javacs/kt/formatting/Formatter.kt', 'server/src/main/kotlin/org/javacs/kt/util/Utils.kt', 'server/src/main/kotlin/org/javacs/kt/util/AsyncExecutor.kt']","['server/src/main/kotlin/org/javacs/kt/util/LoggingMessageCollector.kt', 'server/src/main/kotlin/org/javacs/kt/formatting/Formatter.kt']","['```json\n{\n  ""files"": [\n    ""server/src/main/kotlin/org/javacs/kt/formatting/Formatter.kt"",\n    ""server/src/main/kotlin/org/javacs/kt/util/LoggingMessageCollector.kt"",\n    ""server/src/main/kotlin/org/javacs/kt/util/DelegatePrintStream.kt"",\n    ""server/src/main/kotlin/org/javacs/kt/util/Utils.kt"",\n    ""server/src/main/kotlin/org/javacs/kt/util/AsyncExecutor.kt""\n  ]\n}\n```']",1,1256.5529346466064
1522,fwcd/kotlin-language-server/249/248,fwcd,kotlin-language-server,https://github.com/fwcd/kotlin-language-server/issues/248,https://github.com/fwcd/kotlin-language-server/pull/249,https://github.com/fwcd/kotlin-language-server/pull/249,1,fixes,Resource hog and slow startup,"The file-walk change made in this commit https://github.com/fwcd/kotlin-language-server/commit/adff2f93f43d6fd10635ad2a4d81226c4348c37b makes my fan go crazy and makes the server use several minues to start up. If I revert that commit it takes seconds, and no fan.

I'm testing on a small project on macOS with nvim-lsp. Have the same issue with coc.nvim on stable vim.

I might be able to look further on why, some other time.",ba9a74c1360ab8576dfddf73dc69ca74e787a1de,885a67751ea4ce6cf7c4f80d58e5724cc09f4a21,https://github.com/fwcd/kotlin-language-server/compare/ba9a74c1360ab8576dfddf73dc69ca74e787a1de...885a67751ea4ce6cf7c4f80d58e5724cc09f4a21,"diff --git a/shared/src/main/kotlin/org/javacs/kt/classpath/DefaultClassPathResolver.kt b/shared/src/main/kotlin/org/javacs/kt/classpath/DefaultClassPathResolver.kt
index 9f4f40a..a5bf531 100644
--- a/shared/src/main/kotlin/org/javacs/kt/classpath/DefaultClassPathResolver.kt
+++ b/shared/src/main/kotlin/org/javacs/kt/classpath/DefaultClassPathResolver.kt
@@ -19,21 +19,12 @@ private fun workspaceResolvers(workspaceRoot: Path): Sequence<ClassPathResolver>
 }
 
 /** Searches the folder for all build-files. */
-private fun folderResolvers(root: Path, ignored: List<PathMatcher>): Collection<ClassPathResolver> {
-    val resolvers = mutableListOf<ClassPathResolver>()
-
-    for (file in Files.walk(root)) {
-        // Only test whether non-ignored file is a build-file
-        if (ignored.none { it.matches(root.relativize(file)) }) {
-            val resolver = asClassPathProvider(file)
-            if (resolver != null) {
-                resolvers.add(resolver)
-            }
-        }
-    }
-
-    return resolvers
-}
+private fun folderResolvers(root: Path, ignored: List<PathMatcher>): Collection<ClassPathResolver> =
+    root.toFile()
+        .walk()
+        .onEnter { file -> ignored.none { it.matches(root.relativize(file.toPath())) } }
+        .mapNotNull { asClassPathProvider(it.toPath()) }
+        .toList()
 
 /** Tries to read glob patterns from a gitignore. */
 private fun ignoredPathPatterns(path: Path): List<PathMatcher> =",['shared/src/main/kotlin/org/javacs/kt/classpath/DefaultClassPathResolver.kt'],{'.kt': 1},1,0,1,0,1,238182,49252,6071,58,824,181,21,1,431,65,117,5,1,0,2021-01-17 22:23:51,1235,Kotlin,"{'Kotlin': 501563, 'Python': 10015, 'Java': 1400, 'Dockerfile': 456}",MIT License,"['server/src/main/kotlin/org/javacs/kt/Configuration.kt', 'server/src/main/kotlin/org/javacs/kt/KotlinLanguageServer.kt', 'server/src/main/kotlin/org/javacs/kt/KotlinProtocolExtensionService.kt', 'server/src/main/kotlin/org/javacs/kt/CompiledFile.kt', 'server/src/main/kotlin/org/javacs/kt/CompilerClassPath.kt']","['server/src/main/kotlin/org/javacs/kt/Configuration.kt', 'server/src/main/kotlin/org/javacs/kt/KotlinLanguageServer.kt', 'server/src/main/kotlin/org/javacs/kt/KotlinProtocolExtensionService.kt', 'server/src/main/kotlin/org/javacs/kt/CompiledFile.kt', 'server/src/main/kotlin/org/javacs/kt/CompilerClassPath.kt']","['```json\n{\n  ""files"": [\n    ""server/src/main/kotlin/org/javacs/kt/CompiledFile.kt"",\n    ""server/src/main/kotlin/org/javacs/kt/CompilerClassPath.kt"",\n    ""server/src/main/kotlin/org/javacs/kt/Configuration.kt"",\n    ""server/src/main/kotlin/org/javacs/kt/KotlinLanguageServer.kt"",\n    ""server/src/main/kotlin/org/javacs/kt/KotlinProtocolExtensionService.kt""\n  ]\n}\n```']",1,1246.6812133789062
9750,cashapp/redwood/137/40,cashapp,redwood,https://github.com/cashapp/redwood/issues/40,https://github.com/cashapp/redwood/pull/137,https://github.com/cashapp/redwood/pull/137,1,closes,we need to remove widgets from our map!,"we need to remove widgets from our map!

https://github.com/square/treehouse/blob/1ad7b7242bb7c68e31465a3e65ecfd7bded817ae/treehouse-widget/src/commonMain/kotlin/app/cash/treehouse/widget/WidgetDisplay.kt#L30

```text

package app.cash.treehouse.widget

import app.cash.treehouse.protocol.Diff
import app.cash.treehouse.protocol.WidgetDiff

class WidgetDisplay<T : Any>(
  private val root: Widget<T>,
  private val factory: Widget.Factory<T>,
  private val events: EventSink,
) {
  private val widgets = mutableMapOf(Diff.RootId to root)

  fun apply(diff: Diff) {
    for (widgetDiff in diff.widgetDiffs) {
      val widget = checkNotNull(widgets[widgetDiff.id]) {
        ""Unknown widget ID ${widgetDiff.id}""
      }

      when (widgetDiff) {
        is WidgetDiff.Insert -> {
          val childWidget = factory.create(widget.value, widgetDiff.kind, widgetDiff.childId, events)
          widgets[widgetDiff.childId] = childWidget
          widget.children(widgetDiff.childrenIndex).insert(widgetDiff.index, childWidget.value)
        }
        is WidgetDiff.Move -> {
          widget.children(widgetDiff.childrenIndex).move(widgetDiff.fromIndex, widgetDiff.toIndex, widgetDiff.count)
        }
        is WidgetDiff.Remove -> {
          widget.children(widgetDiff.childrenIndex).remove(widgetDiff.index, widgetDiff.count)
          // TODO we need to remove widgets from our map!
        }
        WidgetDiff.Clear -> {
          widget.children(Diff.RootChildrenIndex).clear()
          widgets.clear()
          widgets[Diff.RootId] = root
        }
      }
    }

    for (propertyDiff in diff.propertyDiffs) {
      val widget = checkNotNull(widgets[propertyDiff.id]) {
        ""Unknown widget iD ${propertyDiff.id}""
      }

      widget.apply(propertyDiff)
    }
  }
}

```

edf3f9a0d1576c577b8785b13ce44e6b2bcae7c4",2fa156dbaca77fe50d3f57de0e64891e2b87fcd5,f9d06e7664695840aa8d14c01b522f1945d6a06e,https://github.com/cashapp/redwood/compare/2fa156dbaca77fe50d3f57de0e64891e2b87fcd5...f9d06e7664695840aa8d14c01b522f1945d6a06e,"diff --git a/treehouse/treehouse-compose/src/commonMain/kotlin/app/cash/treehouse/compose/applier.kt b/treehouse/treehouse-compose/src/commonMain/kotlin/app/cash/treehouse/compose/applier.kt
index 77520f3d4..4383be9a1 100644
--- a/treehouse/treehouse-compose/src/commonMain/kotlin/app/cash/treehouse/compose/applier.kt
+++ b/treehouse/treehouse-compose/src/commonMain/kotlin/app/cash/treehouse/compose/applier.kt
@@ -180,13 +180,19 @@ internal class ProtocolApplier(
   override fun remove(index: Int, count: Int) {
     // Children instances are never removed from their parents.
     val current = current as ProtocolChildrenNode
-
     val children = current.children
+
+    // TODO We should not have to track this and send it as part of the protocol.
+    //  Ideally this would be entirely encapsulated on the display-side with additional bookkeeping.
+    //  For now, we track it here and send it in the protocol as a simple solution.
+    val removedIds = ArrayList<Long>(count)
     for (i in index until index + count) {
-      nodes.remove(children[i].id)
+      removedIds.add(children[i].id)
     }
+
+    nodes.keys.removeAll(removedIds)
     children.remove(index, count)
-    childrenDiffs.add(ChildrenDiff.Remove(current.id, current.tag, index, count))
+    childrenDiffs.add(ChildrenDiff.Remove(current.id, current.tag, index, count, removedIds))
   }
 
   override fun move(from: Int, to: Int, count: Int) {
diff --git a/treehouse/treehouse-protocol/src/commonMain/kotlin/app/cash/treehouse/protocol/protocol.kt b/treehouse/treehouse-protocol/src/commonMain/kotlin/app/cash/treehouse/protocol/protocol.kt
index 42f316c5d..e16bb4a0f 100644
--- a/treehouse/treehouse-protocol/src/commonMain/kotlin/app/cash/treehouse/protocol/protocol.kt
+++ b/treehouse/treehouse-protocol/src/commonMain/kotlin/app/cash/treehouse/protocol/protocol.kt
@@ -84,7 +84,14 @@ public sealed class ChildrenDiff {
     override val tag: Int,
     val index: Int,
     val count: Int,
-  ) : ChildrenDiff()
+    val removedIds: List<Long>,
+  ) : ChildrenDiff() {
+    init {
+      require(count == removedIds.size) {
+        ""Count $count != Removed ID list size ${removedIds.size}""
+      }
+    }
+  }
 
   public companion object {
     public const val RootId: Long = 0L
diff --git a/treehouse/treehouse-protocol/src/commonTest/kotlin/app/cash/treehouse/protocol/ProtocolTest.kt b/treehouse/treehouse-protocol/src/commonTest/kotlin/app/cash/treehouse/protocol/ProtocolTest.kt
index b6adaebf1..31a20c77a 100644
--- a/treehouse/treehouse-protocol/src/commonTest/kotlin/app/cash/treehouse/protocol/ProtocolTest.kt
+++ b/treehouse/treehouse-protocol/src/commonTest/kotlin/app/cash/treehouse/protocol/ProtocolTest.kt
@@ -22,6 +22,7 @@ import kotlinx.serialization.modules.SerializersModule
 import kotlinx.serialization.modules.polymorphic
 import kotlin.test.Test
 import kotlin.test.assertEquals
+import kotlin.test.assertFailsWith
 
 class ProtocolTest {
   private val format = Json {
@@ -51,7 +52,7 @@ class ProtocolTest {
         ChildrenDiff.Clear,
         ChildrenDiff.Insert(1, 2, 3, 4, 5),
         ChildrenDiff.Move(1, 2, 3, 4, 5),
-        ChildrenDiff.Remove(1, 2, 3, 4),
+        ChildrenDiff.Remove(1, 2, 3, 4, listOf(5, 6, 7, 8)),
       ),
       propertyDiffs = listOf(
         PropertyDiff(1, 2, ""Hello""),
@@ -63,7 +64,7 @@ class ProtocolTest {
       """"""[""clear"",{}],"""""" +
       """"""[""insert"",{""id"":1,""tag"":2,""childId"":3,""kind"":4,""index"":5}],"""""" +
       """"""[""move"",{""id"":1,""tag"":2,""fromIndex"":3,""toIndex"":4,""count"":5}],"""""" +
-      """"""[""remove"",{""id"":1,""tag"":2,""index"":3,""count"":4}]"""""" +
+      """"""[""remove"",{""id"":1,""tag"":2,""index"":3,""count"":4,""removedIds"":[5,6,7,8]}]"""""" +
       """"""],""propertyDiffs"":["""""" +
       """"""{""id"":1,""tag"":2,""value"":[""kotlin.String"",""Hello""]},"""""" +
       """"""{""id"":1,""tag"":2}"""""" +
@@ -80,6 +81,12 @@ class ProtocolTest {
     assertJsonRoundtrip(Diff.serializer(), model, json)
   }
 
+  @Test fun removeCountMustMatchListSize() {
+    assertFailsWith<IllegalArgumentException>(""Count 4 != Removed ID list size 3"") {
+      ChildrenDiff.Remove(1, 2, 3, 4, listOf(5, 6, 7))
+    }
+  }
+
   private fun <T> assertJsonRoundtrip(serializer: KSerializer<T>, model: T, json: String) {
     assertEquals(json, format.encodeToString(serializer, model))
     assertEquals(model, format.decodeFromString(serializer, json))
diff --git a/treehouse/treehouse-widget/src/commonMain/kotlin/app/cash/treehouse/widget/WidgetDisplay.kt b/treehouse/treehouse-widget/src/commonMain/kotlin/app/cash/treehouse/widget/WidgetDisplay.kt
index 1c04a3088..c3fdca8ae 100644
--- a/treehouse/treehouse-widget/src/commonMain/kotlin/app/cash/treehouse/widget/WidgetDisplay.kt
+++ b/treehouse/treehouse-widget/src/commonMain/kotlin/app/cash/treehouse/widget/WidgetDisplay.kt
@@ -55,7 +55,7 @@ public class WidgetDisplay<T : Any>(
         }
         is ChildrenDiff.Remove -> {
           children.remove(childrenDiff.index, childrenDiff.count)
-          // TODO we need to remove widgets from our map!
+          widgets.keys.removeAll(childrenDiff.removedIds)
         }
         ChildrenDiff.Clear -> {
           children.clear()","['treehouse/treehouse-protocol/src/commonTest/kotlin/app/cash/treehouse/protocol/ProtocolTest.kt', 'treehouse/treehouse-widget/src/commonMain/kotlin/app/cash/treehouse/widget/WidgetDisplay.kt', 'treehouse/treehouse-compose/src/commonMain/kotlin/app/cash/treehouse/compose/applier.kt', 'treehouse/treehouse-protocol/src/commonMain/kotlin/app/cash/treehouse/protocol/protocol.kt']",{'.kt': 4},4,0,4,0,4,160540,39952,5958,42,948,213,23,3,1828,137,443,58,1,1,2021-07-21 13:41:13,1182,Kotlin,"{'Kotlin': 1348902, 'Java': 1583}",Apache License 2.0,['treehouse/treehouse-widget/src/commonMain/kotlin/app/cash/treehouse/widget/WidgetDisplay.kt'],['treehouse/treehouse-widget/src/commonMain/kotlin/app/cash/treehouse/widget/WidgetDisplay.kt'],"['```json\n{\n  ""files"": [\n    ""treehouse/treehouse-widget/src/commonMain/kotlin/app/cash/treehouse/widget/WidgetDisplay.kt""\n  ]\n}\n```']",1,1122.6222515106201
1578,square/anvil/577/574,square,anvil,https://github.com/square/anvil/issues/574,https://github.com/square/anvil/pull/577,https://github.com/square/anvil/pull/577,1,fixes,"""is...""-named Module properties break build","A module property with a name starting with ""is"" that acts as a provider breaks Dagger processing when processing the module with Anvil 2.4.0-M2. This does not happen when using straight Dagger for annotation processing. I suppose there is some problem with different beans-like name processing being applied by the processors. At a minimum, this is super-confusing; I was chasing this problem for hours before thinking of the property name and finding the actual repro path.

For example:

    @Module
    @ContributesTo(MyComponentScope::class)
    class MyModule {
        @get:Provides
        val isValidCache: BooleanArray = booleanArrayOf(false)
    }

The element needs to be injected somewhere to trigger the error:

    > Task :app:compileDebugJavaWithJavac FAILED
    MyComponent.java:86: error: cannot find symbol
    import com.example.MyModule_IsValidCacheFactory;
    ^
    symbol:   class MyModule_IsValidCacheFactory
    location: package com.example
    app/build/generated/source/kapt/debug/com/example/DaggerMyComponent.java:800: error: cannot find symbol
    return (T) new SampleViewModel(MyModule_IsValidCacheFactory.isValidCache(myComponentImpl.myModule));

If I use a different property name like 'validCache', Dagger prefixes 'get' when generating the component code: 'getValidCache()' instead of 'isValidCache()'",ef17fb6373dff0a30bd2033129f723da06129d2c,446381cf72f53965db29b0011278cc546d984670,https://github.com/square/anvil/compare/ef17fb6373dff0a30bd2033129f723da06129d2c...446381cf72f53965db29b0011278cc546d984670,"diff --git a/compiler/src/main/java/com/squareup/anvil/compiler/codegen/dagger/ProvidesMethodFactoryGenerator.kt b/compiler/src/main/java/com/squareup/anvil/compiler/codegen/dagger/ProvidesMethodFactoryGenerator.kt
index 8df7e7e..fe1f791 100644
--- a/compiler/src/main/java/com/squareup/anvil/compiler/codegen/dagger/ProvidesMethodFactoryGenerator.kt
+++ b/compiler/src/main/java/com/squareup/anvil/compiler/codegen/dagger/ProvidesMethodFactoryGenerator.kt
@@ -116,6 +116,8 @@ internal class ProvidesMethodFactoryGenerator : PrivateCodeGenerator() {
     val isObject = isCompanionObject || clazz.isObject()
 
     val isProperty = declaration.isProperty
+    val declarationName = declaration.fqName.shortName().asString()
+    val useGetPrefix = isProperty && !declarationName.startsWith(""is"")
 
     val isMangled = !isProperty &&
       declaration.visibility == INTERNAL &&
@@ -128,10 +130,10 @@ internal class ProvidesMethodFactoryGenerator : PrivateCodeGenerator() {
       if (isCompanionObject) {
         append(""Companion_"")
       }
-      if (isProperty) {
+      if (useGetPrefix) {
         append(""Get"")
       }
-      append(declaration.fqName.shortName().asString().capitalize())
+      append(declarationName.capitalize())
       if (isMangled) {
         append(""\\$${module.mangledNameSuffix()}"")
       }
@@ -150,7 +152,7 @@ internal class ProvidesMethodFactoryGenerator : PrivateCodeGenerator() {
     val moduleClass = clazz.asClassName()
 
     val byteCodeFunctionName = when {
-      isProperty -> ""get"" + callableName.capitalize()
+      useGetPrefix -> ""get"" + callableName.capitalize()
       isMangled -> ""$callableName\\$${module.mangledNameSuffix()}""
       else -> callableName
     }
diff --git a/compiler/src/test/java/com/squareup/anvil/compiler/dagger/ProvidesMethodFactoryGeneratorTest.kt b/compiler/src/test/java/com/squareup/anvil/compiler/dagger/ProvidesMethodFactoryGeneratorTest.kt
index 92eb5ad..4c4129a 100644
--- a/compiler/src/test/java/com/squareup/anvil/compiler/dagger/ProvidesMethodFactoryGeneratorTest.kt
+++ b/compiler/src/test/java/com/squareup/anvil/compiler/dagger/ProvidesMethodFactoryGeneratorTest.kt
@@ -2624,6 +2624,7 @@ public final class DaggerComponentInterface implements ComponentInterface {
 
   @Test
   fun `a factory class is generated for an uppercase factory function`() {
+    @Suppress(""TestFunctionName"")
     compile(
       """"""
       package com.squareup.test.a
@@ -3319,6 +3320,78 @@ public final class DaggerModule1_ProvideFunctionFactory implements Factory<Set<S
     }
   }
 
+  @Test fun `a provides method with 'is' as prefix is supported`() {
+    compile(
+      """"""
+      package com.squareup.test
+      
+      import dagger.Module
+      import dagger.Provides
+      import javax.inject.Singleton
+      
+      @Module
+      class DaggerModule1 {
+        @get:Provides
+        val isValidCache: BooleanArray = booleanArrayOf(false)
+      }
+      """"""
+    ) {
+      val factoryClass = daggerModule1.moduleFactoryClass(""isValidCache"")
+
+      val constructor = factoryClass.declaredConstructors.single()
+      assertThat(constructor.parameterTypes.toList()).containsExactly(daggerModule1)
+
+      val staticMethods = factoryClass.declaredMethods.filter { it.isStatic }
+      assertThat(staticMethods).hasSize(2)
+
+      val module = daggerModule1.createInstance()
+
+      val factoryInstance = staticMethods.single { it.name == ""create"" }
+        .invoke(null, module)
+      assertThat(factoryInstance::class.java).isEqualTo(factoryClass)
+
+      val providedFactory = staticMethods.single { it.name == ""isValidCache"" }
+        .invoke(null, module) as Any
+
+      assertThat((factoryInstance as Factory<*>).get()).isSameInstanceAs(providedFactory)
+    }
+  }
+
+  @Test fun `a provides method with 'is' as prefix is supported for objects`() {
+    compile(
+      """"""
+      package com.squareup.test
+      
+      import dagger.Module
+      import dagger.Provides
+      import javax.inject.Singleton
+      
+      @Module
+      object DaggerModule1 {
+        @get:Provides
+        val isValidCache: Boolean = false
+      }
+      """"""
+    ) {
+      val factoryClass = daggerModule1.moduleFactoryClass(""isValidCache"")
+
+      val constructor = factoryClass.declaredConstructors.single()
+      assertThat(constructor.parameterTypes.toList()).isEmpty()
+
+      val staticMethods = factoryClass.declaredMethods.filter { it.isStatic }
+
+      val factoryInstance = staticMethods.single { it.name == ""create"" }
+        .invoke(null)
+      assertThat(factoryInstance::class.java).isEqualTo(factoryClass)
+
+      val providedBoolean = staticMethods.single { it.name == ""isValidCache"" }
+        .invoke(null) as Boolean
+
+      assertThat(providedBoolean).isFalse()
+      assertThat((factoryInstance as Factory<Boolean>).get()).isFalse()
+    }
+  }
+
   private fun compile(
     @Language(""kotlin"") vararg sources: String,
     enableDagger: Boolean = useDagger,","['compiler/src/test/java/com/squareup/anvil/compiler/dagger/ProvidesMethodFactoryGeneratorTest.kt', 'compiler/src/main/java/com/squareup/anvil/compiler/codegen/dagger/ProvidesMethodFactoryGenerator.kt']",{'.kt': 2},2,0,2,0,2,440761,92720,11977,98,418,91,8,1,1361,149,291,23,0,0,2022-03-24 03:25:59,1138,Kotlin,"{'Kotlin': 1299266, 'Shell': 712}",Apache License 2.0,"['compiler/src/main/java/com/squareup/anvil/compiler/codegen/ContributesToGenerator.kt', 'compiler/src/main/java/com/squareup/anvil/compiler/codegen/ContributesBindingGenerator.kt', 'compiler/src/main/java/com/squareup/anvil/compiler/codegen/ContributesMultibindingGenerator.kt', 'compiler/src/main/java/com/squareup/anvil/compiler/codegen/BindingModuleGenerator.kt', 'compiler/src/main/java/com/squareup/anvil/compiler/codegen/ContributesSubcomponentGenerator.kt']","['compiler/src/main/java/com/squareup/anvil/compiler/codegen/ContributesToGenerator.kt', 'compiler/src/main/java/com/squareup/anvil/compiler/codegen/ContributesBindingGenerator.kt', 'compiler/src/main/java/com/squareup/anvil/compiler/codegen/ContributesMultibindingGenerator.kt', 'compiler/src/main/java/com/squareup/anvil/compiler/codegen/BindingModuleGenerator.kt', 'compiler/src/main/java/com/squareup/anvil/compiler/codegen/ContributesSubcomponentGenerator.kt']","['```json\n{\n  ""files"": [\n    ""compiler/src/main/java/com/squareup/anvil/compiler/codegen/BindingModuleGenerator.kt"",\n    ""compiler/src/main/java/com/squareup/anvil/compiler/codegen/ContributesToGenerator.kt"",\n    ""compiler/src/main/java/com/squareup/anvil/compiler/codegen/ContributesBindingGenerator.kt"",\n    ""compiler/src/main/java/com/squareup/anvil/compiler/codegen/ContributesSubcomponentGenerator.kt"",\n    ""compiler/src/main/java/com/squareup/anvil/compiler/codegen/ContributesMultibindingGenerator.kt""\n  ]\n}\n```']",1,1394.8912620544434
1582,square/anvil/467/459,square,anvil,https://github.com/square/anvil/issues/459,https://github.com/square/anvil/pull/467,https://github.com/square/anvil/pull/467,1,fixes,ContributesSubcomponent issue in testing,"Hey, I love the `ContributesSubcomponent` feature, now I can move the component definition to a library, and remove some BS abstractions.

Bit of context, I have a monorepo with 3 apps. Each app uses the same scopes, however each app is not feature identical.
When creating integration tests with real dagger component, I had created TestAppComponent, TestUserComponent, in each app, with excluded modules which depend on android and replaced them with fakes

However, now as I moved to ContributesSubcomponent tests fail to compile with

```
com.squareup.anvil.compiler.api.AnvilCompilationException: Back-end (JVM) Internal error: There are multiple contributed bindings with the same bound type. The bound type is sk.o2.radost.auth.di.UserComponent.Factory. The contributed binding classes are: [anvil.component.sk.o2.radost.testcomponent.testappcomponent.UserComponentA.SubcomponentFactory, anvil.component.sk.o2.radost.di.appcomponent.UserComponentA.SubcomponentFactory]
File is unknown

	at com.squareup.anvil.compiler.codegen.BindingModuleGeneratorKt.findHighestPriorityBinding(BindingModuleGenerator.kt:375)
	at com.squareup.anvil.compiler.codegen.BindingModuleGeneratorKt.access$findHighestPriorityBinding(BindingModuleGenerator.kt:1)
	at com.squareup.anvil.compiler.codegen.BindingModuleGenerator.flush$lambda-13$getContributedBindingClasses(BindingModuleGenerator.kt:248)
	at com.squareup.anvil.compiler.codegen.BindingModuleGenerator.flush(BindingModuleGenerator.kt:256)
	at com.squareup.anvil.compiler.codegen.CodeGenerationExtension.analysisCompleted$flush(CodeGenerationExtension.kt:99)
	at com.squareup.anvil.compiler.codegen.CodeGenerationExtension.analysisCompleted(CodeGenerationExtension.kt:110)
	at org.jetbrains.kotlin.cli.jvm.compiler.TopDownAnalyzerFacadeForJVM.analyzeFilesWithJavaIntegration$invokeExtensionsOnAnalysisComplete(TopDownAnalyzerFacadeForJVM.kt:112)
	at org.jetbrains.kotlin.cli.jvm.compiler.TopDownAnalyzerFacadeForJVM.analyzeFilesWithJavaIntegration(TopDownAnalyzerFacadeForJVM.kt:122)
	at org.jetbrains.kotlin.cli.jvm.compiler.TopDownAnalyzerFacadeForJVM.analyzeFilesWithJavaIntegration$default(TopDownAnalyzerFacadeForJVM.kt:86)
	at org.jetbrains.kotlin.cli.jvm.compiler.KotlinToJVMBytecodeCompiler$analyze$1.invoke(KotlinToJVMBytecodeCompiler.kt:252)
	at org.jetbrains.kotlin.cli.jvm.compiler.KotlinToJVMBytecodeCompiler$analyze$1.invoke(KotlinToJVMBytecodeCompiler.kt:243)
	at org.jetbrains.kotlin.cli.common.messages.AnalyzerWithCompilerReport.analyzeAndReport(AnalyzerWithCompilerReport.kt:113)
	at org.jetbrains.kotlin.cli.jvm.compiler.KotlinToJVMBytecodeCompiler.analyze(KotlinToJVMBytecodeCompiler.kt:243)
	at org.jetbrains.kotlin.cli.jvm.compiler.KotlinToJVMBytecodeCompiler.compileModules$cli(KotlinToJVMBytecodeCompiler.kt:90)
	at org.jetbrains.kotlin.cli.jvm.compiler.KotlinToJVMBytecodeCompiler.compileModules$cli$default(KotlinToJVMBytecodeCompiler.kt:56)
	at org.jetbrains.kotlin.cli.jvm.K2JVMCompiler.doExecute(K2JVMCompiler.kt:169)
	at org.jetbrains.kotlin.cli.jvm.K2JVMCompiler.doExecute(K2JVMCompiler.kt:52)
	at org.jetbrains.kotlin.cli.common.CLICompiler.execImpl(CLICompiler.kt:92)
	at org.jetbrains.kotlin.cli.common.CLICompiler.execImpl(CLICompiler.kt:44)
	at org.jetbrains.kotlin.cli.common.CLITool.exec(CLITool.kt:98)
	at org.jetbrains.kotlin.daemon.CompileServiceImpl.compile(CompileServiceImpl.kt:1574)
	at jdk.internal.reflect.GeneratedMethodAccessor105.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at java.rmi/sun.rmi.server.UnicastServerRef.dispatch(UnicastServerRef.java:359)
	at java.rmi/sun.rmi.transport.Transport$1.run(Transport.java:200)
	at java.rmi/sun.rmi.transport.Transport$1.run(Transport.java:197)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.rmi/sun.rmi.transport.Transport.serviceCall(Transport.java:196)
	at java.rmi/sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:562)
	at java.rmi/sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:796)
	at java.rmi/sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.lambda$run$0(TCPTransport.java:677)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.rmi/sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:676)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
```

Real 

```
@UserScope
@OptIn(ExperimentalAnvilApi::class)
@ContributesSubcomponent(
    scope = UserScope::class,
    parentScope = AppScope::class
)
interface UserComponent {

    @ContributesTo(AppScope::class)
    interface ParentComponent {
        val userComponentFactory: Factory
    }

    @ContributesSubcomponent.Factory
    interface Factory {
        fun create(): UserComponent
    }
}
```

The test component definition is as such

```
@UserScope
@MergeSubcomponent(UserScope::class)
interface TestUserComponent {

    @ContributesTo(AppScope::class, replaces = [UserComponent.ParentComponent::class])
    interface ParentComponent {
        val testUserComponentFactory: Factory
    }

    @Subcomponent.Factory
    interface Factory {
        fun create(): TestUserComponent
    }
}

@Module
@ContributesTo(
    scope = UserScope::class,
    replaces = [
        UserImageSaverModule::class
    ]
)
object FakeImageSaverModule {
    @UserScope
    @JvmStatic
    @Provides
    fun imageSaver(): ImageSaver {
        return FakeImageSaver()
    }
}
```

This used to work because I removed the ParentComponent which attached the Factory to the real UserComponent onto AppComponent.

Now there seems the plugin does some more work and the factory to the real thing is there anyways, and it should not

// I noticed your tweet https://twitter.com/vRallev/status/1463627818730864642 but unsure how to do that. I see the exclude parameter on the annotation, however I dont know what to exclude at library level, as the user module doesnt know all the feature it will have in the final app

If there is more idiomatic way, I'm all ears",535153e2624cbe879182df8508183773f90fb53d,44b9750a657b6a46827c9f5c1ad45109eef138e8,https://github.com/square/anvil/compare/535153e2624cbe879182df8508183773f90fb53d...44b9750a657b6a46827c9f5c1ad45109eef138e8,"diff --git a/compiler/src/main/java/com/squareup/anvil/compiler/ClassScannerIr.kt b/compiler/src/main/java/com/squareup/anvil/compiler/ClassScannerIr.kt
index 677df3c..0758e62 100644
--- a/compiler/src/main/java/com/squareup/anvil/compiler/ClassScannerIr.kt
+++ b/compiler/src/main/java/com/squareup/anvil/compiler/ClassScannerIr.kt
@@ -15,7 +15,7 @@ internal fun ClassScanner.findContributedClasses(
   moduleFragment: IrModuleFragment,
   packageName: String,
   annotation: FqName,
-  scope: FqName
+  scope: FqName?
 ): Sequence<IrClassSymbol> {
   return findContributedClasses(moduleFragment.descriptor, packageName, annotation, scope)
     .map {
diff --git a/compiler/src/main/java/com/squareup/anvil/compiler/IrUtils.kt b/compiler/src/main/java/com/squareup/anvil/compiler/IrUtils.kt
index d3e5e69..ee24ce6 100644
--- a/compiler/src/main/java/com/squareup/anvil/compiler/IrUtils.kt
+++ b/compiler/src/main/java/com/squareup/anvil/compiler/IrUtils.kt
@@ -17,9 +17,11 @@ import org.jetbrains.kotlin.ir.types.IrType
 import org.jetbrains.kotlin.ir.types.classifierOrNull
 import org.jetbrains.kotlin.ir.types.getClass
 import org.jetbrains.kotlin.ir.types.typeOrNull
+import org.jetbrains.kotlin.ir.util.classId
 import org.jetbrains.kotlin.ir.util.fqNameWhenAvailable
 import org.jetbrains.kotlin.ir.util.getAnnotation
 import org.jetbrains.kotlin.ir.util.getArgumentsWithIr
+import org.jetbrains.kotlin.name.ClassId
 import org.jetbrains.kotlin.name.FqName
 
 internal fun IrPluginContext.requireReferenceClass(fqName: FqName): IrClassSymbol {
@@ -28,6 +30,21 @@ internal fun IrPluginContext.requireReferenceClass(fqName: FqName): IrClassSymbo
   )
 }
 
+internal fun ClassId.irClass(context: IrPluginContext): IrClassSymbol =
+  context.requireReferenceClass(asSingleFqName())
+
+internal fun ClassId.irClassOrNull(context: IrPluginContext): IrClassSymbol? =
+  context.referenceClass(asSingleFqName())
+
+internal fun IrClass.requireClassId(): ClassId {
+  return classId ?: throw AnvilCompilationException(
+    element = this,
+    message = ""Couldn't find a ClassId for $fqName.""
+  )
+}
+
+internal fun IrClassSymbol.requireClassId(): ClassId = owner.requireClassId()
+
 internal fun IrAnnotationContainer.annotationOrNull(
   annotationFqName: FqName,
   scope: FqName? = null
diff --git a/compiler/src/main/java/com/squareup/anvil/compiler/ModuleMerger.kt b/compiler/src/main/java/com/squareup/anvil/compiler/ModuleMerger.kt
index 678e3e5..964bc20 100644
--- a/compiler/src/main/java/com/squareup/anvil/compiler/ModuleMerger.kt
+++ b/compiler/src/main/java/com/squareup/anvil/compiler/ModuleMerger.kt
@@ -5,12 +5,15 @@ import com.squareup.anvil.annotations.MergeComponent
 import com.squareup.anvil.annotations.MergeSubcomponent
 import com.squareup.anvil.annotations.compat.MergeModules
 import com.squareup.anvil.compiler.api.AnvilCompilationException
+import com.squareup.anvil.compiler.codegen.generatedAnvilSubcomponent
 import com.squareup.anvil.compiler.internal.annotation
 import com.squareup.anvil.compiler.internal.annotationOrNull
 import com.squareup.anvil.compiler.internal.argumentType
+import com.squareup.anvil.compiler.internal.classDescriptorOrNull
 import com.squareup.anvil.compiler.internal.getAnnotationValue
 import com.squareup.anvil.compiler.internal.parentScope
 import com.squareup.anvil.compiler.internal.requireClassDescriptor
+import com.squareup.anvil.compiler.internal.requireClassId
 import com.squareup.anvil.compiler.internal.safePackageString
 import com.squareup.anvil.compiler.internal.scope
 import com.squareup.anvil.compiler.internal.toType
@@ -27,6 +30,7 @@ import org.jetbrains.kotlin.descriptors.ModuleDescriptor
 import org.jetbrains.kotlin.descriptors.annotations.AnnotationDescriptor
 import org.jetbrains.kotlin.descriptors.effectiveVisibility
 import org.jetbrains.kotlin.name.FqName
+import org.jetbrains.kotlin.name.Name
 import org.jetbrains.kotlin.resolve.DescriptorUtils
 import org.jetbrains.kotlin.resolve.constants.ArrayValue
 import org.jetbrains.kotlin.resolve.constants.ConstantValue
@@ -47,18 +51,19 @@ internal class ModuleMerger(
 ) : ExpressionCodegenExtension {
 
   override fun generateClassSyntheticParts(codegen: ImplementationBodyCodegen) {
-    val holder = AnnotationHolder.create(codegen.descriptor) ?: return
+    val thisDescriptor = codegen.descriptor
+    val holder = AnnotationHolder.create(thisDescriptor) ?: return
     val (mergeAnnotation, annotationClass, daggerClass, daggerFqName, modulesKeyword) = holder
 
-    if (codegen.descriptor.annotationOrNull(daggerFqName) != null) {
+    if (thisDescriptor.annotationOrNull(daggerFqName) != null) {
       throw AnvilCompilationException(
-        codegen.descriptor,
+        thisDescriptor,
         ""When using @${annotationClass.simpleName} it's not allowed to annotate the same "" +
           ""class with @${daggerClass.simpleName}. The Dagger annotation will be generated.""
       )
     }
 
-    val module = codegen.descriptor.module
+    val module = thisDescriptor.module
     val scope = mergeAnnotation.scope(module)
     val scopeFqName = scope.fqNameSafe
 
@@ -67,7 +72,7 @@ internal class ModuleMerger(
         ?.value
         ?.map { it.toType(codegen) }
 
-    val anvilModuleName = createAnvilModuleName(codegen.descriptor)
+    val anvilModuleName = createAnvilModuleName(thisDescriptor)
 
     val modules = classScanner
       .findContributedClasses(
@@ -144,15 +149,15 @@ internal class ModuleMerger(
           ?: contributesMultibindingAnnotation?.scope(module)
           ?: contributesSubcomponentAnnotation?.parentScope(module)
           ?: throw AnvilCompilationException(
-            codegen.descriptor,
+            thisDescriptor,
             ""Could not determine the scope of the excluded class "" +
               ""${classDescriptorForExclusion.fqNameSafe}.""
           )
 
         if (scopeOfExclusion.fqNameSafe != scopeFqName) {
           throw AnvilCompilationException(
-            codegen.descriptor,
-            ""${codegen.descriptor.fqNameSafe} with scope $scopeFqName wants to exclude "" +
+            thisDescriptor,
+            ""${thisDescriptor.fqNameSafe} with scope $scopeFqName wants to exclude "" +
               ""${classDescriptorForExclusion.fqNameSafe} with scope "" +
               ""${scopeOfExclusion.fqNameSafe}. The exclusion must use the same scope.""
           )
@@ -234,13 +239,17 @@ internal class ModuleMerger(
       val intersect = predefinedModules.intersect(excludedModules.toSet())
       if (intersect.isNotEmpty()) {
         throw AnvilCompilationException(
-          codegen.descriptor,
-          ""${codegen.descriptor.name} includes and excludes modules "" +
+          thisDescriptor,
+          ""${thisDescriptor.name} includes and excludes modules "" +
             ""at the same time: ${intersect.joinToString { it.className }}""
         )
       }
     }
 
+    val contributedSubcomponentModules =
+      findContributedSubcomponentModules(thisDescriptor, scopeFqName, module)
+        .map { codegen.typeMapper.mapType(it) }
+
     val contributedModules = modules
       .asSequence()
       .map { codegen.typeMapper.mapType(it.first) }
@@ -248,6 +257,7 @@ internal class ModuleMerger(
       .minus(replacedModulesByContributedBindings.toSet())
       .minus(replacedModulesByContributedMultibindings.toSet())
       .minus(excludedModules.toSet())
+      .plus(contributedSubcomponentModules)
       .distinct()
 
     codegen.v
@@ -340,6 +350,29 @@ internal class ModuleMerger(
       )
     }
   }
+
+  private fun findContributedSubcomponentModules(
+    descriptor: ClassDescriptor,
+    scope: FqName,
+    module: ModuleDescriptor
+  ): Sequence<ClassDescriptor> {
+    return classScanner
+      .findContributedClasses(
+        module = module,
+        packageName = HINT_SUBCOMPONENTS_PACKAGE_PREFIX,
+        annotation = contributesSubcomponentFqName,
+        scope = null
+      )
+      .filter {
+        it.annotation(contributesSubcomponentFqName).parentScope(module).fqNameSafe == scope
+      }
+      .mapNotNull { contributedSubcomponent ->
+        contributedSubcomponent.requireClassId()
+          .generatedAnvilSubcomponent(descriptor.requireClassId())
+          .createNestedClassId(Name.identifier(SUBCOMPONENT_MODULE))
+          .classDescriptorOrNull(module)
+      }
+  }
 }
 
 @Suppress(""DataClassPrivateConstructor"")
diff --git a/compiler/src/main/java/com/squareup/anvil/compiler/ModuleMergerIr.kt b/compiler/src/main/java/com/squareup/anvil/compiler/ModuleMergerIr.kt
index f57d971..56e1d5a 100644
--- a/compiler/src/main/java/com/squareup/anvil/compiler/ModuleMergerIr.kt
+++ b/compiler/src/main/java/com/squareup/anvil/compiler/ModuleMergerIr.kt
@@ -2,6 +2,7 @@ package com.squareup.anvil.compiler
 
 import com.squareup.anvil.annotations.ContributesTo
 import com.squareup.anvil.compiler.api.AnvilCompilationException
+import com.squareup.anvil.compiler.codegen.generatedAnvilSubcomponent
 import com.squareup.anvil.compiler.internal.safePackageString
 import dagger.Module
 import org.jetbrains.kotlin.backend.common.extensions.IrGenerationExtension
@@ -24,6 +25,7 @@ import org.jetbrains.kotlin.ir.util.isInterface
 import org.jetbrains.kotlin.ir.util.packageFqName
 import org.jetbrains.kotlin.ir.visitors.IrElementTransformerVoid
 import org.jetbrains.kotlin.name.FqName
+import org.jetbrains.kotlin.name.Name
 import org.jetbrains.kotlin.types.Variance.INVARIANT
 
 internal class ModuleMergerIr(
@@ -223,6 +225,9 @@ internal class ModuleMergerIr(
       }
     }
 
+    val contributedSubcomponentModules =
+      findContributedSubcomponentModules(declaration, scope, pluginContext, moduleFragment)
+
     val contributedModules = modules
       .asSequence()
       .map { it.first.owner }
@@ -231,6 +236,7 @@ internal class ModuleMergerIr(
       .minus(replacedModulesByContributedMultibindings.toSet())
       .minus(excludedModules.toSet())
       .plus(predefinedModules)
+      .plus(contributedSubcomponentModules)
       .distinct()
 
     val annotationConstructorCall = IrConstructorCallImpl
@@ -330,6 +336,32 @@ internal class ModuleMergerIr(
       )
     }
   }
+
+  private fun findContributedSubcomponentModules(
+    declaration: IrClass,
+    scope: FqName,
+    pluginContext: IrPluginContext,
+    moduleFragment: IrModuleFragment
+  ): Sequence<IrClass> {
+    return classScanner
+      .findContributedClasses(
+        pluginContext = pluginContext,
+        moduleFragment = moduleFragment,
+        packageName = HINT_SUBCOMPONENTS_PACKAGE_PREFIX,
+        annotation = contributesSubcomponentFqName,
+        scope = null
+      )
+      .filter {
+        it.owner.annotation(contributesSubcomponentFqName).parentScope() == scope
+      }
+      .mapNotNull { contributedSubcomponent ->
+        contributedSubcomponent.requireClassId()
+          .generatedAnvilSubcomponent(declaration.requireClassId())
+          .createNestedClassId(Name.identifier(SUBCOMPONENT_MODULE))
+          .irClassOrNull(pluginContext)
+          ?.owner
+      }
+  }
 }
 
 @Suppress(""DataClassPrivateConstructor"")
diff --git a/compiler/src/main/java/com/squareup/anvil/compiler/Utils.kt b/compiler/src/main/java/com/squareup/anvil/compiler/Utils.kt
index 0fc2b28..53f608c 100644
--- a/compiler/src/main/java/com/squareup/anvil/compiler/Utils.kt
+++ b/compiler/src/main/java/com/squareup/anvil/compiler/Utils.kt
@@ -76,6 +76,7 @@ internal const val ANVIL_MODULE_SUFFIX = ""AnvilModule""
 internal const val ANVIL_SUBCOMPONENT_SUFFIX = ""A""
 internal const val PARENT_COMPONENT = ""ParentComponent""
 internal const val SUBCOMPONENT_FACTORY = ""SubcomponentFactory""
+internal const val SUBCOMPONENT_MODULE = ""SubcomponentModule""
 
 internal const val REFERENCE_SUFFIX = ""_reference""
 internal const val SCOPE_SUFFIX = ""_scope""
diff --git a/compiler/src/main/java/com/squareup/anvil/compiler/codegen/BindingModuleGenerator.kt b/compiler/src/main/java/com/squareup/anvil/compiler/codegen/BindingModuleGenerator.kt
index 7a0702d..f11457c 100644
--- a/compiler/src/main/java/com/squareup/anvil/compiler/codegen/BindingModuleGenerator.kt
+++ b/compiler/src/main/java/com/squareup/anvil/compiler/codegen/BindingModuleGenerator.kt
@@ -7,6 +7,7 @@ import com.squareup.anvil.compiler.HINT_BINDING_PACKAGE_PREFIX
 import com.squareup.anvil.compiler.HINT_CONTRIBUTES_PACKAGE_PREFIX
 import com.squareup.anvil.compiler.HINT_MULTIBINDING_PACKAGE_PREFIX
 import com.squareup.anvil.compiler.MODULE_PACKAGE_PREFIX
+import com.squareup.anvil.compiler.REFERENCE_SUFFIX
 import com.squareup.anvil.compiler.api.AnvilCompilationException
 import com.squareup.anvil.compiler.api.AnvilContext
 import com.squareup.anvil.compiler.api.GeneratedFile
@@ -290,6 +291,9 @@ internal class BindingModuleGenerator(
         it.findChildrenByClass(KtProperty::class.java).toList()
       }
       .mapNotNull { ktProperty ->
+        // We can safely ignore scopes, we only care about the reference classes.
+        if (ktProperty.name?.endsWith(REFERENCE_SUFFIX) != true) return@mapNotNull null
+
         (ktProperty.initializer as? KtClassLiteralExpression)
           ?.firstChild
           ?.requireFqName(module)
diff --git a/compiler/src/main/java/com/squareup/anvil/compiler/codegen/ContributesSubcomponentHandlerGenerator.kt b/compiler/src/main/java/com/squareup/anvil/compiler/codegen/ContributesSubcomponentHandlerGenerator.kt
index e1464c1..8f79f88 100644
--- a/compiler/src/main/java/com/squareup/anvil/compiler/codegen/ContributesSubcomponentHandlerGenerator.kt
+++ b/compiler/src/main/java/com/squareup/anvil/compiler/codegen/ContributesSubcomponentHandlerGenerator.kt
@@ -1,6 +1,5 @@
 package com.squareup.anvil.compiler.codegen
 
-import com.squareup.anvil.annotations.ContributesBinding
 import com.squareup.anvil.annotations.MergeSubcomponent
 import com.squareup.anvil.compiler.ANVIL_SUBCOMPONENT_SUFFIX
 import com.squareup.anvil.compiler.COMPONENT_PACKAGE_PREFIX
@@ -8,6 +7,7 @@ import com.squareup.anvil.compiler.ClassScanner
 import com.squareup.anvil.compiler.HINT_SUBCOMPONENTS_PACKAGE_PREFIX
 import com.squareup.anvil.compiler.PARENT_COMPONENT
 import com.squareup.anvil.compiler.SUBCOMPONENT_FACTORY
+import com.squareup.anvil.compiler.SUBCOMPONENT_MODULE
 import com.squareup.anvil.compiler.api.AnvilCompilationException
 import com.squareup.anvil.compiler.api.AnvilContext
 import com.squareup.anvil.compiler.api.CodeGenerator
@@ -45,6 +45,8 @@ import com.squareup.kotlinpoet.FunSpec
 import com.squareup.kotlinpoet.KModifier.ABSTRACT
 import com.squareup.kotlinpoet.KModifier.OVERRIDE
 import com.squareup.kotlinpoet.TypeSpec
+import dagger.Binds
+import dagger.Module
 import dagger.Subcomponent
 import org.jetbrains.kotlin.descriptors.ClassDescriptor
 import org.jetbrains.kotlin.descriptors.DescriptorVisibilities.PUBLIC
@@ -235,7 +237,8 @@ internal class ContributesSubcomponentHandlerGenerator(
             .addAnnotations(contribution.classReference.daggerScopes(module))
             .apply {
               if (factoryClass != null) {
-                addType(generateFactory(factoryClass.originalDescriptor, contribution, module))
+                addType(generateFactory(factoryClass.originalDescriptor))
+                addType(generateDaggerModule(factoryClass.originalDescriptor))
               }
             }
             .addType(
@@ -258,9 +261,7 @@ internal class ContributesSubcomponentHandlerGenerator(
   }
 
   private fun generateFactory(
-    factoryDescriptor: ClassDescriptor,
-    contribution: Contribution,
-    module: ModuleDescriptor
+    factoryDescriptor: ClassDescriptor
   ): TypeSpec {
     val superclass = factoryDescriptor.asClassName()
 
@@ -277,12 +278,24 @@ internal class ContributesSubcomponentHandlerGenerator(
 
     return builder
       .addAnnotation(Subcomponent.Factory::class)
-      .addAnnotation(
-        // This will allow injecting the factory instance.
-        AnnotationSpec
-          .builder(ContributesBinding::class)
-          .addMember(""scope = %T::class"", contribution.parentScope.asClassName(module))
-          .addMember(""boundType = %T::class"", superclass)
+      .build()
+  }
+
+  private fun generateDaggerModule(
+    factoryDescriptor: ClassDescriptor
+  ): TypeSpec {
+    // This Dagger module will allow injecting the factory instance.
+    return TypeSpec
+      .classBuilder(SUBCOMPONENT_MODULE)
+      .addModifiers(ABSTRACT)
+      .addAnnotation(Module::class)
+      .addFunction(
+        FunSpec
+          .builder(""bindSubcomponentFactory"")
+          .addAnnotation(Binds::class.java)
+          .addModifiers(ABSTRACT)
+          .addParameter(""factory"", ClassName.bestGuess(SUBCOMPONENT_FACTORY))
+          .returns(factoryDescriptor.asClassName())
           .build()
       )
       .build()
diff --git a/compiler/src/test/java/com/squareup/anvil/compiler/codegen/ContributesSubcomponentHandlerGeneratorTest.kt b/compiler/src/test/java/com/squareup/anvil/compiler/codegen/ContributesSubcomponentHandlerGeneratorTest.kt
index 3d8ee83..6994be5 100644
--- a/compiler/src/test/java/com/squareup/anvil/compiler/codegen/ContributesSubcomponentHandlerGeneratorTest.kt
+++ b/compiler/src/test/java/com/squareup/anvil/compiler/codegen/ContributesSubcomponentHandlerGeneratorTest.kt
@@ -6,6 +6,7 @@ import com.squareup.anvil.compiler.ANVIL_SUBCOMPONENT_SUFFIX
 import com.squareup.anvil.compiler.COMPONENT_PACKAGE_PREFIX
 import com.squareup.anvil.compiler.PARENT_COMPONENT
 import com.squareup.anvil.compiler.SUBCOMPONENT_FACTORY
+import com.squareup.anvil.compiler.SUBCOMPONENT_MODULE
 import com.squareup.anvil.compiler.compile
 import com.squareup.anvil.compiler.componentInterface
 import com.squareup.anvil.compiler.contributingInterface
@@ -18,6 +19,7 @@ import com.squareup.anvil.compiler.secondContributingInterface
 import com.squareup.anvil.compiler.subcomponentInterface
 import com.tschuchort.compiletesting.KotlinCompilation.ExitCode.OK
 import com.tschuchort.compiletesting.KotlinCompilation.Result
+import dagger.Component
 import org.junit.Test
 import javax.inject.Singleton
 import kotlin.test.assertFailsWith
@@ -1048,6 +1050,268 @@ class ContributesSubcomponentHandlerGeneratorTest {
     }
   }
 
+  @Test
+  fun `the generated factory can be injected in a nested subcomponent`() {
+    compile(
+      """"""
+        package com.squareup.test
+  
+        import com.squareup.anvil.annotations.ContributesSubcomponent
+        import com.squareup.anvil.annotations.ContributesSubcomponent.Factory
+        import com.squareup.anvil.annotations.MergeComponent
+        import dagger.BindsInstance
+        import javax.inject.Inject 
+
+        @ContributesSubcomponent(Any::class, parentScope = Unit::class)
+        interface SubcomponentInterface {
+          @Factory
+          interface ComponentFactory {
+            fun createComponent(
+              @BindsInstance integer: Int
+            ): SubcomponentInterface
+          }
+          
+          fun integer(): Int
+        } 
+
+        @ContributesSubcomponent(Unit::class, parentScope = Int::class)
+        interface ComponentInterface1 {
+          fun testClass(): TestClass
+        }
+        
+        @MergeComponent(Int::class)
+        interface ComponentInterface2
+
+        class TestClass @Inject constructor(val factory: SubcomponentInterface.ComponentFactory)
+      """""",
+      enableDaggerAnnotationProcessor = true
+    ) {
+      val daggerComponent = componentInterface2.daggerComponent.declaredMethods
+        .single { it.name == ""create"" }
+        .invoke(null)
+
+      val subcomponent1 = componentInterface2.methods
+        .single()
+        .invoke(daggerComponent)
+
+      val testClassInstance = componentInterface1.declaredMethods
+        .single { it.name == ""testClass"" }
+        .invoke(subcomponent1)
+
+      val factory = testClassInstance::class.java.declaredMethods
+        .single { it.name == ""getFactory"" }
+        .invoke(testClassInstance)
+
+      val subcomponent2 = factory::class.java.declaredMethods
+        .single { it.returnType == subcomponentInterface }
+        .use { it.invoke(factory, 5) }
+
+      val int = subcomponent2::class.java.declaredMethods
+        .single { it.name == ""integer"" }
+        .use { it.invoke(subcomponent2) as Int }
+
+      assertThat(int).isEqualTo(5)
+    }
+  }
+
+  @Test
+  fun `the generated factory can be injected with multiple compilations`() {
+    val firstCompilationResult = compile(
+      """"""
+        package com.squareup.test
+  
+        import com.squareup.anvil.annotations.ContributesSubcomponent
+        import com.squareup.anvil.annotations.ContributesSubcomponent.Factory
+        import com.squareup.anvil.annotations.ContributesTo
+        import com.squareup.anvil.annotations.MergeComponent
+        import dagger.BindsInstance
+
+        @ContributesSubcomponent(
+          scope = Any::class, 
+          parentScope = Unit::class
+        )
+        interface SubcomponentInterface {
+          fun integer(): Int
+
+          @Factory
+          interface ComponentFactory {
+            fun createComponent(@BindsInstance integer: Int): SubcomponentInterface
+          }
+
+          @ContributesTo(Unit::class)
+          interface AnyParentComponent {
+            fun createFactory(): ComponentFactory
+          }
+        }
+
+        @MergeComponent(Unit::class)
+        interface ComponentInterface1
+      """""".trimIndent(),
+      enableDaggerAnnotationProcessor = true
+    ) {
+      assertThat(exitCode).isEqualTo(OK)
+
+      assertThat(
+        componentInterface1 extends subcomponentInterface.anyParentComponentInterface
+      ).isTrue()
+    }
+
+    compile(
+      """"""
+        package com.squareup.test
+  
+        import com.squareup.anvil.annotations.MergeComponent
+
+        @MergeComponent(Unit::class)
+        interface ComponentInterface2
+      """""".trimIndent(),
+      previousCompilationResult = firstCompilationResult,
+      enableDaggerAnnotationProcessor = true
+    ) {
+      assertThat(exitCode).isEqualTo(OK)
+
+      val daggerComponent = componentInterface2.daggerComponent.declaredMethods
+        .single { it.name == ""create"" }
+        .invoke(null)
+
+      val factory = componentInterface2.methods
+        .first { it.name == ""createFactory"" }
+        .invoke(daggerComponent)
+
+      val subcomponent = factory::class.java.declaredMethods
+        .single { it.returnType == subcomponentInterface }
+        .use { it.invoke(factory, 5) }
+
+      val int = subcomponent::class.java.declaredMethods
+        .single { it.name == ""integer"" }
+        .use { it.invoke(subcomponent) as Int }
+
+      assertThat(int).isEqualTo(5)
+    }
+  }
+
+  @Test
+  fun `the correct generated factory is bound`() {
+    compile(
+      """"""
+        package com.squareup.test
+  
+        import com.squareup.anvil.annotations.ContributesSubcomponent
+        import com.squareup.anvil.annotations.ContributesSubcomponent.Factory
+        import com.squareup.anvil.annotations.MergeComponent
+        import dagger.BindsInstance
+        import javax.inject.Inject 
+
+        @ContributesSubcomponent(Any::class, parentScope = Unit::class)
+        interface SubcomponentInterface {
+          @Factory
+          interface ComponentFactory {
+            fun createComponent(
+              @BindsInstance integer: Int
+            ): SubcomponentInterface
+          }
+        }
+        
+        @MergeComponent(Unit::class)
+        interface ComponentInterface1
+        
+        @MergeComponent(Unit::class)
+        interface ComponentInterface2
+      """"""
+    ) {
+      val modules1 = componentInterface1.getAnnotation(Component::class.java).modules.toList()
+      val modules2 = componentInterface2.getAnnotation(Component::class.java).modules.toList()
+
+      val subcomponentModule1 = subcomponentInterface
+        .anvilComponent(componentInterface1)
+        .declaredClasses
+        .single { it.simpleName == SUBCOMPONENT_MODULE }
+        .kotlin
+
+      val subcomponentModule2 = subcomponentInterface
+        .anvilComponent(componentInterface2)
+        .declaredClasses
+        .single { it.simpleName == SUBCOMPONENT_MODULE }
+        .kotlin
+
+      assertThat(modules1).contains(subcomponentModule1)
+      assertThat(modules1).doesNotContain(subcomponentModule2)
+
+      assertThat(modules2).contains(subcomponentModule2)
+      assertThat(modules2).doesNotContain(subcomponentModule1)
+    }
+  }
+
+  @Test
+  fun `the correct generated factory is bound - with Dagger`() {
+    compile(
+      """"""
+        package com.squareup.test
+  
+        import com.squareup.anvil.annotations.ContributesSubcomponent
+        import com.squareup.anvil.annotations.ContributesSubcomponent.Factory
+        import com.squareup.anvil.annotations.MergeComponent
+        import dagger.BindsInstance
+        import javax.inject.Inject 
+
+        @ContributesSubcomponent(Any::class, parentScope = Unit::class)
+        interface SubcomponentInterface {
+          @Factory
+          interface ComponentFactory {
+            fun createComponent(
+              @BindsInstance integer: Int
+            ): SubcomponentInterface
+          }
+          
+          fun integer(): Int
+        }
+        
+        @MergeComponent(Unit::class)
+        interface ComponentInterface1 {
+          fun testClass(): TestClass
+        }
+        
+        @MergeComponent(Unit::class)
+        interface ComponentInterface2 {
+          fun testClass(): TestClass
+        }
+
+        class TestClass @Inject constructor(val factory: SubcomponentInterface.ComponentFactory)
+      """""",
+      enableDaggerAnnotationProcessor = true
+    ) {
+      val daggerComponent1 = componentInterface1.daggerComponent.declaredMethods
+        .single { it.name == ""create"" }
+        .invoke(null)
+
+      val testClassInstance1 = componentInterface1.declaredMethods
+        .single { it.name == ""testClass"" }
+        .invoke(daggerComponent1)
+
+      val factory1 = testClassInstance1::class.java.declaredMethods
+        .single { it.name == ""getFactory"" }
+        .invoke(testClassInstance1)
+
+      assertThat(factory1::class.java.name)
+        .isEqualTo(""com.squareup.test.DaggerComponentInterface1\\$SubcomponentInterfaceAFactory"")
+
+      val daggerComponent2 = componentInterface2.daggerComponent.declaredMethods
+        .single { it.name == ""create"" }
+        .invoke(null)
+
+      val testClassInstance2 = componentInterface2.declaredMethods
+        .single { it.name == ""testClass"" }
+        .invoke(daggerComponent2)
+
+      val factory2 = testClassInstance2::class.java.declaredMethods
+        .single { it.name == ""getFactory"" }
+        .invoke(testClassInstance2)
+
+      assertThat(factory2::class.java.name)
+        .isEqualTo(""com.squareup.test.DaggerComponentInterface2\\$SubcomponentInterfaceAFactory"")
+    }
+  }
+
   @Test fun `the generated subcomponent contains the same scope annotation`() {
     compile(
       """"""","['compiler/src/main/java/com/squareup/anvil/compiler/ClassScannerIr.kt', 'compiler/src/main/java/com/squareup/anvil/compiler/IrUtils.kt', 'compiler/src/main/java/com/squareup/anvil/compiler/ModuleMerger.kt', 'compiler/src/main/java/com/squareup/anvil/compiler/Utils.kt', 'compiler/src/main/java/com/squareup/anvil/compiler/ModuleMergerIr.kt', 'compiler/src/main/java/com/squareup/anvil/compiler/codegen/ContributesSubcomponentHandlerGenerator.kt', 'compiler/src/test/java/com/squareup/anvil/compiler/codegen/ContributesSubcomponentHandlerGeneratorTest.kt', 'compiler/src/main/java/com/squareup/anvil/compiler/codegen/BindingModuleGenerator.kt']",{'.kt': 8},8,0,8,0,8,388387,82487,10583,79,5950,1209,144,7,6432,382,1457,115,1,3,2022-01-25 21:17:30,1138,Kotlin,"{'Kotlin': 1299266, 'Shell': 712}",Apache License 2.0,"['compiler/src/main/java/com/squareup/anvil/compiler/codegen/ContributesSubcomponentHandlerGenerator.kt', 'compiler/src/main/java/com/squareup/anvil/compiler/codegen/ContributesBindingGenerator.kt', 'compiler/src/main/java/com/squareup/anvil/compiler/codegen/BindingModuleGenerator.kt', 'compiler/src/main/java/com/squareup/anvil/compiler/codegen/DescriptorUtils.kt', 'compiler/src/main/java/com/squareup/anvil/compiler/codegen/ContributesSubcomponentGenerator.kt']","['compiler/src/main/java/com/squareup/anvil/compiler/codegen/ContributesSubcomponentHandlerGenerator.kt', 'compiler/src/main/java/com/squareup/anvil/compiler/codegen/ContributesBindingGenerator.kt', 'compiler/src/main/java/com/squareup/anvil/compiler/codegen/BindingModuleGenerator.kt', 'compiler/src/main/java/com/squareup/anvil/compiler/codegen/DescriptorUtils.kt', 'compiler/src/main/java/com/squareup/anvil/compiler/codegen/ContributesSubcomponentGenerator.kt']","['```json\n{\n  ""files"": [\n    ""compiler/src/main/java/com/squareup/anvil/compiler/codegen/BindingModuleGenerator.kt"",\n    ""compiler/src/main/java/com/squareup/anvil/compiler/codegen/ContributesBindingGenerator.kt"",\n    ""compiler/src/main/java/com/squareup/anvil/compiler/codegen/ContributesSubcomponentGenerator.kt"",\n    ""compiler/src/main/java/com/squareup/anvil/compiler/codegen/ContributesSubcomponentHandlerGenerator.kt"",\n    ""compiler/src/main/java/com/squareup/anvil/compiler/codegen/DescriptorUtils.kt""\n  ]\n}\n```']",1,2487.1253967285156
1562,fasterxml/jackson-module-kotlin/631/558,fasterxml,jackson-module-kotlin,https://github.com/FasterXML/jackson-module-kotlin/issues/558,https://github.com/FasterXML/jackson-module-kotlin/pull/631,https://github.com/FasterXML/jackson-module-kotlin/pull/631,1,fix,Minor bugs in `SimpleModule.addSerializer`/`addDeserializer`,"**Describe the bug**
The current process is as follows.
Although it is a guess since there are no comments, the registration is done for both `kClass.java` and `kClass.javaObjectType`, which seems to be aimed at preventing registration omissions when `T` is a `primitive` type.

```kotlin
inline fun <reified T : Any> SimpleModule.addSerializer(kClass: KClass<T>, serializer: JsonSerializer<T>) = this.apply {
    addSerializer(kClass.java, serializer)
    addSerializer(kClass.javaObjectType, serializer)
}
```

On the other hand, as shown below, if you specify a wrapper type for the `primitive` type, `kClass.java` will return the wrapper type.
In other words, this pattern omits registration for the `primitive` type.

```kotlin
val klazz = Integer::class
// -> java.lang.Integer
println(klazz.java.name)
// -> java.lang.Integer
println(klazz.javaObjectType.name)
```

**Additional context**
If it is a straightforward fix, it could be modified to register only when `kClass.javaPrimitiveType` is `non-null`.
However, I personally feel that it would be better to keep only `addSerializer(kClass.java, serializer)` to match the `Jackson` behavior.",13526be3052df4a9681e367bc10331ac4287431a,306d3fc2463020c85157c84d3a3ab15e2301b57b,https://github.com/fasterxml/jackson-module-kotlin/compare/13526be3052df4a9681e367bc10331ac4287431a...306d3fc2463020c85157c84d3a3ab15e2301b57b,"diff --git a/src/main/kotlin/com/fasterxml/jackson/module/kotlin/Extensions.kt b/src/main/kotlin/com/fasterxml/jackson/module/kotlin/Extensions.kt
index 7b1571d..4179a17 100644
--- a/src/main/kotlin/com/fasterxml/jackson/module/kotlin/Extensions.kt
+++ b/src/main/kotlin/com/fasterxml/jackson/module/kotlin/Extensions.kt
@@ -97,13 +97,13 @@ operator fun JsonNode.contains(index: Int) = has(index)
 internal fun JsonMappingException.wrapWithPath(refFrom: Any?, refFieldName: String) = JsonMappingException.wrapWithPath(this, refFrom, refFieldName)
 internal fun JsonMappingException.wrapWithPath(refFrom: Any?, index: Int) = JsonMappingException.wrapWithPath(this, refFrom, index)
 
-inline fun <reified T : Any> SimpleModule.addSerializer(kClass: KClass<T>, serializer: JsonSerializer<T>) = this.apply {
-    addSerializer(kClass.java, serializer)
+fun <T : Any> SimpleModule.addSerializer(kClass: KClass<T>, serializer: JsonSerializer<T>): SimpleModule = this.apply {
+    kClass.javaPrimitiveType?.let { addSerializer(it, serializer) }
     addSerializer(kClass.javaObjectType, serializer)
 }
 
-inline fun <reified T : Any> SimpleModule.addDeserializer(kClass: KClass<T>, deserializer: JsonDeserializer<T>) = this.apply {
-    addDeserializer(kClass.java, deserializer)
+fun <T : Any> SimpleModule.addDeserializer(kClass: KClass<T>, deserializer: JsonDeserializer<T>): SimpleModule = this.apply {
+    kClass.javaPrimitiveType?.let { addDeserializer(it, deserializer) }
     addDeserializer(kClass.javaObjectType, deserializer)
 }
 ",['src/main/kotlin/com/fasterxml/jackson/module/kotlin/Extensions.kt'],{'.kt': 1},1,0,1,0,1,77721,15733,1774,21,731,170,8,1,1174,149,269,25,0,2,2023-02-19 09:55:00,1054,Kotlin,"{'Kotlin': 286662, 'Logos': 11358, 'Java': 1596}",Apache License 2.0,"['KotlinKeySerializers.kt', 'KotlinModule.kt', 'KotlinDeserializers.kt', 'KotlinSerializers.kt', 'KotlinKeyDeserializers.kt']",[],"['```json\n{\n  ""files"": [\n    ""KotlinSerializers.kt"",\n    ""KotlinDeserializers.kt"",\n    ""KotlinKeySerializers.kt"",\n    ""KotlinKeyDeserializers.kt"",\n    ""KotlinModule.kt""\n  ]\n}\n```']",1,1008.084774017334
1561,fasterxml/jackson-module-kotlin/641/340,fasterxml,jackson-module-kotlin,https://github.com/FasterXML/jackson-module-kotlin/issues/340,https://github.com/FasterXML/jackson-module-kotlin/pull/641,https://github.com/FasterXML/jackson-module-kotlin/pull/641,1,fix,Regression on data binding in 2.11.0 with specific field naming,"Dependabot suggested an upgrade from Spring Boot 2.2.7 to 2.3.0, but the build failed; I checked it out and had the same failures. It looked like a Jackson issue, so I went back to Spring Boot 2.2.7 with Jackson 2.11.0, the version used in Spring Boot 2.3.0, and had the same problem.

I'm having this problem in a Kotlin project, but using Jackson-module-kotlin 2.11.0 alone doesn't seem to cause the problem.

I'm having the same problem in two places, the problem seems to be about the same in each case.  It's roughly something like this: I have an API request object that can come in multiple forms, say, an `owner` that can be a person or organization.  So `OwnerRequest` has an `organization` property, but it also has a private internal val `isOrganization` that returns a boolean if the `organization` field is set.

e.g.

```kotlin
data class OwnerRequest(val person: Person = null, val organization: Organization = null) {
    private val isOrganization = this.organization != null
}
```

I can see how there's a risk of confusion here, since Kotlin exposes getters and setters for Vals, and by java bean standards `is<Property>` could be a boolean getter for a a property. But in Jackson 2.10.4, all behaves as desired, and there hasn't been a problem.

However, if I replace 2.10.4 with 2.11.0, now there's a problem.  Suddenly, the server is responding as if `organization` wasn't set (triggering a validation failure).

As a reproduction, this test:
```kotlin
class JacksonTest {

	private val jackson = ObjectMapper()
		.findAndRegisterModules()

	@Test
	fun testOwnerDeserialization() {
		val value: OwnerRequest = jackson.readValue(
				""""""
					{
						""org"": ""Wayne Industries""
					}
				"""""".trimIndent(),
				OwnerRequest::class.java
		)
		assertThat(value.org).isEqualTo(""Wayne Industries"")
		assertThat(value.toString()).isEqualTo(""OwnerRequest(org=Wayne Industries, isOrg=true)"")
	}
}

class OwnerRequest(val org: String? = null) {
	private val isOrg = org != null
	override fun toString(): String {
		return ""OwnerRequest(org=$org, isOrg=$isOrg)""
	}
}
```
passes in 2.10.4 and fails in 2.11.0.

Here's the failure:
```
com.fasterxml.jackson.databind.exc.UnrecognizedPropertyException: Unrecognized field ""org"" (class ca.cpp.api.submitapi.OwnerRequest), not marked as ignorable (one known property: ""isOrg""])
 at [Source: (String)""{
	""org"": ""Wayne Industries""
}""; line: 3, column: 2] (through reference chain: ca.cpp.api.submitapi.OwnerRequest[""org""])

	at com.fasterxml.jackson.databind.exc.UnrecognizedPropertyException.from(UnrecognizedPropertyException.java:61)
	at com.fasterxml.jackson.databind.DeserializationContext.handleUnknownProperty(DeserializationContext.java:855)
	at com.fasterxml.jackson.databind.deser.std.StdDeserializer.handleUnknownProperty(StdDeserializer.java:1206)
	at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.handleUnknownProperty(BeanDeserializerBase.java:1592)
	at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.handleUnknownProperties(BeanDeserializerBase.java:1542)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer._deserializeUsingPropertyBased(BeanDeserializer.java:511)
	at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.deserializeFromObjectUsingNonDefault(BeanDeserializerBase.java:1310)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserializeFromObject(BeanDeserializer.java:331)
	at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:164)
	at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4482)
	at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3434)
	at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3402)
	at ca.cpp.api.submitapi.JacksonTest.testOwnerDeserialization(JacksonTest.kt:23)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
```
",8e7aeb9310874af9a3f39d0f0aca4e3b437241cd,8ada33f383c831c8a77fb8652494e67cf14c2f4e,https://github.com/fasterxml/jackson-module-kotlin/compare/8e7aeb9310874af9a3f39d0f0aca4e3b437241cd...8ada33f383c831c8a77fb8652494e67cf14c2f4e,"diff --git a/src/main/kotlin/com/fasterxml/jackson/module/kotlin/KotlinNamesAnnotationIntrospector.kt b/src/main/kotlin/com/fasterxml/jackson/module/kotlin/KotlinNamesAnnotationIntrospector.kt
index 565487f..312f10d 100644
--- a/src/main/kotlin/com/fasterxml/jackson/module/kotlin/KotlinNamesAnnotationIntrospector.kt
+++ b/src/main/kotlin/com/fasterxml/jackson/module/kotlin/KotlinNamesAnnotationIntrospector.kt
@@ -29,34 +29,34 @@ import kotlin.reflect.jvm.kotlinFunction
 
 internal class KotlinNamesAnnotationIntrospector(val module: KotlinModule, val cache: ReflectionCache, val ignoredClassesForImplyingJsonCreator: Set<KClass<*>>) : NopAnnotationIntrospector() {
     // since 2.4
-    override fun findImplicitPropertyName(member: AnnotatedMember): String? = when (member) {
-        is AnnotatedMethod -> if (member.name.contains('-') && member.parameterCount == 0) {
-            when {
-                member.name.startsWith(""get"") -> member.name.substringAfter(""get"")
-                member.name.startsWith(""is"") -> member.name.substringAfter(""is"")
-                else -> null
-            }?.replaceFirstChar { it.lowercase(Locale.getDefault()) }?.substringBefore('-')
-        } else null
-        is AnnotatedParameter -> findKotlinParameterName(member)
-        else -> null
-    }
-
-    // since 2.11: support Kotlin's way of handling ""isXxx"" backed properties where
-    // logical property name needs to remain ""isXxx"" and not become ""xxx"" as with Java Beans
-    // (see https://kotlinlang.org/docs/reference/java-to-kotlin-interop.html and
-    //  https://github.com/FasterXML/jackson-databind/issues/2527
-    //  for details)
-    override fun findRenameByField(config: MapperConfig<*>,
-                                   field: AnnotatedField,
-                                   implName: PropertyName): PropertyName? {
-        val origSimple = implName.simpleName
-        if (field.declaringClass.isKotlinClass() && origSimple.startsWith(""is"")) {
-            val mangledName: String? = BeanUtil.stdManglePropertyName(origSimple, 2)
-            if ((mangledName != null) && !mangledName.equals(origSimple)) {
-                return PropertyName.construct(mangledName)
-            }
+    override fun findImplicitPropertyName(member: AnnotatedMember): String? {
+        if (!member.declaringClass.isKotlinClass()) return null
+
+        val name = member.name
+
+        return when (member) {
+            is AnnotatedMethod -> if (member.parameterCount == 0) {
+                // The reason for truncating after `-` is to truncate the random suffix
+                // given after the value class accessor name.
+                when {
+                    name.startsWith(""get"") -> name.takeIf { it.contains(""-"") }?.let { _ ->
+                        name.substringAfter(""get"")
+                            .replaceFirstChar { it.lowercase(Locale.getDefault()) }
+                            .substringBefore('-')
+                    }
+                    // since 2.15: support Kotlin's way of handling ""isXxx"" backed properties where
+                    // logical property name needs to remain ""isXxx"" and not become ""xxx"" as with Java Beans
+                    // (see https://kotlinlang.org/docs/reference/java-to-kotlin-interop.html and
+                    //  https://github.com/FasterXML/jackson-databind/issues/2527 and
+                    //  https://github.com/FasterXML/jackson-module-kotlin/issues/340
+                    //  for details)
+                    name.startsWith(""is"") -> if (name.contains(""-"")) name.substringAfter(""-"") else name
+                    else -> null
+                }
+            } else null
+            is AnnotatedParameter -> findKotlinParameterName(member)
+            else -> null
         }
-        return null
     }
 
     @Suppress(""UNCHECKED_CAST"")
diff --git a/src/test/kotlin/com/fasterxml/jackson/module/kotlin/test/ParameterNameTests.kt b/src/test/kotlin/com/fasterxml/jackson/module/kotlin/test/ParameterNameTests.kt
index b3dd29a..127b57b 100644
--- a/src/test/kotlin/com/fasterxml/jackson/module/kotlin/test/ParameterNameTests.kt
+++ b/src/test/kotlin/com/fasterxml/jackson/module/kotlin/test/ParameterNameTests.kt
@@ -25,24 +25,27 @@ class TestJacksonWithKotlin {
         val primaryAddress: String
         val wrongName: Boolean
         val createdDt: Date
+        val isName: Boolean
 
         fun validate(
             nameField: String = name,
             ageField: Int = age,
             addressField: String = primaryAddress,
             wrongNameField: Boolean = wrongName,
-            createDtField: Date = createdDt
+            createDtField: Date = createdDt,
+            isNameField: Boolean = isName,
         ) {
             assertThat(nameField, equalTo(""Frank""))
             assertThat(ageField, equalTo(30))
             assertThat(addressField, equalTo(""something here""))
             assertThat(wrongNameField, equalTo(true))
             assertThat(createDtField, equalTo(Date(1477419948000)))
+            assertThat(isNameField, equalTo(false))
         }
     }
 
-    private val normalCasedJson = """"""{""name"":""Frank"",""age"":30,""primaryAddress"":""something here"",""renamed"":true,""createdDt"":""2016-10-25T18:25:48.000+00:00""}""""""
-    private val pascalCasedJson = """"""{""Name"":""Frank"",""Age"":30,""PrimaryAddress"":""something here"",""Renamed"":true,""CreatedDt"":""2016-10-25T18:25:48.000+00:00""}""""""
+    private val normalCasedJson = """"""{""name"":""Frank"",""age"":30,""primaryAddress"":""something here"",""renamed"":true,""createdDt"":""2016-10-25T18:25:48.000+00:00"",""isName"":false}""""""
+    private val pascalCasedJson = """"""{""Name"":""Frank"",""Age"":30,""PrimaryAddress"":""something here"",""Renamed"":true,""CreatedDt"":""2016-10-25T18:25:48.000+00:00"",""IsName"":false}""""""
 
     private val normalCasedMapper = jacksonObjectMapper()
             .configure(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS, false)
@@ -65,6 +68,7 @@ class TestJacksonWithKotlin {
 
         override var primaryAddress: String = """"
         override var createdDt: Date = Date()
+        override val isName: Boolean = false
     }
 
     @Test fun NoFailWithDefaultAndSpecificConstructor() {
@@ -79,7 +83,8 @@ class TestJacksonWithKotlin {
         override val age: Int,
         override val primaryAddress: String,
         val renamed: Boolean,
-        override val createdDt: Date
+        override val createdDt: Date,
+        override val isName: Boolean
     ) : TestFields {
         @JsonIgnore
         override val wrongName = renamed // here for the test validation only
@@ -97,7 +102,8 @@ class TestJacksonWithKotlin {
         override val age: Int,
         override val primaryAddress: String,
         val renamed: Boolean,
-        override val createdDt: Date
+        override val createdDt: Date,
+        override val isName: Boolean
     ) : TestFields {
         @JsonIgnore
         override val wrongName = renamed // here for the test validation only
@@ -121,7 +127,8 @@ class TestJacksonWithKotlin {
         override val age: Int,
         override val primaryAddress: String,
         @JsonProperty(""renamed"") override val wrongName: Boolean,
-        override val createdDt: Date
+        override val createdDt: Date,
+        override val isName: Boolean
     ) : TestFields
 
     @Test fun testDataClassWithExplicitJsonCreatorAndJsonProperty() {
@@ -141,7 +148,8 @@ class TestJacksonWithKotlin {
         override val age: Int,
         override val primaryAddress: String,
         @JsonProperty(""renamed"") override val wrongName: Boolean,
-        override val createdDt: Date
+        override val createdDt: Date,
+        override val isName: Boolean
     ) : TestFields
 
     @Test fun testNormalClassWithJsonCreator() {
@@ -155,7 +163,8 @@ class TestJacksonWithKotlin {
     private class StateObjectWithPartialFieldsInConstructor(
         override val name: String,
         override val age: Int,
-        override val primaryAddress: String
+        override val primaryAddress: String,
+        override val isName: Boolean
     ) : TestFields {
         @JsonProperty(""renamed"") override var wrongName: Boolean = false
         override var createdDt: Date by Delegates.notNull()
@@ -176,7 +185,8 @@ class TestJacksonWithKotlin {
         override val age: Int,
         override val primaryAddress: String,
         @JsonProperty(""renamed"") override val wrongName: Boolean,
-        override val createdDt: Date
+        override val createdDt: Date,
+        override val isName: Boolean
     ) : TestFields
 
     @Test fun testDataClassWithNonFieldParametersInConstructor() {
@@ -207,7 +217,8 @@ class TestJacksonWithKotlin {
         override val age: Int,
         override val primaryAddress: String,
         override val wrongName: Boolean,
-        override val createdDt: Date
+        override val createdDt: Date,
+        override val isName: Boolean
     ) : TestFields {
         var factoryUsed: Boolean = false
         companion object {
@@ -216,9 +227,10 @@ class TestJacksonWithKotlin {
                 @JsonProperty(""age"") age: Int,
                 @JsonProperty(""primaryAddress"") primaryAddress: String,
                 @JsonProperty(""renamed"") wrongName: Boolean,
-                @JsonProperty(""createdDt"") createdDt: Date
+                @JsonProperty(""createdDt"") createdDt: Date,
+                @JsonProperty(""isName"") isName: Boolean
             ): StateObjectWithFactory {
-                val obj = StateObjectWithFactory(nameThing, age, primaryAddress, wrongName, createdDt)
+                val obj = StateObjectWithFactory(nameThing, age, primaryAddress, wrongName, createdDt, isName)
                 obj.factoryUsed = true
                 return obj
             }
@@ -236,7 +248,8 @@ class TestJacksonWithKotlin {
         val age: Int,
         val primaryAddress: String,
         val renamed: Boolean,
-        val createdDt: Date
+        val createdDt: Date,
+        val isName: Boolean
     ) {
         companion object {
             @JvmStatic @JsonCreator fun create(
@@ -244,9 +257,10 @@ class TestJacksonWithKotlin {
                 age: Int,
                 primaryAddress: String,
                 renamed: Boolean,
-                createdDt: Date
+                createdDt: Date,
+                isName: Boolean
             ): StateObjectWithFactoryNoParamAnnotations {
-                return StateObjectWithFactoryNoParamAnnotations(name, age, primaryAddress, renamed, createdDt)
+                return StateObjectWithFactoryNoParamAnnotations(name, age, primaryAddress, renamed, createdDt, isName)
             }
         }
     }
@@ -266,7 +280,8 @@ class TestJacksonWithKotlin {
         override val age: Int,
         override val primaryAddress: String,
         override val wrongName: Boolean,
-        override val createdDt: Date
+        override val createdDt: Date,
+        override val isName: Boolean
     ) : TestFields {
         var factoryUsed: Boolean = false
         private companion object Named {
@@ -275,9 +290,10 @@ class TestJacksonWithKotlin {
                 @JsonProperty(""age"") age: Int,
                 @JsonProperty(""primaryAddress"") primaryAddress: String,
                 @JsonProperty(""renamed"") wrongName: Boolean,
-                @JsonProperty(""createdDt"") createdDt: Date
+                @JsonProperty(""createdDt"") createdDt: Date,
+                @JsonProperty(""isName"") isName: Boolean
             ): StateObjectWithFactoryOnNamedCompanion {
-                val obj = StateObjectWithFactoryOnNamedCompanion(nameThing, age, primaryAddress, wrongName, createdDt)
+                val obj = StateObjectWithFactoryOnNamedCompanion(nameThing, age, primaryAddress, wrongName, createdDt, isName)
                 obj.factoryUsed = true
                 return obj
             }
diff --git a/src/test/kotlin/com/fasterxml/jackson/module/kotlin/test/github/failing/Github340.kt b/src/test/kotlin/com/fasterxml/jackson/module/kotlin/test/github/Github340.kt
similarity index 55%
rename from src/test/kotlin/com/fasterxml/jackson/module/kotlin/test/github/failing/Github340.kt
rename to src/test/kotlin/com/fasterxml/jackson/module/kotlin/test/github/Github340.kt
index dba6a07..7d38cbd 100644
--- a/src/test/kotlin/com/fasterxml/jackson/module/kotlin/test/github/failing/Github340.kt
+++ b/src/test/kotlin/com/fasterxml/jackson/module/kotlin/test/github/Github340.kt
@@ -1,10 +1,9 @@
-package com.fasterxml.jackson.module.kotlin.test.github.failing
+package com.fasterxml.jackson.module.kotlin.test.github
 
 import com.fasterxml.jackson.databind.ObjectMapper
-import com.fasterxml.jackson.databind.exc.UnrecognizedPropertyException
+import com.fasterxml.jackson.module.kotlin.jacksonObjectMapper
 import com.fasterxml.jackson.module.kotlin.kotlinModule
 import com.fasterxml.jackson.module.kotlin.readValue
-import com.fasterxml.jackson.module.kotlin.test.expectFailure
 import org.junit.Test
 import kotlin.test.assertEquals
 
@@ -21,10 +20,9 @@ class OwnerRequestTest {
 
     @Test
     fun testDeserHit340() {
-        expectFailure<UnrecognizedPropertyException>(""GitHub #340 has been fixed!"") {
-            val value: IsField = jackson.readValue(json)
-            assertEquals(""Got a foo"", value.foo)
-        }
+        val value: IsField = jackson.readValue(json)
+        // Fixed
+        assertEquals(""Got a foo"", value.foo)
     }
 
     @Test
@@ -32,4 +30,17 @@ class OwnerRequestTest {
         val value: NoIsField = jackson.readValue(json)
         assertEquals(""Got a foo"", value.foo)
     }
+
+    // A test case for isSetter to work, added with the fix for this issue.
+    class IsSetter {
+        lateinit var isFoo: String
+    }
+
+    @Test
+    fun isSetterTest() {
+        val json = """"""{""isFoo"":""bar""}""""""
+        val isSetter: IsSetter = jackson.readValue(json)
+
+        assertEquals(""bar"", isSetter.isFoo)
+    }
 }","['src/main/kotlin/com/fasterxml/jackson/module/kotlin/KotlinNamesAnnotationIntrospector.kt', 'src/test/kotlin/com/fasterxml/jackson/module/kotlin/test/ParameterNameTests.kt', 'src/test/kotlin/com/fasterxml/jackson/module/kotlin/test/github/failing/Github340.kt']",{'.kt': 3},3,0,3,0,3,78177,15833,1783,21,3113,642,54,1,5258,407,1197,89,0,3,2023-03-04 14:57:59,1054,Kotlin,"{'Kotlin': 286662, 'Logos': 11358, 'Java': 1596}",Apache License 2.0,"['KotlinAnnotationIntrospector.kt', 'KotlinModule.kt', 'KotlinSerializers.kt', 'KotlinValueInstantiator.kt', 'KotlinBeanDeserializerModifier.kt']",[],"['```json\n{\n  ""files"": [\n    ""KotlinAnnotationIntrospector.kt"",\n    ""KotlinBeanDeserializerModifier.kt"",\n    ""KotlinModule.kt"",\n    ""KotlinSerializers.kt"",\n    ""KotlinValueInstantiator.kt""\n  ]\n}\n```']",1,1251.7127990722656
1941,square/workflow-kotlin/644/642,square,workflow-kotlin,https://github.com/square/workflow-kotlin/issues/642,https://github.com/square/workflow-kotlin/pull/644,https://github.com/square/workflow-kotlin/pull/644,1,fixes,nextRendering() is called in runtime if Workflow's scope is cancelled.,"Right now in `renderWorkflowIn` we check if the `CoroutineScope` `isActive` at the top of the loop:

```
  scope.launch(start = ATOMIC) {
    while (isActive) {
      // It might look weird to start by consuming the output before getting the rendering below,
      // but remember the first render pass already occurred above, before this coroutine was even
      // launched.
      val output = runner.nextOutput()

      // After receiving an output, the next render pass must be done before emitting that output,
      // so that the workflow states appear consistent to observers of the outputs and renderings.
      renderingsAndSnapshots.value = runner.nextRendering()
      output?.let { onOutput(it.value) }
    }
  }
```

But since `nextOutput()` is suspending we could resume and have had an `action` `cancel()` the `CoroutineScope` of the root workflow. We should pro-actively check this before calling `nextRendering()`.

Something like:

```
  scope.launch(start = ATOMIC) {
    while (isActive) {
      // It might look weird to start by consuming the output before getting the rendering below,
      // but remember the first render pass already occurred above, before this coroutine was even
      // launched.
      val output = runner.nextOutput()

      if (!isActive) return@launch
      // After receiving an output, the next render pass must be done before emitting that output,
      // so that the workflow states appear consistent to observers of the outputs and renderings.
      renderingsAndSnapshots.value = runner.nextRendering()
      output?.let { onOutput(it.value) }
    }
  }
```",c84b71ac0d24203a9b3f74a348fd9950cc7da44f,2e8fd8c59e08c0c9752c55ceea49a390a3bc4a85,https://github.com/square/workflow-kotlin/compare/c84b71ac0d24203a9b3f74a348fd9950cc7da44f...2e8fd8c59e08c0c9752c55ceea49a390a3bc4a85,"diff --git a/workflow-runtime/src/main/java/com/squareup/workflow1/RenderWorkflow.kt b/workflow-runtime/src/main/java/com/squareup/workflow1/RenderWorkflow.kt
index 26fd1145..d7006f58 100644
--- a/workflow-runtime/src/main/java/com/squareup/workflow1/RenderWorkflow.kt
+++ b/workflow-runtime/src/main/java/com/squareup/workflow1/RenderWorkflow.kt
@@ -138,6 +138,10 @@ public fun <PropsT, OutputT, RenderingT> renderWorkflowIn(
       // launched.
       val output = runner.nextOutput()
 
+      // After resuming from runner.nextOutput() our coroutine could now be cancelled, check so we
+      // don't surprise anyone with an unexpected rendering pass. Show's over, go home.
+      if (!isActive) return@launch
+
       // After receiving an output, the next render pass must be done before emitting that output,
       // so that the workflow states appear consistent to observers of the outputs and renderings.
       renderingsAndSnapshots.value = runner.nextRendering()
diff --git a/workflow-runtime/src/test/java/com/squareup/workflow1/RenderWorkflowInTest.kt b/workflow-runtime/src/test/java/com/squareup/workflow1/RenderWorkflowInTest.kt
index 03347581..651025ce 100644
--- a/workflow-runtime/src/test/java/com/squareup/workflow1/RenderWorkflowInTest.kt
+++ b/workflow-runtime/src/test/java/com/squareup/workflow1/RenderWorkflowInTest.kt
@@ -380,6 +380,27 @@ class RenderWorkflowInTest {
     assertNull(cancellationException!!.cause)
   }
 
+  @Test fun `cancelling scope in action cancels runtime and does not render again`() {
+    val trigger = CompletableDeferred<Unit>()
+    var renderCount = 0
+    val workflow = Workflow.stateless<Unit, Nothing, Unit> {
+      renderCount++
+      runningWorker(Worker.from { trigger.await() }) {
+        action {
+          expectedSuccessScope.cancel()
+        }
+      }
+    }
+    renderWorkflowIn(workflow, expectedSuccessScope, MutableStateFlow(Unit)) {}
+    assertTrue(expectedSuccessScope.isActive)
+    assertTrue(renderCount == 1)
+
+    trigger.complete(Unit)
+    expectedSuccessScope.advanceUntilIdle()
+    assertFalse(expectedSuccessScope.isActive)
+    assertEquals(1, renderCount, ""Should not render after CoroutineScope is canceled."")
+  }
+
   @Test fun `failing scope cancels runtime`() {
     var cancellationException: Throwable? = null
     val workflow = Workflow.stateless<Unit, Nothing, Unit> {","['workflow-runtime/src/test/java/com/squareup/workflow1/RenderWorkflowInTest.kt', 'workflow-runtime/src/main/java/com/squareup/workflow1/RenderWorkflow.kt']",{'.kt': 2},2,0,2,0,2,841270,190075,24131,313,226,49,4,1,1651,221,345,38,0,2,2022-01-25 18:41:28,918,Kotlin,"{'Kotlin': 1494343, 'Shell': 2325, 'Ruby': 1690, 'Java': 1182}",Apache License 2.0,"['workflow-runtime/src/main/java/com/squareup/workflow1/SimpleLoggingWorkflowInterceptor.kt', 'workflow-runtime/src/main/java/com/squareup/workflow1/WorkflowInterceptor.kt', 'workflow-runtime/src/main/java/com/squareup/workflow1/RenderingAndSnapshot.kt', 'workflow-runtime/src/main/java/com/squareup/workflow1/TreeSnapshot.kt', 'workflow-runtime/src/main/java/com/squareup/workflow1/RenderWorkflow.kt']","['workflow-runtime/src/main/java/com/squareup/workflow1/SimpleLoggingWorkflowInterceptor.kt', 'workflow-runtime/src/main/java/com/squareup/workflow1/WorkflowInterceptor.kt', 'workflow-runtime/src/main/java/com/squareup/workflow1/RenderingAndSnapshot.kt', 'workflow-runtime/src/main/java/com/squareup/workflow1/TreeSnapshot.kt', 'workflow-runtime/src/main/java/com/squareup/workflow1/RenderWorkflow.kt']","['```json\n{\n  ""files"": [\n    ""workflow-runtime/src/main/java/com/squareup/workflow1/RenderWorkflow.kt"",\n    ""workflow-runtime/src/main/java/com/squareup/workflow1/RenderingAndSnapshot.kt"",\n    ""workflow-runtime/src/main/java/com/squareup/workflow1/SimpleLoggingWorkflowInterceptor.kt"",\n    ""workflow-runtime/src/main/java/com/squareup/workflow1/TreeSnapshot.kt"",\n    ""workflow-runtime/src/main/java/com/squareup/workflow1/WorkflowInterceptor.kt""\n  ]\n}\n```']",1,1731.1515808105469
9712,bumble-tech/appyx/33/28,bumble-tech,appyx,https://github.com/bumble-tech/appyx/issues/28,https://github.com/bumble-tech/appyx/pull/33,https://github.com/bumble-tech/appyx/pull/33,1,fixes,Fix sandbox on small screen devices,"On small screen devices (you can reproduce by using split screen if required) several of the lists within the sandbox do not scroll.

This causes the content to become truncated. We should add the vertical scrolling modifier to fix these Nodes.",08c14396bff8b175cbbe13fed3f06b966cf43d73,e606e3bb0abd506b6b1ed1d5fdb3d7877f040f2a,https://github.com/bumble-tech/appyx/compare/08c14396bff8b175cbbe13fed3f06b966cf43d73...e606e3bb0abd506b6b1ed1d5fdb3d7877f040f2a,"diff --git a/sandbox/src/main/java/com/bumble/appyx/sandbox/client/container/ContainerNode.kt b/sandbox/src/main/java/com/bumble/appyx/sandbox/client/container/ContainerNode.kt
index 1287d235..910706c8 100644
--- a/sandbox/src/main/java/com/bumble/appyx/sandbox/client/container/ContainerNode.kt
+++ b/sandbox/src/main/java/com/bumble/appyx/sandbox/client/container/ContainerNode.kt
@@ -8,6 +8,8 @@ import androidx.compose.foundation.layout.Box
 import androidx.compose.foundation.layout.Column
 import androidx.compose.foundation.layout.fillMaxSize
 import androidx.compose.foundation.layout.padding
+import androidx.compose.foundation.rememberScrollState
+import androidx.compose.foundation.verticalScroll
 import androidx.compose.material.Button
 import androidx.compose.material.Text
 import androidx.compose.runtime.Composable
@@ -164,8 +166,10 @@ class ContainerNode(
 
     @Composable
     fun ExamplesList(modifier: Modifier) {
+        val scrollState = rememberScrollState()
         Box(
             modifier = modifier
+                .verticalScroll(scrollState)
                 .fillMaxSize()
                 .padding(24.dp),
             contentAlignment = Alignment.Center
@@ -203,8 +207,10 @@ class ContainerNode(
 
     @Composable
     fun RoutingSources(modifier: Modifier) {
+        val scrollState = rememberScrollState()
         Box(
             modifier = modifier
+                .verticalScroll(scrollState)
                 .fillMaxSize()
                 .padding(24.dp),
             contentAlignment = Alignment.Center
diff --git a/sandbox/src/main/java/com/bumble/appyx/sandbox/client/mvicoreexample/MviCoreExampleView.kt b/sandbox/src/main/java/com/bumble/appyx/sandbox/client/mvicoreexample/MviCoreExampleView.kt
index 35851aef..f96992f3 100644
--- a/sandbox/src/main/java/com/bumble/appyx/sandbox/client/mvicoreexample/MviCoreExampleView.kt
+++ b/sandbox/src/main/java/com/bumble/appyx/sandbox/client/mvicoreexample/MviCoreExampleView.kt
@@ -8,6 +8,8 @@ import androidx.compose.foundation.layout.fillMaxSize
 import androidx.compose.foundation.layout.fillMaxWidth
 import androidx.compose.foundation.layout.padding
 import androidx.compose.foundation.layout.requiredHeight
+import androidx.compose.foundation.rememberScrollState
+import androidx.compose.foundation.verticalScroll
 import androidx.compose.material.Button
 import androidx.compose.material.CircularProgressIndicator
 import androidx.compose.material.Text
@@ -63,8 +65,11 @@ class MviCoreExampleViewImpl(
     @Composable
     override fun ParentNode<Routing>.NodeView(modifier: Modifier) {
         val viewModel = vm ?: return
+        val scrollState = rememberScrollState()
         Column(
-            modifier = modifier.fillMaxSize(),
+            modifier = modifier
+                .verticalScroll(scrollState)
+                .fillMaxSize(),
             verticalArrangement = Arrangement.Center
         ) {
             Text(","['sandbox/src/main/java/com/bumble/appyx/sandbox/client/mvicoreexample/MviCoreExampleView.kt', 'sandbox/src/main/java/com/bumble/appyx/sandbox/client/container/ContainerNode.kt']",{'.kt': 2},2,0,2,0,2,449697,95094,13062,264,611,99,13,2,246,41,46,3,0,0,2022-07-16 17:24:12,814,Kotlin,"{'Kotlin': 732276, 'Python': 2213, 'HTML': 348, 'CSS': 134}",Apache License 2.0,"['sandbox/src/main/java/com/bumble/appyx/sandbox/client/blocker/BlockerExampleNode.kt', 'sandbox/src/main/java/com/bumble/appyx/sandbox/client/tiles/TilesExampleNode.kt', 'sandbox/src/main/java/com/bumble/appyx/sandbox/client/list/LazyListContainerNode.kt', 'sandbox/src/main/java/com/bumble/appyx/sandbox/client/container/ContainerNode.kt', 'sandbox/src/main/java/com/bumble/appyx/sandbox/client/modal/ModalExampleNode.kt']","['sandbox/src/main/java/com/bumble/appyx/sandbox/client/blocker/BlockerExampleNode.kt', 'sandbox/src/main/java/com/bumble/appyx/sandbox/client/tiles/TilesExampleNode.kt', 'sandbox/src/main/java/com/bumble/appyx/sandbox/client/list/LazyListContainerNode.kt', 'sandbox/src/main/java/com/bumble/appyx/sandbox/client/container/ContainerNode.kt', 'sandbox/src/main/java/com/bumble/appyx/sandbox/client/modal/ModalExampleNode.kt']","['```json\n{\n  ""files"": [\n    ""sandbox/src/main/java/com/bumble/appyx/sandbox/client/blocker/BlockerExampleNode.kt"",\n    ""sandbox/src/main/java/com/bumble/appyx/sandbox/client/container/ContainerNode.kt"",\n    ""sandbox/src/main/java/com/bumble/appyx/sandbox/client/list/LazyListContainerNode.kt"",\n    ""sandbox/src/main/java/com/bumble/appyx/sandbox/client/modal/ModalExampleNode.kt"",\n    ""sandbox/src/main/java/com/bumble/appyx/sandbox/client/tiles/TilesExampleNode.kt""\n  ]\n}\n```']",1,1933.058738708496
9714,bumble-tech/appyx/17/16,bumble-tech,appyx,https://github.com/bumble-tech/appyx/issues/16,https://github.com/bumble-tech/appyx/pull/17,https://github.com/bumble-tech/appyx/pull/17,1,closes,Sandbox IntegrationPointExampleNode throws exception when Activity recreated ,"The Sandbox IntegrationPointExampleNode class throws an exception when Activity recreated due to the integrationPoint not being attached yet.

We should change the node to not access the integrationPoint immediately, and also update the error message for clarity.

Demontration
Using the dark mode button to cause the Activity to be recreated.

[appyx-sandbox-lifecycle-crash.webm](https://user-images.githubusercontent.com/1333155/178144662-d73cdf0e-a42a-4687-bf1b-57cb1f213163.webm)


**Stacktrace**
```
java.lang.IllegalStateException: You're accessing an IntegrationPointStub. This means you're using a Node without ever integrating it to a proper IntegrationPoint. This is fine during tests with limited scope, but it looks like the code that leads here requires interfacing with a valid implementation.
	at com.bumble.appyx.core.integrationpoint.IntegrationPointStub.getPermissionRequester(IntegrationPointStub.kt:18)
	at com.bumble.appyx.sandbox.client.integrationpoint.IntegrationPointExampleNode.<init>(IntegrationPointExampleNode.kt:37)
	at com.bumble.appyx.sandbox.client.container.ContainerNode.resolve(ContainerNode.kt:130)
	at com.bumble.appyx.sandbox.client.container.ContainerNode.resolve(ContainerNode.kt:63)
	at com.bumble.appyx.core.children.ChildEntry$Companion.create(ChildEntry.kt:58)
	at com.bumble.appyx.core.node.ParentNode.restoreChildren(ParentNode.kt:121)
	at com.bumble.appyx.core.node.ParentNode.onBuilt(ParentNode.kt:82)
	at com.bumble.appyx.core.node.NodeExtKt.build(NodeExt.kt:3)
	at com.bumble.appyx.core.integration.NodeHostKt$rememberNode$2.invoke(NodeHost.kt:72)
	at com.bumble.appyx.core.integration.NodeHostKt$rememberNode$2.invoke(NodeHost.kt:64)
	at androidx.compose.runtime.saveable.MapSaverKt$mapSaver$2.invoke(MapSaver.kt:52)
	at androidx.compose.runtime.saveable.MapSaverKt$mapSaver$2.invoke(MapSaver.kt:33)
	at androidx.compose.runtime.saveable.SaverKt$Saver$1.restore(Saver.kt:68)
	at androidx.compose.runtime.saveable.RememberSaveableKt$mutableStateSaver$1$2.invoke(RememberSaveable.kt:162)
	at androidx.compose.runtime.saveable.RememberSaveableKt$mutableStateSaver$1$2.invoke(RememberSaveable.kt:151)
	at androidx.compose.runtime.saveable.SaverKt$Saver$1.restore(Saver.kt:68)
	at androidx.compose.runtime.saveable.RememberSaveableKt.rememberSaveable(RememberSaveable.kt:86)
	at androidx.compose.runtime.saveable.RememberSaveableKt.rememberSaveable(RememberSaveable.kt:142)
	at com.bumble.appyx.core.integration.NodeHostKt.rememberNode(NodeHost.kt:62)
	at com.bumble.appyx.core.integration.NodeHostKt.NodeHost(NodeHost.kt:38)
	at com.bumble.appyx.sandbox.MainActivity$onCreate$1$1$1.invoke(MainActivity.kt:25)
	at com.bumble.appyx.sandbox.MainActivity$onCreate$1$1$1.invoke(MainActivity.kt:23)
	at androidx.compose.runtime.internal.ComposableLambdaImpl.invoke(ComposableLambda.jvm.kt:107)
	at androidx.compose.runtime.internal.ComposableLambdaImpl.invoke(ComposableLambda.jvm.kt:34)
	at androidx.compose.material.SurfaceKt$Surface$1.invoke(Surface.kt:134)
	at androidx.compose.material.SurfaceKt$Surface$1.invoke(Surface.kt:117)
	at androidx.compose.runtime.internal.ComposableLambdaImpl.invoke(ComposableLambda.jvm.kt:107)
	at androidx.compose.runtime.internal.ComposableLambdaImpl.invoke(ComposableLambda.jvm.kt:34)
	at androidx.compose.runtime.CompositionLocalKt.CompositionLocalProvider(CompositionLocal.kt:228)
	at androidx.compose.material.SurfaceKt.Surface-F-jzlyU(Surface.kt:114)
	at com.bumble.appyx.sandbox.MainActivity$onCreate$1$1.invoke(MainActivity.kt:23)
	at com.bumble.appyx.sandbox.MainActivity$onCreate$1$1.invoke(MainActivity.kt:21)
	at androidx.compose.runtime.internal.ComposableLambdaImpl.invoke(ComposableLambda.jvm.kt:107)
	at androidx.compose.runtime.internal.ComposableLambdaImpl.invoke(ComposableLambda.jvm.kt:34)
	at androidx.compose.material.MaterialTheme_androidKt.PlatformMaterialTheme(MaterialTheme.android.kt:23)
	at androidx.compose.material.MaterialThemeKt$MaterialTheme$1$1.invoke(MaterialTheme.kt:82)
	at androidx.compose.material.MaterialThemeKt$MaterialTheme$1$1.invoke(MaterialTheme.kt:81)
	at androidx.compose.runtime.internal.ComposableLambdaImpl.invoke(ComposableLambda.jvm.kt:107)
	at androidx.compose.runtime.internal.ComposableLambdaImpl.invoke(ComposableLambda.jvm.kt:34)
	at androidx.compose.runtime.CompositionLocalKt.CompositionLocalProvider(CompositionLocal.kt:228)
	at androidx.compose.material.TextKt.ProvideTextStyle(Text.kt:265)
	at androidx.compose.material.MaterialThemeKt$MaterialTheme$1.invoke(MaterialTheme.kt:81)
	at androidx.compose.material.MaterialThemeKt$MaterialTheme$1.invoke(MaterialTheme.kt:80)
	at androidx.compose.runtime.internal.ComposableLambdaImpl.invoke(ComposableLambda.jvm.kt:107)
	at androidx.compose.runtime.internal.ComposableLambdaImpl.invoke(ComposableLambda.jvm.kt:34)
	at androidx.compose.runtime.CompositionLocalKt.CompositionLocalProvider(CompositionLocal.kt:228)
	at androidx.compose.material.MaterialThemeKt.MaterialTheme(MaterialTheme.kt:72)
	at com.bumble.appyx.sandbox.ui.ThemeKt.AppyxSandboxTheme(Theme.kt:39)
	at com.bumble.appyx.sandbox.MainActivity$onCreate$1.invoke(MainActivity.kt:21)
	at com.bumble.appyx.sandbox.MainActivity$onCreate$1.invoke(MainActivity.kt:20)
	at androidx.compose.runtime.internal.ComposableLambdaImpl.invoke(ComposableLambda.jvm.kt:107)
	at androidx.compose.runtime.internal.ComposableLambdaImpl.invoke(ComposableLambda.jvm.kt:34)
	at androidx.compose.ui.platform.ComposeView.Content(ComposeView.android.kt:402)
	at androidx.compose.ui.platform.AbstractComposeView$ensureCompositionCreated$1.invoke(ComposeView.android.kt:248)
	at androidx.compose.ui.platform.AbstractComposeView$ensureCompositionCreated$1.invoke(ComposeView.android.kt:247)
	at androidx.compose.runtime.internal.ComposableLambdaImpl.invoke(ComposableLambda.jvm.kt:107)
	at androidx.compose.runtime.internal.ComposableLambdaImpl.invoke(ComposableLambda.jvm.kt:34)
	at androidx.compose.runtime.CompositionLocalKt.CompositionLocalProvider(CompositionLocal.kt:228)
	at androidx.compose.ui.platform.CompositionLocalsKt.ProvideCommonCompositionLocals(CompositionLocals.kt:177)
	at androidx.compose.ui.platform.AndroidCompositionLocals_androidKt$ProvideAndroidCompositionLocals$3.invoke(AndroidCompositionLocals.android.kt:123)
	at androidx.compose.ui.platform.AndroidCompositionLocals_androidKt$ProvideAndroidCompositionLocals$3.invoke(AndroidCompositionLocals.android.kt:122)
	at androidx.compose.runtime.internal.ComposableLambdaImpl.invoke(ComposableLambda.jvm.kt:107)
	at androidx.compose.runtime.internal.ComposableLambdaImpl.invoke(ComposableLambda.jvm.kt:34)
	at androidx.compose.runtime.CompositionLocalKt.CompositionLocalProvider(CompositionLocal.kt:228)
	at androidx.compose.ui.platform.AndroidCompositionLocals_androidKt.ProvideAndroidCompositionLocals(AndroidCompositionLocals.android.kt:114)
	at androidx.compose.ui.platform.WrappedComposition$setContent$1$1$3.invoke(Wrapper.android.kt:157)
	at androidx.compose.ui.platform.WrappedComposition$setContent$1$1$3.invoke(Wrapper.android.kt:156)
	at androidx.compose.runtime.internal.ComposableLambdaImpl.invoke(ComposableLambda.jvm.kt:107)
	at androidx.compose.runtime.internal.ComposableLambdaImpl.invoke(ComposableLambda.jvm.kt:34)
	at androidx.compose.runtime.CompositionLocalKt.CompositionLocalProvider(CompositionLocal.kt:228)
	at androidx.compose.ui.platform.WrappedComposition$setContent$1$1.invoke(Wrapper.android.kt:156)
	at androidx.compose.ui.platform.WrappedComposition$setContent$1$1.invoke(Wrapper.android.kt:140)
	at androidx.compose.runtime.internal.ComposableLambdaImpl.invoke(ComposableLambda.jvm.kt:107)
	at androidx.compose.runtime.internal.ComposableLambdaImpl.invoke(ComposableLambda.jvm.kt:34)
	at androidx.compose.runtime.ActualJvm_jvmKt.invokeComposable(ActualJvm.jvm.kt:74)
	at androidx.compose.runtime.ComposerImpl$doCompose$2$5.invoke(Composer.kt:3193)
	at androidx.compose.runtime.ComposerImpl$doCompose$2$5.invoke(Composer.kt:3183)
	at androidx.compose.runtime.SnapshotStateKt__DerivedStateKt.observeDerivedStateRecalculations(DerivedState.kt:252)
	at androidx.compose.runtime.SnapshotStateKt.observeDerivedStateRecalculations(Unknown Source:1)
	at androidx.compose.runtime.ComposerImpl.doCompose(Composer.kt:3183)
	at androidx.compose.runtime.ComposerImpl.composeContent$runtime_release(Composer.kt:3119)
	at androidx.compose.runtime.CompositionImpl.composeContent(Composition.kt:578)
	at androidx.compose.runtime.Recomposer.composeInitial$runtime_release(Recomposer.kt:811)
	at androidx.compose.runtime.CompositionImpl.setContent(Composition.kt:513)
	at androidx.compose.ui.platform.WrappedComposition$setContent$1.invoke(Wrapper.android.kt:140)
	at androidx.compose.ui.platform.WrappedComposition$setContent$1.invoke(Wrapper.android.kt:131)
	at androidx.compose.ui.platform.AndroidComposeView.setOnViewTreeOwnersAvailable(AndroidComposeView.android.kt:1015)
	at androidx.compose.ui.platform.WrappedComposition.setContent(Wrapper.android.kt:131)
	at androidx.compose.ui.platform.WrappedComposition.onStateChanged(Wrapper.android.kt:182)
	at androidx.lifecycle.LifecycleRegistry$ObserverWithState.dispatchEvent(LifecycleRegistry.java:354)
	at androidx.lifecycle.LifecycleRegistry.addObserver(LifecycleRegistry.java:196)
	at androidx.compose.ui.platform.WrappedComposition$setContent$1.invoke(Wrapper.android.kt:138)
	at androidx.compose.ui.platform.WrappedComposition$setContent$1.invoke(Wrapper.android.kt:131)
	at androidx.compose.ui.platform.AndroidComposeView.onAttachedToWindow(AndroidComposeView.android.kt:1102)
	at android.view.View.dispatchAttachedToWindow(View.java:20479)
	at android.view.ViewGroup.dispatchAttachedToWindow(ViewGroup.java:3489)
	at android.view.ViewGroup.dispatchAttachedToWindow(ViewGroup.java:3496)
	at android.view.ViewGroup.dispatchAttachedToWindow(ViewGroup.java:3496)
	at android.view.ViewGroup.dispatchAttachedToWindow(ViewGroup.java:3496)
	at android.view.ViewGroup.dispatchAttachedToWindow(ViewGroup.java:3496)
	at android.view.ViewGroup.dispatchAttachedToWindow(ViewGroup.java:3496)
	at android.view.ViewGroup.dispatchAttachedToWindow(ViewGroup.java:3496)
	at android.view.ViewRootImpl.performTraversals(ViewRootImpl.java:2417)
	at android.view.ViewRootImpl.doTraversal(ViewRootImpl.java:1952)
	at android.view.ViewRootImpl$TraversalRunnable.run(ViewRootImpl.java:8171)
	at android.view.Choreographer$CallbackRecord.run(Choreographer.java:972)
	at android.view.Choreographer.doCallbacks(Choreographer.java:796)
	at android.view.Choreographer.doFrame(Choreographer.java:731)
	at android.view.Choreographer$FrameDisplayEventReceiver.run(Choreographer.java:957)
	at android.os.Handler.handleCallback(Handler.java:938)
	at android.os.Handler.dispatchMessage(Handler.java:99)
	at android.os.Looper.loop(Looper.java:223)
	at android.app.ActivityThread.main(ActivityThread.java:7656)
	at java.lang.reflect.Method.invoke(Native Method)
	at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:592)
	at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:947)
```
",85e73e54fc47fdc50cefb165bf88b69e6432395f,290bca8dc0b8f4515db8dd7505b9f9277ce50a19,https://github.com/bumble-tech/appyx/compare/85e73e54fc47fdc50cefb165bf88b69e6432395f...290bca8dc0b8f4515db8dd7505b9f9277ce50a19,"diff --git a/core/src/main/java/com/bumble/appyx/core/integrationpoint/IntegrationPointStub.kt b/core/src/main/java/com/bumble/appyx/core/integrationpoint/IntegrationPointStub.kt
index 3c76e1b6..a0e78a2a 100644
--- a/core/src/main/java/com/bumble/appyx/core/integrationpoint/IntegrationPointStub.kt
+++ b/core/src/main/java/com/bumble/appyx/core/integrationpoint/IntegrationPointStub.kt
@@ -8,7 +8,8 @@ class IntegrationPointStub : IntegrationPoint(savedInstanceState = null) {
         private const val ERROR = ""You're accessing an IntegrationPointStub. "" +
             ""This means you're using a Node without ever integrating it to a proper IntegrationPoint. "" +
             ""This is fine during tests with limited scope, but it looks like the code that leads here "" +
-            ""requires interfacing with a valid implementation.""
+            ""requires interfacing with a valid implementation. "" +
+            ""You may be attempting to access the IntegrationPoint before it is attached to the Node.""
     }
 
     override val activityStarter: ActivityStarter
diff --git a/sandbox/src/main/java/com/bumble/appyx/sandbox/client/integrationpoint/IntegrationPointExampleNode.kt b/sandbox/src/main/java/com/bumble/appyx/sandbox/client/integrationpoint/IntegrationPointExampleNode.kt
index 695b2d41..e598b4db 100644
--- a/sandbox/src/main/java/com/bumble/appyx/sandbox/client/integrationpoint/IntegrationPointExampleNode.kt
+++ b/sandbox/src/main/java/com/bumble/appyx/sandbox/client/integrationpoint/IntegrationPointExampleNode.kt
@@ -23,6 +23,7 @@ import androidx.compose.ui.Modifier
 import androidx.compose.ui.graphics.Color
 import androidx.compose.ui.tooling.preview.Preview
 import androidx.compose.ui.unit.dp
+import com.bumble.appyx.core.integrationpoint.activitystarter.ActivityStarter
 import com.bumble.appyx.core.integrationpoint.permissionrequester.PermissionRequester
 import com.bumble.appyx.core.integrationpoint.requestcode.RequestCodeClient
 import com.bumble.appyx.core.minimal.reactive.Cancellable
@@ -34,8 +35,8 @@ import java.util.*
 class IntegrationPointExampleNode(buildContext: BuildContext) : Node(buildContext = buildContext),
     RequestCodeClient {
 
-    private val permissionRequester = integrationPoint.permissionRequester
-    private val activityStarter = integrationPoint.activityStarter
+    private val permissionRequester: PermissionRequester get() = integrationPoint.permissionRequester
+    private val activityStarter: ActivityStarter get() = integrationPoint.activityStarter
     private var permissionsResultCancellable: Cancellable? = null
     private var activityResultsCancellable: Cancellable? = null
     private var permissionsResultState by mutableStateOf(""Press request permissions to check permissions state"")
@@ -91,13 +92,13 @@ class IntegrationPointExampleNode(buildContext: BuildContext) : Node(buildContex
     }
 
     private fun launchActivity() {
-        integrationPoint.activityStarter.startActivity {
+        activityStarter.startActivity {
             Intent(this, StartActivityExample::class.java)
         }
     }
 
     private fun launchActivityForResult() {
-        integrationPoint.activityStarter.startActivityForResult(this, StartActivityForResultCode) {
+        activityStarter.startActivityForResult(this, StartActivityForResultCode) {
             Intent(this, StartActivityExample::class.java)
         }
     }","['sandbox/src/main/java/com/bumble/appyx/sandbox/client/integrationpoint/IntegrationPointExampleNode.kt', 'core/src/main/java/com/bumble/appyx/core/integrationpoint/IntegrationPointStub.kt']",{'.kt': 2},2,0,2,0,2,431606,91274,12542,250,935,164,12,2,11173,330,2579,131,1,1,2022-07-10 12:31:59,814,Kotlin,"{'Kotlin': 732276, 'Python': 2213, 'HTML': 348, 'CSS': 134}",Apache License 2.0,['sandbox/src/main/java/com/bumble/appyx/sandbox/client/integrationpoint/IntegrationPointExampleNode.kt'],['sandbox/src/main/java/com/bumble/appyx/sandbox/client/integrationpoint/IntegrationPointExampleNode.kt'],"['```json\n{\n  ""files"": [\n    ""sandbox/src/main/java/com/bumble/appyx/sandbox/client/integrationpoint/IntegrationPointExampleNode.kt""\n  ]\n}\n```']",1,1081.7453861236572
3369,hannah-sten/texify-idea/2532/2530,hannah-sten,texify-idea,https://github.com/Hannah-Sten/TeXiFy-IDEA/issues/2530,https://github.com/Hannah-Sten/TeXiFy-IDEA/pull/2532,https://github.com/Hannah-Sten/TeXiFy-IDEA/pull/2532,1,fix,BibTeX can't find aux file.,"#### Type of JetBrains IDE (IntelliJ, PyCharm, etc.) and version
IntelliJ IDEA 2022.1.1 (Ultimate Edition)

#### Operating System 
Windows 10

#### TeXiFy IDEA version
0.7.19

#### What I did (steps to reproduce)

1. Create new project (MiKTeX Windows SDK (MiKTeX 21.10), Configure with BibTeX support)
2. Project format .idea (directory-based)
3. Add some text to the default `main.tex` file.
4. Add an entry to the default `main.bib` file.
5. Use the `\\cite{}` command in the `main.tex` file.
6. Run 'main'

The result is `I couldn't open file name 'main.aux'` on the bibtex command, and undefined references in the produced PDF.  Note that the bibtex command is 
`bibtex -include-directory=C:/Users/User/Documents/LaTeX_Projects/bibibibib/src -include-directory=C:/Users/User/Documents/LaTeX_Projects/bibibibib/src main`
It seems to me that instead of including the src and auxil directory, the src is included twice, though I have tried running the command manually with the auxil directory included and I get the same result. Copying the `main.aux` file into the out folder makes the bibtex command work and the bibliography is printed, but the references are still undefined, copying it again after the second compilation makes the references work as well.


",16b618226609548003296f3e2f981328573d8b58,44ab0c0aedfd6abe58b3b576262196d7230fcdc1,https://github.com/hannah-sten/texify-idea/compare/16b618226609548003296f3e2f981328573d8b58...44ab0c0aedfd6abe58b3b576262196d7230fcdc1,"diff --git a/src/nl/hannahsten/texifyidea/run/compiler/LatexCompiler.kt b/src/nl/hannahsten/texifyidea/run/compiler/LatexCompiler.kt
index f4dff51fd..5fecb1f3c 100644
--- a/src/nl/hannahsten/texifyidea/run/compiler/LatexCompiler.kt
+++ b/src/nl/hannahsten/texifyidea/run/compiler/LatexCompiler.kt
@@ -43,12 +43,12 @@ enum class LatexCompiler(private val displayName: String, val executableName: St
             command.add(""-output-directory=$outputPath"")
 
             // -aux-directory only exists on MiKTeX
-            if (auxilPath != null && runConfig.getLatexDistributionType().isMiktex()) {
+            if (auxilPath != null && runConfig.getLatexDistributionType().isMiktex(project = runConfig.project)) {
                 command.add(""-aux-directory=$auxilPath"")
             }
 
             // Prepend root paths to the input search path
-            if (runConfig.getLatexDistributionType().isMiktex()) {
+            if (runConfig.getLatexDistributionType().isMiktex(runConfig.project)) {
                 moduleRoots.forEach {
                     command.add(""-include-directory=${it.path}"")
                 }
@@ -126,7 +126,7 @@ enum class LatexCompiler(private val displayName: String, val executableName: St
 
             command.add(""-output-directory=$outputPath"")
 
-            if (auxilPath != null && runConfig.getLatexDistributionType().isMiktex()) {
+            if (auxilPath != null && runConfig.getLatexDistributionType().isMiktex(runConfig.project)) {
                 command.add(""-aux-directory=$auxilPath"")
             }
 
@@ -164,12 +164,12 @@ enum class LatexCompiler(private val displayName: String, val executableName: St
 
             command.add(""-output-directory=$outputPath"")
 
-            if (auxilPath != null && runConfig.getLatexDistributionType().isMiktex()) {
+            if (auxilPath != null && runConfig.getLatexDistributionType().isMiktex(runConfig.project)) {
                 command.add(""-aux-directory=$auxilPath"")
             }
 
             // Prepend root paths to the input search path
-            if (runConfig.getLatexDistributionType().isMiktex()) {
+            if (runConfig.getLatexDistributionType().isMiktex(runConfig.project)) {
                 moduleRoots.forEach {
                     command.add(""-include-directory=${it.path}"")
                 }
diff --git a/src/nl/hannahsten/texifyidea/run/latex/LatexCommandLineState.kt b/src/nl/hannahsten/texifyidea/run/latex/LatexCommandLineState.kt
index a6eb1646c..9431debf4 100644
--- a/src/nl/hannahsten/texifyidea/run/latex/LatexCommandLineState.kt
+++ b/src/nl/hannahsten/texifyidea/run/latex/LatexCommandLineState.kt
@@ -51,7 +51,7 @@ open class LatexCommandLineState(environment: ExecutionEnvironment, private val
         }
 
         firstRunSetup(compiler)
-        if (!runConfig.getLatexDistributionType().isMiktex()) {
+        if (!runConfig.getLatexDistributionType().isMiktex(runConfig.project)) {
             runConfig.outputPath.updateOutputSubDirs()
         }
 
diff --git a/src/nl/hannahsten/texifyidea/run/latex/LatexDistributionType.kt b/src/nl/hannahsten/texifyidea/run/latex/LatexDistributionType.kt
index 408a905cb..9ae3255f9 100644
--- a/src/nl/hannahsten/texifyidea/run/latex/LatexDistributionType.kt
+++ b/src/nl/hannahsten/texifyidea/run/latex/LatexDistributionType.kt
@@ -18,9 +18,8 @@ enum class LatexDistributionType(val displayName: String) {
     DOCKER_MIKTEX(""Dockerized MiKTeX""),
     PROJECT_SDK(""Use project SDK"");
 
-    fun isMiktex() = this == MIKTEX || this == DOCKER_MIKTEX
-
-    fun isTexlive() = this == TEXLIVE || this == WSL_TEXLIVE
+    private fun isMiktex() = this == MIKTEX || this == DOCKER_MIKTEX
+    fun isMiktex(project: Project) = this == MIKTEX || this == DOCKER_MIKTEX || (this == PROJECT_SDK && LatexSdkUtil.getLatexProjectSdkType(project)?.getLatexDistributionType()?.isMiktex() == true)
 
     fun isAvailable(project: Project) = LatexSdkUtil.isAvailable(this, project)
 
diff --git a/src/nl/hannahsten/texifyidea/run/latex/LatexRunConfiguration.kt b/src/nl/hannahsten/texifyidea/run/latex/LatexRunConfiguration.kt
index 735a3484f..5e0c2c63e 100644
--- a/src/nl/hannahsten/texifyidea/run/latex/LatexRunConfiguration.kt
+++ b/src/nl/hannahsten/texifyidea/run/latex/LatexRunConfiguration.kt
@@ -391,7 +391,7 @@ class LatexRunConfiguration constructor(
         bibtexRunConfiguration.setSuggestedName()
 
         // On non-MiKTeX systems, add bibinputs for bibtex to work
-        if (!latexDistribution.isMiktex()) {
+        if (!latexDistribution.isMiktex(project)) {
             // Only if default, because the user could have changed it after creating the run config but before running
             if (mainFile != null && outputPath.virtualFile != mainFile.parent) {
                 // As seen in issue 2165, appending a colon (like with TEXINPUTS) may not work on Windows,
@@ -529,7 +529,7 @@ class LatexRunConfiguration constructor(
      * @return The auxil folder when MiKTeX used, or else the out folder when used.
      */
     fun getAuxilDirectory(): VirtualFile? {
-        return if (latexDistribution.isMiktex()) {
+        return if (latexDistribution.isMiktex(project)) {
             auxilPath.getAndCreatePath()
         }
         else {","['src/nl/hannahsten/texifyidea/run/compiler/LatexCompiler.kt', 'src/nl/hannahsten/texifyidea/run/latex/LatexCommandLineState.kt', 'src/nl/hannahsten/texifyidea/run/latex/LatexRunConfiguration.kt', 'src/nl/hannahsten/texifyidea/run/latex/LatexDistributionType.kt']",{'.kt': 4},4,0,4,0,4,1957652,433851,49610,662,1649,431,21,4,1288,184,329,24,0,0,2022-07-16 10:47:29,788,Kotlin,"{'Kotlin': 2572007, 'TeX': 71017, 'Lex': 28995, 'HTML': 23381, 'Java': 9308, 'JavaScript': 3044, 'Python': 967, 'Perl': 39}",MIT License,"['src/nl/hannahsten/texifyidea/run/bibtex/BibtexCommandLineState.kt', 'src/nl/hannahsten/texifyidea/run/bibtex/BibtexRunConfigurationType.kt', 'src/nl/hannahsten/texifyidea/run/bibtex/BibtexSettingsEditor.kt', 'src/nl/hannahsten/texifyidea/run/bibtex/RunBibtexListener.kt', 'src/nl/hannahsten/texifyidea/run/bibtex/BibtexRunConfiguration.kt']","['src/nl/hannahsten/texifyidea/run/bibtex/BibtexCommandLineState.kt', 'src/nl/hannahsten/texifyidea/run/bibtex/BibtexRunConfigurationType.kt', 'src/nl/hannahsten/texifyidea/run/bibtex/BibtexSettingsEditor.kt', 'src/nl/hannahsten/texifyidea/run/bibtex/RunBibtexListener.kt', 'src/nl/hannahsten/texifyidea/run/bibtex/BibtexRunConfiguration.kt']","['```json\n{\n  ""files"": [\n    ""src/nl/hannahsten/texifyidea/run/bibtex/BibtexCommandLineState.kt"",\n    ""src/nl/hannahsten/texifyidea/run/bibtex/BibtexRunConfiguration.kt"",\n    ""src/nl/hannahsten/texifyidea/run/bibtex/BibtexRunConfigurationType.kt"",\n    ""src/nl/hannahsten/texifyidea/run/bibtex/BibtexSettingsEditor.kt"",\n    ""src/nl/hannahsten/texifyidea/run/bibtex/RunBibtexListener.kt""\n  ]\n}\n```']",1,2589.7035598754883
3390,hannah-sten/texify-idea/1603/1602,hannah-sten,texify-idea,https://github.com/Hannah-Sten/TeXiFy-IDEA/issues/1602,https://github.com/Hannah-Sten/TeXiFy-IDEA/pull/1603,https://github.com/Hannah-Sten/TeXiFy-IDEA/pull/1603,1,fix,LatexLineBreakInspection triggered incorrectly ,"#### Type of JetBrains IDE (IntelliJ, PyCharm, etc.) and version
IntelliJ 2020.2

#### Operating System 
macOS

#### TeXiFy IDEA version
Latest alpha

#### Description
The following bit of text incorrectly triggers the `Sentence does not start on a new line` Inspection.

#### Minimal example to reproduce the problem

```latex
This is an abbreviation (ABC). % commemt
More text here.
```

",bc50a2f4ef2539596cf75712c6f0db1a3b77d8af,cfcae91d365e5b6441ff0fc862a7ca2739f2c9ee,https://github.com/hannah-sten/texify-idea/compare/bc50a2f4ef2539596cf75712c6f0db1a3b77d8af...cfcae91d365e5b6441ff0fc862a7ca2739f2c9ee,"diff --git a/src/nl/hannahsten/texifyidea/inspections/latex/LatexLineBreakInspection.kt b/src/nl/hannahsten/texifyidea/inspections/latex/LatexLineBreakInspection.kt
index 4e6d4f529..f33211117 100644
--- a/src/nl/hannahsten/texifyidea/inspections/latex/LatexLineBreakInspection.kt
+++ b/src/nl/hannahsten/texifyidea/inspections/latex/LatexLineBreakInspection.kt
@@ -47,8 +47,9 @@ open class LatexLineBreakInspection : TexifyInspectionBase() {
                 val startOffset = matcher.start()
                 val endOffset = matcher.end() + (endLine - offset)
 
-                // Do not trigger the inspection when in a comment.
-                if (file.findElementAt(startOffset + text.startOffset)?.isComment() == true) {
+                val element = file.findElementAt(startOffset + text.startOffset)
+                // Do not trigger the inspection when in a comment or when a comment starts directly after.
+                if ((element?.isComment() == true) || (element?.nextSiblingIgnoreWhitespace()?.isComment() == true)) {
                     continue
                 }
 
diff --git a/test/nl/hannahsten/texifyidea/inspections/latex/LatexLineBreakInspectionTest.kt b/test/nl/hannahsten/texifyidea/inspections/latex/LatexLineBreakInspectionTest.kt
index d1ab3f4b5..db6ce91bc 100644
--- a/test/nl/hannahsten/texifyidea/inspections/latex/LatexLineBreakInspectionTest.kt
+++ b/test/nl/hannahsten/texifyidea/inspections/latex/LatexLineBreakInspectionTest.kt
@@ -14,6 +14,29 @@ This e<weak_warning descr=""Sentence does not start on a new line"">tc. is missing
         myFixture.checkHighlighting()
     }
 
+    fun testNoWarning() {
+        myFixture.configureByText(LatexFileType, """"""
+            First sentence.
+            Second sentence.
+        """""".trimIndent())
+        myFixture.checkHighlighting()
+    }
+
+    fun testNoWarningWithComment() {
+        myFixture.configureByText(LatexFileType, """"""
+            This is an abbreviation (ABC). % commemt
+            More text here.
+        """""".trimIndent())
+        myFixture.checkHighlighting()
+    }
+
+    fun testNoWarningInMathMode() {
+        myFixture.configureByText(LatexFileType, """"""
+            \\[ Why. would. you. do. this. \\]
+        """""".trimIndent())
+        myFixture.checkHighlighting()
+    }
+
     fun testQuickfix() {
         myFixture.configureByText(LatexFileType,
         """"""","['src/nl/hannahsten/texifyidea/inspections/latex/LatexLineBreakInspection.kt', 'test/nl/hannahsten/texifyidea/inspections/latex/LatexLineBreakInspectionTest.kt']",{'.kt': 2},2,0,2,0,2,1426242,310649,36700,529,475,92,5,1,409,60,97,20,0,1,2020-10-02 14:05:24,788,Kotlin,"{'Kotlin': 2572007, 'TeX': 71017, 'Lex': 28995, 'HTML': 23381, 'Java': 9308, 'JavaScript': 3044, 'Python': 967, 'Perl': 39}",MIT License,['src/nl/hannahsten/texifyidea/inspections/latex/LatexLineBreakInspection.kt'],['src/nl/hannahsten/texifyidea/inspections/latex/LatexLineBreakInspection.kt'],"['```json\n{\n  ""files"": [\n    ""src/nl/hannahsten/texifyidea/inspections/latex/LatexLineBreakInspection.kt""\n  ]\n}\n```']",1,1329.5261859893799
3339,hannah-sten/texify-idea/3151/3038,hannah-sten,texify-idea,https://github.com/Hannah-Sten/TeXiFy-IDEA/issues/3038,https://github.com/Hannah-Sten/TeXiFy-IDEA/pull/3151,https://github.com/Hannah-Sten/TeXiFy-IDEA/pull/3151#issuecomment-1635633491,1,fix,Indexing of TEXINPUTS,"### Discussed in https://github.com/Hannah-Sten/TeXiFy-IDEA/discussions/3035

<div type='discussions-op-text'>

<sup>Originally posted by **mvscheven** April 14, 2023</sup>
We are using a lot of custom classes and style files to keep the preamble of the main tex-file clean. If these custom files are in the source directory, they are known by TeXiFy and included commands are recognized. But if these files are in a location specified by the TEXINPUTS environment variable this does not work. Is it possible to index also files located at TEXINPUTS?

Thanks for any advice!

### Minimal Example:
#### main.tex
```
\\documentclass[11pt]{scrartcl}
\\RequirePackage{my_style}

\\begin{document}
    \\begin{align}
        \\sigma = E \\varepsilon
    \\end{align}
\\end{document}
```
#### my_style.sty
```
\\RequirePackage{amsmath}
```
If my_style.sty is in the source directory, it is linked in the margin next to the RequirePackage command and align is recognized as valid environment.
If my_style.sty is in a TEXINPUTS directory, it is marked as ""not found"" and for align an error is produced: ""Environment requires amsmath package""

### System:
Windows 11, MikTex, IntelliJ IDEA 2023.1, TexiFy IDEA 0.7.28
</div>",80e8bb010dd489d58ce1dee2cd829c3583957413,3c7f8aaf9545d2c28010dff0f0b89b2790d8f513,https://github.com/hannah-sten/texify-idea/compare/80e8bb010dd489d58ce1dee2cd829c3583957413...3c7f8aaf9545d2c28010dff0f0b89b2790d8f513,"diff --git a/src/nl/hannahsten/texifyidea/reference/InputFileReference.kt b/src/nl/hannahsten/texifyidea/reference/InputFileReference.kt
index 65a6a900e..430839b5b 100644
--- a/src/nl/hannahsten/texifyidea/reference/InputFileReference.kt
+++ b/src/nl/hannahsten/texifyidea/reference/InputFileReference.kt
@@ -17,11 +17,8 @@ import nl.hannahsten.texifyidea.psi.LatexCommands
 import nl.hannahsten.texifyidea.psi.LatexPsiHelper
 import nl.hannahsten.texifyidea.run.latex.LatexRunConfiguration
 import nl.hannahsten.texifyidea.settings.sdk.LatexSdkUtil
-import nl.hannahsten.texifyidea.util.LatexmkRcFileFinder
-import nl.hannahsten.texifyidea.util.expandCommandsOnce
+import nl.hannahsten.texifyidea.util.*
 import nl.hannahsten.texifyidea.util.files.*
-import nl.hannahsten.texifyidea.util.includedPackages
-import nl.hannahsten.texifyidea.util.isTestProject
 import nl.hannahsten.texifyidea.util.magic.CommandMagic
 
 /**
@@ -122,15 +119,17 @@ class InputFileReference(
 
         // Check environment variables
         val runManager = RunManagerImpl.getInstanceImpl(element.project) as RunManager
-        val texInputPath = runManager.allConfigurationsList
+        val texinputsVariable = runManager.allConfigurationsList
             .filterIsInstance<LatexRunConfiguration>()
             .firstOrNull { it.mainFile in rootFiles }
             ?.environmentVariables
             ?.envs
             ?.getOrDefault(""TEXINPUTS"", null)
+            // Not sure which of these takes precedence, or if they are joined together
             ?: LatexmkRcFileFinder.getTexinputsVariable(element.containingFile, null)
+            ?: runCommand(""kpsewhich"", ""--expand-var"", ""'\\$TEXINPUTS'"")
 
-        if (texInputPath != null) {
+        for (texInputPath in texinputsVariable?.split("":"")?.filter { it.isNotBlank() } ?: emptyList()) {
             val path = texInputPath.trimEnd(':')
             searchPaths.add(path.trimEnd('/'))
             // See the kpathsea manual, // expands to subdirs
diff --git a/src/nl/hannahsten/texifyidea/util/LatexmkRcFileFinder.kt b/src/nl/hannahsten/texifyidea/util/LatexmkRcFileFinder.kt
index 4d933f10d..6096a13ff 100644
--- a/src/nl/hannahsten/texifyidea/util/LatexmkRcFileFinder.kt
+++ b/src/nl/hannahsten/texifyidea/util/LatexmkRcFileFinder.kt
@@ -107,7 +107,7 @@ object LatexmkRcFileFinder {
      * Get TEXINPUTS from latexmkrc.
      */
     private fun getTexinputs(file: VirtualFile): String? {
-        return """"""ensure_path\\('TEXINPUTS',\\s*'(?<path>[^']+)'\\)"""""".toRegex().find(file.inputStream.reader().readText())?.groups?.get(""path"")?.value
+        return """"""ensure_path\\(\\s*'TEXINPUTS',\\s*'(?<path>[^']+)'\\s*\\)"""""".toRegex().find(file.inputStream.reader().readText())?.groups?.get(""path"")?.value
     }
 
     private var usesLatexmkrc: Boolean? = null","['src/nl/hannahsten/texifyidea/util/LatexmkRcFileFinder.kt', 'src/nl/hannahsten/texifyidea/reference/InputFileReference.kt']",{'.kt': 2},2,0,2,0,2,2142529,472996,53819,713,998,262,13,2,1235,167,325,31,1,2,2023-07-09 17:47:05,788,Kotlin,"{'Kotlin': 2572007, 'TeX': 71017, 'Lex': 28995, 'HTML': 23381, 'Java': 9308, 'JavaScript': 3044, 'Python': 967, 'Perl': 39}",MIT License,"['src/nl/hannahsten/texifyidea/util/files/LatexPackageLocationCache.kt', 'src/nl/hannahsten/texifyidea/util/files/Files.kt', 'src/nl/hannahsten/texifyidea/util/files/PsiFile.kt', 'src/nl/hannahsten/texifyidea/util/files/VirtualFile.kt', 'src/nl/hannahsten/texifyidea/util/files/ImportPackage.kt']","['src/nl/hannahsten/texifyidea/util/files/LatexPackageLocationCache.kt', 'src/nl/hannahsten/texifyidea/util/files/Files.kt', 'src/nl/hannahsten/texifyidea/util/files/PsiFile.kt', 'src/nl/hannahsten/texifyidea/util/files/VirtualFile.kt', 'src/nl/hannahsten/texifyidea/util/files/ImportPackage.kt']","['```json\n{\n  ""files"": [\n    ""src/nl/hannahsten/texifyidea/util/files/Files.kt"",\n    ""src/nl/hannahsten/texifyidea/util/files/ImportPackage.kt"",\n    ""src/nl/hannahsten/texifyidea/util/files/LatexPackageLocationCache.kt"",\n    ""src/nl/hannahsten/texifyidea/util/files/PsiFile.kt"",\n    ""src/nl/hannahsten/texifyidea/util/files/VirtualFile.kt""\n  ]\n}\n```']",1,2660.067558288574
1957,kordlib/kord/96/94,kordlib,kord,https://github.com/kordlib/kord/issues/94,https://github.com/kordlib/kord/pull/96,https://github.com/kordlib/kord/pull/96,1,fix,Trying to mention the everyone role results in a malformed @@everyone mention in the client,"```kotlin
channel.createMessage(guild.everyoneRole.mention)
```

results in:
`@@everyone`

This behaviour on is correct according the official docs, but it seems like the client stumbles over the special everyone type. Using the literal `@everyone` works fine though.

Proposed solution:
Introduce a check on `RoleBehavior#mention` that checks for `guildId.value == id.value` and returns the literal `@everyone` on true instead.",9793a4060187ac9ec2bb2670bfe162e5a4dd760b,e4a6cd54d771d7e177503289614c82f5b676d898,https://github.com/kordlib/kord/compare/9793a4060187ac9ec2bb2670bfe162e5a4dd760b...e4a6cd54d771d7e177503289614c82f5b676d898,"diff --git a/core/src/main/kotlin/com/gitlab/kordlib/core/behavior/RoleBehavior.kt b/core/src/main/kotlin/com/gitlab/kordlib/core/behavior/RoleBehavior.kt
index 01a18c70de..ea9d068296 100644
--- a/core/src/main/kotlin/com/gitlab/kordlib/core/behavior/RoleBehavior.kt
+++ b/core/src/main/kotlin/com/gitlab/kordlib/core/behavior/RoleBehavior.kt
@@ -37,7 +37,11 @@ interface RoleBehavior : Entity, Strategizable {
     /**
      * The raw mention of this entity.
      */
-    val mention: String get() = ""<@&${id.value}>""
+    val mention: String
+        get() {
+            return if (guildId.value == id.value) ""@everyone""
+            else ""<@&${id.value}>""
+        }
 
     /**
      * Requests to change the [position] of this role.",['core/src/main/kotlin/com/gitlab/kordlib/core/behavior/RoleBehavior.kt'],{'.kt': 1},1,0,1,0,1,771281,172399,21296,282,202,52,6,1,438,55,97,11,0,1,2020-10-24 19:57:08,747,Kotlin,"{'Kotlin': 2380240, 'Java': 87103}",MIT License,['core/src/main/kotlin/com/gitlab/kordlib/core/behavior/RoleBehavior.kt'],['core/src/main/kotlin/com/gitlab/kordlib/core/behavior/RoleBehavior.kt'],"['```json\n{\n  ""files"": [\n    ""core/src/main/kotlin/com/gitlab/kordlib/core/behavior/RoleBehavior.kt""\n  ]\n}\n```']",1,876.8777847290039
1974,horizontalsystems/unstoppable-wallet-android/560/538,horizontalsystems,unstoppable-wallet-android,https://github.com/horizontalsystems/unstoppable-wallet-android/issues/538,https://github.com/horizontalsystems/unstoppable-wallet-android/pull/560,https://github.com/horizontalsystems/unstoppable-wallet-android/pull/560,1,close,TX fee: in send controller and send confirmation controller doesn't match.,"tried sending 0.1 ETH in dev build no.467. The send controller showed fee as $0.01 ut the send confirmation controller showed it as 0$.

I suspect it might be due to rounding. Note that we shouldn't be rounding the values in send AND send confirmation controllers
",42a6feb23ffdb04beb2763850ff40f73a2127f51,ea61f46469e8ce6128f52825a44ed9d3820e9e38,https://github.com/horizontalsystems/unstoppable-wallet-android/compare/42a6feb23ffdb04beb2763850ff40f73a2127f51...ea61f46469e8ce6128f52825a44ed9d3820e9e38,"diff --git a/app/src/main/java/io/horizontalsystems/bankwallet/modules/send/SendModule.kt b/app/src/main/java/io/horizontalsystems/bankwallet/modules/send/SendModule.kt
index 054277d80..a7badc872 100644
--- a/app/src/main/java/io/horizontalsystems/bankwallet/modules/send/SendModule.kt
+++ b/app/src/main/java/io/horizontalsystems/bankwallet/modules/send/SendModule.kt
@@ -114,7 +114,7 @@ object SendModule {
                 ValueFormatter.format(this.coinValue)
             }
             is SendModule.AmountInfo.CurrencyValueInfo -> {
-                ValueFormatter.formatSimple(this.currencyValue)
+                ValueFormatter.format(this.currencyValue)
             }
         }
     }
diff --git a/app/src/main/java/io/horizontalsystems/bankwallet/viewHelpers/ValueFormatter.kt b/app/src/main/java/io/horizontalsystems/bankwallet/viewHelpers/ValueFormatter.kt
index 3e3d4af4c..e4bd7b535 100644
--- a/app/src/main/java/io/horizontalsystems/bankwallet/viewHelpers/ValueFormatter.kt
+++ b/app/src/main/java/io/horizontalsystems/bankwallet/viewHelpers/ValueFormatter.kt
@@ -105,9 +105,4 @@ object ValueFormatter {
         return spannable
     }
 
-    fun formatSimple(currencyValue: CurrencyValue): String? {
-        val result = currencyValue.value.setScale(2, RoundingMode.HALF_EVEN)
-        val formatted = currencyFormatter.format(result)
-        return ""${currencyValue.currency.symbol}$formatted""
-    }
 }","['app/src/main/java/io/horizontalsystems/bankwallet/modules/send/SendModule.kt', 'app/src/main/java/io/horizontalsystems/bankwallet/viewHelpers/ValueFormatter.kt']",{'.kt': 2},2,0,2,0,2,484873,96751,14041,206,389,71,7,2,267,46,62,4,0,0,2019-01-30 11:23:41,649,Kotlin,"{'Kotlin': 4204975, 'Shell': 6112, 'Ruby': 1350}",MIT License,"['app/src/main/java/io/horizontalsystems/bankwallet/modules/send/SendPresenter.kt', 'app/src/main/java/io/horizontalsystems/bankwallet/modules/send/SendViewModel.kt', 'app/src/main/java/io/horizontalsystems/bankwallet/modules/send/ConfirmationFragment.kt']","['app/src/main/java/io/horizontalsystems/bankwallet/modules/send/SendPresenter.kt', 'app/src/main/java/io/horizontalsystems/bankwallet/modules/send/SendViewModel.kt', 'app/src/main/java/io/horizontalsystems/bankwallet/modules/send/ConfirmationFragment.kt']","['```json\n{\n  ""files"": [\n    ""app/src/main/java/io/horizontalsystems/bankwallet/modules/send/SendViewModel.kt"",\n    ""app/src/main/java/io/horizontalsystems/bankwallet/modules/send/SendPresenter.kt"",\n    ""app/src/main/java/io/horizontalsystems/bankwallet/modules/send/ConfirmationFragment.kt""\n  ]\n}\n```']",1,1363.738775253296
3824,jwstegemann/fritz2/430/425,jwstegemann,fritz2,https://github.com/jwstegemann/fritz2/issues/425,https://github.com/jwstegemann/fritz2/pull/430,https://github.com/jwstegemann/fritz2/pull/430,2,fixes,Unclear error handling,"**Is your feature request related to a problem? Please describe.**
I'm learning Fritz2, and I'm making a login form. When user enters bad credentials, and the API returns HTTP 401, I'd like to show the error (toast). I can't find a way how.

Another related issue is in `Tracker`. When I start the remote request, and it fails, the button keeps spinning and I couldn't find any method how to stop it.

**Describe the solution you'd like**
* Make special chapter in documentation about error handling.
* Demonstrate it in remotes example.
  * I have uBlock, which blocks the request to the domain you use in this example. I see the error in developer console, but nothing in the UI.

Abouty the tyracker problem, I'd suggest to change the `track` method like this:
```kotlin
// OLD (0.10.1)
return operation().also { state.value = null } 

// NEW
return try { operation() } finally { state.value = null }
```

**Describe alternatives you've considered**
I couldn't find any. Just provide some documentation and example.

**Additional context**
My handler looks like this. If you could show me how to display the error toast, I'd be grateful.

```kotlin
val login = handle { model ->
    loading.track {
        if (validator.isValid(model, Unit)) {
            try {
                http(""/apiIs2/authUser"")
                    .acceptJson()
                    .contentType(""application/json"")
                    .body(
                        JSON.stringify(
                            json(
                                ""username"" to model.login, ""password"" to model.password
                            )
                        )
                    )
                    .post()
                    .getBody()
                router.navTo(""main"")
            } catch (t: Throwable) {
                console.log(t)
                toast { // NOT DISPLAYED :(
                    content {
                        alert {
                            title(""Login error"")
                            content(
                                if (t is FetchException && t.statusCode == 401.toShort()) {
                                    ""Bad credentials""
                                } else {
                                    ""$t""
                                }
                            )
                        }
                    }
                }
            }
        }
        model
    }
}
```
",2830be2cb6cf589fc467d80d7534f48546012d69,f1fc78e66cb2ad6f49b78682ce49926ed1a017aa,https://github.com/jwstegemann/fritz2/compare/2830be2cb6cf589fc467d80d7534f48546012d69...f1fc78e66cb2ad6f49b78682ce49926ed1a017aa,"diff --git a/core/src/jsMain/kotlin/dev/fritz2/tracking/tracking.kt b/core/src/jsMain/kotlin/dev/fritz2/tracking/tracking.kt
index 8b6a92b2..134e00ac 100644
--- a/core/src/jsMain/kotlin/dev/fritz2/tracking/tracking.kt
+++ b/core/src/jsMain/kotlin/dev/fritz2/tracking/tracking.kt
@@ -36,12 +36,19 @@ class Tracker(
     /**
      * Tracks a given [operation].
      *
+     * Works also with unsafe operations that throw exceptions, as the tracking gets stopped. The exceptions are
+     * not swallowed though.
+     *
      * @param transaction text describing the transaction
      * @param operation function to track
      */
     suspend fun <T> track(transaction: String = defaultTransaction, operation: suspend () -> T): T {
         state.value = transaction
-        return operation().also { state.value = null }
+        return try {
+            operation()
+        } finally {
+            state.value = null
+        }
     }
 
     /**
diff --git a/core/src/jsTest/kotlin/dev/fritz2/tracking/tracking.kt b/core/src/jsTest/kotlin/dev/fritz2/tracking/tracking.kt
index 45f699cb..562fb727 100644
--- a/core/src/jsTest/kotlin/dev/fritz2/tracking/tracking.kt
+++ b/core/src/jsTest/kotlin/dev/fritz2/tracking/tracking.kt
@@ -66,4 +66,51 @@ class TrackingTests {
         assertEquals(endValue, valueAfterTransaction)
 
     }
+
+    @Test
+    fun testStopTrackingIfExceptionOccursDuringOperation() = runTest {
+        initDocument()
+
+        val resultElementId = ""tracker-${uniqueId()}""
+
+        val store = object : RootStore<Int>(0) {
+            val running = tracker()
+
+            val handler = handle {
+                try {
+                    running.track {
+                        delay(500)
+                        throw Exception(""Something unexpected happened"")
+                    }
+                } catch (ex: Exception) {
+                    // we just don't want to let this escape to the log...
+                }
+                it
+            }
+        }
+
+        render {
+            div {
+                span(id = resultElementId) { store.running.data.map { if (it) ""running"" else ""stopped"" }.asText() }
+            }
+        }
+
+        delay(100)
+
+        store.handler()
+
+        val valueBeforeTransaction = document.getElementById(resultElementId)?.textContent
+        assertEquals("""", valueBeforeTransaction)
+
+        delay(200)
+
+        val valueDuringTransaction = document.getElementById(resultElementId)?.textContent
+        assertEquals(""running"", valueDuringTransaction)
+
+        delay(500)
+
+        val valueAfterTransaction = document.getElementById(resultElementId)?.textContent
+        assertEquals(""stopped"", valueAfterTransaction)
+
+    }
 }
\\ No newline at end of file","['core/src/jsTest/kotlin/dev/fritz2/tracking/tracking.kt', 'core/src/jsMain/kotlin/dev/fritz2/tracking/tracking.kt']",{'.kt': 2},2,0,2,0,2,1141711,291226,29056,102,318,59,9,1,2490,272,452,66,0,2,2021-06-09 09:08:57,532,Kotlin,"{'Kotlin': 1109211, 'TypeScript': 107641, 'Nunjucks': 73140, 'JavaScript': 15648, 'CSS': 3463, 'HTML': 891}",MIT License,"['core/src/jsMain/kotlin/dev/fritz2/binding/handlers.kt', 'core/src/jsMain/kotlin/dev/fritz2/binding/patch.kt', 'core/src/jsMain/kotlin/dev/fritz2/binding/job.kt', 'core/src/jsMain/kotlin/dev/fritz2/binding/store.kt', 'core/src/jsMain/kotlin/dev/fritz2/binding/mount.kt']","['core/src/jsMain/kotlin/dev/fritz2/binding/handlers.kt', 'core/src/jsMain/kotlin/dev/fritz2/binding/patch.kt', 'core/src/jsMain/kotlin/dev/fritz2/binding/job.kt', 'core/src/jsMain/kotlin/dev/fritz2/binding/store.kt', 'core/src/jsMain/kotlin/dev/fritz2/binding/mount.kt']","['```json\n{\n  ""files"": [\n    ""core/src/jsMain/kotlin/dev/fritz2/binding/handlers.kt"",\n    ""core/src/jsMain/kotlin/dev/fritz2/binding/job.kt"",\n    ""core/src/jsMain/kotlin/dev/fritz2/binding/mount.kt"",\n    ""core/src/jsMain/kotlin/dev/fritz2/binding/patch.kt"",\n    ""core/src/jsMain/kotlin/dev/fritz2/binding/store.kt""\n  ]\n}\n```']",1,1664.405107498169
3821,jwstegemann/fritz2/679/671,jwstegemann,fritz2,https://github.com/jwstegemann/fritz2/issues/671,https://github.com/jwstegemann/fritz2/pull/679,https://github.com/jwstegemann/fritz2/pull/679,1,fixes,Fix ``for`` Attribute of radioGroupOptionLabel and checkboxGroupOptionLabel,"Currently the ``for`` attribute links to a false Id! It references the Id of the ``radioGroupOption`` and not those of the ``radioGroupOptionToggle``, which would be the correct one.

The  following snippet shows the issue:
```kotlin
radioGroupOption {
    radioGroupOptionToggle(tag = RenderContext::input) {
        type(""radio"")
        // --> id == this@radioGroupOption.id + ""-toggle""
    }
    radioGroupOptionLabel {
        ...
        // --> for == this@radioGroupOption.id
    }
}
```

The same issue exists for ``checkboxGroupOptionLabel`` too.",6f90b789be5368ba4ea5746f09f8b5ad498a1e6d,4453a13249623c9b511eb110ba9d76dfc01dc740,https://github.com/jwstegemann/fritz2/compare/6f90b789be5368ba4ea5746f09f8b5ad498a1e6d...4453a13249623c9b511eb110ba9d76dfc01dc740,"diff --git a/headless/src/jsMain/kotlin/dev/fritz2/headless/components/checkboxGroup.kt b/headless/src/jsMain/kotlin/dev/fritz2/headless/components/checkboxGroup.kt
index bd4439fb..598eac55 100644
--- a/headless/src/jsMain/kotlin/dev/fritz2/headless/components/checkboxGroup.kt
+++ b/headless/src/jsMain/kotlin/dev/fritz2/headless/components/checkboxGroup.kt
@@ -112,6 +112,8 @@ class CheckboxGroup<C : HTMLElement, T>(tag: Tag<C>, private val explicitId: Str
         private var label: Tag<HTMLElement>? = null
         private var descriptions: MutableList<Tag<HTMLElement>> = mutableListOf()
 
+        private val toggleId = ""${optionId}-toggle""
+
         fun render() {
             toggle?.apply {
                 label?.let { attr(Aria.labelledby, it.id) }
@@ -138,7 +140,7 @@ class CheckboxGroup<C : HTMLElement, T>(tag: Tag<C>, private val explicitId: Str
             content: Tag<CT>.() -> Unit
         ): Tag<CT> {
             addComponentStructureInfo(""checkboxGroupOptionToggle"", this@checkboxGroupOptionToggle.scope, this)
-            return tag(this, classes, ""${optionId}-toggle"", scope) {
+            return tag(this, classes, toggleId, scope) {
                 content()
                 attr(""role"", Aria.Role.checkbox)
                 attr(Aria.checked, selected.asString())
@@ -193,7 +195,7 @@ class CheckboxGroup<C : HTMLElement, T>(tag: Tag<C>, private val explicitId: Str
             content: Tag<CL>.() -> Unit
         ): Tag<CL> {
             addComponentStructureInfo(""checkboxGroupOptionLabel"", this@checkboxGroupOptionLabel.scope, this)
-            return tag(this, classes, ""$optionId-label"", scope, content).also { label = it }
+            return tag(this, classes, ""${optionId}-toggle"", scope, content).also { label = it }
         }
 
         /**
diff --git a/headless/src/jsMain/kotlin/dev/fritz2/headless/components/radioGroup.kt b/headless/src/jsMain/kotlin/dev/fritz2/headless/components/radioGroup.kt
index a10f783c..f1101de1 100644
--- a/headless/src/jsMain/kotlin/dev/fritz2/headless/components/radioGroup.kt
+++ b/headless/src/jsMain/kotlin/dev/fritz2/headless/components/radioGroup.kt
@@ -130,6 +130,8 @@ class RadioGroup<C : HTMLElement, T>(tag: Tag<C>, private val explicitId: String
         private var label: Tag<HTMLElement>? = null
         private var descriptions: MutableList<Tag<HTMLElement>> = mutableListOf()
 
+        private val toggleId = ""$optionId-toggle""
+
         fun render() {
             toggle?.apply {
                 label?.let { attr(Aria.labelledby, it.id) }
@@ -156,7 +158,7 @@ class RadioGroup<C : HTMLElement, T>(tag: Tag<C>, private val explicitId: String
             content: Tag<CT>.() -> Unit
         ): Tag<CT> {
             addComponentStructureInfo(""radioGroupOptionToggle"", this@radioGroupOptionToggle.scope, this)
-            return tag(this, classes, ""$optionId-toggle"", scope) {
+            return tag(this, classes, toggleId, scope) {
                 content()
                 attr(""role"", Aria.Role.radio)
                 attr(Aria.checked, selected.asString())
@@ -220,7 +222,7 @@ class RadioGroup<C : HTMLElement, T>(tag: Tag<C>, private val explicitId: String
             content: Tag<HTMLLabelElement>.() -> Unit
         ) = radioGroupOptionLabel(classes, scope, RenderContext::label) {
             content()
-            `for`(optionId)
+            `for`(toggleId)
         }
 
         /**
diff --git a/headless/src/jsMain/kotlin/dev/fritz2/headless/components/switch.kt b/headless/src/jsMain/kotlin/dev/fritz2/headless/components/switch.kt
index 727f7317..782c7386 100644
--- a/headless/src/jsMain/kotlin/dev/fritz2/headless/components/switch.kt
+++ b/headless/src/jsMain/kotlin/dev/fritz2/headless/components/switch.kt
@@ -93,6 +93,8 @@ class SwitchWithLabel<C : HTMLElement>(tag: Tag<C>, id: String?) :
     private var label: Tag<HTMLElement>? = null
     private var descriptions: MutableList<Tag<HTMLElement>> = mutableListOf()
 
+    private val toggleId by lazy { ""$componentId-toggle"" }
+
     override fun render() {
         attr(""id"", componentId)
         toggle?.apply {
@@ -120,7 +122,7 @@ class SwitchWithLabel<C : HTMLElement>(tag: Tag<C>, id: String?) :
         content: Tag<CT>.() -> Unit
     ) : Tag<CT> {
         addComponentStructureInfo(""switchToggle"", this@switchToggle.scope, this)
-        return tag(this, classes, ""$componentId-toggle"", scope) {
+        return tag(this, classes, toggleId, scope) {
             content()
             renderSwitchCore(this)
         }.also { toggle = it }
@@ -170,7 +172,7 @@ class SwitchWithLabel<C : HTMLElement>(tag: Tag<C>, id: String?) :
         content: Tag<HTMLLabelElement>.() -> Unit
     ) = switchLabel(classes, scope, RenderContext::label) {
         content()
-        `for`(componentId)
+        `for`(toggleId)
     }
 
     /**","['headless/src/jsMain/kotlin/dev/fritz2/headless/components/switch.kt', 'headless/src/jsMain/kotlin/dev/fritz2/headless/components/radioGroup.kt', 'headless/src/jsMain/kotlin/dev/fritz2/headless/components/checkboxGroup.kt']",{'.kt': 3},3,0,3,0,3,832406,243975,18774,94,844,195,18,3,571,68,130,17,0,1,2022-09-01 09:43:39,532,Kotlin,"{'Kotlin': 1109211, 'TypeScript': 107641, 'Nunjucks': 73140, 'JavaScript': 15648, 'CSS': 3463, 'HTML': 891}",MIT License,"['headless/src/jsMain/kotlin/dev/fritz2/headless/components/radioGroup.kt', 'core/src/jsMain/kotlin/dev/fritz2/core/rendercontext.kt', 'core/src/jsMain/kotlin/dev/fritz2/core/tags.kt', 'core/src/jsMain/kotlin/dev/fritz2/core/dom.kt', 'headless/src/jsMain/kotlin/dev/fritz2/headless/components/checkboxGroup.kt']","['headless/src/jsMain/kotlin/dev/fritz2/headless/components/radioGroup.kt', 'core/src/jsMain/kotlin/dev/fritz2/core/rendercontext.kt', 'core/src/jsMain/kotlin/dev/fritz2/core/tags.kt', 'core/src/jsMain/kotlin/dev/fritz2/core/dom.kt', 'headless/src/jsMain/kotlin/dev/fritz2/headless/components/checkboxGroup.kt']","['```json\n{\n  ""files"": [\n    ""headless/src/jsMain/kotlin/dev/fritz2/headless/components/checkboxGroup.kt"",\n    ""headless/src/jsMain/kotlin/dev/fritz2/headless/components/radioGroup.kt"",\n    ""core/src/jsMain/kotlin/dev/fritz2/core/rendercontext.kt"",\n    ""core/src/jsMain/kotlin/dev/fritz2/core/tags.kt"",\n    ""core/src/jsMain/kotlin/dev/fritz2/core/dom.kt""\n  ]\n}\n```']",1,1496.1252212524414
1952,theopenconversationkit/tock/1040/1039,theopenconversationkit,tock,https://github.com/theopenconversationkit/tock/issues/1039,https://github.com/theopenconversationkit/tock/pull/1040,https://github.com/theopenconversationkit/tock/pull/1040,1,fixes,[Test context] Allow empty sentences in Xray attachments,"Bot answers stored in Xray attachments created within test context may have empty sentences like this :
`{sentence:}`.
When a test execution is ordered, message parsing fails because of those empty sentences.",da403b484c999bdf16f3005c7cc067a6299e2124,bc4157305a4eab2cca3644b0e7460210000a5912,https://github.com/theopenconversationkit/tock/compare/da403b484c999bdf16f3005c7cc067a6299e2124...bc4157305a4eab2cca3644b0e7460210000a5912,"diff --git a/bot/engine/src/main/kotlin/engine/message/parser/MessageParser.kt b/bot/engine/src/main/kotlin/engine/message/parser/MessageParser.kt
index 1ec8ae65d..3eca8225a 100644
--- a/bot/engine/src/main/kotlin/engine/message/parser/MessageParser.kt
+++ b/bot/engine/src/main/kotlin/engine/message/parser/MessageParser.kt
@@ -54,21 +54,21 @@ object MessageParser {
 
     //duplicate mapper to avoid ALLOW_UNQUOTED_FIELD_NAMES default
     private val mapper: ObjectMapper =
-            jacksonObjectMapper()
-                    .findAndRegisterModules()
-                    //force java time module
-                    .registerModule(JavaTimeModule())
-                    .configure(ALLOW_UNQUOTED_FIELD_NAMES, true)
-                    .configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false)
-                    .setSerializationInclusion(JsonInclude.Include.NON_NULL)
-                    .configure(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS, false)
-                    .configure(JsonParser.Feature.ALLOW_UNQUOTED_CONTROL_CHARS, true)
-                    .configure(MapperFeature.PROPAGATE_TRANSIENT_MARKER, true)
+        jacksonObjectMapper()
+            .findAndRegisterModules()
+            //force java time module
+            .registerModule(JavaTimeModule())
+            .configure(ALLOW_UNQUOTED_FIELD_NAMES, true)
+            .configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false)
+            .setSerializationInclusion(JsonInclude.Include.NON_NULL)
+            .configure(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS, false)
+            .configure(JsonParser.Feature.ALLOW_UNQUOTED_CONTROL_CHARS, true)
+            .configure(MapperFeature.PROPAGATE_TRANSIENT_MARKER, true)
 
     fun parse(content: String): List<Message> {
         return content.trim()
-                .split(multiMessagesSeparator)
-                .map { toMessage(it) }
+            .split(multiMessagesSeparator)
+            .map { toMessage(it) }
     }
 
     internal fun mapToString(map: Map<String, String>): String {
@@ -82,13 +82,17 @@ object MessageParser {
     private fun elementToString(element: GenericMessage): String {
         return with(element) {
             val content = listOfNotNull(
-                    if (connectorType == ConnectorType.none) null else ""connectorType:$connectorType"",
-                    if (attachments.isEmpty()) null else ""attachments:[${attachments.joinToString(fieldSeparator) { it.toPrettyString() }}]"",
-                    if (choices.isEmpty()) null else ""choices:[${choices.joinToString(fieldSeparator) { it.toPrettyString() }}]"",
-                    if (locations.isEmpty()) null else ""locations:[${locations.joinToString(fieldSeparator) { it.toPrettyString() }}]"",
-                    if (texts.isEmpty()) null else ""texts:${mapper.writeValueAsString(texts)}"",
-                    if (metadata.isEmpty()) null else ""metadata:${mapper.writeValueAsString(metadata)}"",
-                    if (subElements.isEmpty()) null else ""subElements:[${subElements.joinToString(subElementsArraySeparator) { subElementToString(it) }}]""
+                if (connectorType == ConnectorType.none) null else ""connectorType:$connectorType"",
+                if (attachments.isEmpty()) null else ""attachments:[${attachments.joinToString(fieldSeparator) { it.toPrettyString() }}]"",
+                if (choices.isEmpty()) null else ""choices:[${choices.joinToString(fieldSeparator) { it.toPrettyString() }}]"",
+                if (locations.isEmpty()) null else ""locations:[${locations.joinToString(fieldSeparator) { it.toPrettyString() }}]"",
+                if (texts.isEmpty()) null else ""texts:${mapper.writeValueAsString(texts)}"",
+                if (metadata.isEmpty()) null else ""metadata:${mapper.writeValueAsString(metadata)}"",
+                if (subElements.isEmpty()) null else ""subElements:[${subElements.joinToString(subElementsArraySeparator) {
+                    subElementToString(
+                        it
+                    )
+                }}]""
             ).joinToString(prefix = elementsSeparator, separator = elementsSeparator)
             ""{$content}""
         }
@@ -97,11 +101,11 @@ object MessageParser {
     private fun subElementToString(element: GenericElement): String {
         return with(element) {
             val content = listOfNotNull(
-                    if (attachments.isEmpty()) null else ""attachments:[${attachments.joinToString(fieldSeparator) { it.toPrettyString() }}]"",
-                    if (choices.isEmpty()) null else ""choices:[${choices.joinToString(fieldSeparator) { it.toPrettyString() }}]"",
-                    if (locations.isEmpty()) null else ""locations:[${locations.joinToString(fieldSeparator) { it.toPrettyString() }}]"",
-                    if (texts.isEmpty()) null else ""texts:${mapper.writeValueAsString(texts)}"",
-                    if (metadata.isEmpty()) null else ""metadata:${mapper.writeValueAsString(metadata)}""
+                if (attachments.isEmpty()) null else ""attachments:[${attachments.joinToString(fieldSeparator) { it.toPrettyString() }}]"",
+                if (choices.isEmpty()) null else ""choices:[${choices.joinToString(fieldSeparator) { it.toPrettyString() }}]"",
+                if (locations.isEmpty()) null else ""locations:[${locations.joinToString(fieldSeparator) { it.toPrettyString() }}]"",
+                if (texts.isEmpty()) null else ""texts:${mapper.writeValueAsString(texts)}"",
+                if (metadata.isEmpty()) null else ""metadata:${mapper.writeValueAsString(metadata)}""
             ).joinToString(prefix = subElementsSeparator, separator = subElementsSeparator)
             ""{$content}""
         }
@@ -109,38 +113,34 @@ object MessageParser {
 
     private fun toMessage(content: String): Message {
         return content.trim().let {
-            if (it.contains(""{$sentence"")) {
-                parseSentence(it)
-            } else if (it.contains(""{$choice"")) {
-                parseChoice(it)
-            } else if (it.contains(""{$attachment"")) {
-                parseAttachment(it)
-            } else if (it.contains(""{$location"")) {
-                parseLocation(it)
-            } else {
-                Sentence(it)
+            when {
+                it.contains(""{$sentence"") -> parseSentence(it)
+                it.contains(""{$choice"") -> parseChoice(it)
+                it.contains(""{$attachment"") -> parseAttachment(it)
+                it.contains(""{$location"") -> parseLocation(it)
+                else -> Sentence(it)
             }
         }
     }
 
     private fun parseSentence(content: String): Sentence {
         return content
-                .removePrefix(""{"")
-                .let {
-                    it.substring(it.indexOf("":"") + 1, it.lastIndexOf(""}""))
-                            .let {
-                                Sentence(
-                                        null,
-                                        //only one element supported
-                                        mutableListOf(parseSentenceElement(it))
-                                )
-                            }
-                }
+            .removePrefix(""{"")
+            .let {
+                it.substring(it.indexOf("":"") + 1, it.lastIndexOf(""}""))
+                    .let {
+                        Sentence(
+                            null,
+                            //only one element supported
+                            mutableListOf(parseSentenceElement(it))
+                        )
+                    }
+            }
     }
 
     private fun parseSentenceElement(content: String): GenericMessage {
-        return content
-                .substring(content.indexOf(""{"") + 1, content.lastIndexOf(""}""))
+        return content.takeIf { it.isNotEmpty() }.let {
+            it?.substring(content.indexOf(""{"") + 1, content.lastIndexOf(""}""))
                 .let {
                     var attachments: List<Attachment> = emptyList()
                     var choices: List<Choice> = emptyList()
@@ -149,135 +149,146 @@ object MessageParser {
                     var metadata: Map<String, String> = emptyMap()
                     var elements: List<GenericElement> = emptyList()
 
-                    it.split(elementsSeparator).forEach { s ->
-                        if (s.startsWith(""attachments"")) {
-                            attachments = s.substring(s.indexOf(""["") + 1, s.lastIndexOf(""]""))
+                    it?.split(elementsSeparator)?.forEach { s ->
+                        when {
+                            s.startsWith(""attachments"") -> {
+                                attachments = s.substring(s.indexOf(""["") + 1, s.lastIndexOf(""]""))
                                     .split(fieldSeparator)
                                     .map { parseAttachment(it.trim()) }
-                        } else if (s.startsWith(""choices"")) {
-                            choices = s.substring(s.indexOf(""["") + 1, s.lastIndexOf(""]""))
+                            }
+                            s.startsWith(""choices"") -> {
+                                choices = s.substring(s.indexOf(""["") + 1, s.lastIndexOf(""]""))
                                     .split(fieldSeparator)
                                     .map { parseChoice(it.trim()) }
-                        } else if (s.startsWith(""locations"")) {
-                            locations = s.substring(s.indexOf(""["") + 1, s.lastIndexOf(""]""))
+                            }
+                            s.startsWith(""locations"") -> {
+                                locations = s.substring(s.indexOf(""["") + 1, s.lastIndexOf(""]""))
                                     .split(fieldSeparator)
                                     .map { parseLocation(it.trim()) }
-                        } else if (s.startsWith(""subElements"")) {
-                            elements = s.substring(s.indexOf(""["") + 1, s.lastIndexOf(""]""))
+                            }
+                            s.startsWith(""subElements"") -> {
+                                elements = s.substring(s.indexOf(""["") + 1, s.lastIndexOf(""]""))
                                     .split(subElementsArraySeparator)
                                     .map { parseSentenceSubElement(it.trim()) }
-                        } else if (s.startsWith(""texts"")) {
-                            texts = s.substring(s.indexOf("":"") + 1)
+                            }
+                            s.startsWith(""texts"") -> {
+                                texts = s.substring(s.indexOf("":"") + 1)
                                     .let { mapper.readValue(it) }
-                        } else if (s.startsWith(""metadata"")) {
-                            metadata = s.substring(s.indexOf("":"") + 1)
+                            }
+                            s.startsWith(""metadata"") -> {
+                                metadata = s.substring(s.indexOf("":"") + 1)
                                     .let { mapper.readValue(it) }
+                            }
                         }
                     }
 
                     GenericMessage(
-                            ConnectorType.none,
-                            attachments,
-                            choices,
-                            texts,
-                            locations,
-                            metadata,
-                            elements)
+                        ConnectorType.none,
+                        attachments,
+                        choices,
+                        texts,
+                        locations,
+                        metadata,
+                        elements
+                    )
                 }
+        }
     }
 
     private fun parseSentenceSubElement(content: String): GenericElement {
         return content
-                .substring(content.indexOf(""{"") + 1, content.lastIndexOf(""}""))
-                .let {
-                    var attachments: List<Attachment> = emptyList()
-                    var choices: List<Choice> = emptyList()
-                    var texts: Map<String, String> = emptyMap()
-                    var locations: List<Location> = emptyList()
-                    var metadata: Map<String, String> = emptyMap()
+            .substring(content.indexOf(""{"") + 1, content.lastIndexOf(""}""))
+            .let {
+                var attachments: List<Attachment> = emptyList()
+                var choices: List<Choice> = emptyList()
+                var texts: Map<String, String> = emptyMap()
+                var locations: List<Location> = emptyList()
+                var metadata: Map<String, String> = emptyMap()
 
-                    it.split(subElementsSeparator).forEach { s ->
-                        if (s.startsWith(""attachments"")) {
-                            attachments = s.substring(s.indexOf(""["") + 1, s.lastIndexOf(""]""))
-                                    .split(fieldSeparator)
-                                    .map { parseAttachment(it.trim()) }
-                        } else if (s.startsWith(""choices"")) {
-                            choices = s.substring(s.indexOf(""["") + 1, s.lastIndexOf(""]""))
-                                    .split(fieldSeparator)
-                                    .map { parseChoice(it.trim()) }
-                        } else if (s.startsWith(""locations"")) {
-                            locations = s.substring(s.indexOf(""["") + 1, s.lastIndexOf(""]""))
-                                    .split(fieldSeparator)
-                                    .map { parseLocation(it.trim()) }
-                        } else if (s.startsWith(""texts"")) {
-                            texts = s.substring(s.indexOf("":"") + 1)
-                                    .let { mapper.readValue(it) }
-                        } else if (s.startsWith(""metadata"")) {
-                            metadata = s.substring(s.indexOf("":"") + 1)
-                                    .let { mapper.readValue(it) }
-                        }
+                it.split(subElementsSeparator).forEach { s ->
+                    if (s.startsWith(""attachments"")) {
+                        attachments = s.substring(s.indexOf(""["") + 1, s.lastIndexOf(""]""))
+                            .split(fieldSeparator)
+                            .map { parseAttachment(it.trim()) }
+                    } else if (s.startsWith(""choices"")) {
+                        choices = s.substring(s.indexOf(""["") + 1, s.lastIndexOf(""]""))
+                            .split(fieldSeparator)
+                            .map { parseChoice(it.trim()) }
+                    } else if (s.startsWith(""locations"")) {
+                        locations = s.substring(s.indexOf(""["") + 1, s.lastIndexOf(""]""))
+                            .split(fieldSeparator)
+                            .map { parseLocation(it.trim()) }
+                    } else if (s.startsWith(""texts"")) {
+                        texts = s.substring(s.indexOf("":"") + 1)
+                            .let { mapper.readValue(it) }
+                    } else if (s.startsWith(""metadata"")) {
+                        metadata = s.substring(s.indexOf("":"") + 1)
+                            .let { mapper.readValue(it) }
                     }
-
-                    GenericElement(
-                            attachments,
-                            choices,
-                            texts,
-                            locations,
-                            metadata)
                 }
+
+                GenericElement(
+                    attachments,
+                    choices,
+                    texts,
+                    locations,
+                    metadata
+                )
+            }
     }
 
     private fun parseChoice(content: String): Choice {
         return content
-                .removePrefix(""{"")
-                .let {
-                    it.substring(it.indexOf("":"") + 1, it.lastIndexOf(""}""))
-                            .let {
-                                val index = it.indexOf("","")
-                                if (index != -1) {
-                                    Choice(
-                                            it.substring(0, index).trim(),
-                                            mapper.readValue<Map<String, String>>(it.substring(index + 1))
-                                    )
-                                } else {
-                                    Choice(it.trim())
-                                }
-                            }
-                }
+            .removePrefix(""{"")
+            .let {
+                it.substring(it.indexOf("":"") + 1, it.lastIndexOf(""}""))
+                    .let {
+                        val index = it.indexOf("","")
+                        if (index != -1) {
+                            Choice(
+                                it.substring(0, index).trim(),
+                                mapper.readValue<Map<String, String>>(it.substring(index + 1))
+                            )
+                        } else {
+                            Choice(it.trim())
+                        }
+                    }
+            }
     }
 
     private fun parseAttachment(content: String): Attachment {
         return content
-                .removePrefix(""{"")
-                .let {
-                    it.substring(it.indexOf("":"") + 1, it.lastIndexOf(""}""))
-                            .let {
-                                val index = it.lastIndexOf("","")
-                                if (index != -1) {
-                                    Attachment(
-                                            it.substring(0, index).trim(),
-                                            enumValueOf(it.substring(index + 1).trim())
-                                    )
-                                } else {
-                                    Attachment(it.trim(), image)
-                                }
-                            }
-                }
+            .removePrefix(""{"")
+            .let {
+                it.substring(it.indexOf("":"") + 1, it.lastIndexOf(""}""))
+                    .let {
+                        val index = it.lastIndexOf("","")
+                        if (index != -1) {
+                            Attachment(
+                                it.substring(0, index).trim(),
+                                enumValueOf(it.substring(index + 1).trim())
+                            )
+                        } else {
+                            Attachment(it.trim(), image)
+                        }
+                    }
+            }
     }
 
     private fun parseLocation(content: String): Location {
         return content
-                .removePrefix(""{"")
-                .let {
-                    it.substring(it.indexOf("":"") + 1, it.lastIndexOf(""}""))
-                            .let {
-                                val index = it.indexOf("","")
-                                Location(
-                                        UserLocation(
-                                                it.substring(0, index).trim().toDouble(),
-                                                it.substring(index + 1).trim().toDouble())
-                                )
-                            }
-                }
+            .removePrefix(""{"")
+            .let {
+                it.substring(it.indexOf("":"") + 1, it.lastIndexOf(""}""))
+                    .let {
+                        val index = it.indexOf("","")
+                        Location(
+                            UserLocation(
+                                it.substring(0, index).trim().toDouble(),
+                                it.substring(index + 1).trim().toDouble()
+                            )
+                        )
+                    }
+            }
     }
 }
\\ No newline at end of file
diff --git a/bot/engine/src/test/kotlin/engine/message/parser/MessageParserTest.kt b/bot/engine/src/test/kotlin/engine/message/parser/MessageParserTest.kt
index af0fe4326..8f7e7e279 100644
--- a/bot/engine/src/test/kotlin/engine/message/parser/MessageParserTest.kt
+++ b/bot/engine/src/test/kotlin/engine/message/parser/MessageParserTest.kt
@@ -16,6 +16,7 @@
 
 package ai.tock.bot.engine.message.parser
 
+import ai.tock.bot.connector.ConnectorMessage
 import ai.tock.bot.engine.action.SendAttachment.AttachmentType.file
 import ai.tock.bot.engine.action.SendAttachment.AttachmentType.image
 import ai.tock.bot.engine.message.Attachment
@@ -26,6 +27,7 @@ import ai.tock.bot.engine.message.GenericMessage
 import ai.tock.bot.engine.message.GenericElement
 import ai.tock.bot.engine.user.UserLocation
 import org.junit.jupiter.api.Test
+import java.awt.font.TextMeasurer
 import kotlin.test.assertEquals
 
 /**
@@ -139,4 +141,12 @@ class MessageParserTest {
         assertEquals(listOf(s, c), MessageParser.parse(""${s.toPrettyString()} |_| ${c.toPrettyString()}""))
     }
 
+
+    @Test
+    fun parse_shouldWork_forSentenceWithEmptyContent() {
+        val s = Sentence(text = null, messages = mutableListOf(GenericMessage()))
+        MessageParser.parse(""{sentence:}"")
+
+        assertEquals(s, MessageParser.parse(s.toPrettyString()).first())
+    }
 }
\\ No newline at end of file
diff --git a/bot/xray/src/main/kotlin/XrayService.kt b/bot/xray/src/main/kotlin/XrayService.kt
index a35383090..c2d81ba53 100644
--- a/bot/xray/src/main/kotlin/XrayService.kt
+++ b/bot/xray/src/main/kotlin/XrayService.kt
@@ -71,6 +71,7 @@ import java.time.OffsetDateTime.ofInstant
 import java.time.temporal.ChronoUnit
 import java.util.Locale
 import java.util.Base64
+import kotlin.math.log
 
 /**
  *
@@ -112,12 +113,12 @@ class XrayService(
 
     fun execute(namespace: String): XrayPlanExecutionResult {
         return when {
-            testKeys.isNotEmpty() && testPlanKeys.isNotEmpty() -> throw AssertionError(""Impossible d'exécuter un test plan et un test à la fois."")
+            testKeys.isNotEmpty() && testPlanKeys.isNotEmpty() -> throw AssertionError(""Cannot execute test plan and test at the same time."")
             testKeys.isNotEmpty() -> executeTests(namespace)
             testPlanKeys.isNotEmpty() -> executeTestPlans(namespace)
             else -> {
-                logger.error { ""Veuillez spécifier le \\""testPlanKey\\"" OU (xor) le \\""testKey\\""."" }
-                XrayPlanExecutionResult(success = 0, total = 0, errorMessage = ""ERREUR : Veuillez spécifier le \\""testPlanKey\\"" OU (xor) le \\""testKey\\""."")
+                logger.warn { ""Specify \\""testPlanKey\\"" OR (xor) \\""testKey\\""."" }
+                XrayPlanExecutionResult(success = 0, total = 0, errorMessage = ""ERROR : Specify \\""testPlanKey\\"" OR (xor) \\""testKey\\""."")
             }
         }
     }
@@ -162,11 +163,11 @@ class XrayService(
      */
     fun executeTests(namespace: String): XrayPlanExecutionResult {
         val dummyTestPlanKey = ""AUTO_${testKeys[0]}""
-        val dummyTestPlan = listOf(""MOCK"")
         val jiraProject = getProjectFromIssue(testKeys[0])
         val executionId = Dice.newId()
 
         logger.info { ""Execute tests with namespace $namespace"" }
+        logger.debug { ""Execution with id : $executionId started for test plan $dummyTestPlanKey"" }
         return try {
             // getBotConfiguration retrieves all configuration for the selected namespace
             // getBotConfiguration will reach information stored in tab Configuration on BotAdmin site
@@ -182,6 +183,7 @@ class XrayService(
                         execTestsOnly(XrayExecutionConfiguration(it, listOf(dummyTestPlanKey), jiraProject), dummyTestPlanKey, testKeys, executionId.toId())
                     }
                     .let {
+                        logger.debug { ""Execution with id : $executionId ended for test plan $dummyTestPlanKey"" }
                         sendToXray(it)
                     }
         } catch (t: Throwable) {
@@ -400,19 +402,20 @@ class XrayService(
         return configuration
                 .xrayTestPlanKeys
                 .mapNotNull { xrayPlanKey ->
-                    logger.info { ""Start plan $xrayPlanKey execution"" }
+                    logger.info { ""Start plan $xrayPlanKey execution for test plan $planKey"" }
                     try {
                         // create a test plan with all given tests
                         val testPlan = createTestPlanWithTests(configuration, planKey, testKeys)
+                        logger.debug { ""Common Tock test plan created : ${testPlan.hashCode()} for test plan $planKey"" }
                         // if the current test plan has dialogs to send, then execute it, otherwise skip it and jump to the next one
                         if (testPlan.dialogs.isNotEmpty()) {
                             executePlan(configuration, testPlan.name, testPlan, executionId)
                         } else {
-                            logger.info { ""Empty test plan for $configuration - skipped"" }
+                            logger.debug { ""Empty test plan for $configuration - skipped"" }
                             null
                         }
                     } finally {
-                        logger.info { ""Plan $xrayPlanKey executed"" }
+                        logger.info { ""Plan $xrayPlanKey executed for test plan $planKey"" }
                     }
                 }
     }
@@ -423,7 +426,7 @@ class XrayService(
      * @param configuration is the configuration to execute the test plan.
      * @param xrayTestPlanKey is the Xray identifier of the test plan to execute.
      * @param testPlan is the test plan to execute formatted in the common Test Plan manageable by Tock test framework.
-     * @return a TestPlanExecutionReport which contains.... TODO
+     * @return a TestPlanExecutionReport which contains test plan execution results
      */
     private fun executePlan(
             configuration: XrayExecutionConfiguration,
@@ -431,9 +434,9 @@ class XrayService(
             testPlan: TestPlan,
             executionId: Id<TestPlanExecution>
     ): TestPlanExecutionReport {
-        logger.debug { ""Execute test plan $testPlan"" }
+        logger.debug { ""Execute test plan ${testPlan.name} with execution id $executionId"" }
         val execution = findTestClient().saveAndExecuteTestPlan(testPlan, executionId)
-        logger.debug { ""Test plan execution $execution"" }
+        logger.debug { ""Test plan execution ${execution.testPlanId}"" }
         return TestPlanExecutionReport(
                 configuration,
                 xrayTestPlanKey,
@@ -516,29 +519,27 @@ class XrayService(
      */
     private fun getDialogReport(configuration: XrayExecutionConfiguration, xrayTest: XrayTest): TestDialogReport {
         val userInterface = xrayTest.findUserInterface()
-        // store all steps of the given xrayTest
         val xraySteps = XrayClient.getTestSteps(xrayTest.key)
-        // return the TestDialogReport with parsed steps
         return TestDialogReport(
-                xraySteps.flatMap {
+                xraySteps.flatMap { xrayTestStep ->
                     listOfNotNull(
                             parseStepData(
                                     configuration,
                                     userInterface,
-                                    it.id,
+                                    xrayTestStep.id,
                                     userId,
-                                    it.data.raw,
-                                    it.attachments.firstOrNull { it.fileName == ""user.message"" }),
+                                    xrayTestStep.data.raw,
+                                    xrayTestStep.attachments.firstOrNull { it.fileName == ""user.message"" }),
                             parseStepData(
                                     configuration,
                                     userInterface,
-                                    it.id,
+                                    xrayTestStep.id,
                                     botId,
-                                    it.result.raw,
-                                    it.attachments.firstOrNull { it.fileName == ""bot.message"" })
+                                    xrayTestStep.result.raw,
+                                    xrayTestStep.attachments.firstOrNull { it.fileName == ""bot.message"" })
                     )
                 },
-                xrayTest.findUserInterface(),
+                userInterface,
                 xrayTest.key.toId()
         )
     }","['bot/xray/src/main/kotlin/XrayService.kt', 'bot/engine/src/main/kotlin/engine/message/parser/MessageParser.kt', 'bot/engine/src/test/kotlin/engine/message/parser/MessageParserTest.kt']",{'.kt': 3},3,0,3,0,3,3878139,811079,105599,1484,19952,3320,338,2,210,32,40,3,0,0,2020-09-02 14:08:25,395,Kotlin,"{'Kotlin': 5544796, 'TypeScript': 1047105, 'HTML': 449744, 'CSS': 156695, 'SCSS': 57853, 'Shell': 10923, 'JavaScript': 5496}",Apache License 2.0,"['bot/xray/src/main/kotlin/model/XrayTestExecutionStepReport.kt', 'bot/xray/src/main/kotlin/model/XrayTestExecution.kt', 'nlp/front/storage-mongo/target/generated-sources/kapt/compile/ai/tock/nlp/front/storage/mongo/ParseRequestLogStatCol_.kt', 'bot/xray/src/main/kotlin/model/XrayTestExecutionReport.kt', 'nlp/front/storage-mongo/target/generated-sources/kapt/compile/ai/tock/nlp/front/storage/mongo/ParseRequestLogStatResult_.kt', 'bot/xray/src/main/kotlin/model/XrayTestExecutionInfo.kt', 'bot/xray/src/main/kotlin/model/XrayTestPlan.kt', 'nlp/front/storage-mongo/target/generated-sources/kapt/compile/ai/tock/nlp/front/storage/mongo/ParseRequestLogCol_.kt', 'nlp/front/storage-mongo/target/generated-sources/kapt/compile/ai/tock/nlp/front/storage/mongo/ParseRequestLogIntentStatCol_.kt']","['bot/xray/src/main/kotlin/model/XrayTestExecutionReport.kt', 'bot/xray/src/main/kotlin/model/XrayTestExecutionStepReport.kt', 'bot/xray/src/main/kotlin/model/XrayTestExecution.kt']","['```json\n{\n  ""files"": [\n    ""bot/xray/src/main/kotlin/model/XrayTestExecutionReport.kt"",\n    ""bot/xray/src/main/kotlin/model/XrayTestExecutionStepReport.kt"",\n    ""bot/xray/src/main/kotlin/model/XrayTestExecutionInfo.kt"",\n    ""bot/xray/src/main/kotlin/model/XrayTestExecution.kt"",\n    ""bot/xray/src/main/kotlin/model/XrayTestPlan.kt""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""nlp/front/storage-mongo/target/generated-sources/kapt/compile/ai/tock/nlp/front/storage/mongo/ParseRequestLogCol_.kt"",\n    ""nlp/front/storage-mongo/target/generated-sources/kapt/compile/ai/tock/nlp/front/storage/mongo/ParseRequestLogCol_.kt"",\n    ""nlp/front/storage-mongo/target/generated-sources/kapt/compile/ai/tock/nlp/front/storage/mongo/ParseRequestLogStatCol_.kt"",\n    ""nlp/front/storage-mongo/target/generated-sources/kapt/compile/ai/tock/nlp/front/storage/mongo/ParseRequestLogStatResult_.kt"",\n    ""nlp/front/storage-mongo/target/generated-sources/kapt/compile/ai/tock/nlp/front/storage/mongo/ParseRequestLogIntentStatCol_.kt""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""bot/xray/src/main/kotlin/model/XrayTestExecutionStepReport.kt"",\n    ""bot/xray/src/main/kotlin/model/XrayTestExecution.kt"",\n    ""bot/xray/src/main/kotlin/model/XrayTestExecutionReport.kt""\n  ]\n}\n```']",2,6042.853116989136
2019,google/android-fhir/301/296,google,android-fhir,https://github.com/google/android-fhir/issues/296,https://github.com/google/android-fhir/pull/301,https://github.com/google/android-fhir/pull/301,1,fixes,Insert unqualified (logical) ids for resources instead of fully qualified ids,"**Describe the bug**
Upon sync, fully qualified IDs are being inserted into the database (in Resource, Index and Local change tables). This leads to crashes when deserialised resources are updated.

**Component**
Core library

**To Reproduce**
Steps to reproduce the behavior:
1. Sync resources from the HAPI FHIR server (happening automatically in the reference app.
2. Modify any resource property e.g. `birthDate`.
3. Call `FhirEngine.update(resource)`
4. Crash while selecting old resource for update.

**Root cause**

Calling `resource.id` on synced resources read from a `Bundle` yields fully qualified id, e.g. `http://hapi.fhir.org/baseR4/Patient/1915026`. 
Upon serialisation the base URL is removed and only the logical part is stored in the JSON representation of the resource. E.g.:
```
{
  ""resourceType"": ""Patient"",
  ""id"": ""1915026"",
 ...
``` 
After deserialising this JSON, calling `resource.id` would yield `1915026`. This will not match with the stored, fully qualified id leading to crashes and the database being essentially unusable.

**Expected behavior**
Synced resources should be update-able via `FhirEngine.update(resource)`

**Screenshots**
N/A

**Smartphone (please complete the following information):**
 - Device:  Pixel4a 
 - Android version: 11

**Additional context**
None.
",b346de862da7eac473d950786df21d4678a90dcf,570560bee28eef369009be866016499a1c7714db,https://github.com/google/android-fhir/compare/b346de862da7eac473d950786df21d4678a90dcf...570560bee28eef369009be866016499a1c7714db,"diff --git a/core/src/androidTest/java/com/google/android/fhir/db/impl/DatabaseImplTest.kt b/core/src/androidTest/java/com/google/android/fhir/db/impl/DatabaseImplTest.kt
index 2671118ee..c7ea7ff2d 100644
--- a/core/src/androidTest/java/com/google/android/fhir/db/impl/DatabaseImplTest.kt
+++ b/core/src/androidTest/java/com/google/android/fhir/db/impl/DatabaseImplTest.kt
@@ -21,6 +21,7 @@ import androidx.test.ext.junit.runners.AndroidJUnit4
 import com.google.android.fhir.FhirServices
 import com.google.android.fhir.db.ResourceNotFoundInDbException
 import com.google.android.fhir.db.impl.entities.LocalChangeEntity
+import com.google.android.fhir.logicalId
 import com.google.android.fhir.resource.TestingUtils
 import com.google.android.fhir.sync.FhirDataSource
 import com.google.common.truth.Truth.assertThat
@@ -158,9 +159,9 @@ class DatabaseImplTest {
     database.update(patient)
     val patientString = services.parser.encodeResourceToString(patient)
     val (_, resourceType, resourceId, _, type, payload) =
-      database.getAllLocalChanges().single { it.second.resourceId.equals(patient.id) }.second
+      database.getAllLocalChanges().single { it.second.resourceId.equals(patient.logicalId) }.second
     assertThat(type).isEqualTo(LocalChangeEntity.Type.INSERT)
-    assertThat(resourceId).isEqualTo(patient.id)
+    assertThat(resourceId).isEqualTo(patient.logicalId)
     assertThat(resourceType).isEqualTo(patient.resourceType.name)
     assertThat(payload).isEqualTo(patientString)
   }
@@ -196,9 +197,11 @@ class DatabaseImplTest {
     database.update(patient)
     services.parser.encodeResourceToString(patient)
     val (token, _) =
-      database.getAllLocalChanges().single { it.second.resourceId.equals(patient.id) }
+      database.getAllLocalChanges().single { it.second.resourceId.equals(patient.logicalId) }
     database.deleteUpdates(token)
-    assertThat(database.getAllLocalChanges().none { it.second.resourceId.equals(patient.id) })
+    assertThat(
+        database.getAllLocalChanges().none { it.second.resourceId.equals(patient.logicalId) }
+      )
       .isTrue()
   }
 
@@ -207,7 +210,9 @@ class DatabaseImplTest {
     val patient: Patient = testingUtils.readFromFile(Patient::class.java, ""/date_test_patient.json"")
     database.insertRemote(patient)
     assertThat(
-        database.getAllLocalChanges().map { it.second }.none { it.resourceId.equals(patient.id) }
+        database.getAllLocalChanges().map { it.second }.none {
+          it.resourceId.equals(patient.logicalId)
+        }
       )
       .isTrue()
   }
@@ -218,7 +223,7 @@ class DatabaseImplTest {
     database.insertAllRemote(listOf(patient, TEST_PATIENT_2))
     assertThat(
         database.getAllLocalChanges().map { it.second }.none {
-          it.resourceId in listOf(patient.id, TEST_PATIENT_2_ID)
+          it.resourceId in listOf(patient.logicalId, TEST_PATIENT_2_ID)
         }
       )
       .isTrue()
@@ -233,9 +238,9 @@ class DatabaseImplTest {
     val updatePatch = testingUtils.readJsonArrayFromFile(""/update_patch_1.json"")
     database.update(updatedPatient)
     val (_, resourceType, resourceId, _, type, payload) =
-      database.getAllLocalChanges().single { it.second.resourceId.equals(patient.id) }.second
+      database.getAllLocalChanges().single { it.second.resourceId.equals(patient.logicalId) }.second
     assertThat(type).isEqualTo(LocalChangeEntity.Type.UPDATE)
-    assertThat(resourceId).isEqualTo(patient.id)
+    assertThat(resourceId).isEqualTo(patient.logicalId)
     assertThat(resourceType).isEqualTo(patient.resourceType.name)
     testingUtils.assertJsonArrayEqualsIgnoringOrder(JSONArray(payload), updatePatch)
   }
@@ -250,9 +255,9 @@ class DatabaseImplTest {
     database.update(patient)
     val updatePatch = testingUtils.readJsonArrayFromFile(""/update_patch_2.json"")
     val (_, resourceType, resourceId, _, type, payload) =
-      database.getAllLocalChanges().single { it.second.resourceId.equals(patient.id) }.second
+      database.getAllLocalChanges().single { it.second.resourceId.equals(patient.logicalId) }.second
     assertThat(type).isEqualTo(LocalChangeEntity.Type.UPDATE)
-    assertThat(resourceId).isEqualTo(patient.id)
+    assertThat(resourceId).isEqualTo(patient.logicalId)
     assertThat(resourceType).isEqualTo(patient.resourceType.name)
     testingUtils.assertJsonArrayEqualsIgnoringOrder(JSONArray(payload), updatePatch)
   }
diff --git a/core/src/main/java/com/google/android/fhir/Util.kt b/core/src/main/java/com/google/android/fhir/Util.kt
index 1ee5c7bf2..495231428 100644
--- a/core/src/main/java/com/google/android/fhir/Util.kt
+++ b/core/src/main/java/com/google/android/fhir/Util.kt
@@ -21,6 +21,7 @@ import java.time.ZoneId
 import java.time.format.DateTimeFormatter
 import java.util.Date
 import java.util.Locale
+import org.hl7.fhir.r4.model.Resource
 
 /** Utility function to format a [Date] object using the system's default locale. */
 @SuppressLint(""NewApi"")
@@ -30,3 +31,10 @@ internal fun Date.toTimeZoneString(): String {
       .withZone(ZoneId.systemDefault())
   return simpleDateFormat.format(this.toInstant())
 }
+
+/**
+ * The logical (unqualified) part of the ID. For example, if the ID is
+ * ""http://example.com/fhir/Patient/123/_history/456"", then this value would be ""123"".
+ */
+internal val Resource.logicalId: String
+  get() = this.idElement.idPart
diff --git a/core/src/main/java/com/google/android/fhir/db/impl/DatabaseImpl.kt b/core/src/main/java/com/google/android/fhir/db/impl/DatabaseImpl.kt
index 6486e339c..2ed49e583 100644
--- a/core/src/main/java/com/google/android/fhir/db/impl/DatabaseImpl.kt
+++ b/core/src/main/java/com/google/android/fhir/db/impl/DatabaseImpl.kt
@@ -25,6 +25,7 @@ import com.google.android.fhir.db.impl.dao.LocalChangeToken
 import com.google.android.fhir.db.impl.dao.LocalChangeUtils
 import com.google.android.fhir.db.impl.entities.LocalChangeEntity
 import com.google.android.fhir.db.impl.entities.SyncedResourceEntity
+import com.google.android.fhir.logicalId
 import com.google.android.fhir.resource.getResourceType
 import com.google.android.fhir.search.impl.Query
 import org.hl7.fhir.r4.model.Resource
@@ -79,7 +80,7 @@ internal class DatabaseImpl(context: Context, private val iParser: IParser, data
 
   @Transaction
   override fun <R : Resource> update(resource: R) {
-    val oldResource = select(resource.javaClass, resource.id)
+    val oldResource = select(resource.javaClass, resource.logicalId)
     resourceDao.update(resource)
     localChangeDao.addUpdate(oldResource, resource)
   }
@@ -157,8 +158,8 @@ internal class DatabaseImpl(context: Context, private val iParser: IParser, data
     codeSystem: String,
     codeValue: String
   ): List<R> {
-    val refs = searchByReference(clazz, reference, referenceValue).map { it.id }
-    return searchByCode(clazz, code, codeSystem, codeValue).filter { refs.contains(it.id) }
+    val refs = searchByReference(clazz, reference, referenceValue).map { it.logicalId }
+    return searchByCode(clazz, code, codeSystem, codeValue).filter { refs.contains(it.logicalId) }
   }
 
   override fun <R : Resource> search(query: Query): List<R> =
diff --git a/core/src/main/java/com/google/android/fhir/db/impl/dao/LocalChangeDao.kt b/core/src/main/java/com/google/android/fhir/db/impl/dao/LocalChangeDao.kt
index fac940d6b..5c4c42956 100644
--- a/core/src/main/java/com/google/android/fhir/db/impl/dao/LocalChangeDao.kt
+++ b/core/src/main/java/com/google/android/fhir/db/impl/dao/LocalChangeDao.kt
@@ -24,6 +24,7 @@ import androidx.room.Transaction
 import ca.uhn.fhir.parser.IParser
 import com.google.android.fhir.db.impl.entities.LocalChangeEntity
 import com.google.android.fhir.db.impl.entities.LocalChangeEntity.Type
+import com.google.android.fhir.logicalId
 import com.google.android.fhir.toTimeZoneString
 import java.util.Date
 import org.hl7.fhir.r4.model.Resource
@@ -48,7 +49,7 @@ internal abstract class LocalChangeDao {
   }
 
   fun addInsert(resource: Resource) {
-    val resourceId = resource.id
+    val resourceId = resource.logicalId
     val resourceType = resource.resourceType
     val timestamp = Date().toTimeZoneString()
     val resourceString = iParser.encodeResourceToString(resource)
@@ -66,7 +67,7 @@ internal abstract class LocalChangeDao {
   }
 
   fun addUpdate(oldResource: Resource, resource: Resource) {
-    val resourceId = resource.id
+    val resourceId = resource.logicalId
     val resourceType = resource.resourceType
     val timestamp = Date().toTimeZoneString()
 
diff --git a/core/src/main/java/com/google/android/fhir/db/impl/dao/ResourceDao.kt b/core/src/main/java/com/google/android/fhir/db/impl/dao/ResourceDao.kt
index 68f55f53f..34aa78b86 100644
--- a/core/src/main/java/com/google/android/fhir/db/impl/dao/ResourceDao.kt
+++ b/core/src/main/java/com/google/android/fhir/db/impl/dao/ResourceDao.kt
@@ -34,6 +34,7 @@ import com.google.android.fhir.db.impl.entities.TokenIndexEntity
 import com.google.android.fhir.db.impl.entities.UriIndexEntity
 import com.google.android.fhir.index.ResourceIndexer
 import com.google.android.fhir.index.ResourceIndices
+import com.google.android.fhir.logicalId
 import org.hl7.fhir.r4.model.Resource
 import org.hl7.fhir.r4.model.ResourceType
 
@@ -45,12 +46,16 @@ internal abstract class ResourceDao {
 
   @Transaction
   open fun update(resource: Resource) {
-    updateResource(resource.id, resource.resourceType, iParser.encodeResourceToString(resource))
+    updateResource(
+      resource.logicalId,
+      resource.resourceType,
+      iParser.encodeResourceToString(resource)
+    )
     val entity =
       ResourceEntity(
         id = 0,
         resourceType = resource.resourceType,
-        resourceId = resource.id,
+        resourceId = resource.logicalId,
         serializedResource = iParser.encodeResourceToString(resource)
       )
     val index = ResourceIndexer.index(resource)
@@ -180,7 +185,7 @@ internal abstract class ResourceDao {
       ResourceEntity(
         id = 0,
         resourceType = resource.resourceType,
-        resourceId = resource.id,
+        resourceId = resource.logicalId,
         serializedResource = iParser.encodeResourceToString(resource)
       )
     insertResource(entity)
diff --git a/core/src/main/java/com/google/android/fhir/index/ResourceIndexer.kt b/core/src/main/java/com/google/android/fhir/index/ResourceIndexer.kt
index 964eb6168..085eb5c94 100644
--- a/core/src/main/java/com/google/android/fhir/index/ResourceIndexer.kt
+++ b/core/src/main/java/com/google/android/fhir/index/ResourceIndexer.kt
@@ -26,6 +26,7 @@ import com.google.android.fhir.index.entities.ReferenceIndex
 import com.google.android.fhir.index.entities.StringIndex
 import com.google.android.fhir.index.entities.TokenIndex
 import com.google.android.fhir.index.entities.UriIndex
+import com.google.android.fhir.logicalId
 import java.math.BigDecimal
 import org.hl7.fhir.r4.hapi.ctx.HapiWorkerContext
 import org.hl7.fhir.r4.model.Base
@@ -55,7 +56,7 @@ internal object ResourceIndexer {
   fun <R : Resource> index(resource: R) = extractIndexValues(resource)
 
   private fun <R : Resource> extractIndexValues(resource: R): ResourceIndices {
-    val indexBuilder = ResourceIndices.Builder(resource.resourceType, resource.id)
+    val indexBuilder = ResourceIndices.Builder(resource.resourceType, resource.logicalId)
     resource
       .javaClass
       .fields","['core/src/main/java/com/google/android/fhir/Util.kt', 'core/src/main/java/com/google/android/fhir/db/impl/dao/ResourceDao.kt', 'core/src/main/java/com/google/android/fhir/index/ResourceIndexer.kt', 'core/src/main/java/com/google/android/fhir/db/impl/dao/LocalChangeDao.kt', 'core/src/androidTest/java/com/google/android/fhir/db/impl/DatabaseImplTest.kt', 'core/src/main/java/com/google/android/fhir/db/impl/DatabaseImpl.kt']",{'.kt': 6},6,0,6,0,6,280340,58976,7689,122,1655,348,34,5,1344,174,308,38,1,1,2021-03-10 08:53:37,354,Kotlin,"{'Kotlin': 2727091, 'Shell': 5594}",Apache License 2.0,"['core/src/main/java/com/google/android/fhir/db/impl/dao/SyncedResourceDao.kt', 'core/src/main/java/com/google/android/fhir/db/impl/dao/LocalChangeToken.kt', 'core/src/main/java/com/google/android/fhir/db/impl/dao/ResourceDao.kt', 'core/src/main/java/com/google/android/fhir/db/impl/dao/LocalChangeDao.kt', 'core/src/main/java/com/google/android/fhir/impl/FhirEngineImpl.kt']","['core/src/main/java/com/google/android/fhir/db/impl/dao/SyncedResourceDao.kt', 'core/src/main/java/com/google/android/fhir/db/impl/dao/LocalChangeToken.kt', 'core/src/main/java/com/google/android/fhir/db/impl/dao/ResourceDao.kt', 'core/src/main/java/com/google/android/fhir/db/impl/dao/LocalChangeDao.kt', 'core/src/main/java/com/google/android/fhir/impl/FhirEngineImpl.kt']","['```json\n{\n  ""files"": [\n    ""core/src/main/java/com/google/android/fhir/impl/FhirEngineImpl.kt"",\n    ""core/src/main/java/com/google/android/fhir/db/impl/dao/ResourceDao.kt"",\n    ""core/src/main/java/com/google/android/fhir/db/impl/dao/SyncedResourceDao.kt"",\n    ""core/src/main/java/com/google/android/fhir/db/impl/dao/LocalChangeDao.kt"",\n    ""core/src/main/java/com/google/android/fhir/db/impl/dao/LocalChangeToken.kt""\n  ]\n}\n```']",1,1962.205171585083
2007,splendo/kaluga/469/468,splendo,kaluga,https://github.com/splendo/kaluga/issues/468,https://github.com/splendo/kaluga/pull/469,https://github.com/splendo/kaluga/pull/469,1,fixes,DateFormatter parsing Timezone inconsistently,"**Describe the bug**
There is a platform difference with the timezone parsed by a DateFormatter.
On Android, the DateFormatter parses into the timezone of the date string, regardless of the timezone set by the formatter. Moreover, the formatter will change its timezone into the parsed timezone.

On iOS, the timezone is entirely ignored and the date is parsed into the default timezone.

This inconsistency should be resolved. Since the Kaluga Date object contains the TimeZone as an integral component, the proposed solution is to parse into the timezone set by the formatter (as opposed by the parsed string). This is partially because iOS does not seem to support parsing the timezone of the string, and partially because it makes the most sense when Date is in a timezone.

**To Reproduce**
```
val utcFormatter = DateFormatter.patternFormat(""yyyy.MM.dd G 'at' HH:mm:ss z"", TimeZone.utc, Locale.enUsPosix)
val pstFormatter = DateFormatter.patternFormat(""yyyy.MM.dd G 'at' HH:mm:ss z"", PSTTimeZone, Locale.enUsPosix)

val epochInUtc = Date.epoch(timeZone = TimeZone.utc, locale = Locale.enUsPosix)
val epochInPst = Date.epoch(timeZone = PSTTimeZone, locale = Locale.enUsPosix)
assertEquals(""1970.01.01 AD at 00:00:00 ${TimeZone.utc.identifier}"", utcFormatter.format(epochInUtc))
assertEquals(""1970.01.01 AD at 00:00:00 ${TimeZone.utc.identifier}"", utcFormatter.format(epochInPst))
assertEquals(""1969.12.31 AD at 16:00:00 PST"", pstFormatter.format(epochInUtc))
assertEquals(""1969.12.31 AD at 16:00:00 PST"", pstFormatter.format(epochInPst))
assertEquals(epochInUtc, utcFormatter.parse(utcFormatter.format(epochInUtc)))
assertEquals(epochInUtc, utcFormatter.parse(pstFormatter.format(epochInPst)))
assertEquals(epochInPst, pstFormatter.parse(utcFormatter.format(epochInUtc)))
assertEquals(epochInPst, pstFormatter.parse(pstFormatter.format(epochInPst)))
```
This code fails

**Expected behavior**
Parse into the timezone of the parser

",f5f4c39a74fa0c53cac8056075ea927890b1e7bd,028ca367df93a6621e4742ff1a8aa96075611b75,https://github.com/splendo/kaluga/compare/f5f4c39a74fa0c53cac8056075ea927890b1e7bd...028ca367df93a6621e4742ff1a8aa96075611b75,"diff --git a/base/src/androidLibMain/kotlin/text/DateFormatter.kt b/base/src/androidLibMain/kotlin/text/DateFormatter.kt
index 6126e836d..d7f118c2e 100644
--- a/base/src/androidLibMain/kotlin/text/DateFormatter.kt
+++ b/base/src/androidLibMain/kotlin/text/DateFormatter.kt
@@ -124,13 +124,22 @@ actual class DateFormatter private constructor(private val format: SimpleDateFor
 
     actual fun format(date: Date): String = format.format(date.calendar.time)
     actual fun parse(string: String): Date? {
+        val currentTimeZone = timeZone
         return try {
             format.parse(string)?.let { date ->
                 val calendar = format.calendar.clone() as Calendar
-                Date(calendar.apply { time = date })
+                Date(
+                    calendar.apply {
+                        time = date
+                        timeZone = currentTimeZone.timeZone
+                    }
+                )
             }
         } catch (e: ParseException) {
             null
+        } finally {
+            // Parse may change the timezone to the timezone parsed by the String. This restores the original timezone
+            timeZone = currentTimeZone
         }
     }
 
diff --git a/base/src/commonTest/kotlin/text/DateFormatterTest.kt b/base/src/commonTest/kotlin/text/DateFormatterTest.kt
index 6881fbcc5..8aa801cca 100644
--- a/base/src/commonTest/kotlin/text/DateFormatterTest.kt
+++ b/base/src/commonTest/kotlin/text/DateFormatterTest.kt
@@ -22,8 +22,10 @@ import com.splendo.kaluga.base.text.DateFormatter
 import com.splendo.kaluga.base.text.dateFormat
 import com.splendo.kaluga.base.text.iso8601Pattern
 import com.splendo.kaluga.base.utils.Date
+import com.splendo.kaluga.base.utils.Locale
 import com.splendo.kaluga.base.utils.Locale.Companion.createLocale
 import com.splendo.kaluga.base.utils.TimeZone
+import com.splendo.kaluga.base.utils.enUsPosix
 import com.splendo.kaluga.base.utils.nowUtc
 import com.splendo.kaluga.base.utils.utc
 import kotlin.test.Test
@@ -64,6 +66,10 @@ class DateFormatterTest {
         assertEquals(2020, date.year)
         assertEquals(1, date.month)
         assertEquals(8, date.day)
+        assertEquals(0, date.hour)
+        assertEquals(0, date.minute)
+        assertEquals(0, date.second)
+        assertEquals(PSTTimeZone.identifier, date.timeZone.identifier)
     }
 
     @Test
@@ -104,4 +110,21 @@ class DateFormatterTest {
         val formatter = DateFormatter.iso8601Pattern(TimeZone.utc)
         assertNull(formatter.parse(""invalid date""))
     }
+
+    @Test
+    fun testParseDateWithDifferentTimezone() {
+        val utcFormatter = DateFormatter.patternFormat(""yyyy.MM.dd G 'at' HH:mm:ss z"", TimeZone.utc, Locale.enUsPosix)
+        val pstFormatter = DateFormatter.patternFormat(""yyyy.MM.dd G 'at' HH:mm:ss z"", PSTTimeZone, Locale.enUsPosix)
+
+        val epochInUtc = Date.epoch(timeZone = TimeZone.utc, locale = Locale.enUsPosix)
+        val epochInPst = Date.epoch(timeZone = PSTTimeZone, locale = Locale.enUsPosix)
+        assertEquals(""1970.01.01 AD at 00:00:00 ${TimeZone.utc.identifier}"", utcFormatter.format(epochInUtc))
+        assertEquals(""1970.01.01 AD at 00:00:00 ${TimeZone.utc.identifier}"", utcFormatter.format(epochInPst))
+        assertEquals(""1969.12.31 AD at 16:00:00 PST"", pstFormatter.format(epochInUtc))
+        assertEquals(""1969.12.31 AD at 16:00:00 PST"", pstFormatter.format(epochInPst))
+        assertEquals(epochInUtc, utcFormatter.parse(utcFormatter.format(epochInUtc)))
+        assertEquals(epochInUtc, utcFormatter.parse(pstFormatter.format(epochInPst)))
+        assertEquals(epochInPst, pstFormatter.parse(utcFormatter.format(epochInUtc)))
+        assertEquals(epochInPst, pstFormatter.parse(pstFormatter.format(epochInPst)))
+    }
 }
diff --git a/base/src/iosMain/kotlin/text/DateFormatter.kt b/base/src/iosMain/kotlin/text/DateFormatter.kt
index 60d4c3442..2501cafe2 100644
--- a/base/src/iosMain/kotlin/text/DateFormatter.kt
+++ b/base/src/iosMain/kotlin/text/DateFormatter.kt
@@ -21,6 +21,7 @@ import com.splendo.kaluga.base.typedList
 import com.splendo.kaluga.base.utils.Date
 import com.splendo.kaluga.base.utils.Locale
 import com.splendo.kaluga.base.utils.TimeZone
+import com.splendo.kaluga.base.utils.utc
 import platform.Foundation.NSCalendar
 import platform.Foundation.NSDateFormatter
 import platform.Foundation.NSDateFormatterFullStyle
@@ -56,6 +57,16 @@ actual class DateFormatter private constructor(private val format: NSDateFormatt
             NSDateFormatter().apply {
                 this.locale = locale.nsLocale
                 this.timeZone = timeZone.timeZone
+                this.defaultDate = Date.now(timeZone = timeZone).apply {
+                    val epoch = Date.epoch(timeZone = TimeZone.utc)
+                    this.era = epoch.era
+                    this.year = epoch.year
+                    this.month = epoch.month
+                    this.day = epoch.day
+                    this.hour = epoch.hour
+                    this.minute = epoch.minute
+                    this.second = epoch.second
+                }.date
                 dateFormat = pattern
             }
         )
@@ -69,6 +80,16 @@ actual class DateFormatter private constructor(private val format: NSDateFormatt
             NSDateFormatter().apply {
                 this.locale = locale.nsLocale
                 this.timeZone = timeZone.timeZone
+                this.defaultDate = Date.now(timeZone = timeZone).apply {
+                    val epoch = Date.epoch(timeZone = TimeZone.utc)
+                    this.era = epoch.era
+                    this.year = epoch.year
+                    this.month = epoch.month
+                    this.day = epoch.day
+                    this.hour = epoch.hour
+                    this.minute = epoch.minute
+                    this.second = epoch.second
+                }.date
                 this.dateStyle = dateStyle.nsDateFormatterStyle()
                 this.timeStyle = timeStyle.nsDateFormatterStyle()
             }
@@ -112,6 +133,7 @@ actual class DateFormatter private constructor(private val format: NSDateFormatt
     actual fun parse(string: String): Date? {
         return format.dateFromString(string)?.let { date ->
             val calendar = format.calendar.copy() as NSCalendar
+            calendar.timeZone = timeZone.timeZone
             Date(calendar, date)
         }
     }
diff --git a/base/src/jvmMain/kotlin/text/DateFormatter.kt b/base/src/jvmMain/kotlin/text/DateFormatter.kt
index 4b3ac8b56..53d0e9835 100644
--- a/base/src/jvmMain/kotlin/text/DateFormatter.kt
+++ b/base/src/jvmMain/kotlin/text/DateFormatter.kt
@@ -127,13 +127,22 @@ actual class DateFormatter private constructor(private val format: SimpleDateFor
 
     actual fun format(date: Date): String = format.format(date.calendar.time)
     actual fun parse(string: String): Date? {
+        val currentTimeZone = timeZone
         return try {
             format.parse(string)?.let { date ->
                 val calendar = format.calendar.clone() as Calendar
-                Date(calendar.apply { time = date })
+                Date(
+                    calendar.apply {
+                        time = date
+                        timeZone = currentTimeZone.timeZone
+                    }
+                )
             }
         } catch (e: ParseException) {
             null
+        } finally {
+            // Parse may change the timezone to the timezone parsed by the String. This restores the original timezone
+            timeZone = currentTimeZone
         }
     }
 ","['base/src/iosMain/kotlin/text/DateFormatter.kt', 'base/src/androidLibMain/kotlin/text/DateFormatter.kt', 'base/src/commonTest/kotlin/text/DateFormatterTest.kt', 'base/src/jvmMain/kotlin/text/DateFormatter.kt']",{'.kt': 4},4,0,4,0,4,3373921,757130,81475,1157,2004,325,44,3,1966,214,447,30,0,1,2022-02-12 00:09:56,205,Kotlin,"{'Kotlin': 6415349, 'Swift': 180252, 'HTML': 3133, 'Shell': 1514, 'CSS': 41}",Apache License 2.0,"['system/src/androidLibMain/kotlin/com.splendo.kaluga/system/network/NetworkManager.kt', 'base/src/iosMain/kotlin/text/DateFormatter.kt', 'system/src/commonMain/kotlin/com.splendo.kaluga/system/network/Network.kt', 'system/src/androidLibMain/kotlin/com.splendo.kaluga/system/network/NetworkManagerBuilder.kt', 'system/src/commonMain/kotlin/com.splendo.kaluga/system/network/BaseNetworkManager.kt', 'system/src/commonMain/kotlin/com.splendo.kaluga/system/network/NetworkState.kt', 'example/shared/src/androidLibMain/kotlin/com/splendo/kaluga/example/shared/platformspecific/compose/contacts/viewModel/ContactsListViewModel.kt', 'base/src/androidLibMain/kotlin/text/DateFormatter.kt']","['base/src/iosMain/kotlin/text/DateFormatter.kt', 'base/src/androidLibMain/kotlin/text/DateFormatter.kt']","['```json\n{\n  ""files"": [\n    ""base/src/androidLibMain/kotlin/text/DateFormatter.kt"",\n    ""base/src/iosMain/kotlin/text/DateFormatter.kt""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""system/src/androidLibMain/kotlin/com.splendo.kaluga/system/network/NetworkManager.kt"",\n    ""system/src/androidLibMain/kotlin/com.splendo.kaluga/system/network/NetworkManagerBuilder.kt"",\n    ""system/src/commonMain/kotlin/com.splendo.kaluga/system/network/BaseNetworkManager.kt"",\n    ""system/src/commonMain/kotlin/com.splendo.kaluga/system/network/Network.kt"",\n    ""system/src/commonMain/kotlin/com.splendo.kaluga/system/network/NetworkState.kt""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""example/shared/src/androidLibMain/kotlin/com/splendo/kaluga/example/shared/platformspecific/compose/contacts/viewModel/ContactsListViewModel.kt""\n  ]\n}\n```', '```json\n{\n  ""files"": [\n    ""base/src/iosMain/kotlin/text/DateFormatter.kt"",\n    ""base/src/androidLibMain/kotlin/text/DateFormatter.kt""\n  ]\n}\n```']",3,4772.489070892334
